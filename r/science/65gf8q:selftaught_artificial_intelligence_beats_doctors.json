[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "science", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": "confidence", "user_reports": [], "secure_media": null, "link_flair_text": "Computer Science", "id": "65gf8q", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 18744, "report_reasons": null, "author": "Aelinsaar", "saved": false, "mod_reports": [], "name": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "approved_by": null, "over_18": false, "domain": "sciencemag.org", "hidden": false, "preview": {"images": [{"source": {"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?s=6fa70b36c3c9013b069ea263f6ff9850", "width": 1280, "height": 720}, "resolutions": [{"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=108&amp;s=33f2b1445a37186a622c621ec3c8964b", "width": 108, "height": 60}, {"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=216&amp;s=50f420bbd0497ca06e3c1fb4f69f3cc6", "width": 216, "height": 121}, {"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=320&amp;s=c2c1867c7b774dd951c32b3f2d45d72a", "width": 320, "height": 180}, {"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=640&amp;s=dba9e6365b810d37efe740d356866de5", "width": 640, "height": 360}, {"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=960&amp;s=0d486f2bcbeb7f8f4f5b184a257e076a", "width": 960, "height": 540}, {"url": "https://i.redditmedia.com/Ssx2MwwXTaPFiU2zq0c-PPEQtup297n8vZy8Ay6WD_A.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=1080&amp;s=8dcf137e60349f74cc6875419e99cbb9", "width": 1080, "height": 607}], "variants": {}, "id": "TqBzRSb_6tOISy5dXDg4-vnc7--bshNPvmET8_1N8uM"}], "enabled": false}, "thumbnail": "https://a.thumbs.redditmedia.com/aii_pEM3OIA9UICtndn_1ZqvHXBJhAFdmGJNXw1FUY4.jpg", "subreddit_id": "t5_mouw", "edited": false, "link_flair_css_class": "compsci badpost", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "post_hint": "link", "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/science/comments/65gf8q/selftaught_artificial_intelligence_beats_doctors/", "num_reports": null, "locked": false, "stickied": false, "created": 1492246782.0, "url": "http://www.sciencemag.org/news/2017/04/self-taught-artificial-intelligence-beats-doctors-predicting-heart-attacks", "author_flair_text": null, "quarantine": false, "title": "Self-taught artificial intelligence beats doctors at predicting heart attacks", "created_utc": 1492217982.0, "distinguished": null, "media": null, "upvote_ratio": 0.9, "num_comments": 753, "visited": false, "subreddit_type": "public", "ups": 18744}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgad9wx", "gilded": 0, "archived": false, "score": 31, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga9770", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgad9wx", "score_hidden": false, "stickied": false, "created": 1492265417.0, "created_utc": 1492236617.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 31}}], "after": null, "before": null}}, "user_reports": [], "id": "dga9770", "gilded": 0, "archived": false, "score": 57, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga1zfn", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga9770", "score_hidden": false, "stickied": false, "created": 1492257702.0, "created_utc": 1492228902.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 57}}], "after": null, "before": null}}, "user_reports": [], "id": "dga1zfn", "gilded": 0, "archived": false, "score": 300, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga1yd4", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga1zfn", "score_hidden": false, "stickied": false, "created": 1492247098.0, "created_utc": 1492218298.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 300}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaive1", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgai86m", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaive1", "score_hidden": false, "stickied": false, "created": 1492281323.0, "created_utc": 1492252523.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgai86m", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgad0kg", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgai86m", "score_hidden": false, "stickied": false, "created": 1492279276.0, "created_utc": 1492250476.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 10}}], "after": null, "before": null}}, "user_reports": [], "id": "dgad0kg", "gilded": 0, "archived": false, "score": 23, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga1yd4", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgad0kg", "score_hidden": false, "stickied": false, "created": 1492264845.0, "created_utc": 1492236045.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 23}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgajqhs", "gilded": 0, "archived": false, "score": 22, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgaiwpz", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajqhs", "score_hidden": false, "stickied": false, "created": 1492283976.0, "created_utc": 1492255176.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 22}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaiwpz", "gilded": 0, "archived": false, "score": 43, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgahtp5", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaiwpz", "score_hidden": false, "stickied": false, "created": 1492281441.0, "created_utc": 1492252641.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 43}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgai5bc", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgahtp5", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgai5bc", "score_hidden": false, "stickied": false, "created": 1492279006.0, "created_utc": 1492250206.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgahtp5", "gilded": 0, "archived": false, "score": 17, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgag9z4", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahtp5", "score_hidden": false, "stickied": false, "created": 1492277960.0, "created_utc": 1492249160.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 17}}], "after": null, "before": null}}, "user_reports": [], "id": "dgag9z4", "gilded": 0, "archived": false, "score": 43, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga48bb", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgag9z4", "score_hidden": false, "stickied": false, "created": 1492273085.0, "created_utc": 1492244285.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 43}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgagveb", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgaere5", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgagveb", "score_hidden": false, "stickied": false, "created": 1492274920.0, "created_utc": 1492246120.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaere5", "gilded": 0, "archived": false, "score": 43, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga48bb", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaere5", "score_hidden": false, "stickied": false, "created": 1492268946.0, "created_utc": 1492240146.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 43}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgahv2g", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgaftcd", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahv2g", "score_hidden": false, "stickied": false, "created": 1492278083.0, "created_utc": 1492249283.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgah97t", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgaftcd", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgah97t", "score_hidden": false, "stickied": false, "created": 1492276146.0, "created_utc": 1492247346.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgahyth", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgaftcd", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahyth", "score_hidden": false, "stickied": false, "created": 1492278412.0, "created_utc": 1492249612.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaftcd", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgadryd", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "[removed]", "edited": 1492244051.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaftcd", "score_hidden": false, "stickied": false, "created": 1492271757.0, "created_utc": 1492242957.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dgadryd", "gilded": 0, "archived": false, "score": 21, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga48bb", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgadryd", "score_hidden": false, "stickied": false, "created": 1492266535.0, "created_utc": 1492237735.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 21}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgai00r", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga48bb", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgai00r", "score_hidden": false, "stickied": false, "created": 1492278520.0, "created_utc": 1492249720.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga48bb", "gilded": 0, "archived": false, "score": 81, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga2gra", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": 1492250875.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga48bb", "score_hidden": false, "stickied": false, "created": 1492250197.0, "created_utc": 1492221397.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 81}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgahkst", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga2gra", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahkst", "score_hidden": false, "stickied": false, "created": 1492277162.0, "created_utc": 1492248362.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga9c15", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga2gra", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": 1492236046.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga9c15", "score_hidden": false, "stickied": false, "created": 1492257917.0, "created_utc": 1492229117.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 8}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga2gra", "gilded": 0, "archived": false, "score": 78, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga1yd4", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga2gra", "score_hidden": false, "stickied": false, "created": 1492247767.0, "created_utc": 1492218967.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 78}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgahk4r", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dga1yd4", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahk4r", "score_hidden": false, "stickied": false, "created": 1492277102.0, "created_utc": 1492248302.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 8}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga1yd4", "gilded": 0, "archived": false, "score": 452, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga1yd4", "score_hidden": false, "stickied": false, "created": 1492247055.0, "created_utc": 1492218255.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 452}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgav9my", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "tvec", "parent_id": "t1_dgau3su", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Perhaps.  My hunch is that we'll have to legislate the use of AI in many areas, but absolutely in healthcare.  Suppose you have an AI machine that makes an error.  Who is responsible?  Can you ask the AI why it made a mistake?  You can't sue a program for making a mistake, so who is ultimately responsible?  How will we license and AI?  Currently, healthcare professionals have tightly regulated training and licensing.  If something goes wrong, you can sue that person.  How are we going to make sure that an AI is well trained?  Will the FDA regulate such programs?  Will the professional societies like the American Medical Society or state boards of pharmacy?  How do we ensure the proficiency of an AI across time?  Who gets to say how an AI can be used?  Is it up to the states?  Is it up to the federal government?  Can an individual opt out of having AI used for their care?  \n\nTons of questions.  It is thrilling to think about all of the potential applications, but we need this to be a slow process.  If there are big mistakes (i.e. people dying), there may be a huge pushback which will delay the use of these potential tools, which I think is hugely important to start using.  However, we must be smart and think about how to regulate these tools and how they will be implemented.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Perhaps.  My hunch is that we&amp;#39;ll have to legislate the use of AI in many areas, but absolutely in healthcare.  Suppose you have an AI machine that makes an error.  Who is responsible?  Can you ask the AI why it made a mistake?  You can&amp;#39;t sue a program for making a mistake, so who is ultimately responsible?  How will we license and AI?  Currently, healthcare professionals have tightly regulated training and licensing.  If something goes wrong, you can sue that person.  How are we going to make sure that an AI is well trained?  Will the FDA regulate such programs?  Will the professional societies like the American Medical Society or state boards of pharmacy?  How do we ensure the proficiency of an AI across time?  Who gets to say how an AI can be used?  Is it up to the states?  Is it up to the federal government?  Can an individual opt out of having AI used for their care?  &lt;/p&gt;\n\n&lt;p&gt;Tons of questions.  It is thrilling to think about all of the potential applications, but we need this to be a slow process.  If there are big mistakes (i.e. people dying), there may be a huge pushback which will delay the use of these potential tools, which I think is hugely important to start using.  However, we must be smart and think about how to regulate these tools and how they will be implemented.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgav9my", "score_hidden": false, "stickied": false, "created": 1492304144.0, "created_utc": 1492275344.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 7}}], "after": null, "before": null}}, "user_reports": [], "id": "dgau3su", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "AlanmanAaron", "parent_id": "t1_dgaq48v", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Not today anyway", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not today anyway&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgau3su", "score_hidden": false, "stickied": false, "created": 1492302502.0, "created_utc": 1492273702.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaq48v", "gilded": 0, "archived": false, "score": 26, "report_reasons": null, "author": "tvec", "parent_id": "t1_dgap140", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I agree. There has been a big push for evidence based medicine, which is really doing that which has the most evidence. This basically means following a treatment algorithm. A computer can memorize random tests and obscure diagnoses better than any person. As we develop better systems to help us make clinical decisions it will unburden us from having to manually scour electonic medical records for lab value trends and read Uptodate or Epocrates to narrow our differential diagnoses. This means that doctors will be able to spend more time conveying information to the patient. A computer will never be able to do that as well as a human. In seconds, I can often gauge the health literacy of a patient. A computer couldn't match that.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree. There has been a big push for evidence based medicine, which is really doing that which has the most evidence. This basically means following a treatment algorithm. A computer can memorize random tests and obscure diagnoses better than any person. As we develop better systems to help us make clinical decisions it will unburden us from having to manually scour electonic medical records for lab value trends and read Uptodate or Epocrates to narrow our differential diagnoses. This means that doctors will be able to spend more time conveying information to the patient. A computer will never be able to do that as well as a human. In seconds, I can often gauge the health literacy of a patient. A computer couldn&amp;#39;t match that.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaq48v", "score_hidden": false, "stickied": false, "created": 1492296849.0, "created_utc": 1492268049.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 26}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgap140", "gilded": 0, "archived": false, "score": 86, "report_reasons": null, "author": "hhdsfhg345435", "parent_id": "t1_dgallad", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "My wife is an internal medicine primary care doctor. Diagnosing disease and creating a treatment plan is often the easy part of her job. The hard part is convincing the patient that they should take the medicines and why the diagnosis matters, because humans have an insane amount of denial. \n\nMy wife: You have high blood pressure. We should probably get you started on some medications so you don't have a heart attack/stroke/kidney failure. \n\nPatient: Really? Because I feel fine, so I'm not sure that I really need medicine. Maybe I can start taking it when I start feeling sick. \n\nMy wife: That's not how this works....that's now how any of this works! \n\nThe human element is what machines will struggle to replace. The rest of my wife's job is pretty algorithmic already. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My wife is an internal medicine primary care doctor. Diagnosing disease and creating a treatment plan is often the easy part of her job. The hard part is convincing the patient that they should take the medicines and why the diagnosis matters, because humans have an insane amount of denial. &lt;/p&gt;\n\n&lt;p&gt;My wife: You have high blood pressure. We should probably get you started on some medications so you don&amp;#39;t have a heart attack/stroke/kidney failure. &lt;/p&gt;\n\n&lt;p&gt;Patient: Really? Because I feel fine, so I&amp;#39;m not sure that I really need medicine. Maybe I can start taking it when I start feeling sick. &lt;/p&gt;\n\n&lt;p&gt;My wife: That&amp;#39;s not how this works....that&amp;#39;s now how any of this works! &lt;/p&gt;\n\n&lt;p&gt;The human element is what machines will struggle to replace. The rest of my wife&amp;#39;s job is pretty algorithmic already. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgap140", "score_hidden": false, "stickied": false, "created": 1492295164.0, "created_utc": 1492266364.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 86}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgancbn", "gilded": 0, "archived": false, "score": 23, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgallad", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgancbn", "score_hidden": false, "stickied": false, "created": 1492292224.0, "created_utc": 1492263424.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 23}}], "after": null, "before": null}}, "user_reports": [], "id": "dgallad", "gilded": 0, "archived": false, "score": 28, "report_reasons": null, "author": "JuicyEmmental", "parent_id": "t1_dgakssm", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "You've got to remember that this is 90% of GPs work anyway. People go to the doctor for a wide range of issues outside of simple medical care.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;ve got to remember that this is 90% of GPs work anyway. People go to the doctor for a wide range of issues outside of simple medical care.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgallad", "score_hidden": false, "stickied": false, "created": 1492288671.0, "created_utc": 1492259871.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 28}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgav8jv", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "useeikick", "parent_id": "t1_dgakssm", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I mean, what happens when we have sentient AI then. Even if they're a machine they could still have emotions. \n\nAren't humans just AI's that were created by evolution?   ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I mean, what happens when we have sentient AI then. Even if they&amp;#39;re a machine they could still have emotions. &lt;/p&gt;\n\n&lt;p&gt;Aren&amp;#39;t humans just AI&amp;#39;s that were created by evolution?   &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgav8jv", "score_hidden": false, "stickied": false, "created": 1492304101.0, "created_utc": 1492275301.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgalqqb", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgakssm", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalqqb", "score_hidden": false, "stickied": false, "created": 1492289000.0, "created_utc": 1492260200.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgakssm", "gilded": 0, "archived": false, "score": 144, "report_reasons": null, "author": "TheTilde", "parent_id": "t1_dgakedp", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; compassionate\n\nIndeed, key word here.\n\n&gt;  The value comes in the form of human empathy not from proving you can interpret symptoms better then a machine.\n\nI hope that in the future we come to see your vision.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;compassionate&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Indeed, key word here.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The value comes in the form of human empathy not from proving you can interpret symptoms better then a machine.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I hope that in the future we come to see your vision.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakssm", "score_hidden": false, "stickied": false, "created": 1492286819.0, "created_utc": 1492258019.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 144}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgao20j", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "dgwingert", "parent_id": "t1_dgakedp", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The problem with this approach is that we still need intelligent data-gathering physicians to ask the right questions, at the right time. If you can build a robot that can do that and a rectal exam, maybe doctors will no longer make decisions.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem with this approach is that we still need intelligent data-gathering physicians to ask the right questions, at the right time. If you can build a robot that can do that and a rectal exam, maybe doctors will no longer make decisions.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgao20j", "score_hidden": false, "stickied": false, "created": 1492293526.0, "created_utc": 1492264726.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgakedp", "gilded": 0, "archived": false, "score": 192, "report_reasons": null, "author": "Darknavigator2233", "parent_id": "t1_dgak5lw", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "As AI gets better I say let it make those decisions.  Make being a doctor about implementing the care plan derived from the decisions of aa AI as compassionate and individually tailored as possible.  The value comes in the form of human empathy not from proving you can interpret symptoms better then a machine.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As AI gets better I say let it make those decisions.  Make being a doctor about implementing the care plan derived from the decisions of aa AI as compassionate and individually tailored as possible.  The value comes in the form of human empathy not from proving you can interpret symptoms better then a machine.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakedp", "score_hidden": false, "stickied": false, "created": 1492285802.0, "created_utc": 1492257002.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 192}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgame1c", "gilded": 0, "archived": false, "score": 16, "report_reasons": null, "author": "unscholarly_source", "parent_id": "t1_dgakqqu", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Not quite. Machine learning is not an end-game solution. It requires data, and training sets. It simply does processing faster than humans, but it doesn't have the capacity to research like a human being.\n\nIt's like an electric drill, it drills faster and more effectively than if we were to drill using a hand-powered drill, but it doesn't know what it's drilling.\n\nThis frees doctors to do research, to infer things to build relationship between pieces of data, which machine learning doesn't do (it requires training sets developed by humans).\n\nHere's an example of how it is intended to help with making decisions: https://youtu.be/tpKx7Oi0oeM\n\nThis is intended to make us better at our jobs, not to replace us. The better we are at our jobs, the more we will thrive as a society. ", "edited": 1492262152.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not quite. Machine learning is not an end-game solution. It requires data, and training sets. It simply does processing faster than humans, but it doesn&amp;#39;t have the capacity to research like a human being.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like an electric drill, it drills faster and more effectively than if we were to drill using a hand-powered drill, but it doesn&amp;#39;t know what it&amp;#39;s drilling.&lt;/p&gt;\n\n&lt;p&gt;This frees doctors to do research, to infer things to build relationship between pieces of data, which machine learning doesn&amp;#39;t do (it requires training sets developed by humans).&lt;/p&gt;\n\n&lt;p&gt;Here&amp;#39;s an example of how it is intended to help with making decisions: &lt;a href=\"https://youtu.be/tpKx7Oi0oeM\"&gt;https://youtu.be/tpKx7Oi0oeM&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;This is intended to make us better at our jobs, not to replace us. The better we are at our jobs, the more we will thrive as a society. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgame1c", "score_hidden": false, "stickied": false, "created": 1492290384.0, "created_utc": 1492261584.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 16}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgawl7m", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "offensivenamehere", "parent_id": "t1_dgakzvv", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Medical school training is different across the world but there are a few things you should know:\n\n1. Reputable medical schools already select and train people with empathy in mind. At my school 40% of your entrance score is based on interviews while previous grades are only 15% and MCAT is 10%. 15% is based on your previous work, volunteer, and extracurricular activities. The rest is based on your essay. \n\n2. You can't just have more people in medical school. In some countries the spots are regulated and subsidized by the government. In others they are set by the universities themselves. At my school there are ~1200 applicants for 109 spots each year. If they wanted to have more doctors they could already be doing it.   \n\n3. A high IQ will help you get good grades but we work on a pass or fail system. If you pass and are empathetic then you will beat out someone who passed with a higher grade and is not. Grades don't matter and are not shared. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Medical school training is different across the world but there are a few things you should know:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;&lt;p&gt;Reputable medical schools already select and train people with empathy in mind. At my school 40% of your entrance score is based on interviews while previous grades are only 15% and MCAT is 10%. 15% is based on your previous work, volunteer, and extracurricular activities. The rest is based on your essay. &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;You can&amp;#39;t just have more people in medical school. In some countries the spots are regulated and subsidized by the government. In others they are set by the universities themselves. At my school there are ~1200 applicants for 109 spots each year. If they wanted to have more doctors they could already be doing it.   &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;A high IQ will help you get good grades but we work on a pass or fail system. If you pass and are empathetic then you will beat out someone who passed with a higher grade and is not. Grades don&amp;#39;t matter and are not shared. &lt;/p&gt;&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgawl7m", "score_hidden": false, "stickied": false, "created": 1492305938.0, "created_utc": 1492277138.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgasbjd", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "lds7zf", "parent_id": "t1_dgaq914", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "That's pretty much what I predict from this AI in medicine game too. Pharma and hospitals will try to use this to employ less physicians, lower costs while maintaining profits, and concentrate their wealth even further. Lucky for them they already have a scapegoat to sell it to congress and the voters: the \"arrogant-quack-greedy\" doctors. \n\nIt's funny because among highly trained professionals, physicians are the only career that have seen their salaries decrease over time (couldn't even keep up with inflation). Eventually, one of two things will happen: people will stop trying to go to medicine because the Herculean effort is not worth the payout, which will lead to an even bigger physician shortage, or doctors will quit and find other jobs or go on strike. There has to be a balance for people to want to pursue such a malignant field, even when you include the altruistic aspect of helping people, and at a certain point people will be unwilling to make these sacrifices. Then we will get to see how well nurses/PA's/deep learning algorithms can take care of patients. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s pretty much what I predict from this AI in medicine game too. Pharma and hospitals will try to use this to employ less physicians, lower costs while maintaining profits, and concentrate their wealth even further. Lucky for them they already have a scapegoat to sell it to congress and the voters: the &amp;quot;arrogant-quack-greedy&amp;quot; doctors. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s funny because among highly trained professionals, physicians are the only career that have seen their salaries decrease over time (couldn&amp;#39;t even keep up with inflation). Eventually, one of two things will happen: people will stop trying to go to medicine because the Herculean effort is not worth the payout, which will lead to an even bigger physician shortage, or doctors will quit and find other jobs or go on strike. There has to be a balance for people to want to pursue such a malignant field, even when you include the altruistic aspect of helping people, and at a certain point people will be unwilling to make these sacrifices. Then we will get to see how well nurses/PA&amp;#39;s/deep learning algorithms can take care of patients. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgasbjd", "score_hidden": false, "stickied": false, "created": 1492300013.0, "created_utc": 1492271213.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaq914", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "asilentsound", "parent_id": "t1_dgap4zi", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Ironically, we already have ML systems which replaced a great many of the folks in finance. The downside is that it simply concentrates the wealth further at the top. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ironically, we already have ML systems which replaced a great many of the folks in finance. The downside is that it simply concentrates the wealth further at the top. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaq914", "score_hidden": false, "stickied": false, "created": 1492297051.0, "created_utc": 1492268251.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaut46", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "asilentsound", "parent_id": "t1_dgatr7c", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "It's one of many reasons why we need higher tax brackets. The ultra-wealthy don't contribute nearly as much to the economy as the extremely conservative often claim, simply because human consumption doesn't scale with wealth. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s one of many reasons why we need higher tax brackets. The ultra-wealthy don&amp;#39;t contribute nearly as much to the economy as the extremely conservative often claim, simply because human consumption doesn&amp;#39;t scale with wealth. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaut46", "score_hidden": false, "stickied": false, "created": 1492303506.0, "created_utc": 1492274706.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgatr7c", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "tequila13", "parent_id": "t1_dgap4zi", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; Why aren't we developing AI to replace investment bankers and chief executives at financial firms?\n\nWall Street trading is done by machines, humans were phased out years ago...\n\nBut like /u/asilentsound said, the net effect of these new technologies is that the money they make doesn't go back into the economy, because machines don't participate in the consumerist lifestyle like the humans they replace. The wage gap between the CEO and the average worker is at a record high, and it's set to grow even more with no end is sight.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Why aren&amp;#39;t we developing AI to replace investment bankers and chief executives at financial firms?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Wall Street trading is done by machines, humans were phased out years ago...&lt;/p&gt;\n\n&lt;p&gt;But like &lt;a href=\"/u/asilentsound\"&gt;/u/asilentsound&lt;/a&gt; said, the net effect of these new technologies is that the money they make doesn&amp;#39;t go back into the economy, because machines don&amp;#39;t participate in the consumerist lifestyle like the humans they replace. The wage gap between the CEO and the average worker is at a record high, and it&amp;#39;s set to grow even more with no end is sight.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgatr7c", "score_hidden": false, "stickied": false, "created": 1492302013.0, "created_utc": 1492273213.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgap4zi", "gilded": 0, "archived": false, "score": 18, "report_reasons": null, "author": "lds7zf", "parent_id": "t1_dgan31t", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "You think any of these companies are developing AI with the goal of making it cheap? Do some research on why the cost of healthcare is so expensive in the US. 10% of current healthcare costs come from physician (take home) salaries. Hospitals, insurance, and medical technology make up the rest, with new technology and medical treatments making up the bulk of new costs. \n\nIf you want proof, look at Gilead, who have been sitting on the best cure for Hep C for years now and no one is using it. Know why? It's a cure, not a chronic treatment, so they charge 10s of thousands of dollars to make sure they meet their bottom line. These competing companies want their AI to be what hospitals use so they can make money, and hospitals will use it as a tool to leverage how much they can pay physicians. Notice how no one in this equation is compelled to lower healthcare costs with this new innovation.\n\nIm always surprised when people come out against doctors so much, as if doing 4 years of med school with upwards of 200k in debt and 3-7 years of residency with a salary of 65-70k max while working 80 hour weeks doesn't entitle them to a salary that correlates with being a very highly trained professional. Why aren't we developing AI to replace investment bankers and chief executives at financial firms? Imagine how much money the American people would save if you didn't have corrupt and incompetent people doing illegal things with your money (and didn't have to bail them out when they crash the economy). End rant.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You think any of these companies are developing AI with the goal of making it cheap? Do some research on why the cost of healthcare is so expensive in the US. 10% of current healthcare costs come from physician (take home) salaries. Hospitals, insurance, and medical technology make up the rest, with new technology and medical treatments making up the bulk of new costs. &lt;/p&gt;\n\n&lt;p&gt;If you want proof, look at Gilead, who have been sitting on the best cure for Hep C for years now and no one is using it. Know why? It&amp;#39;s a cure, not a chronic treatment, so they charge 10s of thousands of dollars to make sure they meet their bottom line. These competing companies want their AI to be what hospitals use so they can make money, and hospitals will use it as a tool to leverage how much they can pay physicians. Notice how no one in this equation is compelled to lower healthcare costs with this new innovation.&lt;/p&gt;\n\n&lt;p&gt;Im always surprised when people come out against doctors so much, as if doing 4 years of med school with upwards of 200k in debt and 3-7 years of residency with a salary of 65-70k max while working 80 hour weeks doesn&amp;#39;t entitle them to a salary that correlates with being a very highly trained professional. Why aren&amp;#39;t we developing AI to replace investment bankers and chief executives at financial firms? Imagine how much money the American people would save if you didn&amp;#39;t have corrupt and incompetent people doing illegal things with your money (and didn&amp;#39;t have to bail them out when they crash the economy). End rant.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgap4zi", "score_hidden": false, "stickied": false, "created": 1492295336.0, "created_utc": 1492266536.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 18}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgan31t", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Cslewisster1980", "parent_id": "t1_dgakzvv", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "I think economics are gonna kick in here and that won't give a crap about a doctor with \"empathy\". It's just gonna be so much cheaper to use a machine than it will to employ a doctor and that will be the driving factor in replacing them. I don't see how doctors can continue to demand such high salaries on the future. ", "edited": 1492263286.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think economics are gonna kick in here and that won&amp;#39;t give a crap about a doctor with &amp;quot;empathy&amp;quot;. It&amp;#39;s just gonna be so much cheaper to use a machine than it will to employ a doctor and that will be the driving factor in replacing them. I don&amp;#39;t see how doctors can continue to demand such high salaries on the future. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgan31t", "score_hidden": false, "stickied": false, "created": 1492291750.0, "created_utc": 1492262950.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgakzvv", "gilded": 0, "archived": false, "score": 18, "report_reasons": null, "author": "Darknavigator2233", "parent_id": "t1_dgakqqu", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "They will try to stop it because it damages the current hierarchy.  If it only takes the equivalence of a nursing education to be a good doctor more people will do it. leading to more competition.\n\nMaybe the future belongs to the doctors who can show the most empathy not the ones with the highest IQ or most prestigious degrees.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They will try to stop it because it damages the current hierarchy.  If it only takes the equivalence of a nursing education to be a good doctor more people will do it. leading to more competition.&lt;/p&gt;\n\n&lt;p&gt;Maybe the future belongs to the doctors who can show the most empathy not the ones with the highest IQ or most prestigious degrees.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakzvv", "score_hidden": false, "stickied": false, "created": 1492287298.0, "created_utc": 1492258498.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 18}}], "after": null, "before": null}}, "user_reports": [], "id": "dgakqqu", "gilded": 0, "archived": false, "score": 28, "report_reasons": null, "author": "L43", "parent_id": "t1_dgakhcw", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Well, it's there to replace parts of their job. And the amount that it can replace will increase over time to the point that they will be glorified nurses. ML driven diagnostics and robot surgeons are coming, and I hope we don't try to stop it. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well, it&amp;#39;s there to replace parts of their job. And the amount that it can replace will increase over time to the point that they will be glorified nurses. ML driven diagnostics and robot surgeons are coming, and I hope we don&amp;#39;t try to stop it. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakqqu", "score_hidden": false, "stickied": false, "created": 1492286674.0, "created_utc": 1492257874.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 28}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgb1j2y", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "kenmacd", "parent_id": "t1_dgakhcw", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; Machine learning applications aren't there to replace people\n\nI'm not sure why you see that limitation. If the ML is better at making a decision than my doctor, I specifically do not want my doctor overridding that decision with their less accurate 'gut feeling'.\n\nI agree with /u/Flexerrr, I want the most accurate decision, not the 'human decision'.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Machine learning applications aren&amp;#39;t there to replace people&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m not sure why you see that limitation. If the ML is better at making a decision than my doctor, I specifically do not want my doctor overridding that decision with their less accurate &amp;#39;gut feeling&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;I agree with &lt;a href=\"/u/Flexerrr\"&gt;/u/Flexerrr&lt;/a&gt;, I want the most accurate decision, not the &amp;#39;human decision&amp;#39;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgb1j2y", "score_hidden": false, "stickied": false, "created": 1492312636.0, "created_utc": 1492283836.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgakhcw", "gilded": 0, "archived": false, "score": 26, "report_reasons": null, "author": "unscholarly_source", "parent_id": "t1_dgak5lw", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Man that's the golden ticket right there... Machine learning applications aren't there to replace people, they should be leveraged as to help SMEs focus on what's important, rather than waste time processing documents and data manually...\n\nI think that's the main thing preventing Watson Health from being more widely adopted...\n\nDoctors who are reading this, Watson Health and other machine learning resources are there to help you, not replace you. You can still review its evaluations.", "edited": 1492262370.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Man that&amp;#39;s the golden ticket right there... Machine learning applications aren&amp;#39;t there to replace people, they should be leveraged as to help SMEs focus on what&amp;#39;s important, rather than waste time processing documents and data manually...&lt;/p&gt;\n\n&lt;p&gt;I think that&amp;#39;s the main thing preventing Watson Health from being more widely adopted...&lt;/p&gt;\n\n&lt;p&gt;Doctors who are reading this, Watson Health and other machine learning resources are there to help you, not replace you. You can still review its evaluations.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakhcw", "score_hidden": false, "stickied": false, "created": 1492286014.0, "created_utc": 1492257214.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 26}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgawowr", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "FrequentScoobers", "parent_id": "t1_dgak5lw", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Why not have it make decisions for them, if it's better at making decisions?\n\nI wouldn't want a physician making a decision on my behalf because they happen to be feeling optimistic or pessimistic that day. It must happen to some degree - I haven't looked at so much as an abstract, but intrarater reliability in human decision-making surely isn't 100%.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why not have it make decisions for them, if it&amp;#39;s better at making decisions?&lt;/p&gt;\n\n&lt;p&gt;I wouldn&amp;#39;t want a physician making a decision on my behalf because they happen to be feeling optimistic or pessimistic that day. It must happen to some degree - I haven&amp;#39;t looked at so much as an abstract, but intrarater reliability in human decision-making surely isn&amp;#39;t 100%.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgawowr", "score_hidden": false, "stickied": false, "created": 1492306079.0, "created_utc": 1492277279.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgak5lw", "gilded": 0, "archived": false, "score": 219, "report_reasons": null, "author": "Crypt0Nihilist", "parent_id": "t1_dgaib3i", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I have to keep telling people I work with, \"This system is to help you make decisions, not to make the decisions for you.\" One would hope that Dr Black Box could add some value over the machine learning black box.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have to keep telling people I work with, &amp;quot;This system is to help you make decisions, not to make the decisions for you.&amp;quot; One would hope that Dr Black Box could add some value over the machine learning black box.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak5lw", "score_hidden": false, "stickied": false, "created": 1492285148.0, "created_utc": 1492256348.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 219}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaux3u", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "sad_over_stella_glow", "parent_id": "t1_dgaunm0", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "We know too little about brains in general. If we had some way of figuring how brains carry out computations, even animal brains, I think we could crack it. But mostly we have very fuzzy, statistical ways to study brains, fMRI doesn't cut it for exploring how they work in-depth, and we don't know how to observe a brains activity in a more fundamental level. We barely understand individual neurons. Current artificial neural networks aren't really similar to how actual brains operate, despite their name, most of their development has come from mathematics and statistics, not neuroscience.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We know too little about brains in general. If we had some way of figuring how brains carry out computations, even animal brains, I think we could crack it. But mostly we have very fuzzy, statistical ways to study brains, fMRI doesn&amp;#39;t cut it for exploring how they work in-depth, and we don&amp;#39;t know how to observe a brains activity in a more fundamental level. We barely understand individual neurons. Current artificial neural networks aren&amp;#39;t really similar to how actual brains operate, despite their name, most of their development has come from mathematics and statistics, not neuroscience.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaux3u", "score_hidden": false, "stickied": false, "created": 1492303661.0, "created_utc": 1492274861.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaunm0", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "smc733", "parent_id": "t1_dgapic2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I agree, we know far too little about the human brain for AGI to be \"around the corner\".", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree, we know far too little about the human brain for AGI to be &amp;quot;around the corner&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaunm0", "score_hidden": false, "stickied": false, "created": 1492303288.0, "created_utc": 1492274488.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgapic2", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "sad_over_stella_glow", "parent_id": "t1_dgajew2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I don't think we'll be able to simulate brains and have AGI anytime soon, I wish.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think we&amp;#39;ll be able to simulate brains and have AGI anytime soon, I wish.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgapic2", "score_hidden": false, "stickied": false, "created": 1492295926.0, "created_utc": 1492267126.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgav89m", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "UncleMeat11", "parent_id": "t1_dgamju6", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "For a neural network this will just be a huge list of arithmetic operations on raw data and another huge list of activation functions. This can't be meaningfully interpreted by humans.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For a neural network this will just be a huge list of arithmetic operations on raw data and another huge list of activation functions. This can&amp;#39;t be meaningfully interpreted by humans.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgav89m", "score_hidden": false, "stickied": false, "created": 1492304090.0, "created_utc": 1492275290.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgbba9p", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "agenthex", "parent_id": "t1_dgamju6", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "No we can't. An ANN can have multiple layers of nodes and multiple nodes per layer. There is no simple decision tree for these constructs. It is not simple, but it is possible to deconstruct. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No we can&amp;#39;t. An ANN can have multiple layers of nodes and multiple nodes per layer. There is no simple decision tree for these constructs. It is not simple, but it is possible to deconstruct. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgbba9p", "score_hidden": false, "stickied": false, "created": 1492326189.0, "created_utc": 1492297389.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgamju6", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "undercover_redditor", "parent_id": "t1_dgajew2", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "Yet we can absolutely tell an AI to list every factor in a decision. Why is this even a concern? Just program the computer to list the details leading to each diagnosis.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yet we can absolutely tell an AI to list every factor in a decision. Why is this even a concern? Just program the computer to list the details leading to each diagnosis.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgamju6", "score_hidden": false, "stickied": false, "created": 1492290710.0, "created_utc": 1492261910.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgajew2", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "agenthex", "parent_id": "t1_dgaib3i", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "For the most part, that's true.\n\nWe do have the ability to dissect physical brains, and we have the ability to view the nodes in an artificial neural network.  Whether or not we can consciously understand the mechanism for why something works is another thing entirely.  We can't exactly map a dead brain down to the molecular level, and we can't yet simulate an ANN that has the complexity of a human brain.  Soon enough, this will not be true and these kinds of A.I. will be running around, co-mingled with cybernetic organisms, but until then you are right.  It's still a black box.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For the most part, that&amp;#39;s true.&lt;/p&gt;\n\n&lt;p&gt;We do have the ability to dissect physical brains, and we have the ability to view the nodes in an artificial neural network.  Whether or not we can consciously understand the mechanism for why something works is another thing entirely.  We can&amp;#39;t exactly map a dead brain down to the molecular level, and we can&amp;#39;t yet simulate an ANN that has the complexity of a human brain.  Soon enough, this will not be true and these kinds of A.I. will be running around, co-mingled with cybernetic organisms, but until then you are right.  It&amp;#39;s still a black box.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajew2", "score_hidden": false, "stickied": false, "created": 1492283018.0, "created_utc": 1492254218.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaib3i", "gilded": 0, "archived": false, "score": 542, "report_reasons": null, "author": "Darknavigator2233", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Can you really tell what went on in the human black box.  The doctor can try and articulate to you what factors went into her decision but we humans have very little insight to our own cognitive bias.  It is effectively swapping one black box for another more accurate black box.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you really tell what went on in the human black box.  The doctor can try and articulate to you what factors went into her decision but we humans have very little insight to our own cognitive bias.  It is effectively swapping one black box for another more accurate black box.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaib3i", "score_hidden": false, "stickied": false, "created": 1492279539.0, "created_utc": 1492250739.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 542}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgajuyc", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "visarga", "parent_id": "t1_dgaiiza", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "You usually use ensembles of trees and that muddles the interpretability.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You usually use ensembles of trees and that muddles the interpretability.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajuyc", "score_hidden": false, "stickied": false, "created": 1492284340.0, "created_utc": 1492255540.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgajee4", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "themoosemind", "parent_id": "t1_dgaj526", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "My point is that deep decision trees are similar as (un)interpretable as deep neural nets. Given a task of reasonable complexity where non-machine learning approaches fail*, both will produce models which can have adversarial examples which a human will not directly see from just looking at the model. (By \"adverserial example\" I mean examples where the model makes a decision which a human would clearly not have made, e.g. see [Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images](https://arxiv.org/abs/1412.1897) for neural networks)\n\nThe \"where non-machine learning approaches fail\" is important. I'm relatively sure for the Titanic survival case you can just hand-engineer a decision tree and get results which are ok.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My point is that deep decision trees are similar as (un)interpretable as deep neural nets. Given a task of reasonable complexity where non-machine learning approaches fail*, both will produce models which can have adversarial examples which a human will not directly see from just looking at the model. (By &amp;quot;adverserial example&amp;quot; I mean examples where the model makes a decision which a human would clearly not have made, e.g. see &lt;a href=\"https://arxiv.org/abs/1412.1897\"&gt;Deep Neural Networks are Easily Fooled: High Confidence Predictions for Unrecognizable Images&lt;/a&gt; for neural networks)&lt;/p&gt;\n\n&lt;p&gt;The &amp;quot;where non-machine learning approaches fail&amp;quot; is important. I&amp;#39;m relatively sure for the Titanic survival case you can just hand-engineer a decision tree and get results which are ok.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajee4", "score_hidden": false, "stickied": false, "created": 1492282975.0, "created_utc": 1492254175.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 11}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaj526", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgaiw8x", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I agree with that of course. However, I don't really see how this is arguing your point, which is that deep decision trees aren't interpretable, right?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree with that of course. However, I don&amp;#39;t really see how this is arguing your point, which is that deep decision trees aren&amp;#39;t interpretable, right?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaj526", "score_hidden": false, "stickied": false, "created": 1492282169.0, "created_utc": 1492253369.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaiw8x", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "themoosemind", "parent_id": "t1_dgaiow1", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Similarly one can just train a MLP without a feature to see its importance (there are more sophisticated techniques).\n\nIf you claim that you know what a ML model is doing you can't just reduce it to a much simpler model. At least you would have to give the performance of that much simpler model.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Similarly one can just train a MLP without a feature to see its importance (there are more sophisticated techniques).&lt;/p&gt;\n\n&lt;p&gt;If you claim that you know what a ML model is doing you can&amp;#39;t just reduce it to a much simpler model. At least you would have to give the performance of that much simpler model.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaiw8x", "score_hidden": false, "stickied": false, "created": 1492281399.0, "created_utc": 1492252599.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaroay", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "mobugs", "parent_id": "t1_dgaiow1", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Trees alone tend to be pretty shit ML models that's why people forgot about them for a long time, now try to interpret boosted trees yeah? \n\nOn a real world complex problem the first tree ain't gonna help you at all, what you're saying is to use difference of averages to gain the insight needed, you don't need ML to do that. There is also is the so called 'variable importance' it doesn't help you interpret the model either it just tells you what variables are helpful, doesn't tell you how\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Trees alone tend to be pretty shit ML models that&amp;#39;s why people forgot about them for a long time, now try to interpret boosted trees yeah? &lt;/p&gt;\n\n&lt;p&gt;On a real world complex problem the first tree ain&amp;#39;t gonna help you at all, what you&amp;#39;re saying is to use difference of averages to gain the insight needed, you don&amp;#39;t need ML to do that. There is also is the so called &amp;#39;variable importance&amp;#39; it doesn&amp;#39;t help you interpret the model either it just tells you what variables are helpful, doesn&amp;#39;t tell you how&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaroay", "score_hidden": false, "stickied": false, "created": 1492299105.0, "created_utc": 1492270305.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaiow1", "gilded": 0, "archived": false, "score": 14, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgaiiza", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Even if a tree has many levels and many features, the first few splits are the ones that it decided were the most important (for optimizing entropy (usually), if you use best split instead of random split). Because of that, I can peak at the first few layers and get a good sense of what the model is considering. For example, looking at chance of survival in the Titanic, an important feature might be gender because women and children were given priority.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Even if a tree has many levels and many features, the first few splits are the ones that it decided were the most important (for optimizing entropy (usually), if you use best split instead of random split). Because of that, I can peak at the first few layers and get a good sense of what the model is considering. For example, looking at chance of survival in the Titanic, an important feature might be gender because women and children were given priority.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaiow1", "score_hidden": false, "stickied": false, "created": 1492280756.0, "created_utc": 1492251956.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 14}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaiiza", "gilded": 0, "archived": false, "score": 47, "report_reasons": null, "author": "themoosemind", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; Well that depends what algorithm you use. If you use a decision tree, then you can very easily see and interpret what happens in between.\n\nI don't think so. How much do you see in a decision tree of more than 7 levels? I doubt that this is more interpretable than a 2-layer MLP.\n\nSee also: [The Mythos of Model Interpretability](https://arxiv.org/abs/1606.03490)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Well that depends what algorithm you use. If you use a decision tree, then you can very easily see and interpret what happens in between.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t think so. How much do you see in a decision tree of more than 7 levels? I doubt that this is more interpretable than a 2-layer MLP.&lt;/p&gt;\n\n&lt;p&gt;See also: &lt;a href=\"https://arxiv.org/abs/1606.03490\"&gt;The Mythos of Model Interpretability&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaiiza", "score_hidden": false, "stickied": false, "created": 1492280236.0, "created_utc": 1492251436.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 47}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgat8fs", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "Smallpaul", "parent_id": "t1_dganyc1", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I understand. I'm referring back to the top post: \"The fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios.\"\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I understand. I&amp;#39;m referring back to the top post: &amp;quot;The fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgat8fs", "score_hidden": false, "stickied": false, "created": 1492301285.0, "created_utc": 1492272485.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dganyc1", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Max_Thunder", "parent_id": "t1_dgamr2q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I'm simplifying but machine learning works this way: you make the model based on a certain dataset then you test it on a different dataset. Let's say your data are from two different American hospitals. The second dataset contained new scenarios, but if you tested the algorithms with data from Pyongyang, your results may vary. That's what is meant by very different.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m simplifying but machine learning works this way: you make the model based on a certain dataset then you test it on a different dataset. Let&amp;#39;s say your data are from two different American hospitals. The second dataset contained new scenarios, but if you tested the algorithms with data from Pyongyang, your results may vary. That&amp;#39;s what is meant by very different.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dganyc1", "score_hidden": false, "stickied": false, "created": 1492293342.0, "created_utc": 1492264542.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgamr2q", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Smallpaul", "parent_id": "t1_dgafucj", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "\"Unless future data is very different\" -&gt; sounds like \"new scenarios\" to me.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Unless future data is very different&amp;quot; -&amp;gt; sounds like &amp;quot;new scenarios&amp;quot; to me.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgamr2q", "score_hidden": false, "stickied": false, "created": 1492291118.0, "created_utc": 1492262318.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgafucj", "gilded": 0, "archived": false, "score": 36, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgafeny", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I wasn't arguing that validation doesn't guarantee good results on new data. On the contrary, I was arguing that the author didn't understand that validation IS a good way to see how well your model generalizes. Validation should be a very strong indication of future results on new data unless the future data is extremely different (e.g. [the tank story](http://lesswrong.com/lw/7qz/machine_learning_and_unintended_consequences/)).  There's a good discussion about this, including some research, [here](https://stats.stackexchange.com/questions/29354/can-you-overfit-by-training-machine-learning-algorithms-using-cv-bootstrap).", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wasn&amp;#39;t arguing that validation doesn&amp;#39;t guarantee good results on new data. On the contrary, I was arguing that the author didn&amp;#39;t understand that validation IS a good way to see how well your model generalizes. Validation should be a very strong indication of future results on new data unless the future data is extremely different (e.g. &lt;a href=\"http://lesswrong.com/lw/7qz/machine_learning_and_unintended_consequences/\"&gt;the tank story&lt;/a&gt;).  There&amp;#39;s a good discussion about this, including some research, &lt;a href=\"https://stats.stackexchange.com/questions/29354/can-you-overfit-by-training-machine-learning-algorithms-using-cv-bootstrap\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgafucj", "score_hidden": false, "stickied": false, "created": 1492271834.0, "created_utc": 1492243034.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 36}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgafeny", "gilded": 0, "archived": false, "score": 73, "report_reasons": null, "author": "strygeren", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Yeah this whole article is poorly written from a CS standpoint. Validation does NOT guarantee good results on new data, it's an estimate of the generalization error not an analytical derivation", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah this whole article is poorly written from a CS standpoint. Validation does NOT guarantee good results on new data, it&amp;#39;s an estimate of the generalization error not an analytical derivation&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgafeny", "score_hidden": false, "stickied": false, "created": 1492270643.0, "created_utc": 1492241843.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 73}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgajla2", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "computeraddict", "parent_id": "t1_dgah4xc", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "In this case, if you understood the decision making process you might be able to extrapolate new risk factors that manual research previously overlooked. And if you have new correlations, you can get more insight into the causes of disease.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In this case, if you understood the decision making process you might be able to extrapolate new risk factors that manual research previously overlooked. And if you have new correlations, you can get more insight into the causes of disease.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajla2", "score_hidden": false, "stickied": false, "created": 1492283553.0, "created_utc": 1492254753.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 11}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgah4xc", "gilded": 0, "archived": false, "score": 35, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgah388", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "True, which is why it's good that interpretability is rarely of interest.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;True, which is why it&amp;#39;s good that interpretability is rarely of interest.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgah4xc", "score_hidden": false, "stickied": false, "created": 1492275763.0, "created_utc": 1492246963.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 35}}], "after": null, "before": null}}, "user_reports": [], "id": "dgah388", "gilded": 0, "archived": false, "score": 34, "report_reasons": null, "author": "falconberger", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Decision trees often perform worse than the harder to interpret models though.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Decision trees often perform worse than the harder to interpret models though.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgah388", "score_hidden": false, "stickied": false, "created": 1492275613.0, "created_utc": 1492246813.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 34}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaju44", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "gusgusgusgusgus", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The point they are trying to make is that they can't use this to make reccomendations about what the warned patients should change. \n\nIf they identify strong predictors, it doesn't mean they are causal. They could just be indicators of some unobserved factor. \n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The point they are trying to make is that they can&amp;#39;t use this to make reccomendations about what the warned patients should change. &lt;/p&gt;\n\n&lt;p&gt;If they identify strong predictors, it doesn&amp;#39;t mean they are causal. They could just be indicators of some unobserved factor. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaju44", "score_hidden": false, "stickied": false, "created": 1492284270.0, "created_utc": 1492255470.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgavoky", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "vincentrevelations", "parent_id": "t1_dgajsw0", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Not in general, and the models that can aren't necessarily the best. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not in general, and the models that can aren&amp;#39;t necessarily the best. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgavoky", "score_hidden": false, "stickied": false, "created": 1492304712.0, "created_utc": 1492275912.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgajsw0", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "visarga", "parent_id": "t1_dgahm3q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Neural nets can indicate which parts of an image contributed most to the decision. Same can be done on text.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Neural nets can indicate which parts of an image contributed most to the decision. Same can be done on text.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajsw0", "score_hidden": false, "stickied": false, "created": 1492284173.0, "created_utc": 1492255373.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dgahm3q", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "BullockHouse", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Generally, the most powerful machine learning algorithms for dealing with unstructured data are pretty opaque, though. Although fixing that is an active area of research, and there is progress being made. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Generally, the most powerful machine learning algorithms for dealing with unstructured data are pretty opaque, though. Although fixing that is an active area of research, and there is progress being made. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahm3q", "score_hidden": false, "stickied": false, "created": 1492277274.0, "created_utc": 1492248474.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 11}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgalco6", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "henker92", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; he fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios. \n\nI beg to disagree here in the general sense. Learning on 80% of the data set and predicting correctly the 20% remaining does not mean it performs well in **NEW** scenarii. If the 80% sample is representative enough of the whole population, the 20 remaining percent are within this population and you did not encounter new scenariis, just some that are similar to what you already know.\n\nWhat people call AI aren't anything more than interpolation schemes. If you have a rich enough model and if you are fitting a rich enough database, you probably will be able to interpolate very well and be able to predict new data. If you are far enough of your learning database, though, you rely on your model being close enough to the underlying phenomenon to be able to extrapolate. \n\nI want to emphasize that when you cross-validate, you are not touching the extrapolation problem at all. In fact, it's kind of the opposite because good cross validation will randomly sample your full data, train on a subset and test on another subset. Therefore sampling the whole population in order to try to include all of it into the training/testing phases.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;he fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I beg to disagree here in the general sense. Learning on 80% of the data set and predicting correctly the 20% remaining does not mean it performs well in &lt;strong&gt;NEW&lt;/strong&gt; scenarii. If the 80% sample is representative enough of the whole population, the 20 remaining percent are within this population and you did not encounter new scenariis, just some that are similar to what you already know.&lt;/p&gt;\n\n&lt;p&gt;What people call AI aren&amp;#39;t anything more than interpolation schemes. If you have a rich enough model and if you are fitting a rich enough database, you probably will be able to interpolate very well and be able to predict new data. If you are far enough of your learning database, though, you rely on your model being close enough to the underlying phenomenon to be able to extrapolate. &lt;/p&gt;\n\n&lt;p&gt;I want to emphasize that when you cross-validate, you are not touching the extrapolation problem at all. In fact, it&amp;#39;s kind of the opposite because good cross validation will randomly sample your full data, train on a subset and test on another subset. Therefore sampling the whole population in order to try to include all of it into the training/testing phases.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalco6", "score_hidden": false, "stickied": false, "created": 1492288148.0, "created_utc": 1492259348.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaih1k", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgahq5g", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I don't think it's misleading at all. Training decision trees involves a bit of math without a great English translation (usually optimizing entropy at each split), but interpreting a trained decision tree is easy. Same goes a linear regression model. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think it&amp;#39;s misleading at all. Training decision trees involves a bit of math without a great English translation (usually optimizing entropy at each split), but interpreting a trained decision tree is easy. Same goes a linear regression model. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaih1k", "score_hidden": false, "stickied": false, "created": 1492280072.0, "created_utc": 1492251272.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaioiw", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "mikbob", "parent_id": "t1_dgahq5g", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Partial dependence plots can really help here", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Partial dependence plots can really help here&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaioiw", "score_hidden": false, "stickied": false, "created": 1492280724.0, "created_utc": 1492251924.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgahq5g", "gilded": 0, "archived": false, "score": 14, "report_reasons": null, "author": "Deezl-Vegas", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; Well that depends what algorithm you use.\n\nThis is somewhat misleading. Machine learning is the process of generating an algorithm. People can know the algorithm, but it generally turns out to be a really oddly constructed math problem with no English translation.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Well that depends what algorithm you use.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is somewhat misleading. Machine learning is the process of generating an algorithm. People can know the algorithm, but it generally turns out to be a really oddly constructed math problem with no English translation.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahq5g", "score_hidden": false, "stickied": false, "created": 1492277637.0, "created_utc": 1492248837.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 14}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgak4z4", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "CODESIGN2", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Whilst I agree that the idea of humans \"tweaking data\" goes against the notion of \"automation\", sometimes it is an easier short-term win to have current experts modify to stop future patterns forming that need work.\n\nAlso read-only access and non-destructive editing are not mutually exclusive to the goals of the program. In any case edits of the data and the original data would both need to be preserved so that sensors or pre-processing of inputs could be improved.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Whilst I agree that the idea of humans &amp;quot;tweaking data&amp;quot; goes against the notion of &amp;quot;automation&amp;quot;, sometimes it is an easier short-term win to have current experts modify to stop future patterns forming that need work.&lt;/p&gt;\n\n&lt;p&gt;Also read-only access and non-destructive editing are not mutually exclusive to the goals of the program. In any case edits of the data and the original data would both need to be preserved so that sensors or pre-processing of inputs could be improved.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak4z4", "score_hidden": false, "stickied": false, "created": 1492285099.0, "created_utc": 1492256299.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgakmk8", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "arkticpanda", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt;  If you use a decision tree, then you can very easily see and interpret what happens in between.\n\nYes you can vaguely see what's going on in a decision tree, but that is only one of many techniques available. Its far more likely that they've used some other less transparent machine learning technique to achieve this (e.g. neural networks, or KNN). \n\n&gt; The fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios. That's the whole idea behind validation/cross-validation.\n\nCross-validation is only effective to a point. All it's data still comes from the same source, improving an ML model's ability to genereralise is one of the biggest challenges to ML today. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;If you use a decision tree, then you can very easily see and interpret what happens in between.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes you can vaguely see what&amp;#39;s going on in a decision tree, but that is only one of many techniques available. Its far more likely that they&amp;#39;ve used some other less transparent machine learning technique to achieve this (e.g. neural networks, or KNN). &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios. That&amp;#39;s the whole idea behind validation/cross-validation.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Cross-validation is only effective to a point. All it&amp;#39;s data still comes from the same source, improving an ML model&amp;#39;s ability to genereralise is one of the biggest challenges to ML today. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakmk8", "score_hidden": false, "stickied": false, "created": 1492286382.0, "created_utc": 1492257582.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgak7m4", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "Darknavigator2233", "parent_id": "t1_dgajo8y", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "People will come around when those trusting AI have demonsrated quanatatively and qualitatively better health.  They will say \"Hey I don't understand what its doing but heck it cured little Johnny's cancer maybe i should lave a go.\"", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People will come around when those trusting AI have demonsrated quanatatively and qualitatively better health.  They will say &amp;quot;Hey I don&amp;#39;t understand what its doing but heck it cured little Johnny&amp;#39;s cancer maybe i should lave a go.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak7m4", "score_hidden": false, "stickied": false, "created": 1492285301.0, "created_utc": 1492256501.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgajo8y", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "of-matter", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Ultimately, if it's not controllable by a human, the current body of people won't trust it.\n\nPeople just aren't ready to give over full or near-full control to AI. Our answer to incorrect humans has always been to add more humans to the equation to validate and correct, and since this algorithm doesn't support that workflow, it's seemingly inherently flawed. \n\n(Not that this is unexpected - TV, movies etc. have been breeding a distrust of AI ever since technology could be an antagonist.)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ultimately, if it&amp;#39;s not controllable by a human, the current body of people won&amp;#39;t trust it.&lt;/p&gt;\n\n&lt;p&gt;People just aren&amp;#39;t ready to give over full or near-full control to AI. Our answer to incorrect humans has always been to add more humans to the equation to validate and correct, and since this algorithm doesn&amp;#39;t support that workflow, it&amp;#39;s seemingly inherently flawed. &lt;/p&gt;\n\n&lt;p&gt;(Not that this is unexpected - TV, movies etc. have been breeding a distrust of AI ever since technology could be an antagonist.)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajo8y", "score_hidden": false, "stickied": false, "created": 1492283798.0, "created_utc": 1492254998.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaoidt", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "RecoveringGrocer", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This sounds like the journalist trying to find some point of controversy by asking a researcher 'what are some existing challenges to this?' and then spinning it to sound like a problem. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This sounds like the journalist trying to find some point of controversy by asking a researcher &amp;#39;what are some existing challenges to this?&amp;#39; and then spinning it to sound like a problem. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaoidt", "score_hidden": false, "stickied": false, "created": 1492294297.0, "created_utc": 1492265497.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgbanro", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ParentPostLacksWang", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "An important point not being made here is:  Why are we so uncomfortable not knowing the exact process by which the machine makes its decisions after the training phase, when we have arguably *much less* insight into how your cardiologist does this, using her extremely lossy stochastic wetware, and achieving statistically worse outcomes?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;An important point not being made here is:  Why are we so uncomfortable not knowing the exact process by which the machine makes its decisions after the training phase, when we have arguably &lt;em&gt;much less&lt;/em&gt; insight into how your cardiologist does this, using her extremely lossy stochastic wetware, and achieving statistically worse outcomes?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgbanro", "score_hidden": false, "stickied": false, "created": 1492325265.0, "created_utc": 1492296465.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgal0zh", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "renrutal", "parent_id": "t1_dga99le", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "No algorithm is a black box. It might take a long time to debug it, but it's no worse than explaining all the steps\u200b a computer does when you move a mouse pointer over the screen.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No algorithm is a black box. It might take a long time to debug it, but it&amp;#39;s no worse than explaining all the steps\u200b a computer does when you move a mouse pointer over the screen.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgal0zh", "score_hidden": false, "stickied": false, "created": 1492287371.0, "created_utc": 1492258571.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga99le", "gilded": 0, "archived": false, "score": 1365, "report_reasons": null, "author": "deltasheep1", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; Kontopantelis notes one limitation to the work: Machine-learning algorithms are like black boxes, in that you can see the data that go in and the decision that comes out, but you can\u2019t grasp what happens in between.\n\nWell that depends what algorithm you use. If you use a decision tree, then you can very easily see and interpret what happens in between.\n\n&gt; That makes it difficult for humans to tweak the algorithm\n\nHumans shouldn't be manually tweaking the algorithm beyond data preprocessing and hyper parameters anyway. All you want is to maximize AUC or minimize some other loss function, with maybe asymmetrical weighting on false negative/positive results.\n\n&gt; it thwarts predictions of what it will do in a new scenario.\n\nNow this part makes no sense. The fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios. That's the whole idea behind validation/cross-validation.\n\nEDIT: \nSom frequent responses\n&gt; Why nitpick?\n\nI made this comment because the author was exaggerating some of the drawbacks of ML. I don't know why authors tend to do this, but I think that if you're going to talk about the drawbacks, you should at least mention some workarounds\n\n&gt; But decision trees have high variance, so they're bad predictors\n\nTotally true, and deep learning is usually better. I made this comment because I felt like the author should mention the interpretability / predictability trade-off instead of implying that all models are opaque. \n\n&gt; Validation doesn't guarantee good accuracy later on\n\nAlso true, but I felt like the author did exaggerate their claim because CV is a really strong indicator of future accuracy if the data is similar.", "edited": 1492291736.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Kontopantelis notes one limitation to the work: Machine-learning algorithms are like black boxes, in that you can see the data that go in and the decision that comes out, but you can\u2019t grasp what happens in between.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Well that depends what algorithm you use. If you use a decision tree, then you can very easily see and interpret what happens in between.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;That makes it difficult for humans to tweak the algorithm&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Humans shouldn&amp;#39;t be manually tweaking the algorithm beyond data preprocessing and hyper parameters anyway. All you want is to maximize AUC or minimize some other loss function, with maybe asymmetrical weighting on false negative/positive results.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;it thwarts predictions of what it will do in a new scenario.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Now this part makes no sense. The fact that it was able to learn from 78% of the data, and then predict on the remaining unseen data means it does do well in new scenarios. That&amp;#39;s the whole idea behind validation/cross-validation.&lt;/p&gt;\n\n&lt;p&gt;EDIT: \nSom frequent responses&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Why nitpick?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I made this comment because the author was exaggerating some of the drawbacks of ML. I don&amp;#39;t know why authors tend to do this, but I think that if you&amp;#39;re going to talk about the drawbacks, you should at least mention some workarounds&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;But decision trees have high variance, so they&amp;#39;re bad predictors&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Totally true, and deep learning is usually better. I made this comment because I felt like the author should mention the interpretability / predictability trade-off instead of implying that all models are opaque. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Validation doesn&amp;#39;t guarantee good accuracy later on&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Also true, but I felt like the author did exaggerate their claim because CV is a really strong indicator of future accuracy if the data is similar.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga99le", "score_hidden": false, "stickied": false, "created": 1492257808.0, "created_utc": 1492229008.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1365}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgay1x4", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "FrequentScoobers", "parent_id": "t1_dgaocr2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "But only if the gut instinct is more accurate than the computer. Otherwise the computer is the way to go. Has this been examined?\n\nI mean the whole point of a clinical practice guideline is that it raises the accuracy of a population of physicians as a whole, right? (IDK if that's actually the case, though)? If some AI outperforms that clinical practice guideline then it might not outperform every individual physician, but it would improve healthcare as a whole, no? At the very least this can be used to fine-tune the guidelines, which I'm sure many physicians or physicians-in-training would use as a benchmark. If the benchmark is more accurate, then it would stand to reason that the end-decision would be more accurate, too.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But only if the gut instinct is more accurate than the computer. Otherwise the computer is the way to go. Has this been examined?&lt;/p&gt;\n\n&lt;p&gt;I mean the whole point of a clinical practice guideline is that it raises the accuracy of a population of physicians as a whole, right? (IDK if that&amp;#39;s actually the case, though)? If some AI outperforms that clinical practice guideline then it might not outperform every individual physician, but it would improve healthcare as a whole, no? At the very least this can be used to fine-tune the guidelines, which I&amp;#39;m sure many physicians or physicians-in-training would use as a benchmark. If the benchmark is more accurate, then it would stand to reason that the end-decision would be more accurate, too.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgay1x4", "score_hidden": false, "stickied": false, "created": 1492307931.0, "created_utc": 1492279131.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgax71o", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "aidanjt", "parent_id": "t1_dgaocr2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Gut instinct is still inherently guestimating and therefore error-prone, it's only important to humans because deliberate calculated thought takes vastly more time, and time is rarely on a doctor's side, they almost always have far too many patients for it, and in emergency situations the patient wont survive lengthy pondering.  A.I.'s don't have that problem because their ability to crunch numbers is the one thing they can inherently do virtually instantly.  It's the 'being intelligent' part that's new for them, and that's coming along in leaps and bounds.  But humans will always suck at quickly calculating math.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gut instinct is still inherently guestimating and therefore error-prone, it&amp;#39;s only important to humans because deliberate calculated thought takes vastly more time, and time is rarely on a doctor&amp;#39;s side, they almost always have far too many patients for it, and in emergency situations the patient wont survive lengthy pondering.  A.I.&amp;#39;s don&amp;#39;t have that problem because their ability to crunch numbers is the one thing they can inherently do virtually instantly.  It&amp;#39;s the &amp;#39;being intelligent&amp;#39; part that&amp;#39;s new for them, and that&amp;#39;s coming along in leaps and bounds.  But humans will always suck at quickly calculating math.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgax71o", "score_hidden": false, "stickied": false, "created": 1492306764.0, "created_utc": 1492277964.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgap6zd", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "X-RT", "parent_id": "t1_dgaocr2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Great book. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great book. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgap6zd", "score_hidden": false, "stickied": false, "created": 1492295425.0, "created_utc": 1492266625.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgb6e57", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ffxivfunk", "parent_id": "t1_dgaocr2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "As an actual medical professional, intuition is over-relied on and get people killed.  Doctors get too used to running on experience and become inflexible when studies show that old methods arent the best.  They tend to fall to confirmation bias and make assumptions.  We do not want computers to mimic humans, we specifically want them to be good at where we are weak.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As an actual medical professional, intuition is over-relied on and get people killed.  Doctors get too used to running on experience and become inflexible when studies show that old methods arent the best.  They tend to fall to confirmation bias and make assumptions.  We do not want computers to mimic humans, we specifically want them to be good at where we are weak.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgb6e57", "score_hidden": false, "stickied": false, "created": 1492319256.0, "created_utc": 1492290456.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaonhi", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "herbaldruid", "parent_id": "t1_dgaocr2", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Instinct is a great way to come up with a plausible hypothesis.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Instinct is a great way to come up with a plausible hypothesis.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaonhi", "score_hidden": false, "stickied": false, "created": 1492294534.0, "created_utc": 1492265734.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaocr2", "gilded": 0, "archived": false, "score": 28, "report_reasons": null, "author": "iBro53", "parent_id": "t1_dgaisgf", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": " Intuition (expert intuition) is actually key to medicine. A doctor isn't punching numbers in their head and outputting risks for diseases. An experienced doctor has a feeling about the diagnosis based on the data, a gut reaction. This feeling is Type 2 reasoning explained in Thinking Fast and Slow by Daniel Kahneman. The end goal of human thinking in medicine (and many other professions) isn't to mimic a computer, it's to hone that gut instinct.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Intuition (expert intuition) is actually key to medicine. A doctor isn&amp;#39;t punching numbers in their head and outputting risks for diseases. An experienced doctor has a feeling about the diagnosis based on the data, a gut reaction. This feeling is Type 2 reasoning explained in Thinking Fast and Slow by Daniel Kahneman. The end goal of human thinking in medicine (and many other professions) isn&amp;#39;t to mimic a computer, it&amp;#39;s to hone that gut instinct.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaocr2", "score_hidden": false, "stickied": false, "created": 1492294033.0, "created_utc": 1492265233.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 28}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaisgf", "gilded": 0, "archived": false, "score": 27, "report_reasons": null, "author": "ffxivfunk", "parent_id": "t1_dgaip0h", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Actually I'd  expect that to mean AI are even more superior. Many doctors are bad at following guidelines and often run on intuition, which is inferior and why the studies in the past have shown we need guidelines.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Actually I&amp;#39;d  expect that to mean AI are even more superior. Many doctors are bad at following guidelines and often run on intuition, which is inferior and why the studies in the past have shown we need guidelines.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaisgf", "score_hidden": false, "stickied": false, "created": 1492281068.0, "created_utc": 1492252268.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 27}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgalq20", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "chucknorris10101", "parent_id": "t1_dgaip0h", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "Yea I'm going to just remind you that even the last guy to graduate from med school still gets called doctor. I think based on the other responses, those guys relying on intuition would likely be significantly worse. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yea I&amp;#39;m going to just remind you that even the last guy to graduate from med school still gets called doctor. I think based on the other responses, those guys relying on intuition would likely be significantly worse. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalq20", "score_hidden": false, "stickied": false, "created": 1492288957.0, "created_utc": 1492260157.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaip0h", "gilded": 0, "archived": false, "score": 35, "report_reasons": null, "author": "Kalladir", "parent_id": "t1_dgahlgf", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt;  ACC/AHA method\n\nThe assumption is that doctors rely on ACC/AHA only. So basically study just showed that self taught AI algorithm is superior to other man-made algorithm, rather than actual doctors. I'd expect AI to still by superior to doctor, but by a smaller margin.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;ACC/AHA method&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The assumption is that doctors rely on ACC/AHA only. So basically study just showed that self taught AI algorithm is superior to other man-made algorithm, rather than actual doctors. I&amp;#39;d expect AI to still by superior to doctor, but by a smaller margin.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaip0h", "score_hidden": false, "stickied": false, "created": 1492280765.0, "created_utc": 1492251965.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 35}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgahlgf", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgahh0e", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Where did I assume that?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where did I assume that?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahlgf", "score_hidden": false, "stickied": false, "created": 1492277219.0, "created_utc": 1492248419.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 7}}], "after": null, "before": null}}, "user_reports": [], "id": "dgahh0e", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "H_is_for_Human", "parent_id": "t1_dgadb0k", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "You are also assuming that doctors only strictly follow guidelines, which is not the case. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You are also assuming that doctors only strictly follow guidelines, which is not the case. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgahh0e", "score_hidden": false, "stickied": false, "created": 1492276830.0, "created_utc": 1492248030.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 25}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgadb0k", "gilded": 0, "archived": false, "score": 150, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgacex8", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "You're right that the AUC isn't very impressive, but I think the better results are these:\n\n&gt; The best one\u2014neural networks\u2014correctly predicted 7.6% more events than the ACC/AHA method, and it raised 1.6% fewer false alarms.\n\nThe fact that it both predicted a lot more heart attacks and it raised fewer false alarms while doing it is significant. \n\nI also don't think it's meaningful to look at 0.4%=355/(total number of people) because not that many people get heart attacks in general. \n\nFinally, they didn't say that \"355 would have been saved\", they said \"could have been saved.\"", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re right that the AUC isn&amp;#39;t very impressive, but I think the better results are these:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The best one\u2014neural networks\u2014correctly predicted 7.6% more events than the ACC/AHA method, and it raised 1.6% fewer false alarms.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The fact that it both predicted a lot more heart attacks and it raised fewer false alarms while doing it is significant. &lt;/p&gt;\n\n&lt;p&gt;I also don&amp;#39;t think it&amp;#39;s meaningful to look at 0.4%=355/(total number of people) because not that many people get heart attacks in general. &lt;/p&gt;\n\n&lt;p&gt;Finally, they didn&amp;#39;t say that &amp;quot;355 would have been saved&amp;quot;, they said &amp;quot;could have been saved.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgadb0k", "score_hidden": false, "stickied": false, "created": 1492265483.0, "created_utc": 1492236683.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 150}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaham8", "gilded": 0, "archived": false, "score": 26, "report_reasons": null, "author": "corelove", "parent_id": "t1_dgacex8", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I think the point is that AI applications have crossed another threshold and can reasonably be expected to improve further.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the point is that AI applications have crossed another threshold and can reasonably be expected to improve further.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaham8", "score_hidden": false, "stickied": false, "created": 1492276264.0, "created_utc": 1492247464.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 26}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgak75t", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "ManyPoo", "parent_id": "t1_dgacex8", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt;&gt; In the test sample of about 83,000 records, that amounts to 355 additional patients whose lives *could* have been saved.\n\n&gt; But it is **grossly** overstating the case that even 355 lives *would* have been saved. \n\nYou changed \"could\" to \"would\".  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;blockquote&gt;\n&lt;p&gt;In the test sample of about 83,000 records, that amounts to 355 additional patients whose lives &lt;em&gt;could&lt;/em&gt; have been saved.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;But it is &lt;strong&gt;grossly&lt;/strong&gt; overstating the case that even 355 lives &lt;em&gt;would&lt;/em&gt; have been saved. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You changed &amp;quot;could&amp;quot; to &amp;quot;would&amp;quot;.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak75t", "score_hidden": false, "stickied": false, "created": 1492285269.0, "created_utc": 1492256469.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaiz3e", "gilded": 0, "archived": false, "score": 47, "report_reasons": null, "author": "pablitorun", "parent_id": "t1_dgah7b7", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "It isn't matching doctors. It's matching an algorithim published for doctors. So it's one algorithm matching another.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It isn&amp;#39;t matching doctors. It&amp;#39;s matching an algorithim published for doctors. So it&amp;#39;s one algorithm matching another.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaiz3e", "score_hidden": false, "stickied": false, "created": 1492281648.0, "created_utc": 1492252848.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 47}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgah7b7", "gilded": 0, "archived": false, "score": 18, "report_reasons": null, "author": "sina12345", "parent_id": "t1_dgacex8", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I think the fact that a neural net is even *matching* doctors is amazing.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the fact that a neural net is even &lt;em&gt;matching&lt;/em&gt; doctors is amazing.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgah7b7", "score_hidden": false, "stickied": false, "created": 1492275973.0, "created_utc": 1492247173.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 18}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgacex8", "gilded": 0, "archived": false, "score": 535, "report_reasons": null, "author": "fernly", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Wait, wait:\n\n&gt; the ACC/AHA guidelines hit 0.728. The four new methods ranged from 0.745 to 0.764, Weng\u2019s team reports this month in PLOS ONE. \n\nHumans get 73% right. AI gets from 75% to 76%. Yes, this is no doubt a \"significant\" result in statistical terms. But is it \"significant\" in *clinical* terms? The article goes *way* over the top trying to make that case,\n\n&gt; In the test sample of about 83,000 records, that amounts to 355 additional patients whose lives could have been saved. \n\nNo. 355 additional patients -- or 0.4 of one percent! -- would have received a *warning* that they were *liable* to have a heart attack in the next ten years. Some number of that tiny fraction might have done something to reduce their chances and thus \"save their lives\". But it is **grossly** overstating the case that even 355 lives would have been saved.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wait, wait:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;the ACC/AHA guidelines hit 0.728. The four new methods ranged from 0.745 to 0.764, Weng\u2019s team reports this month in PLOS ONE. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Humans get 73% right. AI gets from 75% to 76%. Yes, this is no doubt a &amp;quot;significant&amp;quot; result in statistical terms. But is it &amp;quot;significant&amp;quot; in &lt;em&gt;clinical&lt;/em&gt; terms? The article goes &lt;em&gt;way&lt;/em&gt; over the top trying to make that case,&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;In the test sample of about 83,000 records, that amounts to 355 additional patients whose lives could have been saved. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No. 355 additional patients -- or 0.4 of one percent! -- would have received a &lt;em&gt;warning&lt;/em&gt; that they were &lt;em&gt;liable&lt;/em&gt; to have a heart attack in the next ten years. Some number of that tiny fraction might have done something to reduce their chances and thus &amp;quot;save their lives&amp;quot;. But it is &lt;strong&gt;grossly&lt;/strong&gt; overstating the case that even 355 lives would have been saved.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgacex8", "score_hidden": false, "stickied": false, "created": 1492263541.0, "created_utc": 1492234741.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 535}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaqi0n", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Mr_Dugan", "parent_id": "t1_dgakbgc", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "They excluded people with heart disease and people with any previous statin use", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They excluded people with heart disease and people with any previous statin use&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaqi0n", "score_hidden": false, "stickied": false, "created": 1492297427.0, "created_utc": 1492268627.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgakbgc", "gilded": 0, "archived": false, "score": 26, "report_reasons": null, "author": "barnosaur", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "\"Beat doctors\" is a pretty sensational headline when it compared to one metric with the assumption that's the only clinical judgement. They're comparing it to the ACSVD which is used to determine starting a statin if there isn't a compelling reason to. But they compared just that to a sample that included people with diabetes (who have lower LDL parameters than the general population to start a statin so that is a risk consideration made) and probably people with history of heart disease (who you wouldn't use the ACSVD because it's already indicated). ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Beat doctors&amp;quot; is a pretty sensational headline when it compared to one metric with the assumption that&amp;#39;s the only clinical judgement. They&amp;#39;re comparing it to the ACSVD which is used to determine starting a statin if there isn&amp;#39;t a compelling reason to. But they compared just that to a sample that included people with diabetes (who have lower LDL parameters than the general population to start a statin so that is a risk consideration made) and probably people with history of heart disease (who you wouldn&amp;#39;t use the ACSVD because it&amp;#39;s already indicated). &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgakbgc", "score_hidden": false, "stickied": false, "created": 1492285595.0, "created_utc": 1492256795.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 26}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgak26c", "gilded": 0, "archived": false, "score": 27, "report_reasons": null, "author": "ManyPoo", "parent_id": "t1_dga85xa", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "It's the same. When a doctor says you are at risk he is making a statement about the probability of you having an event, I.e. That it's higher. Machine learning algorithms are also just guessing probabilities, they just do it in a a more quantitative and accurate way. Both make probabilistic statements about the future though.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s the same. When a doctor says you are at risk he is making a statement about the probability of you having an event, I.e. That it&amp;#39;s higher. Machine learning algorithms are also just guessing probabilities, they just do it in a a more quantitative and accurate way. Both make probabilistic statements about the future though.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak26c", "score_hidden": false, "stickied": false, "created": 1492284889.0, "created_utc": 1492256089.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 27}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga85xa", "gilded": 0, "archived": false, "score": 160, "report_reasons": null, "author": "Medcait", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "To be fair, doctors never claim to be able to \"predict\" anything. You can be at risk, or it can be diagnosed once it happens.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;To be fair, doctors never claim to be able to &amp;quot;predict&amp;quot; anything. You can be at risk, or it can be diagnosed once it happens.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga85xa", "score_hidden": false, "stickied": false, "created": 1492256009.0, "created_utc": 1492227209.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 160}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgalm0f", "gilded": 0, "archived": false, "score": 53, "report_reasons": null, "author": "dominant_driver", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Misleading headline, and sensationalized article.  The AI systems were able to use 22 more data points that the doctors did not take into account.\n\n&gt;Unlike the ACC/AHA guidelines, the machine-learning methods were allowed to take into account 22 more data points, including ethnicity, arthritis, and kidney disease.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Misleading headline, and sensationalized article.  The AI systems were able to use 22 more data points that the doctors did not take into account.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Unlike the ACC/AHA guidelines, the machine-learning methods were allowed to take into account 22 more data points, including ethnicity, arthritis, and kidney disease.&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalm0f", "score_hidden": false, "stickied": false, "created": 1492288714.0, "created_utc": 1492259914.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 53}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgagizx", "gilded": 0, "archived": false, "score": 42, "report_reasons": null, "author": "nimms", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Misleading title. This is comparing a computer vs clinical guidelines, not physicians. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Misleading title. This is comparing a computer vs clinical guidelines, not physicians. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgagizx", "score_hidden": false, "stickied": false, "created": 1492273843.0, "created_utc": 1492245043.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 42}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaejyr", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaejyr", "score_hidden": false, "stickied": false, "created": 1492268420.0, "created_utc": 1492239620.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 11}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgajxs3", "gilded": 0, "archived": false, "score": 19, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajxs3", "score_hidden": false, "stickied": false, "created": 1492284560.0, "created_utc": 1492255760.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 19}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgafw2y", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "nag204", "parent_id": "t1_dgacd5w", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I agree with most of what you say but I doubt a computer could differentiate flu from the common cold any better.  The human body only has some many responses to certain insults.  So much of medicine is eliciting data as well.  So I agree AI won't be replacing docs anytime soon. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree with most of what you say but I doubt a computer could differentiate flu from the common cold any better.  The human body only has some many responses to certain insults.  So much of medicine is eliciting data as well.  So I agree AI won&amp;#39;t be replacing docs anytime soon. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgafw2y", "score_hidden": false, "stickied": false, "created": 1492271974.0, "created_utc": 1492243174.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgawq6h", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "rootslane", "parent_id": "t1_dgacd5w", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This is one of the best comments in this thread. Basically the most realistic take on the computer vs. doctors arguments going on here (which should be computer vs. guidlines, but a lot of people don't even read the article). You honestly deserve gold for your reasoning. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is one of the best comments in this thread. Basically the most realistic take on the computer vs. doctors arguments going on here (which should be computer vs. guidlines, but a lot of people don&amp;#39;t even read the article). You honestly deserve gold for your reasoning. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgawq6h", "score_hidden": false, "stickied": false, "created": 1492306127.0, "created_utc": 1492277327.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgajrao", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "moolah_dollar_cash", "parent_id": "t1_dgacd5w", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I think it's a good point about fringe cases. Deep learning tech as it stands can't reason through a complicated case to find a difficult solution. \n\nI personally would not be surprised if AI becomes pretty good at detecting that rare case of cancer with better accuracy than Doctors. I think especially once you start giving the AI more and more information it will do surprisingly well at detecting things based on things that are pretty imperceptible to humans.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s a good point about fringe cases. Deep learning tech as it stands can&amp;#39;t reason through a complicated case to find a difficult solution. &lt;/p&gt;\n\n&lt;p&gt;I personally would not be surprised if AI becomes pretty good at detecting that rare case of cancer with better accuracy than Doctors. I think especially once you start giving the AI more and more information it will do surprisingly well at detecting things based on things that are pretty imperceptible to humans.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgajrao", "score_hidden": false, "stickied": false, "created": 1492284042.0, "created_utc": 1492255242.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgacd5w", "gilded": 0, "archived": false, "score": 72, "report_reasons": null, "author": "noelsusman", "parent_id": "t1_dga9a2n", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "FWIW, I do research on machine learning applications in clinical settings.\n\nThe way I view it is that algorithms and humans are currently good at different tasks.  Let's take drug interactions, for example.  There are a fuckload of drugs out there, and any one doctor doesn't have the capacity to fully understand how every single drug interacts with every other drug.  Traditionally, this has been handled using databases of studies involving individual drugs.\n\nTheoretically a computer could look at every medical record ever produced and quickly come up with a model for how every single drug interacts with every other drug.  This is the kind of task that computers are great for and humans aren't.\n\nHowever, computers don't understand how the body works.  They don't possess that bit of knowledge that would spark something in a doctor's brain to perform a test for something that's not immediately obvious.  A computer could correctly diagnose the flu vs. a common cold (or whatever) almost all of the time, but would it be able to recognize the few times that it was actually cancer?  The answer is no.  Computers are generally very bad at edge cases like that.\n\nComputers are vastly superior to humans at tasks that require a massive scale of information.  There are certain pieces of information that only become apparent from looking at millions of medical records at once.  This is what computers are good for.  They can find patterns that the human brain simply isn't capable of finding.  However, in medicine you're often working with very little information rather than too much information.  This is the domain where humans vastly outperform computers.\n\nThe bottom line is that I don't see computers replacing doctors anytime even remotely soon.  I do see computers augmenting a doctor's abilities and allowing a doctor to see more patients in a given amount of time.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;FWIW, I do research on machine learning applications in clinical settings.&lt;/p&gt;\n\n&lt;p&gt;The way I view it is that algorithms and humans are currently good at different tasks.  Let&amp;#39;s take drug interactions, for example.  There are a fuckload of drugs out there, and any one doctor doesn&amp;#39;t have the capacity to fully understand how every single drug interacts with every other drug.  Traditionally, this has been handled using databases of studies involving individual drugs.&lt;/p&gt;\n\n&lt;p&gt;Theoretically a computer could look at every medical record ever produced and quickly come up with a model for how every single drug interacts with every other drug.  This is the kind of task that computers are great for and humans aren&amp;#39;t.&lt;/p&gt;\n\n&lt;p&gt;However, computers don&amp;#39;t understand how the body works.  They don&amp;#39;t possess that bit of knowledge that would spark something in a doctor&amp;#39;s brain to perform a test for something that&amp;#39;s not immediately obvious.  A computer could correctly diagnose the flu vs. a common cold (or whatever) almost all of the time, but would it be able to recognize the few times that it was actually cancer?  The answer is no.  Computers are generally very bad at edge cases like that.&lt;/p&gt;\n\n&lt;p&gt;Computers are vastly superior to humans at tasks that require a massive scale of information.  There are certain pieces of information that only become apparent from looking at millions of medical records at once.  This is what computers are good for.  They can find patterns that the human brain simply isn&amp;#39;t capable of finding.  However, in medicine you&amp;#39;re often working with very little information rather than too much information.  This is the domain where humans vastly outperform computers.&lt;/p&gt;\n\n&lt;p&gt;The bottom line is that I don&amp;#39;t see computers replacing doctors anytime even remotely soon.  I do see computers augmenting a doctor&amp;#39;s abilities and allowing a doctor to see more patients in a given amount of time.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgacd5w", "score_hidden": false, "stickied": false, "created": 1492263436.0, "created_utc": 1492234636.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 72}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga9a2n", "gilded": 0, "archived": false, "score": 13, "report_reasons": null, "author": "Montgomery0", "parent_id": "t1_dga2vbw", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Is this because it's too difficult to train for or because they haven't actually trained the ai to recognize the issues?  I'd imagine, given enough training, an ai would be more competent than average, especially with complicated cases.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this because it&amp;#39;s too difficult to train for or because they haven&amp;#39;t actually trained the ai to recognize the issues?  I&amp;#39;d imagine, given enough training, an ai would be more competent than average, especially with complicated cases.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga9a2n", "score_hidden": false, "stickied": false, "created": 1492257828.0, "created_utc": 1492229028.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 13}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga2vbw", "gilded": 0, "archived": false, "score": 61, "report_reasons": null, "author": "xipha", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "To be fair, it is ai beats human in bookeeping. Simple and classic task yes, will not be better than docs with complicate cases. Plus, knowing patient need a test for heart disease and knowing which test they need is way more important than know how to read a test result.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;To be fair, it is ai beats human in bookeeping. Simple and classic task yes, will not be better than docs with complicate cases. Plus, knowing patient need a test for heart disease and knowing which test they need is way more important than know how to read a test result.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga2vbw", "score_hidden": false, "stickied": false, "created": 1492248328.0, "created_utc": 1492219528.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 61}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaq1gy", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaq1gy", "score_hidden": false, "stickied": false, "created": 1492296732.0, "created_utc": 1492267932.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga8cnq", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "3lmochilero", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "From the bot in another thread. Sorry if not okay to post this.\n\n\nThis is an automatic summary, original reduced by 80%.\n\nIn an effort to predict these cases, many doctors use guidelines similar to those of the American College of Cardiology/American Heart Association.\n\nIn the new study, Weng and his colleagues compared use of the ACC/AHA guidelines with four machine-learning algorithms: random forest, logistic regression, gradient boosting, and neural networks.\n\nUsing record data available in 2005, they predicted which patients would have their first cardiovascular event over the next 10 years, and checked the guesses against the 2015 records.\n\nUnlike the ACC/AHA guidelines, the machine-learning methods were allowed to take into account 22 more data points, including ethnicity, arthritis, and kidney disease.\n\nAll four AI methods performed significantly better than the ACC/AHA guidelines.\n\nSeveral of the risk factors that the machine-learning algorithms identified as the strongest predictors are not included in the ACC/AHA guidelines, such as severe mental illness and taking oral corticosteroids.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From the bot in another thread. Sorry if not okay to post this.&lt;/p&gt;\n\n&lt;p&gt;This is an automatic summary, original reduced by 80%.&lt;/p&gt;\n\n&lt;p&gt;In an effort to predict these cases, many doctors use guidelines similar to those of the American College of Cardiology/American Heart Association.&lt;/p&gt;\n\n&lt;p&gt;In the new study, Weng and his colleagues compared use of the ACC/AHA guidelines with four machine-learning algorithms: random forest, logistic regression, gradient boosting, and neural networks.&lt;/p&gt;\n\n&lt;p&gt;Using record data available in 2005, they predicted which patients would have their first cardiovascular event over the next 10 years, and checked the guesses against the 2015 records.&lt;/p&gt;\n\n&lt;p&gt;Unlike the ACC/AHA guidelines, the machine-learning methods were allowed to take into account 22 more data points, including ethnicity, arthritis, and kidney disease.&lt;/p&gt;\n\n&lt;p&gt;All four AI methods performed significantly better than the ACC/AHA guidelines.&lt;/p&gt;\n\n&lt;p&gt;Several of the risk factors that the machine-learning algorithms identified as the strongest predictors are not included in the ACC/AHA guidelines, such as severe mental illness and taking oral corticosteroids.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga8cnq", "score_hidden": false, "stickied": false, "created": 1492256311.0, "created_utc": 1492227511.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgadhwj", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "DrTzTz", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Interesting. Though I wonder. The AI should end up undervalueing some risk factors because human physicists are already looking for them very thoroughly which leads to early treatment of diabetes for example. So it might just not be a factor in the machines prediction because we are normally treating the patients. It doesn't state that the AI took applied treatments into account.\n\nIt's nice to see how AI is progressing but it seems we need to think for ourselves for a few more years at least.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting. Though I wonder. The AI should end up undervalueing some risk factors because human physicists are already looking for them very thoroughly which leads to early treatment of diabetes for example. So it might just not be a factor in the machines prediction because we are normally treating the patients. It doesn&amp;#39;t state that the AI took applied treatments into account.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s nice to see how AI is progressing but it seems we need to think for ourselves for a few more years at least.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgadhwj", "score_hidden": false, "stickied": false, "created": 1492265899.0, "created_utc": 1492237099.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaezpo", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "TheBeardedSatanist", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I've been operating under the assumption that we didn't have self-teaching and self-improving AI yet\n\nMixed philosophical ideas about the concept, but from a technological standpoint it's fascinating, and I hadn't even thought about the medical applications.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve been operating under the assumption that we didn&amp;#39;t have self-teaching and self-improving AI yet&lt;/p&gt;\n\n&lt;p&gt;Mixed philosophical ideas about the concept, but from a technological standpoint it&amp;#39;s fascinating, and I hadn&amp;#39;t even thought about the medical applications.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaezpo", "score_hidden": false, "stickied": false, "created": 1492269549.0, "created_utc": 1492240749.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaf2z7", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Bungle954", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The real news is that a machine learning algorithm was able to identify more risk factors than the current AHA guidelines, then prognotiscate pretty well (i.e. A bit better than a really well trained human.)\n\nFrom the data set supplied, it identified 350 or so more patients who were likely to suffer (what I presume is) an MI in the next 10 years. The author is bullshitting when they say it would save 350 lives. Predicting an MI is fine, but we have no idea what the predicted morbidity or mortality rate is for those patients, nor how effective treatment would be for them. \n\nSounds like a handy tool, and another great way to help doctors make better decisions when faced with complex data. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The real news is that a machine learning algorithm was able to identify more risk factors than the current AHA guidelines, then prognotiscate pretty well (i.e. A bit better than a really well trained human.)&lt;/p&gt;\n\n&lt;p&gt;From the data set supplied, it identified 350 or so more patients who were likely to suffer (what I presume is) an MI in the next 10 years. The author is bullshitting when they say it would save 350 lives. Predicting an MI is fine, but we have no idea what the predicted morbidity or mortality rate is for those patients, nor how effective treatment would be for them. &lt;/p&gt;\n\n&lt;p&gt;Sounds like a handy tool, and another great way to help doctors make better decisions when faced with complex data. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaf2z7", "score_hidden": false, "stickied": false, "created": 1492269778.0, "created_utc": 1492240978.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgamtcv", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "hollerinn", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This title is misleading to the point of being dishonest. There's no such thing as \"self-taught artificial intelligence.\" There are algorithms, tuned by the analysis of astronomically large data sets, that arrive at certain \"conclusions\" on that data, which are then interpreted and communicated by engineers. Read Superintelligence by Nick Bostrom or any other book on AI and you'll know how troubling it is to label a machine learning network as \"self-taught\" AI. Is a falling leaf self-spinning? Does your rumba understand the layout of your house? Sensationalist journalistic responses to legitimate advances in computational intelligence are only going to slow things down.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This title is misleading to the point of being dishonest. There&amp;#39;s no such thing as &amp;quot;self-taught artificial intelligence.&amp;quot; There are algorithms, tuned by the analysis of astronomically large data sets, that arrive at certain &amp;quot;conclusions&amp;quot; on that data, which are then interpreted and communicated by engineers. Read Superintelligence by Nick Bostrom or any other book on AI and you&amp;#39;ll know how troubling it is to label a machine learning network as &amp;quot;self-taught&amp;quot; AI. Is a falling leaf self-spinning? Does your rumba understand the layout of your house? Sensationalist journalistic responses to legitimate advances in computational intelligence are only going to slow things down.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgamtcv", "score_hidden": false, "stickied": false, "created": 1492291242.0, "created_utc": 1492262442.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgap23q", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "mrmo24", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This is just another tool doctors can use in their clinical judgement. This can in no way harm the medical field because it just gives a more accurate tool for doctors. And of course, in an anecdotal way, some doctors will use it blindly and blah blah blah, but if used properly, it could help millions of people. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is just another tool doctors can use in their clinical judgement. This can in no way harm the medical field because it just gives a more accurate tool for doctors. And of course, in an anecdotal way, some doctors will use it blindly and blah blah blah, but if used properly, it could help millions of people. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgap23q", "score_hidden": false, "stickied": false, "created": 1492295208.0, "created_utc": 1492266408.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgavx2s", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "Aelinsaar", "parent_id": "t1_dgavv8y", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Unfortunately the article does present things in a confrontational way, and I think that's definitely gotten in the way of the underlying message: another small benchmark of progress. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unfortunately the article does present things in a confrontational way, and I think that&amp;#39;s definitely gotten in the way of the underlying message: another small benchmark of progress. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgavx2s", "score_hidden": false, "stickied": false, "created": 1492305037.0, "created_utc": 1492276237.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dgavv8y", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "sarahjustme", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "People are thinking of this as \"machine vs Drs\".  I think it will become a tool used by insurance companies to offer incentives to patients, to go to extra check ups or get extra benefits like a health coach, to hopefully head off extra costs in the long run.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People are thinking of this as &amp;quot;machine vs Drs&amp;quot;.  I think it will become a tool used by insurance companies to offer incentives to patients, to go to extra check ups or get extra benefits like a health coach, to hopefully head off extra costs in the long run.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgavv8y", "score_hidden": false, "stickied": false, "created": 1492304968.0, "created_utc": 1492276168.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgamsew", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "foreheadmelon", "parent_id": "t1_dgade2e", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "the question is: are 8 false positives a lot in this case and how do humans compare?\n\nof course you can increase detection rate by increasing sensitivity, but on the other hand simply diagnosing everyone would have a 100% detection rate.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the question is: are 8 false positives a lot in this case and how do humans compare?&lt;/p&gt;\n\n&lt;p&gt;of course you can increase detection rate by increasing sensitivity, but on the other hand simply diagnosing everyone would have a 100% detection rate.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgamsew", "score_hidden": false, "stickied": false, "created": 1492291191.0, "created_utc": 1492262391.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgade2e", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "deltasheep1", "parent_id": "t1_dgac133", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Another awesome related article you may like: https://www.google.com/amp/www.mirror.co.uk/tech/googles-artificial-intelligence-can-diagnose-9975987.amp\n\ntl;dr\n&gt; \"At 8 false positives per image, we detect 92.4% of the tumours, relative to 82.7% by the previous best automated approach. For comparison, a human pathologist attempting exhaustive search achieved 73.2% sensitivity.\"", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Another awesome related article you may like: &lt;a href=\"https://www.google.com/amp/www.mirror.co.uk/tech/googles-artificial-intelligence-can-diagnose-9975987.amp\"&gt;https://www.google.com/amp/www.mirror.co.uk/tech/googles-artificial-intelligence-can-diagnose-9975987.amp&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;tl;dr&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;At 8 false positives per image, we detect 92.4% of the tumours, relative to 82.7% by the previous best automated approach. For comparison, a human pathologist attempting exhaustive search achieved 73.2% sensitivity.&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgade2e", "score_hidden": false, "stickied": false, "created": 1492265668.0, "created_utc": 1492236868.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 8}}], "after": null, "before": null}}, "user_reports": [], "id": "dgac133", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "Atariskyline", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "A Swedish study published in the fall of 1997, led by Lars Edenbrandt, compared the ability to predict a heart attack by analyzing EGKs between Ohlin, a top Swedish cardiologist, and Edenbrandts own computer system. Out of 2240 EKGs the cardiologist correctly picked 620 out of the 1120 of which were confirmed to show heart attacks. The computer picked up 738. Machine beat man by 20 percent. \n\nIt is not surprising that computers, and our ability to utilize it, improve. \n\nSourced from \"Complications: A Surgeon's Notes on an Imperfect Science\" by Atul Gawande (2003). Check out this book for more on the myth of medical infallibility. \nEdit: grammatical errors.", "edited": 1492239169.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A Swedish study published in the fall of 1997, led by Lars Edenbrandt, compared the ability to predict a heart attack by analyzing EGKs between Ohlin, a top Swedish cardiologist, and Edenbrandts own computer system. Out of 2240 EKGs the cardiologist correctly picked 620 out of the 1120 of which were confirmed to show heart attacks. The computer picked up 738. Machine beat man by 20 percent. &lt;/p&gt;\n\n&lt;p&gt;It is not surprising that computers, and our ability to utilize it, improve. &lt;/p&gt;\n\n&lt;p&gt;Sourced from &amp;quot;Complications: A Surgeon&amp;#39;s Notes on an Imperfect Science&amp;quot; by Atul Gawande (2003). Check out this book for more on the myth of medical infallibility. \nEdit: grammatical errors.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgac133", "score_hidden": false, "stickied": false, "created": 1492262750.0, "created_utc": 1492233950.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dga4gzv", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": 1492221939.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga4gzv", "score_hidden": false, "stickied": false, "created": 1492250543.0, "created_utc": 1492221743.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgas11k", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "lheritier1789", "parent_id": "t1_dga96h3", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The problem with updating medical guidelines is that if you include too many variables, real clinician will either not have access to that information or the variable may be borderline, making the guideline more difficult to apply in real life. Often what the guidelines are trying to accomplish is not to maximally predict, but rather to use the fewest and most easily-available variables to predict the most cases. \n\nIn the real world, clinicians plug in whatever variables are called for in the calculator and then contextualize the output in what other knowledge they are able to elicit from the patient (e.g. mental health, historic compliance, health education, socio-economic status, etc.). I think it would be irresponsible and bad medicine to just go off the calculator.\n\nIn an ideal world, we would have one single, comprehensive database for everyone's health information, based on which we can freely draw associations and design these types of software to aid in clinical decisions. But we are far from that now.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem with updating medical guidelines is that if you include too many variables, real clinician will either not have access to that information or the variable may be borderline, making the guideline more difficult to apply in real life. Often what the guidelines are trying to accomplish is not to maximally predict, but rather to use the fewest and most easily-available variables to predict the most cases. &lt;/p&gt;\n\n&lt;p&gt;In the real world, clinicians plug in whatever variables are called for in the calculator and then contextualize the output in what other knowledge they are able to elicit from the patient (e.g. mental health, historic compliance, health education, socio-economic status, etc.). I think it would be irresponsible and bad medicine to just go off the calculator.&lt;/p&gt;\n\n&lt;p&gt;In an ideal world, we would have one single, comprehensive database for everyone&amp;#39;s health information, based on which we can freely draw associations and design these types of software to aid in clinical decisions. But we are far from that now.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgas11k", "score_hidden": false, "stickied": false, "created": 1492299609.0, "created_utc": 1492270809.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga96h3", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Conspiracy313", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This looks more like a case where the standard medical guidelines need to be updated. Yet good on this group for making such effective software.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This looks more like a case where the standard medical guidelines need to be updated. Yet good on this group for making such effective software.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga96h3", "score_hidden": false, "stickied": false, "created": 1492257671.0, "created_utc": 1492228871.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgalvn6", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "lostintransactions", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I am really saddened that in r/science of all places, AI has been redefined.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I am really saddened that in &lt;a href=\"/r/science\"&gt;r/science&lt;/a&gt; of all places, AI has been redefined.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalvn6", "score_hidden": false, "stickied": false, "created": 1492289300.0, "created_utc": 1492260500.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgan4oa", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Skibbittbeebop", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This is one statistical method improving on another, and certainly not computer learning 'beating doctors'. The current guidelines come from massive epidemiological studies, and are risk factor models (Framingham Study). Doctors purposefully use statistical models to help identify risk factors. To say this study 'calls out doctors' is like saying guns beats soldier at killing the enemy, when in reality this is actually saying something like a tank is better than a rocket launcher for the purpose of dispatching the enemy. This study compares tools.\n\nSecond and probably more important, to project into the future that this would actually save lives simply by identifying those at risk is also a stretch. It certainly helps and we're grateful for new tools, but the timeline between risk factors (what was identified here) and outcomes (the cardiac event they hope to prevent) relies on what interventions can be implemented in between, if the patient is adherent with those recommendations, and how effective those interventions are. All of those steps - from risk factor identification, to prevention, and then treatment - are what doctors do.", "edited": 1492263568.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is one statistical method improving on another, and certainly not computer learning &amp;#39;beating doctors&amp;#39;. The current guidelines come from massive epidemiological studies, and are risk factor models (Framingham Study). Doctors purposefully use statistical models to help identify risk factors. To say this study &amp;#39;calls out doctors&amp;#39; is like saying guns beats soldier at killing the enemy, when in reality this is actually saying something like a tank is better than a rocket launcher for the purpose of dispatching the enemy. This study compares tools.&lt;/p&gt;\n\n&lt;p&gt;Second and probably more important, to project into the future that this would actually save lives simply by identifying those at risk is also a stretch. It certainly helps and we&amp;#39;re grateful for new tools, but the timeline between risk factors (what was identified here) and outcomes (the cardiac event they hope to prevent) relies on what interventions can be implemented in between, if the patient is adherent with those recommendations, and how effective those interventions are. All of those steps - from risk factor identification, to prevention, and then treatment - are what doctors do.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgan4oa", "score_hidden": false, "stickied": false, "created": 1492291832.0, "created_utc": 1492263032.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgapc2j", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "TheDyingLight", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "One piece that seems to explain the increase in predictive value is that the algorithm was allowed to use more variables. The AI algorithm had access to more information.\n\nWe already have docs that order additional lab testing to get a more complete picture than what the traditional guidelines recommend. Perhaps they also have better predictive rates than the standard algorithm?\n\nIf we want an apples to apples comparison, shouldn't the AI algorithm only have the same variables as the docs?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;One piece that seems to explain the increase in predictive value is that the algorithm was allowed to use more variables. The AI algorithm had access to more information.&lt;/p&gt;\n\n&lt;p&gt;We already have docs that order additional lab testing to get a more complete picture than what the traditional guidelines recommend. Perhaps they also have better predictive rates than the standard algorithm?&lt;/p&gt;\n\n&lt;p&gt;If we want an apples to apples comparison, shouldn&amp;#39;t the AI algorithm only have the same variables as the docs?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgapc2j", "score_hidden": false, "stickied": false, "created": 1492295649.0, "created_utc": 1492266849.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaq6st", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Mr_Dugan", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The article is grossly sensationalized. The study is comparing the current risk calculator to different risk calculators. It's not Humans vs AI its models vs models. The study is pretty boring and the predictive variables in the new models don't all make sense. As an example, the neural networks found the variable \"BMI missing\" to be predictive of heart attack....what the hell am I supposed to do with that?!?\n\nAlso, the caption under the picture mentions preventing heart failure and heart failure isn't mentioned in the journal article at all", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The article is grossly sensationalized. The study is comparing the current risk calculator to different risk calculators. It&amp;#39;s not Humans vs AI its models vs models. The study is pretty boring and the predictive variables in the new models don&amp;#39;t all make sense. As an example, the neural networks found the variable &amp;quot;BMI missing&amp;quot; to be predictive of heart attack....what the hell am I supposed to do with that?!?&lt;/p&gt;\n\n&lt;p&gt;Also, the caption under the picture mentions preventing heart failure and heart failure isn&amp;#39;t mentioned in the journal article at all&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaq6st", "score_hidden": false, "stickied": false, "created": 1492296957.0, "created_utc": 1492268157.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaldfj", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "Aelinsaar", "parent_id": "t1_dgak7l8", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt;The problem with machine learning algorithms is that they learn based on data supplied.\n\n...As opposed to humans, who generate their learning through magic and candy? Drug manufacturers manipulate humans by manipulating data, and also just bribing them... ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The problem with machine learning algorithms is that they learn based on data supplied.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;...As opposed to humans, who generate their learning through magic and candy? Drug manufacturers manipulate humans by manipulating data, and also just bribing them... &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaldfj", "score_hidden": false, "stickied": false, "created": 1492288194.0, "created_utc": 1492259394.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgak7l8", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "VPee", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The problem with machine learning algorithms is that they learn based on data supplied. If drug manufacturers can manipulate the data flowing it and create a bias it will definitely lead to a positive outcome for their drugs being recommended. Example - Statins the most over prescribed medications with inadequate data points to link to preventing heart attacks (first time)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem with machine learning algorithms is that they learn based on data supplied. If drug manufacturers can manipulate the data flowing it and create a bias it will definitely lead to a positive outcome for their drugs being recommended. Example - Statins the most over prescribed medications with inadequate data points to link to preventing heart attacks (first time)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak7l8", "score_hidden": false, "stickied": false, "created": 1492285299.0, "created_utc": 1492256499.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgadjap", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ronzohar", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Did anyone find a link to the Plos One research paper?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did anyone find a link to the Plos One research paper?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgadjap", "score_hidden": false, "stickied": false, "created": 1492265982.0, "created_utc": 1492237182.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaofxw", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Darknavigator2233", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "So are you daying a talented nurse couldnt have the deft hand eye coordination.  My main point is all the left over skills not automated bt AI would be approachable in a practical manner by a lot more people.  The hard part of being a doctor is the knowledge and analytics which a machine is already starting to do better.  \n\nBefore the assembly line cars were built by specialty machinists afterwards it was built by less talented people who only had to get very profficient at a few smaller subtasks.  \n\nIm say AI is like the assembly line for the mind. It potentially makes a really hard profession like a doctor more manageable by removing the need to generate all aspects of treatment just as no one worker was required to build the car.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So are you daying a talented nurse couldnt have the deft hand eye coordination.  My main point is all the left over skills not automated bt AI would be approachable in a practical manner by a lot more people.  The hard part of being a doctor is the knowledge and analytics which a machine is already starting to do better.  &lt;/p&gt;\n\n&lt;p&gt;Before the assembly line cars were built by specialty machinists afterwards it was built by less talented people who only had to get very profficient at a few smaller subtasks.  &lt;/p&gt;\n\n&lt;p&gt;Im say AI is like the assembly line for the mind. It potentially makes a really hard profession like a doctor more manageable by removing the need to generate all aspects of treatment just as no one worker was required to build the car.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaofxw", "score_hidden": false, "stickied": false, "created": 1492294182.0, "created_utc": 1492265382.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaowcw", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "blove1150r", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Mass media often leaves out that AI requires sharp software developers writing algorithms to attack the problem at hand. Yes the software learned on its own but without human coders it would have accomplished very little. \n\nAnd AI is custom to a problem being solved. One AI algorithm for face recognition won't be useful for a AI communicator.\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Mass media often leaves out that AI requires sharp software developers writing algorithms to attack the problem at hand. Yes the software learned on its own but without human coders it would have accomplished very little. &lt;/p&gt;\n\n&lt;p&gt;And AI is custom to a problem being solved. One AI algorithm for face recognition won&amp;#39;t be useful for a AI communicator.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaowcw", "score_hidden": false, "stickied": false, "created": 1492294941.0, "created_utc": 1492266141.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaqt0o", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaqt0o", "score_hidden": false, "stickied": false, "created": 1492297871.0, "created_utc": 1492269071.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgaquoz", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Darknavigator2233", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Automated cars are changing governments notions of this.  They are allowing black box machines to drive on our roads without complete understanding of its moral algorithm. I.e the trolly car problem.  It will be a really tough ethics debate but I dont think there is much that will stop machines in the realm of medicine because the designers will make the same argument as automous car manufacturers.  The good far outways the bad of granting the AI autonomy limited to its domain.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Automated cars are changing governments notions of this.  They are allowing black box machines to drive on our roads without complete understanding of its moral algorithm. I.e the trolly car problem.  It will be a really tough ethics debate but I dont think there is much that will stop machines in the realm of medicine because the designers will make the same argument as automous car manufacturers.  The good far outways the bad of granting the AI autonomy limited to its domain.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaquoz", "score_hidden": false, "stickied": false, "created": 1492297934.0, "created_utc": 1492269134.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgas4xn", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Hexomin", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This seems highly misleading, to the point where the headline is essentially incorrect. It wasn't superior to doctors, it was better than the ACC/AHA guidelines, which isn't surprising considering the guidelines use only eight pieces of information while their model used 30. Basically, algorithms with more data performed better than an algorithm with less.\n\nThe ACC/AHA guidelines only include so much. Plenty of known cardiovascular risk factors are not included in them. For example, this study showed that atrial fibrillation is associated with an increased risk of CVD. Everyone already knows this. That's why people with AF are usually put on anticoagulants. This certainly shouldn't be news to any doctor.\n\nThis study shows that the current guidelines may need some revision, and definitely shows that expert systems are going to play an increasingly important role in medicine in the future. However, the headline about the new algorithm beating doctors at predicting heart attacks is so misleading as to be essentially wrong.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This seems highly misleading, to the point where the headline is essentially incorrect. It wasn&amp;#39;t superior to doctors, it was better than the ACC/AHA guidelines, which isn&amp;#39;t surprising considering the guidelines use only eight pieces of information while their model used 30. Basically, algorithms with more data performed better than an algorithm with less.&lt;/p&gt;\n\n&lt;p&gt;The ACC/AHA guidelines only include so much. Plenty of known cardiovascular risk factors are not included in them. For example, this study showed that atrial fibrillation is associated with an increased risk of CVD. Everyone already knows this. That&amp;#39;s why people with AF are usually put on anticoagulants. This certainly shouldn&amp;#39;t be news to any doctor.&lt;/p&gt;\n\n&lt;p&gt;This study shows that the current guidelines may need some revision, and definitely shows that expert systems are going to play an increasingly important role in medicine in the future. However, the headline about the new algorithm beating doctors at predicting heart attacks is so misleading as to be essentially wrong.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgas4xn", "score_hidden": false, "stickied": false, "created": 1492299757.0, "created_utc": 1492270957.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgawpav", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "AOEUD", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Someone in my lab did scoliosis progression using this method.\n\nHis program beat the snot out of two orthopaedic surgeons and a number of physicians and orthotists, but was completely trashed by a nurse practitioner.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Someone in my lab did scoliosis progression using this method.&lt;/p&gt;\n\n&lt;p&gt;His program beat the snot out of two orthopaedic surgeons and a number of physicians and orthotists, but was completely trashed by a nurse practitioner.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgawpav", "score_hidden": false, "stickied": false, "created": 1492306093.0, "created_utc": 1492277293.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgb26r3", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "RaspberryBliss", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I hadn't thought doctors would have any particularly great skill at *predicting* heart attacks. Their job is to treat ailments, not predict them.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I hadn&amp;#39;t thought doctors would have any particularly great skill at &lt;em&gt;predicting&lt;/em&gt; heart attacks. Their job is to treat ailments, not predict them.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgb26r3", "score_hidden": false, "stickied": false, "created": 1492313508.0, "created_utc": 1492284708.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65gf8q", "likes": null, "replies": "", "user_reports": [], "id": "dgbxsdh", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "mkmlls743", "parent_id": "t3_65gf8q", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "the majority of doctors are ego fueled by all the books and test they took so they stop learning thinking they already have climbed the mountain. a computer does not have to battle an ego. this alone will make it better than any human and there is so much more to be happy about when discussing taking away the decision making  from faulty humans. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the majority of doctors are ego fueled by all the books and test they took so they stop learning thinking they already have climbed the mountain. a computer does not have to battle an ego. this alone will make it better than any human and there is so much more to be happy about when discussing taking away the decision making  from faulty humans. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgbxsdh", "score_hidden": false, "stickied": false, "created": 1492370670.0, "created_utc": 1492341870.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "more"}], "after": null, "before": null}}]