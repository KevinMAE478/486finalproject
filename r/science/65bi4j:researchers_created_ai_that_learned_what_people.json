[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "science", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": "confidence", "user_reports": [], "secure_media": null, "link_flair_text": "Computer Science", "id": "65bi4j", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 81, "report_reasons": null, "author": "the_phet", "saved": false, "mod_reports": [], "name": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "approved_by": null, "over_18": false, "domain": "science.sciencemag.org", "hidden": false, "preview": {"images": [{"source": {"url": "https://i.redditmedia.com/ONbWejyK8frqdBIT4MlyVLRJ5wnaO2oopAkOTXFmvpA.jpg?s=1a090d7be969152ec115402991fab1ea", "width": 346, "height": 440}, "resolutions": [{"url": "https://i.redditmedia.com/ONbWejyK8frqdBIT4MlyVLRJ5wnaO2oopAkOTXFmvpA.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=108&amp;s=e5201f3d73f175c2497f5d4b1f1e8b60", "width": 108, "height": 137}, {"url": "https://i.redditmedia.com/ONbWejyK8frqdBIT4MlyVLRJ5wnaO2oopAkOTXFmvpA.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=216&amp;s=5764d72acbb3dfbb933d9a9fd3d998e0", "width": 216, "height": 274}, {"url": "https://i.redditmedia.com/ONbWejyK8frqdBIT4MlyVLRJ5wnaO2oopAkOTXFmvpA.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=320&amp;s=6d33ea8dbcd43052d685ad5c463cc56d", "width": 320, "height": 406}], "variants": {}, "id": "W0v6D34qbhNPvgat7OBqSVd-sND-3BGy9Xsmg0lFAus"}], "enabled": false}, "thumbnail": "https://b.thumbs.redditmedia.com/ZypZtk-MUiONSXfKkgjH-EZuSlZtL5kJrlu7xWNLpaA.jpg", "subreddit_id": "t5_mouw", "edited": false, "link_flair_css_class": "compsci", "author_flair_css_class": "  reward1", "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "post_hint": "link", "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/science/comments/65bi4j/researchers_created_ai_that_learned_what_people/", "num_reports": null, "locked": false, "stickied": false, "created": 1492189301.0, "url": "http://science.sciencemag.org/content/356/6334/183", "author_flair_text": null, "quarantine": false, "title": "Researchers created A.I. that learned what people know implicitly by analysing millions of texts and words association. In doing so the A.I. acquired biases against race and gender", "created_utc": 1492160501.0, "distinguished": null, "media": null, "upvote_ratio": 0.8, "num_comments": 43, "visited": false, "subreddit_type": "public", "ups": 81}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dg9jmgo", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "positive_electron42", "parent_id": "t1_dg9g1se", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Fair enough - bad data may not be the only problem. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair enough - bad data may not be the only problem. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9jmgo", "score_hidden": false, "stickied": false, "created": 1492223709.0, "created_utc": 1492194909.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9g1se", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "PM_ME_AWKWARD", "parent_id": "t1_dg98b6b", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I wouldn't say it's garbage in and garbage out, because that assumes given good data the method will produce good reliable results. I'm not sure that's true of the Implicit Association Test.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wouldn&amp;#39;t say it&amp;#39;s garbage in and garbage out, because that assumes given good data the method will produce good reliable results. I&amp;#39;m not sure that&amp;#39;s true of the Implicit Association Test.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9g1se", "score_hidden": false, "stickied": false, "created": 1492219504.0, "created_utc": 1492190704.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg98b6b", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "positive_electron42", "parent_id": "t1_dg94qpv", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "That's what I was thinking - garbage in, garbage out. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s what I was thinking - garbage in, garbage out. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg98b6b", "score_hidden": false, "stickied": false, "created": 1492210593.0, "created_utc": 1492181793.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgapbyy", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Bowgentle", "parent_id": "t1_dgal6hg", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt; But the same code is used in things like translation and web search, so it can affect some AI outputs.\n\nAnd similar code is being pushed in other fields where the training data comprises a corpus of human judgements (which may even have been made under different legal/social conditions from those the resulting AI is to be applied under).\n\nIt's not a criticism of AI to say this - it's a criticism of unthinking use of it (and indeed of any data set). Current AI, because it *can* cope analytically with large data sets, doesn't need to use the kind of heuristics that human judgement is often based on - it seems a pity to unthinkingly have it replicate those heuristics as a result of thoughtless training.\n\nUnfortunately, first one has to recognise that the data may contain biases, and that's traditionally a difficult thing for people to do. The response to this research in several threads here suggests that a common initial reaction to biased input is to seek a defensive narrative that 'justifies' the resulting biased output - although whether that's to justify one's own existing biases, political agenda, or least effort is hard to say.\n\nVery interesting research, by the way - congratulations and thanks!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;But the same code is used in things like translation and web search, so it can affect some AI outputs.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;And similar code is being pushed in other fields where the training data comprises a corpus of human judgements (which may even have been made under different legal/social conditions from those the resulting AI is to be applied under).&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not a criticism of AI to say this - it&amp;#39;s a criticism of unthinking use of it (and indeed of any data set). Current AI, because it &lt;em&gt;can&lt;/em&gt; cope analytically with large data sets, doesn&amp;#39;t need to use the kind of heuristics that human judgement is often based on - it seems a pity to unthinkingly have it replicate those heuristics as a result of thoughtless training.&lt;/p&gt;\n\n&lt;p&gt;Unfortunately, first one has to recognise that the data may contain biases, and that&amp;#39;s traditionally a difficult thing for people to do. The response to this research in several threads here suggests that a common initial reaction to biased input is to seek a defensive narrative that &amp;#39;justifies&amp;#39; the resulting biased output - although whether that&amp;#39;s to justify one&amp;#39;s own existing biases, political agenda, or least effort is hard to say.&lt;/p&gt;\n\n&lt;p&gt;Very interesting research, by the way - congratulations and thanks!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgapbyy", "score_hidden": false, "stickied": false, "created": 1492295645.0, "created_utc": 1492266845.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgal6hg", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg9jv34", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "right.  We just used a bit of AI as a tool to look at human language.  But the same code is used in things like translation and web search, so it can affect some AI outputs.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;right.  We just used a bit of AI as a tool to look at human language.  But the same code is used in things like translation and web search, so it can affect some AI outputs.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgal6hg", "score_hidden": false, "stickied": false, "created": 1492287740.0, "created_utc": 1492258940.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9jv34", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Bowgentle", "parent_id": "t1_dg9dwaj", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This kind of \"AI\" doesn't think at all. It's just a way of finding statistical correlations in large multidimensional data sets. That's all it's doing.\n\nAs such, feed it biased data and its findings will reflect those biases.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This kind of &amp;quot;AI&amp;quot; doesn&amp;#39;t think at all. It&amp;#39;s just a way of finding statistical correlations in large multidimensional data sets. That&amp;#39;s all it&amp;#39;s doing.&lt;/p&gt;\n\n&lt;p&gt;As such, feed it biased data and its findings will reflect those biases.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9jv34", "score_hidden": false, "stickied": false, "created": 1492223995.0, "created_utc": 1492195195.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dg9qutd", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "minimicronano", "parent_id": "t1_dg9ecp1", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Well if people are statistically biased then the computer will be too", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well if people are statistically biased then the computer will be too&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9qutd", "score_hidden": false, "stickied": false, "created": 1492232429.0, "created_utc": 1492203629.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ecp1", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "sidefx00", "parent_id": "t1_dg9e4sc", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "From what I understand, it's not designed to think the way humans think.  I am no expert this in this field, but I believe most of machine learning is based on statistics. \n\nHere is a Wiki link: https://en.wikipedia.org/wiki/Machine_learning\n\nBut I think if we could get machines to learn the way humans think, we'd have a major breakthrough. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From what I understand, it&amp;#39;s not designed to think the way humans think.  I am no expert this in this field, but I believe most of machine learning is based on statistics. &lt;/p&gt;\n\n&lt;p&gt;Here is a Wiki link: &lt;a href=\"https://en.wikipedia.org/wiki/Machine_learning\"&gt;https://en.wikipedia.org/wiki/Machine_learning&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;But I think if we could get machines to learn the way humans think, we&amp;#39;d have a major breakthrough. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9ecp1", "score_hidden": false, "stickied": false, "created": 1492217565.0, "created_utc": 1492188765.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9e4sc", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "tribal_thinking", "parent_id": "t1_dg9dwaj", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "If it's designed to read between the lines and learn to think the way humans think...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If it&amp;#39;s designed to read between the lines and learn to think the way humans think...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9e4sc", "score_hidden": false, "stickied": false, "created": 1492217319.0, "created_utc": 1492188519.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dg9l9ma", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "coyotesage", "parent_id": "t1_dg9earv", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I think it would be interesting if it could help us understand why some people reject their upbringing rather than engage it.  For instance, I'm an atheist, but I grew up in a devout family.  Despite being devout, they were never cruel to me for my lack of interest in religion and ultimate dismissal of it, and I never felt any need to rebel on such a basis. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it would be interesting if it could help us understand why some people reject their upbringing rather than engage it.  For instance, I&amp;#39;m an atheist, but I grew up in a devout family.  Despite being devout, they were never cruel to me for my lack of interest in religion and ultimate dismissal of it, and I never felt any need to rebel on such a basis. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9l9ma", "score_hidden": false, "stickied": false, "created": 1492225688.0, "created_utc": 1492196888.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9earv", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "iaanacho", "parent_id": "t1_dg9dwaj", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I'm no AI programmer specialist but they're using stuff we made as a learning tool, think of it like this, if you grew up in North Korea learning that Kim Jong-un was a God and all that propaganda, then you would believe that and form your personalityaround such knowledge. Since they don't seem to be having the thing learn straight off of textbooks and dictionaries but more human materials then it would definitely be more human in a sense and form biases", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m no AI programmer specialist but they&amp;#39;re using stuff we made as a learning tool, think of it like this, if you grew up in North Korea learning that Kim Jong-un was a God and all that propaganda, then you would believe that and form your personalityaround such knowledge. Since they don&amp;#39;t seem to be having the thing learn straight off of textbooks and dictionaries but more human materials then it would definitely be more human in a sense and form biases&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9earv", "score_hidden": false, "stickied": false, "created": 1492217504.0, "created_utc": 1492188704.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgal5le", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg9dwaj", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "It isn't that all AI has to be biased.  We just used one specific kind of AI that is built to understand human language.  What's really cool about the outcome is that this shows something fundamental about cognitive science, about the meaning of language. It supports the theory that a word's meaning is exactly the contexts in which it's used.  Mostly that is awesome; we showed you can learn basic visceral facts about the world just from patterns in language.  But it does mean that the bad comes with the good -- the facts of our history we don't like as well as the fast majority of stuff which is useful.  I tried to clear this up with a blogpost.  https://joanna-bryson.blogspot.co.uk/2017/04/we-didnt-prove-prejudice-is-true-role.html", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It isn&amp;#39;t that all AI has to be biased.  We just used one specific kind of AI that is built to understand human language.  What&amp;#39;s really cool about the outcome is that this shows something fundamental about cognitive science, about the meaning of language. It supports the theory that a word&amp;#39;s meaning is exactly the contexts in which it&amp;#39;s used.  Mostly that is awesome; we showed you can learn basic visceral facts about the world just from patterns in language.  But it does mean that the bad comes with the good -- the facts of our history we don&amp;#39;t like as well as the fast majority of stuff which is useful.  I tried to clear this up with a blogpost.  &lt;a href=\"https://joanna-bryson.blogspot.co.uk/2017/04/we-didnt-prove-prejudice-is-true-role.html\"&gt;https://joanna-bryson.blogspot.co.uk/2017/04/we-didnt-prove-prejudice-is-true-role.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgal5le", "score_hidden": false, "stickied": false, "created": 1492287678.0, "created_utc": 1492258878.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9dwaj", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "sidefx00", "parent_id": "t1_dg94qpv", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Why would the AI be biases since a human is biases?  The architecture of the AI 'brain' as I understand it isn't the same as our biological brain.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why would the AI be biases since a human is biases?  The architecture of the AI &amp;#39;brain&amp;#39; as I understand it isn&amp;#39;t the same as our biological brain.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9dwaj", "score_hidden": false, "stickied": false, "created": 1492217052.0, "created_utc": 1492188252.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgal2nw", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg94qpv", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Hi -- it's based on English language scrapes of the world wide web.  To ensure we didn't introduce bias ourselves, we just used off-the-shelf corpora.  We had to use the biggest we could find though because some of the terms were very low-frequency (to be specific, the African American names).  The main article shows results from Stanford's Common Crawl corpus, and the word embeddings are created using their GLoVe algorithm.  There's a similar table of results in the supplementary material that is based on Google's own News scrape, and the word2vec word embeddings they created.  The results are almost the same, showing these results hold for two different large sets of data and two different algorithms for creating word embeddings.  All those corpora and software are available free for download from the people who made them.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hi -- it&amp;#39;s based on English language scrapes of the world wide web.  To ensure we didn&amp;#39;t introduce bias ourselves, we just used off-the-shelf corpora.  We had to use the biggest we could find though because some of the terms were very low-frequency (to be specific, the African American names).  The main article shows results from Stanford&amp;#39;s Common Crawl corpus, and the word embeddings are created using their GLoVe algorithm.  There&amp;#39;s a similar table of results in the supplementary material that is based on Google&amp;#39;s own News scrape, and the word2vec word embeddings they created.  The results are almost the same, showing these results hold for two different large sets of data and two different algorithms for creating word embeddings.  All those corpora and software are available free for download from the people who made them.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgal2nw", "score_hidden": false, "stickied": false, "created": 1492287482.0, "created_utc": 1492258682.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgaptkf", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "NeoconnoissaurusRex", "parent_id": "t1_dg94qpv", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I think it's likely AI would develop biases regardless. Statistical correlation is hugely useful data. If a program is hiring people for a job to get the best candidate possible, surely it would take into account race, gender, mental health, and a host of other uncomfortable factors. \n\nThe reason we shouldn't discriminate is not because it isn't statistically useful, it's because as human beings we've (mostly) decided it's a moral prerogative to ensure that all people receive a \"fair shake\" and aren't condemned to a certain life based on factors they had no control over, and because we (mostly) realize that people who have an outsized effect on the world (Einsteins, Curies, MLKs) can come from any background however statically unlikely, and missing out on those rare individuals talents is an incredible opportunity loss. \n\nDiscrimination makes perfect sense on a selfish short term basis, it's just detrimental on a long term communal basis.  \n\nAs a tall white male, I benefit greatly from our society's stigma on physical biases. But I might not have been. My children might not be. My friends and family might not be. I recognize that were all in this together, and that most racial and gender statistical differences derive from the inertia of past societies and cultures, not inherent traits. \n\nI don't think AI would care about that, and would put more value on the short term benefits of racism, sexism and other biases. You can program it however you want sure, but real AI won't really be programmed, it will program itself, and we just have to see what happens.   ", "edited": 1492268166.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s likely AI would develop biases regardless. Statistical correlation is hugely useful data. If a program is hiring people for a job to get the best candidate possible, surely it would take into account race, gender, mental health, and a host of other uncomfortable factors. &lt;/p&gt;\n\n&lt;p&gt;The reason we shouldn&amp;#39;t discriminate is not because it isn&amp;#39;t statistically useful, it&amp;#39;s because as human beings we&amp;#39;ve (mostly) decided it&amp;#39;s a moral prerogative to ensure that all people receive a &amp;quot;fair shake&amp;quot; and aren&amp;#39;t condemned to a certain life based on factors they had no control over, and because we (mostly) realize that people who have an outsized effect on the world (Einsteins, Curies, MLKs) can come from any background however statically unlikely, and missing out on those rare individuals talents is an incredible opportunity loss. &lt;/p&gt;\n\n&lt;p&gt;Discrimination makes perfect sense on a selfish short term basis, it&amp;#39;s just detrimental on a long term communal basis.  &lt;/p&gt;\n\n&lt;p&gt;As a tall white male, I benefit greatly from our society&amp;#39;s stigma on physical biases. But I might not have been. My children might not be. My friends and family might not be. I recognize that were all in this together, and that most racial and gender statistical differences derive from the inertia of past societies and cultures, not inherent traits. &lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think AI would care about that, and would put more value on the short term benefits of racism, sexism and other biases. You can program it however you want sure, but real AI won&amp;#39;t really be programmed, it will program itself, and we just have to see what happens.   &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaptkf", "score_hidden": false, "stickied": false, "created": 1492296393.0, "created_utc": 1492267593.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg94qpv", "gilded": 0, "archived": false, "score": 19, "report_reasons": null, "author": "iaanacho", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Well it would seem likely that a learning ai would gain biases since humanity is biased. Also race &amp; gender(sexuality) are hot topics these days. I wonder what pool of information they used as the knowledge base.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well it would seem likely that a learning ai would gain biases since humanity is biased. Also race &amp;amp; gender(sexuality) are hot topics these days. I wonder what pool of information they used as the knowledge base.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg94qpv", "score_hidden": false, "stickied": false, "created": 1492205709.0, "created_utc": 1492176909.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 19}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dg8y1wr", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "the_phet", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "More here: http://www.sciencemag.org/news/2017/04/even-artificial-intelligence-can-acquire-biases-against-race-and-gender", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More here: &lt;a href=\"http://www.sciencemag.org/news/2017/04/even-artificial-intelligence-can-acquire-biases-against-race-and-gender\"&gt;http://www.sciencemag.org/news/2017/04/even-artificial-intelligence-can-acquire-biases-against-race-and-gender&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg8y1wr", "score_hidden": false, "stickied": false, "created": 1492189318.0, "created_utc": 1492160518.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgaomyo", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "hunbadger", "parent_id": "t1_dgandsi", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "&gt;How do you think the statistical regularities got into the original IAT results that got published through peer review? And how do you account for the correlation between those results and this entirely different method?\n\nBecause they fit the biases of the peer reviewers? You're not foolish enough to believe that anything that passes peer review is true are you? You know that \"passing peer review\" doesn't mean \"incontrovertible science\" right? Because you seem to be very confused. \n\nThe \"statistical regularities\" in the IAT test DO NOT demonstrate an unconscious bias that implies any type of discrimination. It is incredibly dishonest of anyone to suggest that it does. If you didn't read the original paper and are instead depending on second hand sources that lied to you, I recommend you do some reading about how much of a sham the original test is by people critiquing it, rather than take the original work as true because it passed \"peer review\". \n\nAs to how to account for correlation. Well it could be as simple as correlation mining by junk scientists looking to push a political agenda. That would be one way, for example. Do you know what correlation mining is?\n\n&gt;You can redefine \"implicit bias\" to mean something that the IAT doesn't show, e.g shoe colour, deliberate intention, whatever. But these biases are indeed replicable and have been replicated, there's a large literature showing that.\n\nAnd all of it can easily be explained as novelty detection by humans. There's no reason to assume it's bias other than, ironically, the bias of authors looking to push a political agenda.\n\nThis is junk science. It should never have been published as it shows nothing close to what it claims.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;How do you think the statistical regularities got into the original IAT results that got published through peer review? And how do you account for the correlation between those results and this entirely different method?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because they fit the biases of the peer reviewers? You&amp;#39;re not foolish enough to believe that anything that passes peer review is true are you? You know that &amp;quot;passing peer review&amp;quot; doesn&amp;#39;t mean &amp;quot;incontrovertible science&amp;quot; right? Because you seem to be very confused. &lt;/p&gt;\n\n&lt;p&gt;The &amp;quot;statistical regularities&amp;quot; in the IAT test DO NOT demonstrate an unconscious bias that implies any type of discrimination. It is incredibly dishonest of anyone to suggest that it does. If you didn&amp;#39;t read the original paper and are instead depending on second hand sources that lied to you, I recommend you do some reading about how much of a sham the original test is by people critiquing it, rather than take the original work as true because it passed &amp;quot;peer review&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;As to how to account for correlation. Well it could be as simple as correlation mining by junk scientists looking to push a political agenda. That would be one way, for example. Do you know what correlation mining is?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You can redefine &amp;quot;implicit bias&amp;quot; to mean something that the IAT doesn&amp;#39;t show, e.g shoe colour, deliberate intention, whatever. But these biases are indeed replicable and have been replicated, there&amp;#39;s a large literature showing that.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;And all of it can easily be explained as novelty detection by humans. There&amp;#39;s no reason to assume it&amp;#39;s bias other than, ironically, the bias of authors looking to push a political agenda.&lt;/p&gt;\n\n&lt;p&gt;This is junk science. It should never have been published as it shows nothing close to what it claims.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgaomyo", "score_hidden": false, "stickied": false, "created": 1492294511.0, "created_utc": 1492265711.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgandsi", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dgalcgm", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "How do you think the statistical regularities got into the original IAT results that got published through peer review?  And how do you account for the correlation between those results and this entirely different method?\n\nYou can redefine \"implicit bias\" to mean something that the IAT doesn't show, e.g shoe colour, deliberate intention, whatever.  But these biases are indeed replicable and have been replicated, there's a large literature showing that.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How do you think the statistical regularities got into the original IAT results that got published through peer review?  And how do you account for the correlation between those results and this entirely different method?&lt;/p&gt;\n\n&lt;p&gt;You can redefine &amp;quot;implicit bias&amp;quot; to mean something that the IAT doesn&amp;#39;t show, e.g shoe colour, deliberate intention, whatever.  But these biases are indeed replicable and have been replicated, there&amp;#39;s a large literature showing that.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgandsi", "score_hidden": false, "stickied": false, "created": 1492292301.0, "created_utc": 1492263501.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgalcgm", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "hunbadger", "parent_id": "t1_dgal8s9", "subreddit_name_prefixed": "r/science", "controversiality": 1, "body": "The IAT is not easily replicable. It does not have the power you are claiming. The authors even acknowledge this in the original paper. One author is quite pissed at the useful idiots who are pushing it further than it has any scientific merit of going, while the other is an ideologue who is pleased as punch that their research is being used without any scientific basis for it.\n\nSo I'm sorry, but you're completely wrong. There is no evidence that the IAT proves anything about implicit bias. None what so ever. And people pushing it, such as yourself, should be ashamed at the appalling lack of rigor they're bringing to the scientific world.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The IAT is not easily replicable. It does not have the power you are claiming. The authors even acknowledge this in the original paper. One author is quite pissed at the useful idiots who are pushing it further than it has any scientific merit of going, while the other is an ideologue who is pleased as punch that their research is being used without any scientific basis for it.&lt;/p&gt;\n\n&lt;p&gt;So I&amp;#39;m sorry, but you&amp;#39;re completely wrong. There is no evidence that the IAT proves anything about implicit bias. None what so ever. And people pushing it, such as yourself, should be ashamed at the appalling lack of rigor they&amp;#39;re bringing to the scientific world.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalcgm", "score_hidden": false, "stickied": false, "created": 1492288134.0, "created_utc": 1492259334.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dgal8s9", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg9jels", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The IAT is easily replicable.  The first time I found out about it the scientist speaking (Banaji) illustrated it by writing a \"good\" and \"bad\" interleaved in a random order a bunch of times in a circle, then timed us as we tried to tap our right hand to \"good\" and our left hand to \"bad\", and then the other way around.  It was unbelievably more difficult to do the \"left:good\" \"right:bad\".  This is well proved, well published science.  The fact we have now found support for it in another domain (word embeddings, which are standard commercial technology) is even more validation of the IAT.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The IAT is easily replicable.  The first time I found out about it the scientist speaking (Banaji) illustrated it by writing a &amp;quot;good&amp;quot; and &amp;quot;bad&amp;quot; interleaved in a random order a bunch of times in a circle, then timed us as we tried to tap our right hand to &amp;quot;good&amp;quot; and our left hand to &amp;quot;bad&amp;quot;, and then the other way around.  It was unbelievably more difficult to do the &amp;quot;left:good&amp;quot; &amp;quot;right:bad&amp;quot;.  This is well proved, well published science.  The fact we have now found support for it in another domain (word embeddings, which are standard commercial technology) is even more validation of the IAT.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgal8s9", "score_hidden": false, "stickied": false, "created": 1492287894.0, "created_utc": 1492259094.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9jels", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "hunbadger", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The IAT is junk science that cannot be used to determine anything. The fact that it is being propagated and used to make broad sweeping generalizations is completely abhorrent considering it is completely incapable of doing so. \n\nThis is junk science.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The IAT is junk science that cannot be used to determine anything. The fact that it is being propagated and used to make broad sweeping generalizations is completely abhorrent considering it is completely incapable of doing so. &lt;/p&gt;\n\n&lt;p&gt;This is junk science.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9jels", "score_hidden": false, "stickied": false, "created": 1492223440.0, "created_utc": 1492194640.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgalbrp", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg9w9o5", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "That's pretty right, but the one thing is that we did use the words that had already been published in the early IAT papers, before they switched to focus on pictures.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s pretty right, but the one thing is that we did use the words that had already been published in the early IAT papers, before they switched to focus on pictures.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalbrp", "score_hidden": false, "stickied": false, "created": 1492288092.0, "created_utc": 1492259292.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9w9o5", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "PM_ME_AWKWARD", "parent_id": "t1_dg9o7r6", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Just text. They used a statistically analogous test called the Word Embedded Association Test, or WEAT. It took into account many things like word proximity and frequency of use, 300 hundred \"dimensions\" were measured. The resultant data was used to create a vector for each word in 300 dimensional vector space. The distance between two vectors was used as an analog of the time it took humans to make the association on the IAT.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just text. They used a statistically analogous test called the Word Embedded Association Test, or WEAT. It took into account many things like word proximity and frequency of use, 300 hundred &amp;quot;dimensions&amp;quot; were measured. The resultant data was used to create a vector for each word in 300 dimensional vector space. The distance between two vectors was used as an analog of the time it took humans to make the association on the IAT.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9w9o5", "score_hidden": false, "stickied": false, "created": 1492239495.0, "created_utc": 1492210695.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgalb9e", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg9o7r6", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The original IAT used words, but I think they got flack for their word choice and switched to using pictures.  The fact we replicated the IAT findings over what were to be fair some pretty random word choices on their part is really awesome :-)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The original IAT used words, but I think they got flack for their word choice and switched to using pictures.  The fact we replicated the IAT findings over what were to be fair some pretty random word choices on their part is really awesome :-)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalb9e", "score_hidden": false, "stickied": false, "created": 1492288059.0, "created_utc": 1492259259.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9o7r6", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "looks_at_lines", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I remember taking the IAT long ago and remember it as a visual test. Was the AI processing images in addition to text?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I remember taking the IAT long ago and remember it as a visual test. Was the AI processing images in addition to text?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9o7r6", "score_hidden": false, "stickied": false, "created": 1492229236.0, "created_utc": 1492200436.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgale36", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dga8z31", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "One of the things we say in our article is that in ML/AI, we use the word \"bias\" just to mean \"patterns we found\" that is, knowledge.  What our results indicate (particularly the WEFAT bits, the graphs with the coloured dots) is that stereotypes are just biases society has decided we need to change.  I think it's great that society wants everyone to have a shot at a cool career, but I don't think anyone wants you to not be afraid of firearms.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;One of the things we say in our article is that in ML/AI, we use the word &amp;quot;bias&amp;quot; just to mean &amp;quot;patterns we found&amp;quot; that is, knowledge.  What our results indicate (particularly the WEFAT bits, the graphs with the coloured dots) is that stereotypes are just biases society has decided we need to change.  I think it&amp;#39;s great that society wants everyone to have a shot at a cool career, but I don&amp;#39;t think anyone wants you to not be afraid of firearms.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgale36", "score_hidden": false, "stickied": false, "created": 1492288234.0, "created_utc": 1492259434.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga8z31", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "beachbbqlover", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "I have a bias against people who point firearms at me, or flay small children.\n\nDo I need to change?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have a bias against people who point firearms at me, or flay small children.&lt;/p&gt;\n\n&lt;p&gt;Do I need to change?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga8z31", "score_hidden": false, "stickied": false, "created": 1492257325.0, "created_utc": 1492228525.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgallrf", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "tuckmyjunksofast", "parent_id": "t1_dgalfvc", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "News is biased towards negative stories.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;News is biased towards negative stories.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgallrf", "score_hidden": false, "stickied": false, "created": 1492288698.0, "created_utc": 1492259898.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgalfvc", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dgak8ak", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "This *might* be an issue, but the google news / word2vec stuff is from the news, not just random stuff, and also the original IAT results were run on just normal people.  Our article suggests the gender stuff comes out of history.  If you want to see our my best guess at the race stuff, read this blog post: https://joanna-bryson.blogspot.co.uk/2017/04/we-didnt-prove-prejudice-is-true-role.html", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This &lt;em&gt;might&lt;/em&gt; be an issue, but the google news / word2vec stuff is from the news, not just random stuff, and also the original IAT results were run on just normal people.  Our article suggests the gender stuff comes out of history.  If you want to see our my best guess at the race stuff, read this blog post: &lt;a href=\"https://joanna-bryson.blogspot.co.uk/2017/04/we-didnt-prove-prejudice-is-true-role.html\"&gt;https://joanna-bryson.blogspot.co.uk/2017/04/we-didnt-prove-prejudice-is-true-role.html&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalfvc", "score_hidden": false, "stickied": false, "created": 1492288343.0, "created_utc": 1492259543.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgak8ak", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgak8ak", "score_hidden": false, "stickied": false, "created": 1492285354.0, "created_utc": 1492256554.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgalhs4", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dga6ryi", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Of course you have the choice.  You could go read a physical book in a field instead of posting on reddit!  But there are all kinds of AI; a lot is programmed by hand, not trained off of big data like this study.  And you are right, that may have other problems.  I really like the new Guardian editorial about this.  https://www.theguardian.com/commentisfree/2017/apr/14/the-guardian-view-on-computers-and-language-reproducing-bias", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Of course you have the choice.  You could go read a physical book in a field instead of posting on reddit!  But there are all kinds of AI; a lot is programmed by hand, not trained off of big data like this study.  And you are right, that may have other problems.  I really like the new Guardian editorial about this.  &lt;a href=\"https://www.theguardian.com/commentisfree/2017/apr/14/the-guardian-view-on-computers-and-language-reproducing-bias\"&gt;https://www.theguardian.com/commentisfree/2017/apr/14/the-guardian-view-on-computers-and-language-reproducing-bias&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgalhs4", "score_hidden": false, "stickied": false, "created": 1492288461.0, "created_utc": 1492259661.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6ryi", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "PoliticalWolf", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "All tech and every algorithm by its nature is created by humans, so everything we use is a blend of biases and motivations in our digital landscape. The real question is why do we keep posting our entire lives online for free to be sold by whoever wants to advertise to you.. oh wait we don't have a choice", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;All tech and every algorithm by its nature is created by humans, so everything we use is a blend of biases and motivations in our digital landscape. The real question is why do we keep posting our entire lives online for free to be sold by whoever wants to advertise to you.. oh wait we don&amp;#39;t have a choice&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dga6ryi", "score_hidden": false, "stickied": false, "created": 1492253872.0, "created_utc": 1492225072.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 0}}, {"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_mouw", "removal_reason": null, "link_id": "t3_65bi4j", "likes": null, "replies": "", "user_reports": [], "id": "dgala9f", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Joanna_Bryson", "parent_id": "t1_dg9ecgl", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "Sort of.  Actually, what's very cool is that in experimental economics people have shown there are contexts where the IAT completely fails to predict things like who you cooperate with.  So while a bunch of our behaviour may get run by our unconscious (my psych profs said \"never say subconscious, because it's not less important!), it's also true that our conscious lets us be better than that.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sort of.  Actually, what&amp;#39;s very cool is that in experimental economics people have shown there are contexts where the IAT completely fails to predict things like who you cooperate with.  So while a bunch of our behaviour may get run by our unconscious (my psych profs said &amp;quot;never say subconscious, because it&amp;#39;s not less important!), it&amp;#39;s also true that our conscious lets us be better than that.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dgala9f", "score_hidden": false, "stickied": false, "created": 1492287993.0, "created_utc": 1492259193.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ecgl", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "OldManHadTooMuchWine", "parent_id": "t3_65bi4j", "subreddit_name_prefixed": "r/science", "controversiality": 0, "body": "The subconscious makes decisions the conscious brain doesn't like.  We are all just products of our inputs.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The subconscious makes decisions the conscious brain doesn&amp;#39;t like.  We are all just products of our inputs.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "science", "name": "t1_dg9ecgl", "score_hidden": false, "stickied": false, "created": 1492217557.0, "created_utc": 1492188757.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}]