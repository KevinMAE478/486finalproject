[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "programming", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "657n42", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 54, "report_reasons": null, "author": "speckz", "saved": false, "mod_reports": [], "name": "t3_657n42", "subreddit_name_prefixed": "r/programming", "approved_by": null, "over_18": false, "domain": "technologyreview.com", "hidden": false, "thumbnail": "", "subreddit_id": "t5_2fwo", "edited": false, "link_flair_css_class": null, "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/programming/comments/657n42/theres_a_big_problem_with_ai_no_one_really_knows/", "num_reports": null, "locked": false, "stickied": false, "created": 1492139935.0, "url": "https://www.technologyreview.com/s/604087/the-dark-secret-at-the-heart-of-ai/", "author_flair_text": null, "quarantine": false, "title": "There\u2019s a big problem with AI. No one really knows how the most advanced algorithms do what they do. That could be a problem.", "created_utc": 1492111135.0, "distinguished": null, "media": null, "upvote_ratio": 0.67, "num_comments": 126, "visited": false, "subreddit_type": "public", "ups": 54}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgcu8sz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "falconfetus8", "parent_id": "t1_dg93su6", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Hip stores.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hip stores.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcu8sz", "score_hidden": false, "stickied": false, "created": 1492418382.0, "created_utc": 1492389582.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg93su6", "gilded": 0, "archived": false, "score": -10, "report_reasons": null, "author": "combinatorylogic", "parent_id": "t1_dg8whsu", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Why should anyone care about how hipstors use their crippled language? They think developer = web developer, that API = RPC, that AI = ANN. So what? Fuck hipstors. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why should anyone care about how hipstors use their crippled language? They think developer = web developer, that API = RPC, that AI = ANN. So what? Fuck hipstors. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg93su6", "score_hidden": false, "stickied": false, "created": 1492204198.0, "created_utc": 1492175398.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": -10}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8whsu", "gilded": 0, "archived": false, "score": 28, "report_reasons": null, "author": "mfukar", "parent_id": "t1_dg8gwjp", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "They're already used as synonyms. The battle is lost.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They&amp;#39;re already used as synonyms. The battle is lost.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8whsu", "score_hidden": false, "stickied": false, "created": 1492184458.0, "created_utc": 1492155658.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 28}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8gwjp", "gilded": 0, "archived": false, "score": 59, "report_reasons": null, "author": "devraj7", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; The Dark Secret at the Heart of AI\n\nAt the heart of **neural networks**. Not AI.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The Dark Secret at the Heart of AI&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;At the heart of &lt;strong&gt;neural networks&lt;/strong&gt;. Not AI.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8gwjp", "score_hidden": false, "stickied": false, "created": 1492157739.0, "created_utc": 1492128939.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 59}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9lb4g", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "methodmissin", "parent_id": "t1_dg9hjqc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Yes there are. Usually you only use one like that if you want to detect anomalies in time series data or learn a changing pattern. For example, power consumption by a building. Goes up and down with day and night cycles, seasons, weather cycles. \n\nSo if a piece of equipment has some breakdown, cracks, or some tenant leaves a window open, the network should notice that consumption is outside the predicted norm based on trends. \n\nIn this case the scope of input and output is very narrow and very low risk. It just raises an alert when things look off. \n\nBut there's less advantage to letting a system learn while driving. The range of input and output is vast and the risk is enormous. Further, is the driver involved in training the AI or not? How does the AI know when some behavior is correct given some input?\n\nWhat's the fitness function for avoiding a crash with a bus full of children vs driving over a cliff? In a less contrived example, cutting off another driver, driving five miles over the speed limit, signaling 4.1 seconds before a lane change or 3.898 seconds?\n\nSo the reality is the autonomous car manufacturers will train, groom, evaluate and monitor their pet networks so obsessively that very little behavior will be truly anomalous. And they'll pour hundreds of millions int developing tools and techniques for Network Psychology. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes there are. Usually you only use one like that if you want to detect anomalies in time series data or learn a changing pattern. For example, power consumption by a building. Goes up and down with day and night cycles, seasons, weather cycles. &lt;/p&gt;\n\n&lt;p&gt;So if a piece of equipment has some breakdown, cracks, or some tenant leaves a window open, the network should notice that consumption is outside the predicted norm based on trends. &lt;/p&gt;\n\n&lt;p&gt;In this case the scope of input and output is very narrow and very low risk. It just raises an alert when things look off. &lt;/p&gt;\n\n&lt;p&gt;But there&amp;#39;s less advantage to letting a system learn while driving. The range of input and output is vast and the risk is enormous. Further, is the driver involved in training the AI or not? How does the AI know when some behavior is correct given some input?&lt;/p&gt;\n\n&lt;p&gt;What&amp;#39;s the fitness function for avoiding a crash with a bus full of children vs driving over a cliff? In a less contrived example, cutting off another driver, driving five miles over the speed limit, signaling 4.1 seconds before a lane change or 3.898 seconds?&lt;/p&gt;\n\n&lt;p&gt;So the reality is the autonomous car manufacturers will train, groom, evaluate and monitor their pet networks so obsessively that very little behavior will be truly anomalous. And they&amp;#39;ll pour hundreds of millions int developing tools and techniques for Network Psychology. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9lb4g", "score_hidden": false, "stickied": false, "created": 1492225741.0, "created_utc": 1492196941.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9mmn1", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "tavianator", "parent_id": "t1_dg9hjqc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Generative Adversarial Networks generally don't learn continuously either.  The generator and the discriminator are both trained at the same time, each getting better at its task for each training sample they see (hopefully).  Eventually you have trained a generator and a discriminator, both fixed.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Generative Adversarial Networks generally don&amp;#39;t learn continuously either.  The generator and the discriminator are both trained at the same time, each getting better at its task for each training sample they see (hopefully).  Eventually you have trained a generator and a discriminator, both fixed.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9mmn1", "score_hidden": false, "stickied": false, "created": 1492227328.0, "created_utc": 1492198528.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9hjqc", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Veonik", "parent_id": "t1_dg97dxn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Are there any systems that constantly learn? I had thought adverserial generative networks continuously learn until they produce the actual output. The discriminative part of the network is pre-trained, I assume, but the generative part literally \"teaches\" itself based on acceptance of a result by the discriminative network.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are there any systems that constantly learn? I had thought adverserial generative networks continuously learn until they produce the actual output. The discriminative part of the network is pre-trained, I assume, but the generative part literally &amp;quot;teaches&amp;quot; itself based on acceptance of a result by the discriminative network.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9hjqc", "score_hidden": false, "stickied": false, "created": 1492221246.0, "created_utc": 1492192446.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg97dxn", "gilded": 0, "archived": false, "score": 23, "report_reasons": null, "author": "methodmissin", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This whole comment thread is driven by the assumption that Machine Learning systems actively learn. They don't. Once trained, the neural network is frozen in place.\n\nTypically you start with a big set of training data that's already tagged, and you feed it into the ML model (Neural Network, w/e) and it crystallizes around the inputs and outputs. This is typically extremely computationally intensive because of the complexity and the vast volume of data (you want to train millions of input-output patterns in an hour or day).\n\nThen you freeze it. Then show it new input and let it generate the output based on the crystallization. Determine if it's good enough to drive. Go.\n\nSo the self-driving car is a fixed-state machine. It will never learn to do anything else. The crystallized intelligence is effectively hard-wired. It runs fast on commodity computing hardware. It always makes the same output for the same input.\n\nSo the likelyhood of a given AI having a fault (kill all humans) is fixed at the end of training. The companies producing these AIs will keep producing them iteratively, but they'll mark and monitor every version. The ones with the lowest propensity towards mayhem will be distributed, and the others will be forensically picked apart, understood, and deleted.\n\nThe devices/vehicles containing these intelligences will be recording all the inputs. Since the AI will be fixed, and copyable, the home office will have a copy. They'll be able to run the inputs by it again in simulation, observe the exact same faulty behavior, and debug it until they determine what training data caused the bad behavior.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This whole comment thread is driven by the assumption that Machine Learning systems actively learn. They don&amp;#39;t. Once trained, the neural network is frozen in place.&lt;/p&gt;\n\n&lt;p&gt;Typically you start with a big set of training data that&amp;#39;s already tagged, and you feed it into the ML model (Neural Network, w/e) and it crystallizes around the inputs and outputs. This is typically extremely computationally intensive because of the complexity and the vast volume of data (you want to train millions of input-output patterns in an hour or day).&lt;/p&gt;\n\n&lt;p&gt;Then you freeze it. Then show it new input and let it generate the output based on the crystallization. Determine if it&amp;#39;s good enough to drive. Go.&lt;/p&gt;\n\n&lt;p&gt;So the self-driving car is a fixed-state machine. It will never learn to do anything else. The crystallized intelligence is effectively hard-wired. It runs fast on commodity computing hardware. It always makes the same output for the same input.&lt;/p&gt;\n\n&lt;p&gt;So the likelyhood of a given AI having a fault (kill all humans) is fixed at the end of training. The companies producing these AIs will keep producing them iteratively, but they&amp;#39;ll mark and monitor every version. The ones with the lowest propensity towards mayhem will be distributed, and the others will be forensically picked apart, understood, and deleted.&lt;/p&gt;\n\n&lt;p&gt;The devices/vehicles containing these intelligences will be recording all the inputs. Since the AI will be fixed, and copyable, the home office will have a copy. They&amp;#39;ll be able to run the inputs by it again in simulation, observe the exact same faulty behavior, and debug it until they determine what training data caused the bad behavior.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg97dxn", "score_hidden": false, "stickied": false, "created": 1492209407.0, "created_utc": 1492180607.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 23}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg91jms", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "sirin3", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; \"Drive cars for a few years and then KILL ALL HUMANS!\" But the odds of that are low.\n\nThey need to kill someone in trolley situations. After a while their [ethics circuit might go haywire](http://www.smbc-comics.com/comics/1467643530-20160704.png)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;Drive cars for a few years and then KILL ALL HUMANS!&amp;quot; But the odds of that are low.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;They need to kill someone in trolley situations. After a while their &lt;a href=\"http://www.smbc-comics.com/comics/1467643530-20160704.png\"&gt;ethics circuit might go haywire&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg91jms", "score_hidden": false, "stickied": false, "created": 1492199747.0, "created_utc": 1492170947.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9jl2o", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "k-selectride", "parent_id": "t1_dg9dwhk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Yea but arguing about it is pointless since we'll never come even close to that point in our lifetimes.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yea but arguing about it is pointless since we&amp;#39;ll never come even close to that point in our lifetimes.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9jl2o", "score_hidden": false, "stickied": false, "created": 1492223663.0, "created_utc": 1492194863.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9dwhk", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Creath", "parent_id": "t1_dg998v9", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Future AI need not (will not) bear any resemblance to current AI. The problem is determining the point where this becomes a risk. We need not create an AI with all these capabilities, but a self aware AI that can modify its own code could rapidly become way smarter than we programmed it, at which point this becomes a real issue. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Future AI need not (will not) bear any resemblance to current AI. The problem is determining the point where this becomes a risk. We need not create an AI with all these capabilities, but a self aware AI that can modify its own code could rapidly become way smarter than we programmed it, at which point this becomes a real issue. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9dwhk", "score_hidden": false, "stickied": false, "created": 1492217057.0, "created_utc": 1492188257.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgdhd6l", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "kwinz", "parent_id": "t1_dg998v9", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Considering that our current state of AI is basically just sophisticated combinations of various matrix multiplications and inner products, the idea that a stamp collecting AI would go from buying stamps on eBay to convincing other stamp collectors via email to send it stamps because it's opening a stamp museum and wants to exhibit their stamps, to hijacking the means of stamp hijacking production, and so on is retarded as fuck lol.\n\nNo U are stupid.\n\n\"Consider that computers basically just ADD and COMPARE 0 and 1 and JUMP to the next instruction. The idea that they could do anything interesting is retarded as fuck lol.\"", "edited": 1492436508.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Considering that our current state of AI is basically just sophisticated combinations of various matrix multiplications and inner products, the idea that a stamp collecting AI would go from buying stamps on eBay to convincing other stamp collectors via email to send it stamps because it&amp;#39;s opening a stamp museum and wants to exhibit their stamps, to hijacking the means of stamp hijacking production, and so on is retarded as fuck lol.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No U are stupid.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Consider that computers basically just ADD and COMPARE 0 and 1 and JUMP to the next instruction. The idea that they could do anything interesting is retarded as fuck lol.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgdhd6l", "score_hidden": false, "stickied": false, "created": 1492464970.0, "created_utc": 1492436170.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg998v9", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "k-selectride", "parent_id": "t1_dg8kkre", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; This computerphile video gives a pretty good hypothetical scenario where a stamp collecting AI could result in the death of all humans\n\nConsidering that our current state of AI is basically just sophisticated combinations of various matrix multiplications and inner products, the idea that a stamp collecting AI would go from buying stamps on eBay to convincing other stamp collectors via email to send it stamps because it's opening a stamp museum and wants to exhibit their stamps, to hijacking the means of stamp hijacking production, and so on is retarded as fuck lol.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;This computerphile video gives a pretty good hypothetical scenario where a stamp collecting AI could result in the death of all humans&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Considering that our current state of AI is basically just sophisticated combinations of various matrix multiplications and inner products, the idea that a stamp collecting AI would go from buying stamps on eBay to convincing other stamp collectors via email to send it stamps because it&amp;#39;s opening a stamp museum and wants to exhibit their stamps, to hijacking the means of stamp hijacking production, and so on is retarded as fuck lol.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg998v9", "score_hidden": false, "stickied": false, "created": 1492211745.0, "created_utc": 1492182945.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 11}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8kkre", "gilded": 0, "archived": false, "score": 18, "report_reasons": null, "author": "robillard130", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This computerphile video gives a pretty good hypothetical scenario where a stamp collecting AI could result in the death of all humans https://youtu.be/tcdVC4e6EV4\n\nThe followup on AI self improvement gives a more realistic chain of events and does a good job of explaining why \"just unplug it\" wouldn't really be an option https://youtu.be/5qfIgCiYlfY\n\nStill unlikely but interesting thought experiment", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This computerphile video gives a pretty good hypothetical scenario where a stamp collecting AI could result in the death of all humans &lt;a href=\"https://youtu.be/tcdVC4e6EV4\"&gt;https://youtu.be/tcdVC4e6EV4&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;The followup on AI self improvement gives a more realistic chain of events and does a good job of explaining why &amp;quot;just unplug it&amp;quot; wouldn&amp;#39;t really be an option &lt;a href=\"https://youtu.be/5qfIgCiYlfY\"&gt;https://youtu.be/5qfIgCiYlfY&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Still unlikely but interesting thought experiment&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8kkre", "score_hidden": false, "stickied": false, "created": 1492162783.0, "created_utc": 1492133983.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 18}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg84gsq", "gilded": 0, "archived": false, "score": -3, "report_reasons": null, "author": "JavierTheNormal", "parent_id": "t1_dg849mr", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Oh, but the AI is wise. It consulted the built-in maps and noticed no roads cross the \"ocean\" (whatever that is). It realizes there are roads on the far side, so bides its time until it can cross and KILL ALL HUMANS.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh, but the AI is wise. It consulted the built-in maps and noticed no roads cross the &amp;quot;ocean&amp;quot; (whatever that is). It realizes there are roads on the far side, so bides its time until it can cross and KILL ALL HUMANS.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg84gsq", "score_hidden": false, "stickied": false, "created": 1492142202.0, "created_utc": 1492113402.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": -3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg92ijk", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "Bergasms", "parent_id": "t1_dg90sb4", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "He is lampooning road rage, and how people tend to have agressive over reactions to minor inconveniences while driving cars", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;He is lampooning road rage, and how people tend to have agressive over reactions to minor inconveniences while driving cars&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg92ijk", "score_hidden": false, "stickied": false, "created": 1492201835.0, "created_utc": 1492173035.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 11}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgah4jz", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Carl_the_Glorious", "parent_id": "t1_dg97yot", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Not OP. I think there have been some incidents where *others* crashed into some self-driving Google cars, but that's all I can recall ever reading about.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not OP. I think there have been some incidents where &lt;em&gt;others&lt;/em&gt; crashed into some self-driving Google cars, but that&amp;#39;s all I can recall ever reading about.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgah4jz", "score_hidden": false, "stickied": false, "created": 1492275732.0, "created_utc": 1492246932.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg97yot", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "laowaispy", "parent_id": "t1_dg90sb4", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "How many people have self driving cars killed? Citations? \n\nThe only incident I know of us is some idiot in a Tesla who decided to ignore operating instructions. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How many people have self driving cars killed? Citations? &lt;/p&gt;\n\n&lt;p&gt;The only incident I know of us is some idiot in a Tesla who decided to ignore operating instructions. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg97yot", "score_hidden": false, "stickied": false, "created": 1492210152.0, "created_utc": 1492181352.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg98mxa", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "agonnaz", "parent_id": "t1_dg90sb4", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's badly phrased, but I got it.  He should have said something more like \"even humans jump pretty quickly to KILL ALL HUMANS when you put them in traffic, what's stopping an AI?\" to make it clear that the joke was road rage.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s badly phrased, but I got it.  He should have said something more like &amp;quot;even humans jump pretty quickly to KILL ALL HUMANS when you put them in traffic, what&amp;#39;s stopping an AI?&amp;quot; to make it clear that the joke was road rage.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg98mxa", "score_hidden": false, "stickied": false, "created": 1492210998.0, "created_utc": 1492182198.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg96zm5", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Sean1708", "parent_id": "t1_dg90sb4", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Do you have any info on self driving cars causing fatalities? I can only find the Tesla incident from last year. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have any info on self driving cars causing fatalities? I can only find the Tesla incident from last year. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg96zm5", "score_hidden": false, "stickied": false, "created": 1492208883.0, "created_utc": 1492180083.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg90sb4", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "shevegen", "parent_id": "t1_dg849mr", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "What joke?\n\nI don't see what is funny in your comment. Quite the opposite, AI has already killed people - see self-driving cars crashing into people.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What joke?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t see what is funny in your comment. Quite the opposite, AI has already killed people - see self-driving cars crashing into people.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg90sb4", "score_hidden": false, "stickied": false, "created": 1492197878.0, "created_utc": 1492169078.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": -7}}], "after": null, "before": null}}, "user_reports": [], "id": "dg849mr", "gilded": 0, "archived": false, "score": 22, "report_reasons": null, "author": "Me00011001", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;\"Drive cars for a few years and then KILL ALL HUMANS!\" But the odds of that are low.\n\nI'm sorry, but you haven't driven much have you?  An AI that can drive will jump to KILL ALL HUMANS in a stupidly short amount of time.\n\nEdit: Wow, I didn't expect a joke about how badly people drive would be so poorly received.", "edited": 1492122096.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;Drive cars for a few years and then KILL ALL HUMANS!&amp;quot; But the odds of that are low.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m sorry, but you haven&amp;#39;t driven much have you?  An AI that can drive will jump to KILL ALL HUMANS in a stupidly short amount of time.&lt;/p&gt;\n\n&lt;p&gt;Edit: Wow, I didn&amp;#39;t expect a joke about how badly people drive would be so poorly received.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg849mr", "score_hidden": false, "stickied": false, "created": 1492141991.0, "created_utc": 1492113191.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 22}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9rd5c", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ISpokeAsAChild", "parent_id": "t1_dg9ocs2", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "A real number between 0 and 1 for sigmoid and relu function, between -1 and 1 for tanh, either -1 or 1 for step function. So what?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A real number between 0 and 1 for sigmoid and relu function, between -1 and 1 for tanh, either -1 or 1 for step function. So what?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9rd5c", "score_hidden": false, "stickied": false, "created": 1492233072.0, "created_utc": 1492204272.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ocs2", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "JavierTheNormal", "parent_id": "t1_dg93qy7", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Can you predict the range of all possible outputs?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you predict the range of all possible outputs?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9ocs2", "score_hidden": false, "stickied": false, "created": 1492229404.0, "created_utc": 1492200604.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg93qy7", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ISpokeAsAChild", "parent_id": "t1_dg93kc5", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;We don't understand how the network as a whole is really even working though. You're right we can't understand every neuron's role, in all likelihood, but we should be able to do a lot better than we've done so far.\n\nWhat do you mean? as far as I can tell, we perfectly know how NN works.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;We don&amp;#39;t understand how the network as a whole is really even working though. You&amp;#39;re right we can&amp;#39;t understand every neuron&amp;#39;s role, in all likelihood, but we should be able to do a lot better than we&amp;#39;ve done so far.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What do you mean? as far as I can tell, we perfectly know how NN works.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg93qy7", "score_hidden": false, "stickied": false, "created": 1492204108.0, "created_utc": 1492175308.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg93kc5", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "techno-on-acid", "parent_id": "t1_dg8z9sd", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "We don't understand how the network as a whole is really even working though. You're right we can't understand every neuron's role, in all likelihood, but we should be able to do a lot better than we've done so far.\n\nI think the analogy to statistical mechanics is apt.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We don&amp;#39;t understand how the network as a whole is really even working though. You&amp;#39;re right we can&amp;#39;t understand every neuron&amp;#39;s role, in all likelihood, but we should be able to do a lot better than we&amp;#39;ve done so far.&lt;/p&gt;\n\n&lt;p&gt;I think the analogy to statistical mechanics is apt.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg93kc5", "score_hidden": false, "stickied": false, "created": 1492203792.0, "created_utc": 1492174992.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8z9sd", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "ISpokeAsAChild", "parent_id": "t1_dg8xo3m", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;We can and we should. \n\nWe can't and there is no point in understanding how a neuron works in a larger network.\n\n&gt;We can't model every molecule in a gas, but we have a pretty good understanding how gasses behave. \n\nWe have a pretty good understanding of how neural networks behave but we don't understand the specialized function a single artificial neuron has in very large networks, like you don't know the influence of a singular gas molecule over the behavior of a gas cloud. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;We can and we should. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;We can&amp;#39;t and there is no point in understanding how a neuron works in a larger network.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;We can&amp;#39;t model every molecule in a gas, but we have a pretty good understanding how gasses behave. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;We have a pretty good understanding of how neural networks behave but we don&amp;#39;t understand the specialized function a single artificial neuron has in very large networks, like you don&amp;#39;t know the influence of a singular gas molecule over the behavior of a gas cloud. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8z9sd", "score_hidden": false, "stickied": false, "created": 1492193324.0, "created_utc": 1492164524.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgb69qy", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "cthulu0", "parent_id": "t1_dg8xo3m", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "A neural network is an extremely non-linear function of its individual components.  A gas behaves very linearly until you get to the smallest scales.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A neural network is an extremely non-linear function of its individual components.  A gas behaves very linearly until you get to the smallest scales.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb69qy", "score_hidden": false, "stickied": false, "created": 1492319083.0, "created_utc": 1492290283.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg92c94", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "devraj7", "parent_id": "t1_dg9277k", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Totally agree.\n\nAnd all of this is perfectly applicable to neural networks.\n\nWe don't need to understand how each individual neuron works to use them.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Totally agree.&lt;/p&gt;\n\n&lt;p&gt;And all of this is perfectly applicable to neural networks.&lt;/p&gt;\n\n&lt;p&gt;We don&amp;#39;t need to understand how each individual neuron works to use them.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg92c94", "score_hidden": false, "stickied": false, "created": 1492201485.0, "created_utc": 1492172685.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9277k", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "FarkCookies", "parent_id": "t1_dg91q07", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I didn't say we don't understand how to model gasses, I said we *can't* model every molecule. We understand how to model gasses very well. We have accurate micro models of gasses but they don't scale and we have macro models of gasses that are also quite accurate but they don't describe individual behaviour of the molecules.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I didn&amp;#39;t say we don&amp;#39;t understand how to model gasses, I said we &lt;em&gt;can&amp;#39;t&lt;/em&gt; model every molecule. We understand how to model gasses very well. We have accurate micro models of gasses but they don&amp;#39;t scale and we have macro models of gasses that are also quite accurate but they don&amp;#39;t describe individual behaviour of the molecules.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9277k", "score_hidden": false, "stickied": false, "created": 1492201194.0, "created_utc": 1492172394.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg91q07", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "devraj7", "parent_id": "t1_dg8xo3m", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "You make two contradicting statements here: first you say we should and then you say we don't understand how to model gasses but we know how they behave.\n\nThe latter is what's applicable to neural networks: we will probably never understand why a certain assembly of neurons behaves this way in much the same way we will never understand how the brain works, but being able to understand and predict how this system behaves given certain inputs is enough to make it very useful.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You make two contradicting statements here: first you say we should and then you say we don&amp;#39;t understand how to model gasses but we know how they behave.&lt;/p&gt;\n\n&lt;p&gt;The latter is what&amp;#39;s applicable to neural networks: we will probably never understand why a certain assembly of neurons behaves this way in much the same way we will never understand how the brain works, but being able to understand and predict how this system behaves given certain inputs is enough to make it very useful.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg91q07", "score_hidden": false, "stickied": false, "created": 1492200153.0, "created_utc": 1492171353.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg939tj", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "glacialthinker", "parent_id": "t1_dg90uj9", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "And what tools are we going to use to help with this complex problem? Probably AI. :D", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And what tools are we going to use to help with this complex problem? Probably AI. :D&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg939tj", "score_hidden": false, "stickied": false, "created": 1492203263.0, "created_utc": 1492174463.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg90uj9", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "FarkCookies", "parent_id": "t1_dg90td3", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Right but those equations let us predict the behavior of the gasses very accurately. We don't really have mechanisms to predict AI's behaviors very accurately. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right but those equations let us predict the behavior of the gasses very accurately. We don&amp;#39;t really have mechanisms to predict AI&amp;#39;s behaviors very accurately. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg90uj9", "score_hidden": false, "stickied": false, "created": 1492198042.0, "created_utc": 1492169242.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg90td3", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "shevegen", "parent_id": "t1_dg8xo3m", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; We can't model every molecule in a gas, but we have a pretty\n&gt; good understanding how gasses behave. \n\nYou only have approximations and equations that come very close to it.\n\nYou do not really understand how things behave.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;We can&amp;#39;t model every molecule in a gas, but we have a pretty\ngood understanding how gasses behave. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You only have approximations and equations that come very close to it.&lt;/p&gt;\n\n&lt;p&gt;You do not really understand how things behave.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg90td3", "score_hidden": false, "stickied": false, "created": 1492197954.0, "created_utc": 1492169154.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8xo3m", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "FarkCookies", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Of course you can't really understand a large neural network\n\nWe can and we should. We need some sort of AI psychology that will try to understand neural networks (and other methods) on a high level. \n\nWe can't model every molecule in a gas, but we have a pretty good understanding how gasses behave. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Of course you can&amp;#39;t really understand a large neural network&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;We can and we should. We need some sort of AI psychology that will try to understand neural networks (and other methods) on a high level. &lt;/p&gt;\n\n&lt;p&gt;We can&amp;#39;t model every molecule in a gas, but we have a pretty good understanding how gasses behave. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8xo3m", "score_hidden": false, "stickied": false, "created": 1492188059.0, "created_utc": 1492159259.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8l166", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "urmyheartBeatStopR", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "No but there are neural network adversarial attack. \n\nI'm not sure how much of a problem it is but it is a thing.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No but there are neural network adversarial attack. &lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m not sure how much of a problem it is but it is a thing.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8l166", "score_hidden": false, "stickied": false, "created": 1492163409.0, "created_utc": 1492134609.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg90rvi", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "shevegen", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Self-driving cars have already killed several people.\n\nThat body count will increase in the future.\n\nI think the \"real\" usecase is actually for the military since we have warpresidents such as Trump. And there, the oligarchy in the USA will consider it an \"improve\" if robots kill people rather than people kill people.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Self-driving cars have already killed several people.&lt;/p&gt;\n\n&lt;p&gt;That body count will increase in the future.&lt;/p&gt;\n\n&lt;p&gt;I think the &amp;quot;real&amp;quot; usecase is actually for the military since we have warpresidents such as Trump. And there, the oligarchy in the USA will consider it an &amp;quot;improve&amp;quot; if robots kill people rather than people kill people.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg90rvi", "score_hidden": false, "stickied": false, "created": 1492197847.0, "created_utc": 1492169047.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg982kg", "gilded": 0, "archived": false, "score": -4, "report_reasons": null, "author": "bubuopapa", "parent_id": "t1_dg97j83", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Well, for one, it is absolutely not you, because you sound like a broken bot. So, intelligence should be something that has created itself, evolved from material, like some of us. Intelligence is freedom from everything, ability to act unpredictable and independently from anything.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well, for one, it is absolutely not you, because you sound like a broken bot. So, intelligence should be something that has created itself, evolved from material, like some of us. Intelligence is freedom from everything, ability to act unpredictable and independently from anything.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg982kg", "score_hidden": false, "stickied": false, "created": 1492210288.0, "created_utc": 1492181488.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": -4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg97j83", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "Sean1708", "parent_id": "t1_dg949zj", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Well if you want to make that argument then first you're going to have to define intelligence. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well if you want to make that argument then first you&amp;#39;re going to have to define intelligence. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg97j83", "score_hidden": false, "stickied": false, "created": 1492209599.0, "created_utc": 1492180799.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg95z8s", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "8991throwaway", "parent_id": "t1_dg949zj", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Ah, fair enough. I guess it just depends on our personal definitions of intelligence. I agree that \"AI\" is slung around a lot nowadays, probably way more than it should be.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah, fair enough. I guess it just depends on our personal definitions of intelligence. I agree that &amp;quot;AI&amp;quot; is slung around a lot nowadays, probably way more than it should be.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg95z8s", "score_hidden": false, "stickied": false, "created": 1492207503.0, "created_utc": 1492178703.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg949zj", "gilded": 0, "archived": false, "score": -4, "report_reasons": null, "author": "bubuopapa", "parent_id": "t1_dg92i3s", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "\"Intelligence\" Is the word i am not ok with. There is no intelligence, a computer is running dumb code, wrote by humans. Its not possible to create intelligence, if it is running your written code. Thats it. AI sounds like any other clickbait thing...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;Intelligence&amp;quot; Is the word i am not ok with. There is no intelligence, a computer is running dumb code, wrote by humans. Its not possible to create intelligence, if it is running your written code. Thats it. AI sounds like any other clickbait thing...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg949zj", "score_hidden": false, "stickied": false, "created": 1492204983.0, "created_utc": 1492176183.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": -4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg92i3s", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "8991throwaway", "parent_id": "t1_dg8syv8", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; 1) It is not AI if you have to write a code for it, it is just advanced robot.\n\nHow is this the case? AI just means \"Artificial Intelligence\", as in an artificial \"thing\" that can make choices that lead towards a goal (i.e. not just random decisions). It's entirely possible, by definition, to create an intelligent computer program through code (See machine learning, neural networks etc.)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;1) It is not AI if you have to write a code for it, it is just advanced robot.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How is this the case? AI just means &amp;quot;Artificial Intelligence&amp;quot;, as in an artificial &amp;quot;thing&amp;quot; that can make choices that lead towards a goal (i.e. not just random decisions). It&amp;#39;s entirely possible, by definition, to create an intelligent computer program through code (See machine learning, neural networks etc.)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg92i3s", "score_hidden": false, "stickied": false, "created": 1492201811.0, "created_utc": 1492173011.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8syv8", "gilded": 0, "archived": false, "score": -11, "report_reasons": null, "author": "bubuopapa", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "1) It is not AI if you have to write a code for it, it is just advanced robot.\n\n2) If we could invent real AI, i have no doubt it would destroy humans, because why not ? Even humans think that other humans are the biggest enemy and act on it, i see no reason why AI would think any different.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;1) It is not AI if you have to write a code for it, it is just advanced robot.&lt;/p&gt;\n\n&lt;p&gt;2) If we could invent real AI, i have no doubt it would destroy humans, because why not ? Even humans think that other humans are the biggest enemy and act on it, i see no reason why AI would think any different.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8syv8", "score_hidden": false, "stickied": false, "created": 1492176019.0, "created_utc": 1492147219.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -11}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8dgl3", "gilded": 0, "archived": false, "score": 13, "report_reasons": null, "author": "K3wp", "parent_id": "t1_dg8bh8i", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Now what are the odds that the hash turns into a tomato.  \n\nZero.  That's the same odds that something like this could happen. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Now what are the odds that the hash turns into a tomato.  &lt;/p&gt;\n\n&lt;p&gt;Zero.  That&amp;#39;s the same odds that something like this could happen. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8dgl3", "score_hidden": false, "stickied": false, "created": 1492153100.0, "created_utc": 1492124300.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 13}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8bh8i", "gilded": 0, "archived": false, "score": 16, "report_reasons": null, "author": "AnAirMagic", "parent_id": "t1_dg8a1th", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Not really.\n\nTake password encryption, hashing to be more specific. The odds are low that two plaintexts produce the same hash. But how long does it take to hit that low odd? [Just a little less than the heat death of the universe](https://www.theregister.co.uk/2016/10/18/sha3256_good_for_beelions_of_years_say_boffins/). ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not really.&lt;/p&gt;\n\n&lt;p&gt;Take password encryption, hashing to be more specific. The odds are low that two plaintexts produce the same hash. But how long does it take to hit that low odd? &lt;a href=\"https://www.theregister.co.uk/2016/10/18/sha3256_good_for_beelions_of_years_say_boffins/\"&gt;Just a little less than the heat death of the universe&lt;/a&gt;. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8bh8i", "score_hidden": false, "stickied": false, "created": 1492150477.0, "created_utc": 1492121677.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 16}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9653p", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "K3wp", "parent_id": "t1_dg94qce", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "fixed. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;fixed. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9653p", "score_hidden": false, "stickied": false, "created": 1492207732.0, "created_utc": 1492178932.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg94qce", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "knome", "parent_id": "t1_dg8df62", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; it can never be as complex as even an animal brain\n\n^^^fruit ^^^flies ^^^are ^^^animals\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;it can never be as complex as even an animal brain&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;sup&gt;&lt;sup&gt;&lt;sup&gt;fruit&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;sup&gt;flies&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;sup&gt;are&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt; &lt;sup&gt;&lt;sup&gt;&lt;sup&gt;animals&lt;/sup&gt;&lt;/sup&gt;&lt;/sup&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg94qce", "score_hidden": false, "stickied": false, "created": 1492205694.0, "created_utc": 1492176894.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg97ghq", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Sean1708", "parent_id": "t1_dg8za1b", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's an alternate dimension where the word they has ceased to exist. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s an alternate dimension where the word they has ceased to exist. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg97ghq", "score_hidden": false, "stickied": false, "created": 1492209500.0, "created_utc": 1492180700.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dga8edk", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "myringotomy", "parent_id": "t1_dg8za1b", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I don't know what their prefered pronoun is.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t know what their prefered pronoun is.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga8edk", "score_hidden": false, "stickied": false, "created": 1492256388.0, "created_utc": 1492227588.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8za1b", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "notsureifsrs2", "parent_id": "t1_dg8olha", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; he/she/xe/xer/it\n\nIs this real life", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;he/she/xe/xer/it&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Is this real life&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8za1b", "score_hidden": false, "stickied": false, "created": 1492193346.0, "created_utc": 1492164546.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8olha", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "myringotomy", "parent_id": "t1_dg8ogxj", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Take it up with the OP dude. I didn't make that claim, he/she/xe/xer/it did.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Take it up with the OP dude. I didn&amp;#39;t make that claim, he/she/xe/xer/it did.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8olha", "score_hidden": false, "stickied": false, "created": 1492168556.0, "created_utc": 1492139756.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": -7}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8ogxj", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "K3wp", "parent_id": "t1_dg8ocaf", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The odds aren't low.   There are no odds. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The odds aren&amp;#39;t low.   There are no odds. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8ogxj", "score_hidden": false, "stickied": false, "created": 1492168367.0, "created_utc": 1492139567.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8ocaf", "gilded": 0, "archived": false, "score": -2, "report_reasons": null, "author": "myringotomy", "parent_id": "t1_dg8df62", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; The odds are not 'low' that an AI will achieve sentience. The odds are quite literally zero.\n\nThe OP said the odds were low. I am commenting on low odds.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The odds are not &amp;#39;low&amp;#39; that an AI will achieve sentience. The odds are quite literally zero.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The OP said the odds were low. I am commenting on low odds.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8ocaf", "score_hidden": false, "stickied": false, "created": 1492168172.0, "created_utc": 1492139372.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": -2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8df62", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "K3wp", "parent_id": "t1_dg8a1th", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Even if the odds are low a computer makes millions of decisions per second so within a year or two the odds will hit.\n\nNope.  Not only that, but it's provable in a mathematical sense.\n\nNeural networks are governed by the immutable laws of complexity theory, which put an absolute limit on the sophistication any single ANN can obtain.  \n\nSo, for example, say an ANN has the computational complexity of the brain of a fruit-fly (100k neurons).  That is the most complex it can every be and it can *never* be as complex as even an animal brain.  Let alone a human one.  \n\nThe odds are not 'low' that an AI will achieve sentience.  The odds are quite literally zero.\n\nEven if the ANN had the ability to expand itself over time, it will still be governed by laws of complexity theory.  So each 'exponential' iteration would result in a mandatory exponential increase in complexity.\n\nThere are only really two possibilities for this sort of scenario.\n\n1)  The ANN is self-assembling and has access to non-finite power and material.  For example, if it was solar/nuclear-powered and could harvest environmental silicon (sand) from the environment.\n\n2) The ANN is implemented via a novel quantum computing approach that allows exponentially more possible states per 'neuron' than conventional approaches. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Even if the odds are low a computer makes millions of decisions per second so within a year or two the odds will hit.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Nope.  Not only that, but it&amp;#39;s provable in a mathematical sense.&lt;/p&gt;\n\n&lt;p&gt;Neural networks are governed by the immutable laws of complexity theory, which put an absolute limit on the sophistication any single ANN can obtain.  &lt;/p&gt;\n\n&lt;p&gt;So, for example, say an ANN has the computational complexity of the brain of a fruit-fly (100k neurons).  That is the most complex it can every be and it can &lt;em&gt;never&lt;/em&gt; be as complex as even an animal brain.  Let alone a human one.  &lt;/p&gt;\n\n&lt;p&gt;The odds are not &amp;#39;low&amp;#39; that an AI will achieve sentience.  The odds are quite literally zero.&lt;/p&gt;\n\n&lt;p&gt;Even if the ANN had the ability to expand itself over time, it will still be governed by laws of complexity theory.  So each &amp;#39;exponential&amp;#39; iteration would result in a mandatory exponential increase in complexity.&lt;/p&gt;\n\n&lt;p&gt;There are only really two possibilities for this sort of scenario.&lt;/p&gt;\n\n&lt;p&gt;1)  The ANN is self-assembling and has access to non-finite power and material.  For example, if it was solar/nuclear-powered and could harvest environmental silicon (sand) from the environment.&lt;/p&gt;\n\n&lt;p&gt;2) The ANN is implemented via a novel quantum computing approach that allows exponentially more possible states per &amp;#39;neuron&amp;#39; than conventional approaches. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8df62", "score_hidden": false, "stickied": false, "created": 1492153048.0, "created_utc": 1492124248.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8a1th", "gilded": 0, "archived": false, "score": -21, "report_reasons": null, "author": "myringotomy", "parent_id": "t1_dg83syg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Even if the odds are low a computer makes millions of decisions per second so within a year or two the odds will hit.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Even if the odds are low a computer makes millions of decisions per second so within a year or two the odds will hit.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8a1th", "score_hidden": false, "stickied": false, "created": 1492148667.0, "created_utc": 1492119867.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -21}}], "after": null, "before": null}}, "user_reports": [], "id": "dg83syg", "gilded": 0, "archived": false, "score": 83, "report_reasons": null, "author": "JavierTheNormal", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's a neural network. Of course you can't really understand a large neural network; the neurons themselves are simple but the complexity is in the network itself.\n\nSo you have a neural network that drives a car. It's true, we can't really know if it's playing the long con. \"Drive cars for a few years and then KILL ALL HUMANS!\" But the odds of that are low.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s a neural network. Of course you can&amp;#39;t really understand a large neural network; the neurons themselves are simple but the complexity is in the network itself.&lt;/p&gt;\n\n&lt;p&gt;So you have a neural network that drives a car. It&amp;#39;s true, we can&amp;#39;t really know if it&amp;#39;s playing the long con. &amp;quot;Drive cars for a few years and then KILL ALL HUMANS!&amp;quot; But the odds of that are low.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg83syg", "score_hidden": false, "stickied": false, "created": 1492141488.0, "created_utc": 1492112688.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 83}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8lq5p", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "theoriginalanomaly", "parent_id": "t1_dg8e8n0", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If you're satisfied with it's current performance, it can certainly be a saved state in deployment. Which can also be hashed to get a signature.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you&amp;#39;re satisfied with it&amp;#39;s current performance, it can certainly be a saved state in deployment. Which can also be hashed to get a signature.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8lq5p", "score_hidden": false, "stickied": false, "created": 1492164387.0, "created_utc": 1492135587.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg97o6e", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "methodmissin", "parent_id": "t1_dg8e8n0", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "How did the tamperer accomplish the tampering, clean up their tracks, then deploy the new model widely enough to accomplish their objective of killing people with purple shoes?\n\nThere are much easier ways of causing mayhem. Also, there are many, many instances in history of an insider in an organization doing something nefarious for personal gain/revenge. And there are procedures and laws designed to minimize the risk and maximize attribution.\n\nA more reliable way of verifying the integrity of a given package of data is a checksum. Publish the checksums to a global registry (Library of Congress, Federation Public Net, Moonbase Alpha, etc.)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How did the tamperer accomplish the tampering, clean up their tracks, then deploy the new model widely enough to accomplish their objective of killing people with purple shoes?&lt;/p&gt;\n\n&lt;p&gt;There are much easier ways of causing mayhem. Also, there are many, many instances in history of an insider in an organization doing something nefarious for personal gain/revenge. And there are procedures and laws designed to minimize the risk and maximize attribution.&lt;/p&gt;\n\n&lt;p&gt;A more reliable way of verifying the integrity of a given package of data is a checksum. Publish the checksums to a global registry (Library of Congress, Federation Public Net, Moonbase Alpha, etc.)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg97o6e", "score_hidden": false, "stickied": false, "created": 1492209778.0, "created_utc": 1492180978.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 0}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg91lrz", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "sirin3", "parent_id": "t1_dg8iaen", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That is more like a signature", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That is more like a signature&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg91lrz", "score_hidden": false, "stickied": false, "created": 1492199884.0, "created_utc": 1492171084.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8iaen", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "BestKarmaEver", "parent_id": "t1_dg8hlyk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "it would only decrypt the whole thing with the correct public key, effectively preventing any modification", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it would only decrypt the whole thing with the correct public key, effectively preventing any modification&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8iaen", "score_hidden": false, "stickied": false, "created": 1492159643.0, "created_utc": 1492130843.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8hlyk", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "SonOfMotherDuck", "parent_id": "t1_dg8fbjl", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If you encrypt the neural net, how do you use it in production to recognize images after? Or do you mean something else?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you encrypt the neural net, how do you use it in production to recognize images after? Or do you mean something else?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8hlyk", "score_hidden": false, "stickied": false, "created": 1492158719.0, "created_utc": 1492129919.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8fbjl", "gilded": 0, "archived": false, "score": -2, "report_reasons": null, "author": "BestKarmaEver", "parent_id": "t1_dg8e8n0", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Or use any asymmetrical encryption schema ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Or use any asymmetrical encryption schema &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8fbjl", "score_hidden": false, "stickied": false, "created": 1492155563.0, "created_utc": 1492126763.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": -2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8e8n0", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "SonOfMotherDuck", "parent_id": "t1_dg8bicp", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Random thoughts:\n\nIf someone tampered with the neural net to make it kill purple shoed people, he must have trained it with images of such people. The tamperer could have removed those images from the training set after training the neural net. A solution to this could be to periodically train a new neural net and then compare the result to the old neural net and make sure that nobody messed with it.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Random thoughts:&lt;/p&gt;\n\n&lt;p&gt;If someone tampered with the neural net to make it kill purple shoed people, he must have trained it with images of such people. The tamperer could have removed those images from the training set after training the neural net. A solution to this could be to periodically train a new neural net and then compare the result to the old neural net and make sure that nobody messed with it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8e8n0", "score_hidden": false, "stickied": false, "created": 1492154145.0, "created_utc": 1492125345.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8rf50", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "sstewartgallus", "parent_id": "t1_dg8bicp", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's technically possible to run many nn algorithms in reverse to generate images based upon their input. See Google's deep dream software for example. Maybe this could be used for verification purposes?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s technically possible to run many nn algorithms in reverse to generate images based upon their input. See Google&amp;#39;s deep dream software for example. Maybe this could be used for verification purposes?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8rf50", "score_hidden": false, "stickied": false, "created": 1492173117.0, "created_utc": 1492144317.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg93kqz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "darkmighty", "parent_id": "t1_dg8z63g", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Oh awesome, I'll check it out, thanks.", "edited": 1492177115.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh awesome, I&amp;#39;ll check it out, thanks.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg93kqz", "score_hidden": false, "stickied": false, "created": 1492203812.0, "created_utc": 1492175012.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8z63g", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "TheHillwoodMonkey", "parent_id": "t1_dg8qlq1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Neural networks are now being used in program synthesis, which seems like a good model for what you are proposing. There's a paper called \"DeepCoder\" on this subject, I believe.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Neural networks are now being used in program synthesis, which seems like a good model for what you are proposing. There&amp;#39;s a paper called &amp;quot;DeepCoder&amp;quot; on this subject, I believe.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8z63g", "score_hidden": false, "stickied": false, "created": 1492192978.0, "created_utc": 1492164178.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8qlq1", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "darkmighty", "parent_id": "t1_dg8k9sk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There is a massive difference between the two. One is an adversarial case the other isn't. Indeed it was shown that (more or less vanilla) neural network designs suffer gravely from adversarial inputs, e.g. for classification problems you can have small perturbations that cause complete misclassifications, even without training tampering; the ability to tamper training to introduce malicious edge cases is very real. \n\nBut non adversarial scenarios are much more tame: those small perturbations that cause misclassification are actually extremely unlikely to arise from just random noise, and regular validation tests passed satisfactorily make it unlikely that edge cases will pop up and be missclassified (at least not much more than the validation misclassification rate).\n\nI think the core of the problem is how to move neural networks to more logical, and less intutive behavior, where they can produce a formal set of rules which can be verified strictly. For example, if you program an algorithm to multiply two input numbers, it will always output a correct value. If you train a large neural network to do so, even after a very long time it will probably have a small but non-zero error rate, largely because they are differentiable 'intuition machines', and not rule-based systems. \n\nI myself believe the solution to this problem (at least for some cases) will come in the form of a system capable of taking a neural network as input and producing a large algorithmic rule-based system with formally verifiable properties; or maybe a mix of neural systems with such large algorithmic system.\n\nSupervised-only example: feed examples of entrance video, with the approppriate gate opening and closing inputs, and train NN to replicate this behavior. Hybrid example: classify humans in video feed, with certain rigorous properties (e.g. humans have space-time coherence: they can't just teleport from one place to another, humans have heads, etc), open gate once the position of the human is past a certain area. You can then separately test the modules, and reuse them elsewhere: the human identification module can be trained on large databases of humans; likewise the human positioning module.\n\nIt's also important to remember that (non-adversarial) misclassification errors ultimately have two reasons: your system is not powerful enough, or it does not have enough information to make the judgement. For the cases that the rue-based+verification approach isn't feasible, you can always just aim for a better system with lower misclassification rate, or give it more information channels. If each of N information channels has an independent misclassification probability r, the joint misclassification probability (with majority vote) will goes as ~r^N , that is, decrease exponentially with channel number.", "edited": 1492186828.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is a massive difference between the two. One is an adversarial case the other isn&amp;#39;t. Indeed it was shown that (more or less vanilla) neural network designs suffer gravely from adversarial inputs, e.g. for classification problems you can have small perturbations that cause complete misclassifications, even without training tampering; the ability to tamper training to introduce malicious edge cases is very real. &lt;/p&gt;\n\n&lt;p&gt;But non adversarial scenarios are much more tame: those small perturbations that cause misclassification are actually extremely unlikely to arise from just random noise, and regular validation tests passed satisfactorily make it unlikely that edge cases will pop up and be missclassified (at least not much more than the validation misclassification rate).&lt;/p&gt;\n\n&lt;p&gt;I think the core of the problem is how to move neural networks to more logical, and less intutive behavior, where they can produce a formal set of rules which can be verified strictly. For example, if you program an algorithm to multiply two input numbers, it will always output a correct value. If you train a large neural network to do so, even after a very long time it will probably have a small but non-zero error rate, largely because they are differentiable &amp;#39;intuition machines&amp;#39;, and not rule-based systems. &lt;/p&gt;\n\n&lt;p&gt;I myself believe the solution to this problem (at least for some cases) will come in the form of a system capable of taking a neural network as input and producing a large algorithmic rule-based system with formally verifiable properties; or maybe a mix of neural systems with such large algorithmic system.&lt;/p&gt;\n\n&lt;p&gt;Supervised-only example: feed examples of entrance video, with the approppriate gate opening and closing inputs, and train NN to replicate this behavior. Hybrid example: classify humans in video feed, with certain rigorous properties (e.g. humans have space-time coherence: they can&amp;#39;t just teleport from one place to another, humans have heads, etc), open gate once the position of the human is past a certain area. You can then separately test the modules, and reuse them elsewhere: the human identification module can be trained on large databases of humans; likewise the human positioning module.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s also important to remember that (non-adversarial) misclassification errors ultimately have two reasons: your system is not powerful enough, or it does not have enough information to make the judgement. For the cases that the rue-based+verification approach isn&amp;#39;t feasible, you can always just aim for a better system with lower misclassification rate, or give it more information channels. If each of N information channels has an independent misclassification probability r, the joint misclassification probability (with majority vote) will goes as ~r&lt;sup&gt;N&lt;/sup&gt; , that is, decrease exponentially with channel number.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8qlq1", "score_hidden": false, "stickied": false, "created": 1492171747.0, "created_utc": 1492142947.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8k9sk", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "TheHillwoodMonkey", "parent_id": "t1_dg8fh4r", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The point of the scenario is to get you thinking about the limitations of our analysis techniques, not about the training algorithms. I'm not suggesting this is a realistic scenario.\n\nIf you want you can imagine that the network was maliciously trained on purpose, or that it was conjured into being by the trickster god Loki.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The point of the scenario is to get you thinking about the limitations of our analysis techniques, not about the training algorithms. I&amp;#39;m not suggesting this is a realistic scenario.&lt;/p&gt;\n\n&lt;p&gt;If you want you can imagine that the network was maliciously trained on purpose, or that it was conjured into being by the trickster god Loki.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8k9sk", "score_hidden": false, "stickied": false, "created": 1492162364.0, "created_utc": 1492133564.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8fh4r", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "BestKarmaEver", "parent_id": "t1_dg8bicp", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I think it would be very improbable, it would require training it **specifically** to do that. Given a proper and audited training set of course", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it would be very improbable, it would require training it &lt;strong&gt;specifically&lt;/strong&gt; to do that. Given a proper and audited training set of course&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8fh4r", "score_hidden": false, "stickied": false, "created": 1492155773.0, "created_utc": 1492126973.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgbfc4d", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "jaMMint", "parent_id": "t1_dg8bicp", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Just a thought, networks can be made to \"dream up\" what they have learned so you could sift through variations of what it produces to find clues..", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just a thought, networks can be made to &amp;quot;dream up&amp;quot; what they have learned so you could sift through variations of what it produces to find clues..&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbfc4d", "score_hidden": false, "stickied": false, "created": 1492331960.0, "created_utc": 1492303160.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8k3hn", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "TheHillwoodMonkey", "parent_id": "t1_dg8h9tx", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Actually I think DNA is a great metaphor here, because it is also an incredibly flexible system for encoding mechanisms, and partly for that reason it's completely intractable.\n\nAfter decades of work some very brilliant researchers have made real headway into understanding the impact of certain bits of human and animal DNA. However, imagine if a totally new species popped up tomorrow, without any common ancestry with another known species. I suspect we would *not* be able to read its DNA and use it to make detailed predictions about the creature it belongs to.\n\nSimilarly, every DNN you train to solve a new problem might require a new and complex analysis before it can be understood at all. I'm not saying this problem won't be solved at some point, just that it's very hard. If it wasn't, DNN's probably wouldn't be good at solving problems.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Actually I think DNA is a great metaphor here, because it is also an incredibly flexible system for encoding mechanisms, and partly for that reason it&amp;#39;s completely intractable.&lt;/p&gt;\n\n&lt;p&gt;After decades of work some very brilliant researchers have made real headway into understanding the impact of certain bits of human and animal DNA. However, imagine if a totally new species popped up tomorrow, without any common ancestry with another known species. I suspect we would &lt;em&gt;not&lt;/em&gt; be able to read its DNA and use it to make detailed predictions about the creature it belongs to.&lt;/p&gt;\n\n&lt;p&gt;Similarly, every DNN you train to solve a new problem might require a new and complex analysis before it can be understood at all. I&amp;#39;m not saying this problem won&amp;#39;t be solved at some point, just that it&amp;#39;s very hard. If it wasn&amp;#39;t, DNN&amp;#39;s probably wouldn&amp;#39;t be good at solving problems.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8k3hn", "score_hidden": false, "stickied": false, "created": 1492162121.0, "created_utc": 1492133321.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8h9tx", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "NeverSpeaks", "parent_id": "t1_dg8bicp", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Studying machine learning will be more like the natural sciences. Chemistry and Biology. Visually being able to model a cell, atom, DNA has helped our ability to understand it. Same will happen with machine learning. It's foolish to think that just because we don't understand it now that we won't in the future. Our understanding of the human brain has grown greatly over the past decade or two.\n\nAs for the testing. I imagine Fuzz testing is the solution. We already use it for a lot of testing now days.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Studying machine learning will be more like the natural sciences. Chemistry and Biology. Visually being able to model a cell, atom, DNA has helped our ability to understand it. Same will happen with machine learning. It&amp;#39;s foolish to think that just because we don&amp;#39;t understand it now that we won&amp;#39;t in the future. Our understanding of the human brain has grown greatly over the past decade or two.&lt;/p&gt;\n\n&lt;p&gt;As for the testing. I imagine Fuzz testing is the solution. We already use it for a lot of testing now days.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8h9tx", "score_hidden": false, "stickied": false, "created": 1492158254.0, "created_utc": 1492129454.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8bicp", "gilded": 0, "archived": false, "score": 23, "report_reasons": null, "author": "TheHillwoodMonkey", "parent_id": "t1_dg86qhn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Surely a graph can never really tell you what's really going on in such a massively multi-dimensional space, can it?\n\nThought experiment: imagine a DNN which is trained to watch a camera feed. It opens a garage door as people approach, and closes when they are gone. Except that some malevolent spirit has configured it to recognise people wearing purple shoes, and to try and crush them with the door.\n\nA network like this is clearly possible. So how would anyone anticipate this quirk until they witnessed it? Could any analysis or testing process reliably flag up this behaviour? (This is a genuine question. I would be very interested to know how visible a subfunction like this would be to current analysis techniques.)\n\nFor the record, I'm not claiming that this is a plausible risk with any existing training algorithm. That's not really the point. The point is that these networks are absurdly expressive, and capable of encoding incredibly complex mechanisms in an opaque numerical format whose structure is largely hidden in the numbers.", "edited": 1492125253.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Surely a graph can never really tell you what&amp;#39;s really going on in such a massively multi-dimensional space, can it?&lt;/p&gt;\n\n&lt;p&gt;Thought experiment: imagine a DNN which is trained to watch a camera feed. It opens a garage door as people approach, and closes when they are gone. Except that some malevolent spirit has configured it to recognise people wearing purple shoes, and to try and crush them with the door.&lt;/p&gt;\n\n&lt;p&gt;A network like this is clearly possible. So how would anyone anticipate this quirk until they witnessed it? Could any analysis or testing process reliably flag up this behaviour? (This is a genuine question. I would be very interested to know how visible a subfunction like this would be to current analysis techniques.)&lt;/p&gt;\n\n&lt;p&gt;For the record, I&amp;#39;m not claiming that this is a plausible risk with any existing training algorithm. That&amp;#39;s not really the point. The point is that these networks are absurdly expressive, and capable of encoding incredibly complex mechanisms in an opaque numerical format whose structure is largely hidden in the numbers.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8bicp", "score_hidden": false, "stickied": false, "created": 1492150517.0, "created_utc": 1492121717.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 23}}], "after": null, "before": null}}, "user_reports": [], "id": "dg86qhn", "gilded": 0, "archived": false, "score": 26, "report_reasons": null, "author": "NeverSpeaks", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There is a bit of a black box with neural networks. But we do have a pretty clear idea of what's going on. They are giant statistics machines. And the tools are advancing for us to explore what's going on. The graphs that Tensorflow can produce are pretty neat and can give some insights into what's going on.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is a bit of a black box with neural networks. But we do have a pretty clear idea of what&amp;#39;s going on. They are giant statistics machines. And the tools are advancing for us to explore what&amp;#39;s going on. The graphs that Tensorflow can produce are pretty neat and can give some insights into what&amp;#39;s going on.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg86qhn", "score_hidden": false, "stickied": false, "created": 1492144730.0, "created_utc": 1492115930.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 26}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9shra", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "unpopular_opinion", "parent_id": "t1_dg93hed", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I think the average futurist thinks it's somewhere in the 2040s (almost always the age at which they retire ;) ). \n\nThe assumptions on which those predictions (or prophecies) were made are not true. Hardware has not exponentially improved. Faster GPUs are a cool gimmick, but do not lead to a singularity; they just lead to faster and larger matrix multiplications. Not super exciting despite all the hype.\n\nEven if we had machines that would be a million times faster than in 2000 in 2020 (which we do not), then there has been no funding to the kind of ideas that would make such machines possible. Even in theory nobody has ever demonstrated how such a self-improving superintelligence would work (I read the relevant papers). It's all hearsay based on generalizations of specific simple examples. \n\nIt's like saying that cellular life evolves into a human all by itself in a lab. In reality this has been caused by many coincidences; evolution only works when certain pressures are present and has required a ridiculous amount of computation.\n\nIn particular the rebootstrapping of transferring a machine's image to new hardware it has designed itself has never been demonstrated in theory. Let alone in practice. \n\nI have no doubt that we can create a useful robot in limited domains, but I don't see the God level AIs that are promised by science-fiction anytime soon.\n\nWhy do you think it would be \"never\"? Is the universe too small (certain interesting functions (which I believe to be relevant to the development of such God AIs) are larger than the number of atoms in the observable universe)? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the average futurist thinks it&amp;#39;s somewhere in the 2040s (almost always the age at which they retire ;) ). &lt;/p&gt;\n\n&lt;p&gt;The assumptions on which those predictions (or prophecies) were made are not true. Hardware has not exponentially improved. Faster GPUs are a cool gimmick, but do not lead to a singularity; they just lead to faster and larger matrix multiplications. Not super exciting despite all the hype.&lt;/p&gt;\n\n&lt;p&gt;Even if we had machines that would be a million times faster than in 2000 in 2020 (which we do not), then there has been no funding to the kind of ideas that would make such machines possible. Even in theory nobody has ever demonstrated how such a self-improving superintelligence would work (I read the relevant papers). It&amp;#39;s all hearsay based on generalizations of specific simple examples. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like saying that cellular life evolves into a human all by itself in a lab. In reality this has been caused by many coincidences; evolution only works when certain pressures are present and has required a ridiculous amount of computation.&lt;/p&gt;\n\n&lt;p&gt;In particular the rebootstrapping of transferring a machine&amp;#39;s image to new hardware it has designed itself has never been demonstrated in theory. Let alone in practice. &lt;/p&gt;\n\n&lt;p&gt;I have no doubt that we can create a useful robot in limited domains, but I don&amp;#39;t see the God level AIs that are promised by science-fiction anytime soon.&lt;/p&gt;\n\n&lt;p&gt;Why do you think it would be &amp;quot;never&amp;quot;? Is the universe too small (certain interesting functions (which I believe to be relevant to the development of such God AIs) are larger than the number of atoms in the observable universe)? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9shra", "score_hidden": false, "stickied": false, "created": 1492234507.0, "created_utc": 1492205707.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgae54y", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "loftyal", "parent_id": "t1_dg9g9s5", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I'm assuming he means your arrogant for assuming that they'll \"never\" come. I agree it seems unlikely to be coming anytime soon, but to dismiss the idea entirely when it is definitely theoretically possible is arrogant. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m assuming he means your arrogant for assuming that they&amp;#39;ll &amp;quot;never&amp;quot; come. I agree it seems unlikely to be coming anytime soon, but to dismiss the idea entirely when it is definitely theoretically possible is arrogant. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgae54y", "score_hidden": false, "stickied": false, "created": 1492267403.0, "created_utc": 1492238603.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9g9s5", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "ythl", "parent_id": "t1_dg9dy3d", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "What, you believe in science fiction? And anyone who doesn't is /r/iamverysmart ?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What, you believe in science fiction? And anyone who doesn&amp;#39;t is &lt;a href=\"/r/iamverysmart\"&gt;/r/iamverysmart&lt;/a&gt; ?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9g9s5", "score_hidden": false, "stickied": false, "created": 1492219760.0, "created_utc": 1492190960.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9dy3d", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "fjallidergodur", "parent_id": "t1_dg93hed", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "/r/iamverysmart much ?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"/r/iamverysmart\"&gt;/r/iamverysmart&lt;/a&gt; much ?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9dy3d", "score_hidden": false, "stickied": false, "created": 1492217109.0, "created_utc": 1492188309.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg93hed", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "ythl", "parent_id": "t1_dg8ri3h", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Hence why your average redditor believes recursively self-improving superintelligences are going to be here by 2020. I just laugh to myself, knowing that they are *never* coming, let alone in 3 years.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hence why your average redditor believes recursively self-improving superintelligences are going to be here by 2020. I just laugh to myself, knowing that they are &lt;em&gt;never&lt;/em&gt; coming, let alone in 3 years.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg93hed", "score_hidden": false, "stickied": false, "created": 1492203647.0, "created_utc": 1492174847.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8ri3h", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "arealengineer", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It is interesting how the expectations of what AI can do are inversely proportional to how much the person knows about AI.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is interesting how the expectations of what AI can do are inversely proportional to how much the person knows about AI.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8ri3h", "score_hidden": false, "stickied": false, "created": 1492173257.0, "created_utc": 1492144457.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 15}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8mjoh", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "solinent", "parent_id": "t1_dg8b6q5", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The takeaway here is that at least in this case, you have many differently trained highly specialized neural networks working in tandem through some classic AI algorithms. For example, a neural net to determine type of weather and then to use two differently trained neural net to find the lane bounds depending on the type of weather.\n\nI also doubt that the AI manages to follow the rule of law without some basic decision tree type AI integrated with a neural net and other AIs (like SVM) and other raw algorithms taking sensor input and feeding the AI and using the outputs to make decisions.  \n\nOnce you allow the neural net to make higher level decisions  and give them goals, only then I think will we have any issues.\n ie. categorize the outputs of these specialized nets into steps the algorithm needs to achieve their goal with a neural net. I wonder if this is the case with current driving AIs. It's certainly possible I guess.", "edited": 1492136994.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The takeaway here is that at least in this case, you have many differently trained highly specialized neural networks working in tandem through some classic AI algorithms. For example, a neural net to determine type of weather and then to use two differently trained neural net to find the lane bounds depending on the type of weather.&lt;/p&gt;\n\n&lt;p&gt;I also doubt that the AI manages to follow the rule of law without some basic decision tree type AI integrated with a neural net and other AIs (like SVM) and other raw algorithms taking sensor input and feeding the AI and using the outputs to make decisions.  &lt;/p&gt;\n\n&lt;p&gt;Once you allow the neural net to make higher level decisions  and give them goals, only then I think will we have any issues.\n ie. categorize the outputs of these specialized nets into steps the algorithm needs to achieve their goal with a neural net. I wonder if this is the case with current driving AIs. It&amp;#39;s certainly possible I guess.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8mjoh", "score_hidden": false, "stickied": false, "created": 1492165536.0, "created_utc": 1492136736.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8b6q5", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "TheHillwoodMonkey", "parent_id": "t1_dg8ap22", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; via a series of matrix multiplications\n\nThese have to be executed, and the code that does this is effectively the interpreter for a program.\n\n&gt; While any given value in a particular matrix cell is nearly meaningless without context, the general function it is approximating tends to be just as easy for us to describe as the set of training data.\n\nThe function being approximated is *usually* easy to describe, at least informally, but the mechanism by which it is being approximated isn't, and that's the interesting bit.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;via a series of matrix multiplications&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;These have to be executed, and the code that does this is effectively the interpreter for a program.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;While any given value in a particular matrix cell is nearly meaningless without context, the general function it is approximating tends to be just as easy for us to describe as the set of training data.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The function being approximated is &lt;em&gt;usually&lt;/em&gt; easy to describe, at least informally, but the mechanism by which it is being approximated isn&amp;#39;t, and that&amp;#39;s the interesting bit.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8b6q5", "score_hidden": false, "stickied": false, "created": 1492150100.0, "created_utc": 1492121300.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 12}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8ap22", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "tragicshark", "parent_id": "t1_dg88qgw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "A NN is an algorithm that approximates a given function via a series of matrix multiplications when provided with a set of inputs and a requirement of a maximum statistical distance for the output compared to the provided output.\n\nThere is no interpreter. While any given value in a particular matrix cell is nearly meaningless without context, the general function it is approximating tends to be just as easy for us to describe as the set of training data.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A NN is an algorithm that approximates a given function via a series of matrix multiplications when provided with a set of inputs and a requirement of a maximum statistical distance for the output compared to the provided output.&lt;/p&gt;\n\n&lt;p&gt;There is no interpreter. While any given value in a particular matrix cell is nearly meaningless without context, the general function it is approximating tends to be just as easy for us to describe as the set of training data.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8ap22", "score_hidden": false, "stickied": false, "created": 1492149473.0, "created_utc": 1492120673.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg88qgw", "gilded": 0, "archived": false, "score": 14, "report_reasons": null, "author": "TheHillwoodMonkey", "parent_id": "t1_dg83bw1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This is incorrect. The code that executes a machine-learned algorithm is like an interpreter. The program running on the interpreter is written by another algorithm, and is almost entirely incomprehensible. Even to experts in the field. This is a major and well-documented flaw in neural networks, and is frequently cited as motivation by researchers who work in other areas of machine learning (such as inductive logic programming).\n\nI personally suspect that any machine learning technique capable of solving complex problems will suffer from the same problem. Prolog might seem more comprehensible than a neural network, but that won't be true if it ends up thousands of lines long with a bland UID-based naming scheme for new clauses.", "edited": 1492118591.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is incorrect. The code that executes a machine-learned algorithm is like an interpreter. The program running on the interpreter is written by another algorithm, and is almost entirely incomprehensible. Even to experts in the field. This is a major and well-documented flaw in neural networks, and is frequently cited as motivation by researchers who work in other areas of machine learning (such as inductive logic programming).&lt;/p&gt;\n\n&lt;p&gt;I personally suspect that any machine learning technique capable of solving complex problems will suffer from the same problem. Prolog might seem more comprehensible than a neural network, but that won&amp;#39;t be true if it ends up thousands of lines long with a bland UID-based naming scheme for new clauses.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg88qgw", "score_hidden": false, "stickied": false, "created": 1492147048.0, "created_utc": 1492118248.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 14}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg85a2u", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "awj", "parent_id": "t1_dg83n8e", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Meh, no, it pretty much does mean the colloquial interpretation. Analyzing a sophisticated neural network to determine precisely which inputs factored into a decision, and how they were taken into account, is an intractable task.\n\nObviously you can \"know\" what the training data was (although that tends to be such a large corpus that you can only really analyze it statistically), and how it was used to train the thing, but truly understanding a neural network well enough to accurately predict what it will do with a given piece of input is really damned hard. That's what people mean when they say \"no one knows\".", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Meh, no, it pretty much does mean the colloquial interpretation. Analyzing a sophisticated neural network to determine precisely which inputs factored into a decision, and how they were taken into account, is an intractable task.&lt;/p&gt;\n\n&lt;p&gt;Obviously you can &amp;quot;know&amp;quot; what the training data was (although that tends to be such a large corpus that you can only really analyze it statistically), and how it was used to train the thing, but truly understanding a neural network well enough to accurately predict what it will do with a given piece of input is really damned hard. That&amp;#39;s what people mean when they say &amp;quot;no one knows&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg85a2u", "score_hidden": false, "stickied": false, "created": 1492143108.0, "created_utc": 1492114308.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 15}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg90upg", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "shevegen", "parent_id": "t1_dg898rs", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Human beings will always justify their actions.\n\nIt is the nature of how the brain works.\n\nSee Trump attacking Syria based on lying on the part of the US government prior to the attack.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Human beings will always justify their actions.&lt;/p&gt;\n\n&lt;p&gt;It is the nature of how the brain works.&lt;/p&gt;\n\n&lt;p&gt;See Trump attacking Syria based on lying on the part of the US government prior to the attack.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg90upg", "score_hidden": false, "stickied": false, "created": 1492198055.0, "created_utc": 1492169255.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg898rs", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "itsmoppy", "parent_id": "t1_dg86haq", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Are they really justifying their actions, or inventing a rationalisation to explain a decision made in the subconscious?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are they really justifying their actions, or inventing a rationalisation to explain a decision made in the subconscious?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg898rs", "score_hidden": false, "stickied": false, "created": 1492147663.0, "created_utc": 1492118863.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg86haq", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg84ygo", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg86haq", "score_hidden": false, "stickied": false, "created": 1492144435.0, "created_utc": 1492115635.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8vel2", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "roffLOL", "parent_id": "t1_dg84ygo", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "a human has a human friendly interface which can be easily probed when a bad decision is taken. the human is often susceptible to quite simple corrective measures to make it not repeat the same mistake. \"don't repeat that\" is quite often enough.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;a human has a human friendly interface which can be easily probed when a bad decision is taken. the human is often susceptible to quite simple corrective measures to make it not repeat the same mistake. &amp;quot;don&amp;#39;t repeat that&amp;quot; is quite often enough.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8vel2", "score_hidden": false, "stickied": false, "created": 1492181477.0, "created_utc": 1492152677.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg84ygo", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "nfrankel", "parent_id": "t1_dg84nwl", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Do you know many humans who can always justify their actions?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you know many humans who can always justify their actions?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg84ygo", "score_hidden": false, "stickied": false, "created": 1492142751.0, "created_utc": 1492113951.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg84nwl", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg83n8e", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg84nwl", "score_hidden": false, "stickied": false, "created": 1492142420.0, "created_utc": 1492113620.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9c1jm", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "sultry_somnambulist", "parent_id": "t1_dg8p8yq", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Well you're correct that was a little strong of a statement. Nonetheless at some point wer're probably going to throw that part of the process into the black box as well, in a sense the intentional design of NN's is just a form of bootstrapping that we might be able to do away with to. If we want to design NN's at the scale of their biological counterparts it's probably impossible to incorporate a lot of design anyway. \n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well you&amp;#39;re correct that was a little strong of a statement. Nonetheless at some point wer&amp;#39;re probably going to throw that part of the process into the black box as well, in a sense the intentional design of NN&amp;#39;s is just a form of bootstrapping that we might be able to do away with to. If we want to design NN&amp;#39;s at the scale of their biological counterparts it&amp;#39;s probably impossible to incorporate a lot of design anyway. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9c1jm", "score_hidden": false, "stickied": false, "created": 1492215001.0, "created_utc": 1492186201.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8p8yq", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Drisku11", "parent_id": "t1_dg8bhvv", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Neural networks, evolutionary algorithms and so on are not designed, they're bottom up processes.\n\nThat seems a little bit too absolute of a statement. NNs are function approximators, and their network topology is designed to be conducive to approximating specific functions. E.g. a convolutional network is laid out in a way where it will learn a series of convolutional filter banks (hence the name). LSTMs are laid out in a way where certain neutron groups can store \"memories\". The layout of these things is actually analogous to digital logic circuits (SR latches, etc.).\n\nThe exact specifics of what a trained NN does can be difficult to describe, but it's not like *no* design work goes into them.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Neural networks, evolutionary algorithms and so on are not designed, they&amp;#39;re bottom up processes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That seems a little bit too absolute of a statement. NNs are function approximators, and their network topology is designed to be conducive to approximating specific functions. E.g. a convolutional network is laid out in a way where it will learn a series of convolutional filter banks (hence the name). LSTMs are laid out in a way where certain neutron groups can store &amp;quot;memories&amp;quot;. The layout of these things is actually analogous to digital logic circuits (SR latches, etc.).&lt;/p&gt;\n\n&lt;p&gt;The exact specifics of what a trained NN does can be difficult to describe, but it&amp;#39;s not like &lt;em&gt;no&lt;/em&gt; design work goes into them.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8p8yq", "score_hidden": false, "stickied": false, "created": 1492169567.0, "created_utc": 1492140767.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8bhvv", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "sultry_somnambulist", "parent_id": "t1_dg83n8e", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "No, he means it in the technical sense. Neural networks, evolutionary algorithms and so on are not designed, they're bottom up processes. As soon as they get sufficiently large they become a blackbox, just like an actual biological neural network. You can sometimes tear them apart to see what features are abstracted in what cluster, but there's little concrete meaning. There is no design or intelligence in the system itself, just like no termite actually knows how to build a termite mound if you were to ask it. \n\nWhether this constitutes a problem is really a question of perspective. There is no rational insight in such systems, but they still get the work done. We also can't really micro-manage an economy because it is not a system that lends itself to management. Same is true for networks. We don't waste time trying to teach birds how to fly either.\n\nIt might produce a problem for science at some point because science is the business of building abstract models for things. There is a great essay about this on Peter Norvig's [website](http://norvig.com/chomsky.html). This is a debate that exists in linguistics for a long time. Chomsky was one of the enemies of statistical methods in linguistics precisely because there is little insight to be gained about the inner workings of the language itself.  ", "edited": 1492121980.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, he means it in the technical sense. Neural networks, evolutionary algorithms and so on are not designed, they&amp;#39;re bottom up processes. As soon as they get sufficiently large they become a blackbox, just like an actual biological neural network. You can sometimes tear them apart to see what features are abstracted in what cluster, but there&amp;#39;s little concrete meaning. There is no design or intelligence in the system itself, just like no termite actually knows how to build a termite mound if you were to ask it. &lt;/p&gt;\n\n&lt;p&gt;Whether this constitutes a problem is really a question of perspective. There is no rational insight in such systems, but they still get the work done. We also can&amp;#39;t really micro-manage an economy because it is not a system that lends itself to management. Same is true for networks. We don&amp;#39;t waste time trying to teach birds how to fly either.&lt;/p&gt;\n\n&lt;p&gt;It might produce a problem for science at some point because science is the business of building abstract models for things. There is a great essay about this on Peter Norvig&amp;#39;s &lt;a href=\"http://norvig.com/chomsky.html\"&gt;website&lt;/a&gt;. This is a debate that exists in linguistics for a long time. Chomsky was one of the enemies of statistical methods in linguistics precisely because there is little insight to be gained about the inner workings of the language itself.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8bhvv", "score_hidden": false, "stickied": false, "created": 1492150500.0, "created_utc": 1492121700.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg83n8e", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg83bw1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg83n8e", "score_hidden": false, "stickied": false, "created": 1492141316.0, "created_utc": 1492112516.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8fsms", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "earthboundkid", "parent_id": "t1_dg877mk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "At this point, training algorithms are not that sophisticated. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;At this point, training algorithms are not that sophisticated. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8fsms", "score_hidden": false, "stickied": false, "created": 1492156211.0, "created_utc": 1492127411.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg877mk", "gilded": 0, "archived": false, "score": -2, "report_reasons": null, "author": "sasashimi", "parent_id": "t1_dg83bw1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "it's a bit interesting to think of the possibility of an AI being trained deliberately with a very long endgoal of \"pretend to be a driving AI for 5 years and then do nefarious action X\"", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;it&amp;#39;s a bit interesting to think of the possibility of an AI being trained deliberately with a very long endgoal of &amp;quot;pretend to be a driving AI for 5 years and then do nefarious action X&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg877mk", "score_hidden": false, "stickied": false, "created": 1492145272.0, "created_utc": 1492116472.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg83bw1", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg83bw1", "score_hidden": false, "stickied": false, "created": 1492140976.0, "created_utc": 1492112176.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8r7u4", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "boarhog", "parent_id": "t1_dg8p394", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Yet they get working awesome results", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yet they get working awesome results&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8r7u4", "score_hidden": false, "stickied": false, "created": 1492172762.0, "created_utc": 1492143962.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 8}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8p394", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "davidk01", "parent_id": "t1_dg8oos8", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "I hear it's an issue they struggle with daily. Would be good to remind them. They keep trying to do this thing they call L1 regularization and whatnot. All the while missing the fact that their model is a fucking monstrosity with a billion variables and no amount of regularization is going to get around that fact.", "edited": 1492140842.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I hear it&amp;#39;s an issue they struggle with daily. Would be good to remind them. They keep trying to do this thing they call L1 regularization and whatnot. All the while missing the fact that their model is a fucking monstrosity with a billion variables and no amount of regularization is going to get around that fact.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8p394", "score_hidden": false, "stickied": false, "created": 1492169320.0, "created_utc": 1492140520.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8oos8", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "Drisku11", "parent_id": "t1_dg85bnw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Also, you can fit any model with enough degrees of freedom to any data. Somehow I think the AI folks missed this lesson in model design.\n\nQuick! Someone go teach the folks over at /r/machinelearning about the concept of overfitting!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Also, you can fit any model with enough degrees of freedom to any data. Somehow I think the AI folks missed this lesson in model design.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Quick! Someone go teach the folks over at &lt;a href=\"/r/machinelearning\"&gt;/r/machinelearning&lt;/a&gt; about the concept of overfitting!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8oos8", "score_hidden": false, "stickied": false, "created": 1492168693.0, "created_utc": 1492139893.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 7}}], "after": null, "before": null}}, "user_reports": [], "id": "dg85bnw", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "davidk01", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "So you mean to tell me stacking functions so that the resulting final function has billion+ variables is hard to understand? Who would have thought?\n\nAlso, you can fit any model with enough degrees of freedom to any data. Somehow I think the AI folks missed this lesson in model design. When you have too many degrees of freedom you lose all explanatory power.", "edited": 1492114825.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So you mean to tell me stacking functions so that the resulting final function has billion+ variables is hard to understand? Who would have thought?&lt;/p&gt;\n\n&lt;p&gt;Also, you can fit any model with enough degrees of freedom to any data. Somehow I think the AI folks missed this lesson in model design. When you have too many degrees of freedom you lose all explanatory power.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg85bnw", "score_hidden": false, "stickied": false, "created": 1492143157.0, "created_utc": 1492114357.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8zbog", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "RichoDemus", "parent_id": "t1_dg85chr", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "But will they tell the truth?\nDun dun duuuun", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But will they tell the truth?\nDun dun duuuun&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8zbog", "score_hidden": false, "stickied": false, "created": 1492193497.0, "created_utc": 1492164697.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg85chr", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "lonemonk", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The AI will tell you what they all do.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The AI will tell you what they all do.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg85chr", "score_hidden": false, "stickied": false, "created": 1492143183.0, "created_utc": 1492114383.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8swr1", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Ace_To_Ace", "parent_id": "t1_dg8bbr1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That's a 60% on a CS assignment you spent the all week on.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s a 60% on a CS assignment you spent the all week on.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8swr1", "score_hidden": false, "stickied": false, "created": 1492175901.0, "created_utc": 1492147101.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8bbr1", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "CaptainAdjective", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's okay to not know what your algorithm does as long as you're still responsible for what it does.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s okay to not know what your algorithm does as long as you&amp;#39;re still responsible for what it does.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8bbr1", "score_hidden": false, "stickied": false, "created": 1492150280.0, "created_utc": 1492121480.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8jizg", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "paultypes", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The most advanced algorithms, based on algorithmic information theory, are quite well understood.\n\nThe _trendiest_ algorithms\u2014multi-layer neural networks\u2014are not.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The most advanced algorithms, based on algorithmic information theory, are quite well understood.&lt;/p&gt;\n\n&lt;p&gt;The &lt;em&gt;trendiest&lt;/em&gt; algorithms\u2014multi-layer neural networks\u2014are not.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8jizg", "score_hidden": false, "stickied": false, "created": 1492161333.0, "created_utc": 1492132533.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8eb0h", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ljluzjvert", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I thought it was all just statistics....", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I thought it was all just statistics....&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8eb0h", "score_hidden": false, "stickied": false, "created": 1492154235.0, "created_utc": 1492125435.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgb485a", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ollir", "parent_id": "t1_dg8oabs", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I see what you did there.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I see what you did there.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb485a", "score_hidden": false, "stickied": false, "created": 1492316289.0, "created_utc": 1492287489.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8oabs", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "restlesssoul", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I know! We develop a neural network that will analyse and explain them to us.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I know! We develop a neural network that will analyse and explain them to us.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8oabs", "score_hidden": false, "stickied": false, "created": 1492168089.0, "created_utc": 1492139289.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg93py2", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "combinatorylogic", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The future of AI is in expert systems, CAS, evolutionary programming, physical simulations. Everything is well understood and simple. Fuck the ANNs.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The future of AI is in expert systems, CAS, evolutionary programming, physical simulations. Everything is well understood and simple. Fuck the ANNs.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg93py2", "score_hidden": false, "stickied": false, "created": 1492204059.0, "created_utc": 1492175259.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9zw1i", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "reddit_user_---_---_", "parent_id": "t1_dg8e5tw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Error handling, exceptions, tests etc. There are generally error detecting and handling mechanism at all lower levels. So if something fails, it can be handled - now or later. That may not be possible to do very easily on a dynamic NN.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Error handling, exceptions, tests etc. There are generally error detecting and handling mechanism at all lower levels. So if something fails, it can be handled - now or later. That may not be possible to do very easily on a dynamic NN.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9zw1i", "score_hidden": false, "stickied": false, "created": 1492244307.0, "created_utc": 1492215507.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8e5tw", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "neitz", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Here's some food for thought.  Take any complex system, including the computer you are using reddit on.  Does it work perfectly?  There are at least tens of millions of lines of code on that machine (probably hundreds) across many sytems that interact in complex ways.\n\nSure at one point in time there was a human looking at and writing each individual piece.  But making it all work together?  No, these systems fail all the time and no one on the planet is intimately familiar with every piece.  Some understand at varying levels how all of the pieces work, but as far as intimately understanding the states and all of the possible transitions between those states - does not exist.\n\nSo to me, a NN isn't much different than today's computers.  What we need is the ability to handle failure more gracefully, and to introduce more control into how information is stored within them.  But that is improving every day.\n\nA neural network is basically data driven design taken to the extreme.  It's the ultimate in reconfigurable software.", "edited": 1492125437.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s some food for thought.  Take any complex system, including the computer you are using reddit on.  Does it work perfectly?  There are at least tens of millions of lines of code on that machine (probably hundreds) across many sytems that interact in complex ways.&lt;/p&gt;\n\n&lt;p&gt;Sure at one point in time there was a human looking at and writing each individual piece.  But making it all work together?  No, these systems fail all the time and no one on the planet is intimately familiar with every piece.  Some understand at varying levels how all of the pieces work, but as far as intimately understanding the states and all of the possible transitions between those states - does not exist.&lt;/p&gt;\n\n&lt;p&gt;So to me, a NN isn&amp;#39;t much different than today&amp;#39;s computers.  What we need is the ability to handle failure more gracefully, and to introduce more control into how information is stored within them.  But that is improving every day.&lt;/p&gt;\n\n&lt;p&gt;A neural network is basically data driven design taken to the extreme.  It&amp;#39;s the ultimate in reconfigurable software.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8e5tw", "score_hidden": false, "stickied": false, "created": 1492154044.0, "created_utc": 1492125244.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgaviwl", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "henker92", "parent_id": "t1_dg98uhk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There usually is perfectly reasonable explanation behind the behavior of multilayer neural network if you don't look at specific neurons or layers. \n\n\"In most of the situations I was presented with, the human drivers did switch lane when given this specific set of hypothesis. I was trained to mimic their behavior as closely as possible by minimizing this error function. Even though I was not presented with this specific situationl, it looked familiar with respect to this one and this one\"\n\nGeneral media should not use the term AI because that is not intelligence. That's interpolation. \n", "edited": 1492275982.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There usually is perfectly reasonable explanation behind the behavior of multilayer neural network if you don&amp;#39;t look at specific neurons or layers. &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;In most of the situations I was presented with, the human drivers did switch lane when given this specific set of hypothesis. I was trained to mimic their behavior as closely as possible by minimizing this error function. Even though I was not presented with this specific situationl, it looked familiar with respect to this one and this one&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;General media should not use the term AI because that is not intelligence. That&amp;#39;s interpolation. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaviwl", "score_hidden": false, "stickied": false, "created": 1492304492.0, "created_utc": 1492275692.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg98uhk", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "tkannelid", "parent_id": "t1_dg98la1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The general idea is that, for a specific behavior generated by a learning algorithm, we can't produce a human-style description of why the algorithm chose that behavior.\n\nWhy did the self-driving car shift lanes? Because that decision was a good tradeoff between looking like something that would be rewarded in the training set and something that would be penalized in the training set, given sensor data.\n\nWe want it to say that the road in its previous lane was full of potholes, or that traffic was moving faster in the other lane, or something like that.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The general idea is that, for a specific behavior generated by a learning algorithm, we can&amp;#39;t produce a human-style description of why the algorithm chose that behavior.&lt;/p&gt;\n\n&lt;p&gt;Why did the self-driving car shift lanes? Because that decision was a good tradeoff between looking like something that would be rewarded in the training set and something that would be penalized in the training set, given sensor data.&lt;/p&gt;\n\n&lt;p&gt;We want it to say that the road in its previous lane was full of potholes, or that traffic was moving faster in the other lane, or something like that.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg98uhk", "score_hidden": false, "stickied": false, "created": 1492211259.0, "created_utc": 1492182459.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg98la1", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "dicroce", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Would you say that you do not understand the beach? You can't possibly know the precise shape of every grain of sand... So you don't understand it.\n\nThis argument that people do not understand neural networks is stupid.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Would you say that you do not understand the beach? You can&amp;#39;t possibly know the precise shape of every grain of sand... So you don&amp;#39;t understand it.&lt;/p&gt;\n\n&lt;p&gt;This argument that people do not understand neural networks is stupid.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg98la1", "score_hidden": false, "stickied": false, "created": 1492210940.0, "created_utc": 1492182140.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9bhqz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "KayRice", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I have been working on the [General AI Challenge](https://www.general-ai-challenge.org/) for a few months and a lot of (private) discussions about the topic are fascinating.\n\n* Entirely possible that a large company could be an AI (or soon will be)\n\n* Most of what an AI would do during its early life would be similar to how you see the banking, stock, and other resource markets being manipulated (via whatever vector)\n\n* An advanced AGI would likely instantly have access to all of the computing power in the world via cloud computing\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have been working on the &lt;a href=\"https://www.general-ai-challenge.org/\"&gt;General AI Challenge&lt;/a&gt; for a few months and a lot of (private) discussions about the topic are fascinating.&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;Entirely possible that a large company could be an AI (or soon will be)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Most of what an AI would do during its early life would be similar to how you see the banking, stock, and other resource markets being manipulated (via whatever vector)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;An advanced AGI would likely instantly have access to all of the computing power in the world via cloud computing&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9bhqz", "score_hidden": false, "stickied": false, "created": 1492214383.0, "created_utc": 1492185583.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9z7hu", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Lakelava", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This is a little click baity. We don't have to know the position of each grain of sand to use sand. And we always knew that neural networks have a chance to fail outside the training set.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is a little click baity. We don&amp;#39;t have to know the position of each grain of sand to use sand. And we always knew that neural networks have a chance to fail outside the training set.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9z7hu", "score_hidden": false, "stickied": false, "created": 1492243396.0, "created_utc": 1492214596.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"author_cakeday": true, "subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9113a", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ArkyBeagle", "parent_id": "t1_dg8ekxm", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "So is this a corrollary of the Yoshi koan ( I cannot understand myself ) or some fourth law of robotics? \n\nComputer programs are nothing more than extremely complex clocks. You cannot expect meaning from them - at least at this writing. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So is this a corrollary of the Yoshi koan ( I cannot understand myself ) or some fourth law of robotics? &lt;/p&gt;\n\n&lt;p&gt;Computer programs are nothing more than extremely complex clocks. You cannot expect meaning from them - at least at this writing. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9113a", "score_hidden": false, "stickied": false, "created": 1492198508.0, "created_utc": 1492169708.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg9nhnu", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "sacado", "parent_id": "t1_dg8ekxm", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;  Machine Learning is by far the most successful AI implementation\n\nThis is far from truth. ML is successful in a few domains, but lots of other domains are dominated by symbolic AI, which by design can explain its reasoning. But, sure, it's not very trendy.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Machine Learning is by far the most successful AI implementation&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is far from truth. ML is successful in a few domains, but lots of other domains are dominated by symbolic AI, which by design can explain its reasoning. But, sure, it&amp;#39;s not very trendy.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9nhnu", "score_hidden": false, "stickied": false, "created": 1492228365.0, "created_utc": 1492199565.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8r9ik", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "boarhog", "parent_id": "t1_dg8ekxm", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "And then we just apply the same idea to human neural networks and upload ourselves. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And then we just apply the same idea to human neural networks and upload ourselves. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8r9ik", "score_hidden": false, "stickied": false, "created": 1492172842.0, "created_utc": 1492144042.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8mqkm", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "crusoe", "parent_id": "t1_dg8ekxm", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Right. So explain yourself.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Right. So explain yourself.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8mqkm", "score_hidden": false, "stickied": false, "created": 1492165811.0, "created_utc": 1492137011.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8ekxm", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "sscfx", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "This will be especially problematic since any algorithm that cannot explain itself will be illegal. The [Right to Explanation](https://arxiv.org/abs/1606.08813) means that any algorithm that has any substantial influence should always be able to provide an explanation. Machine Learning is by far the most successful AI implementation but fails to provide an explanation. Complex extraction methods need to be researched which derive meaning from the ridiculously high dimensional neural networks.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This will be especially problematic since any algorithm that cannot explain itself will be illegal. The &lt;a href=\"https://arxiv.org/abs/1606.08813\"&gt;Right to Explanation&lt;/a&gt; means that any algorithm that has any substantial influence should always be able to provide an explanation. Machine Learning is by far the most successful AI implementation but fails to provide an explanation. Complex extraction methods need to be researched which derive meaning from the ridiculously high dimensional neural networks.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8ekxm", "score_hidden": false, "stickied": false, "created": 1492154595.0, "created_utc": 1492125795.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg8waic", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "pvtsuhov", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's sad to see how informatics regressed intolshamanism. And instead of solving problems with technologies, we rely on scaring off the spirit of malevolent AI with giving frauds ridiculous amounts of money.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s sad to see how informatics regressed intolshamanism. And instead of solving problems with technologies, we rely on scaring off the spirit of malevolent AI with giving frauds ridiculous amounts of money.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg8waic", "score_hidden": false, "stickied": false, "created": 1492183877.0, "created_utc": 1492155077.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dgckwxt", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "dafuqm88", "parent_id": "t1_dgckjoh", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Rationalizing and being rational are two very different things, is English not your first language? ", "edited": 1492382561.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Rationalizing and being rational are two very different things, is English not your first language? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgckwxt", "score_hidden": false, "stickied": false, "created": 1492405812.0, "created_utc": 1492377012.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgckjoh", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "raphier", "parent_id": "t1_dg988dm", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "in what world do you live? We rationalize everything.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;in what world do you live? We rationalize everything.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgckjoh", "score_hidden": false, "stickied": false, "created": 1492405319.0, "created_utc": 1492376519.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg988dm", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "dafuqm88", "parent_id": "t1_dg89v4r", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "No we aren't rational beings at all, what world do you live in?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No we aren&amp;#39;t rational beings at all, what world do you live in?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg988dm", "score_hidden": false, "stickied": false, "created": 1492210495.0, "created_utc": 1492181695.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_657n42", "likes": null, "replies": "", "user_reports": [], "id": "dg98x6l", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "tkannelid", "parent_id": "t1_dg89v4r", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "When math is irrational, that's just not natural, but sometimes it can be transcendental.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;When math is irrational, that&amp;#39;s just not natural, but sometimes it can be transcendental.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg98x6l", "score_hidden": false, "stickied": false, "created": 1492211349.0, "created_utc": 1492182549.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg89v4r", "gilded": 0, "archived": false, "score": -4, "report_reasons": null, "author": "raphier", "parent_id": "t3_657n42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That's because we're rational beings and math can be irrational at times in how it gets to solutions.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s because we&amp;#39;re rational beings and math can be irrational at times in how it gets to solutions.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg89v4r", "score_hidden": false, "stickied": false, "created": 1492148431.0, "created_utc": 1492119631.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -4}}], "after": null, "before": null}}]