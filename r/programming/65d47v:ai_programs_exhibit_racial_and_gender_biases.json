[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "programming", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "65d47v", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 212, "report_reasons": null, "author": "trot-trot", "saved": false, "mod_reports": [], "name": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "approved_by": null, "over_18": false, "domain": "theguardian.com", "hidden": false, "thumbnail": "", "subreddit_id": "t5_2fwo", "edited": false, "link_flair_css_class": null, "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/programming/comments/65d47v/ai_programs_exhibit_racial_and_gender_biases/", "num_reports": null, "locked": false, "stickied": false, "created": 1492211970.0, "url": "https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals", "author_flair_text": null, "quarantine": false, "title": "AI programs exhibit racial and gender biases, research reveals: \"Machine learning algorithms are picking up deeply ingrained race and gender prejudices concealed within the patterns of language use, scientists say\"", "created_utc": 1492183170.0, "distinguished": null, "media": null, "upvote_ratio": 0.71, "num_comments": 253, "visited": false, "subreddit_type": "public", "ups": 212}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgado31", "gilded": 0, "archived": false, "score": 22, "report_reasons": null, "author": "mujjingun", "parent_id": "t1_dg9o9tq", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Well, the training set is a sample of our society, so if the sample doesn't suffer from selection bias, my argument follows.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well, the training set is a sample of our society, so if the sample doesn&amp;#39;t suffer from selection bias, my argument follows.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgado31", "score_hidden": false, "stickied": false, "created": 1492266290.0, "created_utc": 1492237490.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 22}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgakllg", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "MagicMurderBagYT", "parent_id": "t1_dgag5sv", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Harding referred to Newton's Principia Mathematica as a \"rape manual\" in her 1986 book \"The Science Question in Feminism\", a characterization that she later said she regretted.\n\nWat.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Harding referred to Newton&amp;#39;s Principia Mathematica as a &amp;quot;rape manual&amp;quot; in her 1986 book &amp;quot;The Science Question in Feminism&amp;quot;, a characterization that she later said she regretted.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Wat.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgakllg", "score_hidden": false, "stickied": false, "created": 1492286314.0, "created_utc": 1492257514.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 25}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbk2im", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "AlotOfReading", "parent_id": "t1_dgag5sv", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Harding's argument is not that the facts of the universe are gender biased, but that our methods of learning those facts (a process called \"science\") can be gender biased. This isn't even necessarily through active bias. There's significantly less information available on the effects of most drugs on pregnant women for instance, simply as a result of the ethical concerns with drug testing. \n\nSome of her other views are completely insane of course, but the core of her argument is at least worth considering.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Harding&amp;#39;s argument is not that the facts of the universe are gender biased, but that our methods of learning those facts (a process called &amp;quot;science&amp;quot;) can be gender biased. This isn&amp;#39;t even necessarily through active bias. There&amp;#39;s significantly less information available on the effects of most drugs on pregnant women for instance, simply as a result of the ethical concerns with drug testing. &lt;/p&gt;\n\n&lt;p&gt;Some of her other views are completely insane of course, but the core of her argument is at least worth considering.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbk2im", "score_hidden": false, "stickied": false, "created": 1492338823.0, "created_utc": 1492310023.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgag5sv", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "mujjingun", "parent_id": "t1_dgaea8h", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Still, [there exist people](https://en.wikipedia.org/wiki/Sandra_Harding) who claim biology is gender biased. It's sad, really. The whole world is depressing.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Still, &lt;a href=\"https://en.wikipedia.org/wiki/Sandra_Harding\"&gt;there exist people&lt;/a&gt; who claim biology is gender biased. It&amp;#39;s sad, really. The whole world is depressing.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgag5sv", "score_hidden": false, "stickied": false, "created": 1492272752.0, "created_utc": 1492243952.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dganae9", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "mcguire", "parent_id": "t1_dgaea8h", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I was incorrect: \n\n&gt; Rather than train the embedding ourselves, we used pretrained GloVe embeddings distributed by its authors. This ensures impartiality, simplifies reproducing our results, and allows us to replicate the effects that may be found in real applications of machine learning. We used the largest of the four corpora provided\u2014the \u201cCommon Crawl\u201d corpus obtained from a large-scale crawl of the Internet, containing 840 billion tokens (roughly, words). Tokens in this corpus are case sensitive, resulting in 2.2 million different ones. Each word corresponds to a 300-dimensional vector derived from counts of other words that co-occur with it in a 10-word window.\n\nThe original paper: [Semantics derived automatically from language corpora contain human-like biases](http://science.sciencemag.org/content/356/6334/183.full).", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was incorrect: &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Rather than train the embedding ourselves, we used pretrained GloVe embeddings distributed by its authors. This ensures impartiality, simplifies reproducing our results, and allows us to replicate the effects that may be found in real applications of machine learning. We used the largest of the four corpora provided\u2014the \u201cCommon Crawl\u201d corpus obtained from a large-scale crawl of the Internet, containing 840 billion tokens (roughly, words). Tokens in this corpus are case sensitive, resulting in 2.2 million different ones. Each word corresponds to a 300-dimensional vector derived from counts of other words that co-occur with it in a 10-word window.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The original paper: &lt;a href=\"http://science.sciencemag.org/content/356/6334/183.full\"&gt;Semantics derived automatically from language corpora contain human-like biases&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dganae9", "score_hidden": false, "stickied": false, "created": 1492292126.0, "created_utc": 1492263326.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgagoea", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "kefeer", "parent_id": "t1_dgaea8h", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Look for yourself: https://en.wikipedia.org/wiki/Protein_structure\n\nQuite a bit of men named there, but no women.\n\n*disclaimer: personally, i find the whole talk about gender biases dumb.*", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Look for yourself: &lt;a href=\"https://en.wikipedia.org/wiki/Protein_structure\"&gt;https://en.wikipedia.org/wiki/Protein_structure&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Quite a bit of men named there, but no women.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;disclaimer: personally, i find the whole talk about gender biases dumb.&lt;/em&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgagoea", "score_hidden": false, "stickied": false, "created": 1492274295.0, "created_utc": 1492245495.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaea8h", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "shevegen", "parent_id": "t1_dga6bom", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Fairly unlikely. There are many articles in Wikipedia where gender plays exactly no role at all. Common example: molecular biology.\n\nWhere is gender bias in protein structure?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fairly unlikely. There are many articles in Wikipedia where gender plays exactly no role at all. Common example: molecular biology.&lt;/p&gt;\n\n&lt;p&gt;Where is gender bias in protein structure?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaea8h", "score_hidden": false, "stickied": false, "created": 1492267749.0, "created_utc": 1492238949.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 7}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6bom", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "mcguire", "parent_id": "t1_dg9o9tq", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Wasn't the training set Wikipedia?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wasn&amp;#39;t the training set Wikipedia?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga6bom", "score_hidden": false, "stickied": false, "created": 1492253215.0, "created_utc": 1492224415.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9o9tq", "gilded": 0, "archived": false, "score": 97, "report_reasons": null, "author": "MagicMurderBagYT", "parent_id": "t1_dg9cia8", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; \"statistical evidence that our society is biased\"\n\n*training set", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;statistical evidence that our society is biased&amp;quot;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;*training set&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9o9tq", "score_hidden": false, "stickied": false, "created": 1492229306.0, "created_utc": 1492200506.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 97}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgb0lzh", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "PM_ME_A_FACT", "parent_id": "t1_dgb0jqn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This made no sense either", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This made no sense either&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb0lzh", "score_hidden": false, "stickied": false, "created": 1492311427.0, "created_utc": 1492282627.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgcj10q", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Lepidostrix", "parent_id": "t1_dgb0jqn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The real problem is that you people don't seem to want to keep up with any of the literature that explores race and implicit biases. The only kind of racism that you know about is the KKK. So when people do not look like the KKK you assume they are no racist. \n\nHowever, in academic circles race and biases have been talked about in a different capacity for over 50 years. This is what the people who are calling folks like you racist are responding to. And you lack the vocabulary to understand what they are talking about because you don't care to seek the science.\n\nThis is the case in almost every circumstance where people are upset words are changing meanings. There have already been decades of discussion. You haven't been part of it. Catch up.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The real problem is that you people don&amp;#39;t seem to want to keep up with any of the literature that explores race and implicit biases. The only kind of racism that you know about is the KKK. So when people do not look like the KKK you assume they are no racist. &lt;/p&gt;\n\n&lt;p&gt;However, in academic circles race and biases have been talked about in a different capacity for over 50 years. This is what the people who are calling folks like you racist are responding to. And you lack the vocabulary to understand what they are talking about because you don&amp;#39;t care to seek the science.&lt;/p&gt;\n\n&lt;p&gt;This is the case in almost every circumstance where people are upset words are changing meanings. There have already been decades of discussion. You haven&amp;#39;t been part of it. Catch up.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcj10q", "score_hidden": false, "stickied": false, "created": 1492403337.0, "created_utc": 1492374537.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb0jqn", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgasscf", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "The definition of the word \"racist\" has changed from \"discriminating against someone for being a different race\" to \"thinking races are biologically or psychologically different in any way.\"\n\nThus, the definition has been expanded to the point where it no longer has a negative connotation. There are biological differences between the races, so if you're \"racist\" for thinking that, then racism is not an insult.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The definition of the word &amp;quot;racist&amp;quot; has changed from &amp;quot;discriminating against someone for being a different race&amp;quot; to &amp;quot;thinking races are biologically or psychologically different in any way.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Thus, the definition has been expanded to the point where it no longer has a negative connotation. There are biological differences between the races, so if you&amp;#39;re &amp;quot;racist&amp;quot; for thinking that, then racism is not an insult.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb0jqn", "score_hidden": false, "stickied": false, "created": 1492311342.0, "created_utc": 1492282542.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dgasscf", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "PM_ME_A_FACT", "parent_id": "t1_dga3j1v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This position never makes sense and nobody can explain why they think it's true. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This position never makes sense and nobody can explain why they think it&amp;#39;s true. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgasscf", "score_hidden": false, "stickied": false, "created": 1492300673.0, "created_utc": 1492271873.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 12}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgaasgo", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "TB1080", "parent_id": "t1_dga3j1v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Which is giving endless power to actual racists because there is no longer an identifier for them.\n\nOn top of that, calling someone a racist will pretty much get the rest of your argument completely ignored, even if the designation is true.\n\n[When everybody is racist, nobody is.](https://youtu.be/GYmHYQPaHaw?t=38)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Which is giving endless power to actual racists because there is no longer an identifier for them.&lt;/p&gt;\n\n&lt;p&gt;On top of that, calling someone a racist will pretty much get the rest of your argument completely ignored, even if the designation is true.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://youtu.be/GYmHYQPaHaw?t=38\"&gt;When everybody is racist, nobody is.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaasgo", "score_hidden": false, "stickied": false, "created": 1492260446.0, "created_utc": 1492231646.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dga3j1v", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "FlatlanderMachine", "parent_id": "t1_dga30u1", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "It truly has lost it's meaning. What a shame.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It truly has lost it&amp;#39;s meaning. What a shame.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga3j1v", "score_hidden": false, "stickied": false, "created": 1492249244.0, "created_utc": 1492220444.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dga30u1", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "bishopindict", "parent_id": "t1_dg9zsfp", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "It's also racist, because *racist* in 2017 is the most vague and watered down word to have ever existed.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s also racist, because &lt;em&gt;racist&lt;/em&gt; in 2017 is the most vague and watered down word to have ever existed.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga30u1", "score_hidden": false, "stickied": false, "created": 1492248547.0, "created_utc": 1492219747.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 15}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgaflj1", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgafh0r", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "My argument was never about when people don't take it to be 'fundamental' or 'genetic' though.  It's why I don't know really how to deal with a comment that seems well outside the scope of what I was arguing about, or what particular line drew my interest, which yes, involved a line of reasoning that indeed seem to draw upon rather strange and false notions about what constitutes a 'race'.  In a discussion about how programs interpret race, that seems important, the fact that people of a 'race' speak a certain language, by contrast, seems irrelevant.\n\nHow am I supposed to deal with that kind of comment?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;My argument was never about when people don&amp;#39;t take it to be &amp;#39;fundamental&amp;#39; or &amp;#39;genetic&amp;#39; though.  It&amp;#39;s why I don&amp;#39;t know really how to deal with a comment that seems well outside the scope of what I was arguing about, or what particular line drew my interest, which yes, involved a line of reasoning that indeed seem to draw upon rather strange and false notions about what constitutes a &amp;#39;race&amp;#39;.  In a discussion about how programs interpret race, that seems important, the fact that people of a &amp;#39;race&amp;#39; speak a certain language, by contrast, seems irrelevant.&lt;/p&gt;\n\n&lt;p&gt;How am I supposed to deal with that kind of comment?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaflj1", "score_hidden": false, "stickied": false, "created": 1492271172.0, "created_utc": 1492242372.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgafh0r", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "ManifestedLurker", "parent_id": "t1_dga2vmi", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;You were asking something that effectively was not what I was arguing.\n\nYou were arguing a strawman, just because someone says that there is a statistical correlation between a race and another thing doesn't mean that that person is talking about it beeing inherently genetic.\n\n\n&gt; I'd only talk to someone in those languages after I had confirmed they knew it.\n\nDo you also wait to check if a tiger is realy hungry till you start running? Maybe it just wants to be friends.", "edited": 1492242272.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;You were asking something that effectively was not what I was arguing.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You were arguing a strawman, just because someone says that there is a statistical correlation between a race and another thing doesn&amp;#39;t mean that that person is talking about it beeing inherently genetic.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;d only talk to someone in those languages after I had confirmed they knew it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Do you also wait to check if a tiger is realy hungry till you start running? Maybe it just wants to be friends.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgafh0r", "score_hidden": false, "stickied": false, "created": 1492270823.0, "created_utc": 1492242023.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 8}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga5axm", "gilded": 0, "archived": false, "score": -6, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga4vtg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I prefer nuance thanks. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I prefer nuance thanks. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga5axm", "score_hidden": false, "stickied": false, "created": 1492251767.0, "created_utc": 1492222967.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": -6}}], "after": null, "before": null}}, "user_reports": [], "id": "dga4vtg", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "FlatlanderMachine", "parent_id": "t1_dga2vmi", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; You were asking something that effectively was not what I was arguing.\n\nI replied to your argument, if you have something to say, boil it down to a simple statement.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;You were asking something that effectively was not what I was arguing.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I replied to your argument, if you have something to say, boil it down to a simple statement.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga4vtg", "score_hidden": false, "stickied": false, "created": 1492251149.0, "created_utc": 1492222349.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgafti1", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgafai6", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;How would you do that without trying to speak to them in those languages? I mean, someone needs to say the first word in some language.\n\nThat's just it, someone needs to say a first word.  So what use is the stereotype?  If you have to 'pick' a language, and say \"hello\", when someone else responds \"hola\", either party can adjust their language at will, but the stereotype doesn't make it terribly useful for judging what language to use first.  The default is usually just 'your own native language' or 'the native language used in the region you occupy'.  My use of the word 'freeway' makes it pretty clear I'm from Southern California on linguistic tests, but looking at me would give few clues.  Likewise, looking at a person possibly being \"chinese\" might help \"ok, they use a chinese dialect\", but in this case that's so diverse that even saying \"hello\" might require first talking to them to identify *which* regional dialect they use.\n\nThe 'stereotype' in this case doesn't really convey much \"actionable\" information.  \"A European person is more likely to speak some European language\", but conversation doesn't work with statistical likelihoods, it works between individuals where there's some primary exchange of information via words like \"hello\" to set whatever language the exchange happens in.\n\nSo then what's the point?  \"Some statistics happen to be true\"?  I don't know what to do with that information though. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;How would you do that without trying to speak to them in those languages? I mean, someone needs to say the first word in some language.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That&amp;#39;s just it, someone needs to say a first word.  So what use is the stereotype?  If you have to &amp;#39;pick&amp;#39; a language, and say &amp;quot;hello&amp;quot;, when someone else responds &amp;quot;hola&amp;quot;, either party can adjust their language at will, but the stereotype doesn&amp;#39;t make it terribly useful for judging what language to use first.  The default is usually just &amp;#39;your own native language&amp;#39; or &amp;#39;the native language used in the region you occupy&amp;#39;.  My use of the word &amp;#39;freeway&amp;#39; makes it pretty clear I&amp;#39;m from Southern California on linguistic tests, but looking at me would give few clues.  Likewise, looking at a person possibly being &amp;quot;chinese&amp;quot; might help &amp;quot;ok, they use a chinese dialect&amp;quot;, but in this case that&amp;#39;s so diverse that even saying &amp;quot;hello&amp;quot; might require first talking to them to identify &lt;em&gt;which&lt;/em&gt; regional dialect they use.&lt;/p&gt;\n\n&lt;p&gt;The &amp;#39;stereotype&amp;#39; in this case doesn&amp;#39;t really convey much &amp;quot;actionable&amp;quot; information.  &amp;quot;A European person is more likely to speak some European language&amp;quot;, but conversation doesn&amp;#39;t work with statistical likelihoods, it works between individuals where there&amp;#39;s some primary exchange of information via words like &amp;quot;hello&amp;quot; to set whatever language the exchange happens in.&lt;/p&gt;\n\n&lt;p&gt;So then what&amp;#39;s the point?  &amp;quot;Some statistics happen to be true&amp;quot;?  I don&amp;#39;t know what to do with that information though. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgafti1", "score_hidden": false, "stickied": false, "created": 1492271768.0, "created_utc": 1492242968.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgafai6", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Klockan4", "parent_id": "t1_dga2vmi", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; I'd only talk to someone in those languages after I had confirmed they knew it.\n\nHow would you do that without trying to speak to them in those languages? I mean, someone needs to say the first word in some language.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;d only talk to someone in those languages after I had confirmed they knew it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;How would you do that without trying to speak to them in those languages? I mean, someone needs to say the first word in some language.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgafai6", "score_hidden": false, "stickied": false, "created": 1492270326.0, "created_utc": 1492241526.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga2vmi", "gilded": 0, "archived": false, "score": -10, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga2a7k", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Perfect, but that's not what I was asking.\n\nYou were asking something that effectively was not what I was arguing.  To what end, I'm not sure, even if I knew mandarin or Lithuanian I'd only talk to someone in those languages **after** I had confirmed they knew it.  And that wouldn't be possible by physical features alone.\n\nBasically, what's the point of this?  I responded with what is the heart of my comment, the \"point\" I care about.  I added the semantic jab because it felt appropriate for how I felt you treated my comment.\n\nSo this time I'll be more explicit.  What idea are you trying to get across?  \"Sometimes stereotypes can reflect partially accurate statistical data about particular datasets\"?  Yeah?  That seems different from the idea that I originally responded to though, \"purely *acting* rational (and therefore not racist)\".", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Perfect, but that&amp;#39;s not what I was asking.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You were asking something that effectively was not what I was arguing.  To what end, I&amp;#39;m not sure, even if I knew mandarin or Lithuanian I&amp;#39;d only talk to someone in those languages &lt;strong&gt;after&lt;/strong&gt; I had confirmed they knew it.  And that wouldn&amp;#39;t be possible by physical features alone.&lt;/p&gt;\n\n&lt;p&gt;Basically, what&amp;#39;s the point of this?  I responded with what is the heart of my comment, the &amp;quot;point&amp;quot; I care about.  I added the semantic jab because it felt appropriate for how I felt you treated my comment.&lt;/p&gt;\n\n&lt;p&gt;So this time I&amp;#39;ll be more explicit.  What idea are you trying to get across?  &amp;quot;Sometimes stereotypes can reflect partially accurate statistical data about particular datasets&amp;quot;?  Yeah?  That seems different from the idea that I originally responded to though, &amp;quot;purely &lt;em&gt;acting&lt;/em&gt; rational (and therefore not racist)&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga2vmi", "score_hidden": false, "stickied": false, "created": 1492248340.0, "created_utc": 1492219540.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": -10}}], "after": null, "before": null}}, "user_reports": [], "id": "dga2a7k", "gilded": 0, "archived": false, "score": 20, "report_reasons": null, "author": "FlatlanderMachine", "parent_id": "t1_dga0fth", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; How's this, pretty sure that regardless of statistics, genetically, an Asian person is as likely to speak Chinese as Lithuanian. In that an Asian infant is not inherently 'predisposed' to a language.\n\nPerfect, but that's not what I was asking. By \"statistically\" , I meant the total amount of people speaking Lithuanian vs the total number of people speaking a dialect of Chinese and their race. You can call it \"stereotyping\" but it's statistically practical to assume someone will be speaking a certain language based on a given race.\n\n&gt;  Incidentally, I don't know what you mean by \"Chinese\".\n\nYou do, but you choose semantics over the argument. \n\n&gt; If I see a \"European\" person I'm not likely to think their first language is Lithuanian.\n\nWhy is that ? You just mentioned in the same comment that an Asian person is as likely to speak Chinese as Lithuanian. so why not every European having the same chance of speaking Lithuanian ? \n\nIf you didn't get anything from this comment, here's this:\n\nStatistically, as in the Webster use of the term, people are more likely to learn a *dialect of Chinese* than Lithuanian, as defined by number of Lithuanians divided by number of Chinese (yes, I know there's going to be a discrepancy) which is : 2.17833456e^-9.\n\nShit odds dude. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;How&amp;#39;s this, pretty sure that regardless of statistics, genetically, an Asian person is as likely to speak Chinese as Lithuanian. In that an Asian infant is not inherently &amp;#39;predisposed&amp;#39; to a language.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Perfect, but that&amp;#39;s not what I was asking. By &amp;quot;statistically&amp;quot; , I meant the total amount of people speaking Lithuanian vs the total number of people speaking a dialect of Chinese and their race. You can call it &amp;quot;stereotyping&amp;quot; but it&amp;#39;s statistically practical to assume someone will be speaking a certain language based on a given race.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Incidentally, I don&amp;#39;t know what you mean by &amp;quot;Chinese&amp;quot;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You do, but you choose semantics over the argument. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If I see a &amp;quot;European&amp;quot; person I&amp;#39;m not likely to think their first language is Lithuanian.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why is that ? You just mentioned in the same comment that an Asian person is as likely to speak Chinese as Lithuanian. so why not every European having the same chance of speaking Lithuanian ? &lt;/p&gt;\n\n&lt;p&gt;If you didn&amp;#39;t get anything from this comment, here&amp;#39;s this:&lt;/p&gt;\n\n&lt;p&gt;Statistically, as in the Webster use of the term, people are more likely to learn a &lt;em&gt;dialect of Chinese&lt;/em&gt; than Lithuanian, as defined by number of Lithuanians divided by number of Chinese (yes, I know there&amp;#39;s going to be a discrepancy) which is : 2.17833456e&lt;sup&gt;-9.&lt;/sup&gt;&lt;/p&gt;\n\n&lt;p&gt;Shit odds dude. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga2a7k", "score_hidden": false, "stickied": false, "created": 1492247514.0, "created_utc": 1492218714.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 20}}], "after": null, "before": null}}, "user_reports": [], "id": "dga0fth", "gilded": 0, "archived": false, "score": -5, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dg9zsfp", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "How's this, pretty sure that regardless of statistics, genetically, an Asian person is as likely to speak Chinese as Lithuanian.  In that an Asian infant is not inherently 'predisposed' to a language.\n\nWhen talking about races, I care that people are considering the concept 'a reflection of genetic makeup'.  I get concerned when people indicate that anything justified with stereotypes is \"purely acting rational (and therefore not racist).\"\n\nIncidentally, I don't know what you mean by \"Chinese\".\n\nIf I see a \"European\" person I'm not likely to think their first language is Lithuanian.  I'm going to think maybe \"some European language\".  Chinese is kinda the same.  There are people living in different parts of China who speak such different 'dialects' that really they're unintelligible between.  \"Chinese\" isn't really a single language any more than \"European\" would be a single language.\n\n... I'm a linguistic nerd.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How&amp;#39;s this, pretty sure that regardless of statistics, genetically, an Asian person is as likely to speak Chinese as Lithuanian.  In that an Asian infant is not inherently &amp;#39;predisposed&amp;#39; to a language.&lt;/p&gt;\n\n&lt;p&gt;When talking about races, I care that people are considering the concept &amp;#39;a reflection of genetic makeup&amp;#39;.  I get concerned when people indicate that anything justified with stereotypes is &amp;quot;purely acting rational (and therefore not racist).&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;Incidentally, I don&amp;#39;t know what you mean by &amp;quot;Chinese&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;If I see a &amp;quot;European&amp;quot; person I&amp;#39;m not likely to think their first language is Lithuanian.  I&amp;#39;m going to think maybe &amp;quot;some European language&amp;quot;.  Chinese is kinda the same.  There are people living in different parts of China who speak such different &amp;#39;dialects&amp;#39; that really they&amp;#39;re unintelligible between.  &amp;quot;Chinese&amp;quot; isn&amp;#39;t really a single language any more than &amp;quot;European&amp;quot; would be a single language.&lt;/p&gt;\n\n&lt;p&gt;... I&amp;#39;m a linguistic nerd.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga0fth", "score_hidden": false, "stickied": false, "created": 1492245029.0, "created_utc": 1492216229.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": -5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9zsfp", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "FlatlanderMachine", "parent_id": "t1_dg9wmff", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "You see an Asian person , statistically, is he more likely to have Chinese or Lithuanian as their first language ? That's stereotyping. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You see an Asian person , statistically, is he more likely to have Chinese or Lithuanian as their first language ? That&amp;#39;s stereotyping. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9zsfp", "score_hidden": false, "stickied": false, "created": 1492244176.0, "created_utc": 1492215376.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 25}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgbwuzi", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "polite-1", "parent_id": "t1_dgbvo1m", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Ok. I suggest you go to r/biology to help you understand the studies you're quoting.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ok. I suggest you go to &lt;a href=\"/r/biology\"&gt;r/biology&lt;/a&gt; to help you understand the studies you&amp;#39;re quoting.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbwuzi", "score_hidden": false, "stickied": false, "created": 1492367647.0, "created_utc": 1492338847.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbvo1m", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "anechoicmedia", "parent_id": "t1_dgbpa87", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I have no education in anything.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I have no education in anything.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbvo1m", "score_hidden": false, "stickied": false, "created": 1492363490.0, "created_utc": 1492334690.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbpa87", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "polite-1", "parent_id": "t1_dgal0aw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Do you have any formal education in biology? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have any formal education in biology? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbpa87", "score_hidden": false, "stickied": false, "created": 1492347125.0, "created_utc": 1492318325.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbsscb", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgal0aw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;This is not necessary for what I am saying.\n\nIt really seems to be because it's kinda essential for your point.\n\n&gt;The point of contention is \"will computers reinvent something analogous to race anyway\", or more broadly, \"will computers reinvent existing racial stereotypes\", to which I think the answer is overwhelmingly \"yes\". They will do this because any 'objective' classification schemes using genetic data tend to look awkwardly similar to the socially constructed 'races'.\n\nI'm not arguing the first but the second seems mighty hard to justify.  \"Objective classification schemes using genetic data\" doesn't look much like modern day 'races' I'm used to.\n\n[Check out the 2002 Rosenberg study](https://web.stanford.edu/group/rosenberglab/papers/popstruct.pdf). He ends up dividing the world into 52 distinct population groups.  And within each you can go even more specified.  But yes, when I say the lines are 'fuzzy' I mean exactly that, for example the Adyghe people from Northern Russia are more similar to the Balochi of Northern Iran than they are to the Basque in Europe, but more similar to the Russians than anyone else, who share less in common with the Adyghe but more in common with the Basque.  Druze and Palestinians share about as much in common with the people of Iran as they do with Tuscans and Spaniards but much less with the Basque. \n\nSo how do you want to divide the lines and delineate 'races'? And are we really using racial terms in today's society as indicative of ancient ancestral populations that are sometimes named after dying languages of small populations with limited admixture?  \n\nThe conclusion is basically pretty simple\n&gt;The challenge of genetic studies of human history is to use the smal\nl amount of genetic differentiation among populations to infer the history  of human migrations.  Because most alleles are widespread,  genetic differences among human populations derive mainly from gradations  in  allele  frequencies  rather than from distinctive diagnostic genotypes. Indeed, it was only in the accumulation of small allele-frequency differences across many loci that population structure was identified. Patterns of modern human population structure discussed here can be used to guide construction of historical models of migration and admixture that will be useful in inferential studies of human genetic history.\n\nI don't really think anyone is questioning genetic's ability to give insight into historical human population migrations.  But that's rather different from saying \"race is a real and substantial genetic thing\".\n\nEven in 2002 studies about racial lines weren't saying that type of thing.\n\n&gt;These points refute nobody and they aren't intended to; They're just distractions to confuse bystanders. The defender of the race concept doesn't need to show that race is categorical, fixed, is the most perfect way of grouping people, or other such stilted strawman positions. All that matters is that the labels functionally proxy some underlying biological reality, which they do.\n\nWhat 'biological reality' do they underline?  That humans had historic population migrations?  Is that really what we care about in society about race?\n\n&gt;Are the social conceptions of \"blackness\" and \"whiteness\" all-encompassing or eternal buckets of human variation? No. But they are heuristically useful and valid. Westerners with a religious aversion to inegalitarian thinking will expend much energy trying to define away race. But at most they only succeed in deconstructing the language with which we describe human differences, not at showing that those differences don't exist, which is really the goal, is it not?\n\nWhat?  No, genetic differences exist in everyone.  Huh??  The 'goal' is an accurate representation of what exactly we mean by the 'race' concept in biology, because it really is substantially different from what's meant by the concept in society.  For as long as human beings will exist, there will be substantial genetic differences among diverse populations from genetic drift.  It's inescapable.  What you can't really do is tie all of those variations into neat and tidy packages of 'races'.  I mean, you can try, but you'll end up with 'races' being defined from incredibly tiny variations between populations when most variation happens *within*.  \"Egalitarian\" or not, no one says that there isn't any genetic variation among populations. \n\n**I** didn't even say that, or really anything close.  Here, try this, tell me how many \"races\" there are.  How do we decide on a method of clustering to give us that answer?\n\nHave you noticed that clustering experiments can give us radically different numbers to that pretty simple question?\n\nIt's not saying \"there isn't such a thing as groups and subgroups\", but it **is** making it pretty fucking hard to call any of the dividing lines we use anything but arbitrary.\n\nI can extend this to the species level too.  Usually a 'species' is defined as 'animals that can no longer interbreed' but fringe cases in the process of speciation make it clear that such a simplistic definition **doesn't capture** the process of what goes on with specialization, and a ring species exemplifies the issue of what it means for us to call something two distinct 'species' isn't clear cut.  That's not to say there aren't genetic differences between populations, but rather, the idea itself is tied to inherently arbitrary definitions. Anyone trying to sell you on the idea that a 'species' is simply or elegantly defined is selling you a bold face lie.  \n\nYou can try to argue that words used in society might be the same phonemes as those used in sciences, but when you really look at things, you realize even words you understand, know, find so easy and intuitive like \"fish\" are terribly, **TERRIBLY** defined on a biologic level.  So much so that I'd argue that the word \"fish\" holds literally zero taxonomic value.\n\nIn fact, I'd say the same about race.  Does that mean that all things we call \"fish\" are identical?  Hell fucking no!  It means that there is **too much** diversity among the groups labeled \"fish\" for it to be a properly classifiable taxonomic label.  \n\nReally, look into trying to define a \"fish\" in biology.  The term is [paraphyletic](http://www.ucmp.berkeley.edu/glossary/gloss1/phyly.html) in that it includes some clades of 'fish' but not others that under any consistent cladistic diagram would otherwise be included.  \n\n\"These words don't mean what they do to biologists as they do to common society\" is a very, very different thing from \"no differences exist\".  And you can say \"well they reflect some underlying biological reality\", but no, no they really don't.  Because the 'differences' biologists tend to talk about have very little to do with 'differences' that societies tend to talk about.  The words are used in different contexts with different meanings and different uses.\n\nIt's like trying to call a random \"theory\" the same as some scientific \"theory\", because again, the phonemes happen to be the same. \n\n\"Don't deconstruct language\" is a poor defense when people literally appear to be speaking different languages, putting different meanings behind the same phonemes. \n\n[snip]\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;This is not necessary for what I am saying.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It really seems to be because it&amp;#39;s kinda essential for your point.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The point of contention is &amp;quot;will computers reinvent something analogous to race anyway&amp;quot;, or more broadly, &amp;quot;will computers reinvent existing racial stereotypes&amp;quot;, to which I think the answer is overwhelmingly &amp;quot;yes&amp;quot;. They will do this because any &amp;#39;objective&amp;#39; classification schemes using genetic data tend to look awkwardly similar to the socially constructed &amp;#39;races&amp;#39;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m not arguing the first but the second seems mighty hard to justify.  &amp;quot;Objective classification schemes using genetic data&amp;quot; doesn&amp;#39;t look much like modern day &amp;#39;races&amp;#39; I&amp;#39;m used to.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://web.stanford.edu/group/rosenberglab/papers/popstruct.pdf\"&gt;Check out the 2002 Rosenberg study&lt;/a&gt;. He ends up dividing the world into 52 distinct population groups.  And within each you can go even more specified.  But yes, when I say the lines are &amp;#39;fuzzy&amp;#39; I mean exactly that, for example the Adyghe people from Northern Russia are more similar to the Balochi of Northern Iran than they are to the Basque in Europe, but more similar to the Russians than anyone else, who share less in common with the Adyghe but more in common with the Basque.  Druze and Palestinians share about as much in common with the people of Iran as they do with Tuscans and Spaniards but much less with the Basque. &lt;/p&gt;\n\n&lt;p&gt;So how do you want to divide the lines and delineate &amp;#39;races&amp;#39;? And are we really using racial terms in today&amp;#39;s society as indicative of ancient ancestral populations that are sometimes named after dying languages of small populations with limited admixture?  &lt;/p&gt;\n\n&lt;p&gt;The conclusion is basically pretty simple&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The challenge of genetic studies of human history is to use the smal\nl amount of genetic differentiation among populations to infer the history  of human migrations.  Because most alleles are widespread,  genetic differences among human populations derive mainly from gradations  in  allele  frequencies  rather than from distinctive diagnostic genotypes. Indeed, it was only in the accumulation of small allele-frequency differences across many loci that population structure was identified. Patterns of modern human population structure discussed here can be used to guide construction of historical models of migration and admixture that will be useful in inferential studies of human genetic history.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t really think anyone is questioning genetic&amp;#39;s ability to give insight into historical human population migrations.  But that&amp;#39;s rather different from saying &amp;quot;race is a real and substantial genetic thing&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Even in 2002 studies about racial lines weren&amp;#39;t saying that type of thing.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;These points refute nobody and they aren&amp;#39;t intended to; They&amp;#39;re just distractions to confuse bystanders. The defender of the race concept doesn&amp;#39;t need to show that race is categorical, fixed, is the most perfect way of grouping people, or other such stilted strawman positions. All that matters is that the labels functionally proxy some underlying biological reality, which they do.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What &amp;#39;biological reality&amp;#39; do they underline?  That humans had historic population migrations?  Is that really what we care about in society about race?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Are the social conceptions of &amp;quot;blackness&amp;quot; and &amp;quot;whiteness&amp;quot; all-encompassing or eternal buckets of human variation? No. But they are heuristically useful and valid. Westerners with a religious aversion to inegalitarian thinking will expend much energy trying to define away race. But at most they only succeed in deconstructing the language with which we describe human differences, not at showing that those differences don&amp;#39;t exist, which is really the goal, is it not?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What?  No, genetic differences exist in everyone.  Huh??  The &amp;#39;goal&amp;#39; is an accurate representation of what exactly we mean by the &amp;#39;race&amp;#39; concept in biology, because it really is substantially different from what&amp;#39;s meant by the concept in society.  For as long as human beings will exist, there will be substantial genetic differences among diverse populations from genetic drift.  It&amp;#39;s inescapable.  What you can&amp;#39;t really do is tie all of those variations into neat and tidy packages of &amp;#39;races&amp;#39;.  I mean, you can try, but you&amp;#39;ll end up with &amp;#39;races&amp;#39; being defined from incredibly tiny variations between populations when most variation happens &lt;em&gt;within&lt;/em&gt;.  &amp;quot;Egalitarian&amp;quot; or not, no one says that there isn&amp;#39;t any genetic variation among populations. &lt;/p&gt;\n\n&lt;p&gt;&lt;strong&gt;I&lt;/strong&gt; didn&amp;#39;t even say that, or really anything close.  Here, try this, tell me how many &amp;quot;races&amp;quot; there are.  How do we decide on a method of clustering to give us that answer?&lt;/p&gt;\n\n&lt;p&gt;Have you noticed that clustering experiments can give us radically different numbers to that pretty simple question?&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not saying &amp;quot;there isn&amp;#39;t such a thing as groups and subgroups&amp;quot;, but it &lt;strong&gt;is&lt;/strong&gt; making it pretty fucking hard to call any of the dividing lines we use anything but arbitrary.&lt;/p&gt;\n\n&lt;p&gt;I can extend this to the species level too.  Usually a &amp;#39;species&amp;#39; is defined as &amp;#39;animals that can no longer interbreed&amp;#39; but fringe cases in the process of speciation make it clear that such a simplistic definition &lt;strong&gt;doesn&amp;#39;t capture&lt;/strong&gt; the process of what goes on with specialization, and a ring species exemplifies the issue of what it means for us to call something two distinct &amp;#39;species&amp;#39; isn&amp;#39;t clear cut.  That&amp;#39;s not to say there aren&amp;#39;t genetic differences between populations, but rather, the idea itself is tied to inherently arbitrary definitions. Anyone trying to sell you on the idea that a &amp;#39;species&amp;#39; is simply or elegantly defined is selling you a bold face lie.  &lt;/p&gt;\n\n&lt;p&gt;You can try to argue that words used in society might be the same phonemes as those used in sciences, but when you really look at things, you realize even words you understand, know, find so easy and intuitive like &amp;quot;fish&amp;quot; are terribly, &lt;strong&gt;TERRIBLY&lt;/strong&gt; defined on a biologic level.  So much so that I&amp;#39;d argue that the word &amp;quot;fish&amp;quot; holds literally zero taxonomic value.&lt;/p&gt;\n\n&lt;p&gt;In fact, I&amp;#39;d say the same about race.  Does that mean that all things we call &amp;quot;fish&amp;quot; are identical?  Hell fucking no!  It means that there is &lt;strong&gt;too much&lt;/strong&gt; diversity among the groups labeled &amp;quot;fish&amp;quot; for it to be a properly classifiable taxonomic label.  &lt;/p&gt;\n\n&lt;p&gt;Really, look into trying to define a &amp;quot;fish&amp;quot; in biology.  The term is &lt;a href=\"http://www.ucmp.berkeley.edu/glossary/gloss1/phyly.html\"&gt;paraphyletic&lt;/a&gt; in that it includes some clades of &amp;#39;fish&amp;#39; but not others that under any consistent cladistic diagram would otherwise be included.  &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;These words don&amp;#39;t mean what they do to biologists as they do to common society&amp;quot; is a very, very different thing from &amp;quot;no differences exist&amp;quot;.  And you can say &amp;quot;well they reflect some underlying biological reality&amp;quot;, but no, no they really don&amp;#39;t.  Because the &amp;#39;differences&amp;#39; biologists tend to talk about have very little to do with &amp;#39;differences&amp;#39; that societies tend to talk about.  The words are used in different contexts with different meanings and different uses.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like trying to call a random &amp;quot;theory&amp;quot; the same as some scientific &amp;quot;theory&amp;quot;, because again, the phonemes happen to be the same. &lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Don&amp;#39;t deconstruct language&amp;quot; is a poor defense when people literally appear to be speaking different languages, putting different meanings behind the same phonemes. &lt;/p&gt;\n\n&lt;p&gt;[snip]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbsscb", "score_hidden": false, "stickied": false, "created": 1492354689.0, "created_utc": 1492325889.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbsslw", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgal0aw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "\n&gt;You can quibble about the relative precision of mapping race onto genes, but unless you're an especially misinformed egalitarian, you probably don't seriously think that a machine learning or other clustering approach is going to suddenly reveal the hidden truth, obscured by a racist society, that ethnic Somalis and Japanese are basically fungible on the same scale as Swedes and Finns.   In short, nobody seriously thinks that an objective person or computer, removed from their social biases, \"doesn't see race\" and will reinvent human clustering in some manner orthogonal to the way we see it.\n\n... Huh??  I literally don't understand what you mean by this.  What does it mean for two groups of people to be \"fungible\"?  How are Swedes and Finns 'interchangeable'?  How are Japanese and Somali 'interchangeable'?  What does it mean for ethnic groups to literally be 'interchangeable'?  On what level do we call people \"fungible\"?  \n\n... Huh?\n\nI would go far enough to argue 'any individual human is as fungible as any other individual human', as in, you could adopt a member of any race in any society and raise them in that environment, genetically, their heritage doesn't matter beyond medical testing perhaps of recessive alleles.  Your language, personality, etc, are not dominated by anything that could reasonably be tied to individual genetic cluster analysis.  Far more variation is the result of random genetic drift or your closest relatives than could **ever** be reasonably attributed to ancestral genetic populations.  It'd be like saying \"astrology is real, because the gravity of Jupiter really DOES impact human bodies\".  Which is true, but it's also true that rock outside your room exerts a greater gravitational pull on you than Jupiter. \n\nIt'd be trying to attribute things that literally can't be attributed to those types of ancestral population genetics. \n\n&gt;It's like arguments over map projections. Every projection has its own bias, and represents picking certain features to optimize for. But there is a shared reality underlying them all. A different map projection may draw two countries closer, or make one look more prominent - but there is no map projection that is going to suddenly put Kenya in the middle of the Americas. These abstractions are not totally divorced from reality.\n\nUsing this example, it seems a bit more akin to a map that distorts all human created roads to a few thousand times their actual scale, to where they take up the map, and saying \"see, look how much of the earth we've taken up with our roadways!\"\n\nThe data people are looking at in no way matches the scale of things they attribute to them.  At all.  \"Races\" are effectively artificial constructs, they don't really **mean** anything.  Yeah, sure, an ancestral population had a particular gene mutation delineating a bad amount of a protein which regulates heart cholesterol.  And you can track the movement of that gene and use it to determine the potential risk of people within your society of a certain ancestral line as having that risk.\n\n... \"So and so is inherently X and Y\" on the other hand is decidedly **not** that.  Genetics is far, FAR too complex for **any** kind of sweeping statements and 'races' are nebulous fuzzy concepts where regardless of the clustering, you're still basically focusing on a tiny number of gene changes that literally **can't** have the kinds of impact people attribute to race.\n\n... To quite Rosenberg again since he is often tossed around on this topic...\n\n&gt;The challenge of genetic studies of human history is to use the small amount of genetic differentiation among populations to infer the history of human migrations. Because most alleles are widespread, genetic differences among human populations derive mainly from gradations in allele frequencies rather than from distinctive diagnostic genotypes. **Indeed, it was only in the accumulation of small allele-frequency differences across many loci that population structure was identified.** Patterns of modern human population structure discussed here can be used to guide construction of historical models of migration and admixture that will be useful in inferential studies of human genetic history.\n\nUse more markers, and you can find more traits, but these populations are very, **very** diverse, and ancestral clustering makes up a rather small proportion of overall human variation.  Humans will **always** vary.  We will **always** be diverse.  We will see clusters form no matter what.  We will never be 'the same' we'll never have entirely genetically homogeneous populations.  \n\n&gt;The study you link is wholly compatible with everything I have said. It starts off pointing to several other studies which found similar SIRE:cluster correlations that found little divergence between social category and genes. The Brazil study doesn't directly dispute this, instead looking at the more specific case of a highly intermixed population. It also had a greatly reduced number of markers, which adds more fuzziness.\n\n&gt;In this context, they found that the self-report fuzziness was substantially greater, to the point where they determined it was not sufficient. This is fine and does not contradict anything I have said here. This is because that fuzziness was contained within the same racial stereotypes - That is, their cluster analysis still had a conception of \"African-ness\" and \"European-ness\" that looked exactly as we understand them, even though this population was more evenly distributed along a gradient between them.\n\n&gt;So, within this fuzzier context, the same race concept was upheld. The people who identified as \"black\" were indeed found to have much higher \"African\" ancestry on average. Those who identified as \"white\" were indeed closer to the \"European\" cluster. The people who identified as mixed, who were many in this case, were in the middle. There were large error bars all around, but the framing device of \"race\" as we understand it remained.\n\nExcept again, the point is that even within the 'clusters' you **still** needed genetic testing because the 'clusters' themselves all tend to have genetically distinct subgroups who all require different types of treatment based on different genetic backgrounds.\n\n... Which you'll always get.  You'll get clusters out of clusters to literally any degree of specification you want, and **all** of these groups are going to have different genetic mutations that all require their own specialized targeted effort.\n\nTry a thought experiment \"A Finnish farmer had a bad mutation on this one particular loci.  His descendants made up about 5% of the Finnish population 500 years later, but he also had a branch of his family move to Ukraine, where we find 2% of the population have the same mutation, but it's not found anywhere else\"\n\nSo is this a \"European\" trait?  I think you'd argue not, and I'd agree, since it'd be only shared among a single particular 'ethnic group' within Europe, and only among a single particular line from there.\n\nThat's what the process of tracking down genetic diseases is like.  A large cluster like \"European\" might have subpopulations **with** these traits, but the whole point is that variation is so significant that what you really need to do is look at actual genetic history to get an accurate idea of what someone has.\n\nThere are lots, and lots and lots of potential markers for genetic diseases.  All from many many different populations and subpopulations.  So if you want to get accurate results, you do genetic testing.\n\n&gt;In the context of this discussion, then, the point as applied to machine learning remains. The computers have indeed mostly just reinvented race in their analysis of genetic data. That spectrum of stereotypes remains intact even though there is ambiguity within it. The computers have not, from their innocent, non-racist perspective, corrected our understanding of human kinds and shown us some totally new alignment of ancestry and stereotypes, cutting far across racial lines. They have, at most, just given us a slightly different map projection of the same racist world.\n\nNot really sure what you're arguing here either.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;You can quibble about the relative precision of mapping race onto genes, but unless you&amp;#39;re an especially misinformed egalitarian, you probably don&amp;#39;t seriously think that a machine learning or other clustering approach is going to suddenly reveal the hidden truth, obscured by a racist society, that ethnic Somalis and Japanese are basically fungible on the same scale as Swedes and Finns.   In short, nobody seriously thinks that an objective person or computer, removed from their social biases, &amp;quot;doesn&amp;#39;t see race&amp;quot; and will reinvent human clustering in some manner orthogonal to the way we see it.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;... Huh??  I literally don&amp;#39;t understand what you mean by this.  What does it mean for two groups of people to be &amp;quot;fungible&amp;quot;?  How are Swedes and Finns &amp;#39;interchangeable&amp;#39;?  How are Japanese and Somali &amp;#39;interchangeable&amp;#39;?  What does it mean for ethnic groups to literally be &amp;#39;interchangeable&amp;#39;?  On what level do we call people &amp;quot;fungible&amp;quot;?  &lt;/p&gt;\n\n&lt;p&gt;... Huh?&lt;/p&gt;\n\n&lt;p&gt;I would go far enough to argue &amp;#39;any individual human is as fungible as any other individual human&amp;#39;, as in, you could adopt a member of any race in any society and raise them in that environment, genetically, their heritage doesn&amp;#39;t matter beyond medical testing perhaps of recessive alleles.  Your language, personality, etc, are not dominated by anything that could reasonably be tied to individual genetic cluster analysis.  Far more variation is the result of random genetic drift or your closest relatives than could &lt;strong&gt;ever&lt;/strong&gt; be reasonably attributed to ancestral genetic populations.  It&amp;#39;d be like saying &amp;quot;astrology is real, because the gravity of Jupiter really DOES impact human bodies&amp;quot;.  Which is true, but it&amp;#39;s also true that rock outside your room exerts a greater gravitational pull on you than Jupiter. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;d be trying to attribute things that literally can&amp;#39;t be attributed to those types of ancestral population genetics. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;It&amp;#39;s like arguments over map projections. Every projection has its own bias, and represents picking certain features to optimize for. But there is a shared reality underlying them all. A different map projection may draw two countries closer, or make one look more prominent - but there is no map projection that is going to suddenly put Kenya in the middle of the Americas. These abstractions are not totally divorced from reality.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Using this example, it seems a bit more akin to a map that distorts all human created roads to a few thousand times their actual scale, to where they take up the map, and saying &amp;quot;see, look how much of the earth we&amp;#39;ve taken up with our roadways!&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;The data people are looking at in no way matches the scale of things they attribute to them.  At all.  &amp;quot;Races&amp;quot; are effectively artificial constructs, they don&amp;#39;t really &lt;strong&gt;mean&lt;/strong&gt; anything.  Yeah, sure, an ancestral population had a particular gene mutation delineating a bad amount of a protein which regulates heart cholesterol.  And you can track the movement of that gene and use it to determine the potential risk of people within your society of a certain ancestral line as having that risk.&lt;/p&gt;\n\n&lt;p&gt;... &amp;quot;So and so is inherently X and Y&amp;quot; on the other hand is decidedly &lt;strong&gt;not&lt;/strong&gt; that.  Genetics is far, FAR too complex for &lt;strong&gt;any&lt;/strong&gt; kind of sweeping statements and &amp;#39;races&amp;#39; are nebulous fuzzy concepts where regardless of the clustering, you&amp;#39;re still basically focusing on a tiny number of gene changes that literally &lt;strong&gt;can&amp;#39;t&lt;/strong&gt; have the kinds of impact people attribute to race.&lt;/p&gt;\n\n&lt;p&gt;... To quite Rosenberg again since he is often tossed around on this topic...&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The challenge of genetic studies of human history is to use the small amount of genetic differentiation among populations to infer the history of human migrations. Because most alleles are widespread, genetic differences among human populations derive mainly from gradations in allele frequencies rather than from distinctive diagnostic genotypes. &lt;strong&gt;Indeed, it was only in the accumulation of small allele-frequency differences across many loci that population structure was identified.&lt;/strong&gt; Patterns of modern human population structure discussed here can be used to guide construction of historical models of migration and admixture that will be useful in inferential studies of human genetic history.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Use more markers, and you can find more traits, but these populations are very, &lt;strong&gt;very&lt;/strong&gt; diverse, and ancestral clustering makes up a rather small proportion of overall human variation.  Humans will &lt;strong&gt;always&lt;/strong&gt; vary.  We will &lt;strong&gt;always&lt;/strong&gt; be diverse.  We will see clusters form no matter what.  We will never be &amp;#39;the same&amp;#39; we&amp;#39;ll never have entirely genetically homogeneous populations.  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The study you link is wholly compatible with everything I have said. It starts off pointing to several other studies which found similar SIRE:cluster correlations that found little divergence between social category and genes. The Brazil study doesn&amp;#39;t directly dispute this, instead looking at the more specific case of a highly intermixed population. It also had a greatly reduced number of markers, which adds more fuzziness.&lt;/p&gt;\n\n&lt;p&gt;In this context, they found that the self-report fuzziness was substantially greater, to the point where they determined it was not sufficient. This is fine and does not contradict anything I have said here. This is because that fuzziness was contained within the same racial stereotypes - That is, their cluster analysis still had a conception of &amp;quot;African-ness&amp;quot; and &amp;quot;European-ness&amp;quot; that looked exactly as we understand them, even though this population was more evenly distributed along a gradient between them.&lt;/p&gt;\n\n&lt;p&gt;So, within this fuzzier context, the same race concept was upheld. The people who identified as &amp;quot;black&amp;quot; were indeed found to have much higher &amp;quot;African&amp;quot; ancestry on average. Those who identified as &amp;quot;white&amp;quot; were indeed closer to the &amp;quot;European&amp;quot; cluster. The people who identified as mixed, who were many in this case, were in the middle. There were large error bars all around, but the framing device of &amp;quot;race&amp;quot; as we understand it remained.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Except again, the point is that even within the &amp;#39;clusters&amp;#39; you &lt;strong&gt;still&lt;/strong&gt; needed genetic testing because the &amp;#39;clusters&amp;#39; themselves all tend to have genetically distinct subgroups who all require different types of treatment based on different genetic backgrounds.&lt;/p&gt;\n\n&lt;p&gt;... Which you&amp;#39;ll always get.  You&amp;#39;ll get clusters out of clusters to literally any degree of specification you want, and &lt;strong&gt;all&lt;/strong&gt; of these groups are going to have different genetic mutations that all require their own specialized targeted effort.&lt;/p&gt;\n\n&lt;p&gt;Try a thought experiment &amp;quot;A Finnish farmer had a bad mutation on this one particular loci.  His descendants made up about 5% of the Finnish population 500 years later, but he also had a branch of his family move to Ukraine, where we find 2% of the population have the same mutation, but it&amp;#39;s not found anywhere else&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;So is this a &amp;quot;European&amp;quot; trait?  I think you&amp;#39;d argue not, and I&amp;#39;d agree, since it&amp;#39;d be only shared among a single particular &amp;#39;ethnic group&amp;#39; within Europe, and only among a single particular line from there.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s what the process of tracking down genetic diseases is like.  A large cluster like &amp;quot;European&amp;quot; might have subpopulations &lt;strong&gt;with&lt;/strong&gt; these traits, but the whole point is that variation is so significant that what you really need to do is look at actual genetic history to get an accurate idea of what someone has.&lt;/p&gt;\n\n&lt;p&gt;There are lots, and lots and lots of potential markers for genetic diseases.  All from many many different populations and subpopulations.  So if you want to get accurate results, you do genetic testing.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;In the context of this discussion, then, the point as applied to machine learning remains. The computers have indeed mostly just reinvented race in their analysis of genetic data. That spectrum of stereotypes remains intact even though there is ambiguity within it. The computers have not, from their innocent, non-racist perspective, corrected our understanding of human kinds and shown us some totally new alignment of ancestry and stereotypes, cutting far across racial lines. They have, at most, just given us a slightly different map projection of the same racist world.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Not really sure what you&amp;#39;re arguing here either.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbsslw", "score_hidden": false, "stickied": false, "created": 1492354708.0, "created_utc": 1492325908.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgal0aw", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "anechoicmedia", "parent_id": "t1_dgai6so", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;genetic markers do not form clean and even lines. \n\nThis is not necessary for what I am saying.\n\nThe point of contention is \"will computers reinvent something analogous to race anyway\", or more broadly, \"will computers reinvent existing racial stereotypes\", to which I think the answer is overwhelmingly \"yes\". They will do this because any 'objective' classification schemes using genetic data tend to look awkwardly similar to the socially constructed 'races'.\n\nAttempting to parse what you say, you don't actually dispute this directly, instead making the usual obfuscations:\n\n- there are no clean breaks\n- genetic clusters can be more accurate than the socially constructed categories\n- you can lump together or split apart human populations at higher/lower levels of abstraction than is usually meant by 'race'\n- ambiguous persons and populations exist\n\nThese points refute nobody and they aren't intended to; They're just distractions to confuse bystanders. The defender of the race concept doesn't need to show that race is categorical, fixed, is the most perfect way of grouping people, or other such stilted strawman positions. All that matters is that the labels functionally proxy some underlying biological reality, which they do.\n\nAre the social conceptions of \"blackness\" and \"whiteness\" all-encompassing or eternal buckets of human variation? No. But they are heuristically useful and valid. Westerners with a religious aversion to inegalitarian thinking will expend much energy trying to define away race. But at most they only succeed in deconstructing the language with which we describe human differences, not at showing that those differences don't exist, which is really the goal, is it not?\n\nYou can quibble about the relative precision of mapping race onto genes, but unless you're an especially misinformed egalitarian, you probably don't seriously think that a machine learning or other clustering approach is going to suddenly reveal the hidden truth, obscured by a racist society, that ethnic Somalis and Japanese are basically fungible on the same scale as Swedes and Finns. In short, nobody seriously thinks that an objective person or computer, removed from their social biases, \"doesn't see race\" and will reinvent human clustering in some manner orthogonal to the way we see it.\n\nIt's like arguments over [map projections](https://s-media-cache-ak0.pinimg.com/736x/6e/52/e7/6e52e71165b3cd4527c6b5f00ac103dd.jpg). Every projection has its own bias, and represents picking certain features to optimize for. But there is a shared reality underlying them all. A different map projection may draw two countries closer, or make one look more prominent - but there is no map projection that is going to suddenly put Kenya in the middle of the Americas. These abstractions are not totally divorced from reality.\n\n-----\n\nThe study you link is wholly compatible with everything I have said. It starts off pointing to several other studies which found similar SIRE:cluster correlations that found little divergence between social category and genes. The Brazil study doesn't directly dispute this, instead looking at the more specific case of a highly intermixed population. It also had a greatly reduced number of markers, which adds more fuzziness.\n\nIn this context, they found that the self-report fuzziness was substantially greater, to the point where they determined it was not sufficient. This is fine and does not contradict anything I have said here. This is because that fuzziness was contained within the same racial stereotypes - That is, their cluster analysis still had a conception of \"African-ness\" and \"European-ness\" that looked exactly as we understand them, even though this population was more evenly distributed along a gradient between them.\n\nSo, within this fuzzier context, the same race concept was upheld. The people who identified as \"black\" were indeed found to have much higher \"African\" ancestry on average. Those who identified as \"white\" were indeed closer to the \"European\" cluster. The people who identified as mixed, who were many in this case, were in the middle. There were large error bars all around, but the framing device of \"race\" as we understand it remained.\n\nIn the context of this discussion, then, the point as applied to machine learning remains. The computers have indeed mostly just reinvented race in their analysis of genetic data. That spectrum of stereotypes remains intact even though there is ambiguity within it. The computers have not, from their innocent, non-racist perspective, corrected our understanding of human kinds and shown us some totally new alignment of ancestry and stereotypes, cutting far across racial lines. They have, at most, just given us a slightly different map projection of the same racist world.", "edited": 1492259063.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;genetic markers do not form clean and even lines. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is not necessary for what I am saying.&lt;/p&gt;\n\n&lt;p&gt;The point of contention is &amp;quot;will computers reinvent something analogous to race anyway&amp;quot;, or more broadly, &amp;quot;will computers reinvent existing racial stereotypes&amp;quot;, to which I think the answer is overwhelmingly &amp;quot;yes&amp;quot;. They will do this because any &amp;#39;objective&amp;#39; classification schemes using genetic data tend to look awkwardly similar to the socially constructed &amp;#39;races&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;Attempting to parse what you say, you don&amp;#39;t actually dispute this directly, instead making the usual obfuscations:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;there are no clean breaks&lt;/li&gt;\n&lt;li&gt;genetic clusters can be more accurate than the socially constructed categories&lt;/li&gt;\n&lt;li&gt;you can lump together or split apart human populations at higher/lower levels of abstraction than is usually meant by &amp;#39;race&amp;#39;&lt;/li&gt;\n&lt;li&gt;ambiguous persons and populations exist&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;These points refute nobody and they aren&amp;#39;t intended to; They&amp;#39;re just distractions to confuse bystanders. The defender of the race concept doesn&amp;#39;t need to show that race is categorical, fixed, is the most perfect way of grouping people, or other such stilted strawman positions. All that matters is that the labels functionally proxy some underlying biological reality, which they do.&lt;/p&gt;\n\n&lt;p&gt;Are the social conceptions of &amp;quot;blackness&amp;quot; and &amp;quot;whiteness&amp;quot; all-encompassing or eternal buckets of human variation? No. But they are heuristically useful and valid. Westerners with a religious aversion to inegalitarian thinking will expend much energy trying to define away race. But at most they only succeed in deconstructing the language with which we describe human differences, not at showing that those differences don&amp;#39;t exist, which is really the goal, is it not?&lt;/p&gt;\n\n&lt;p&gt;You can quibble about the relative precision of mapping race onto genes, but unless you&amp;#39;re an especially misinformed egalitarian, you probably don&amp;#39;t seriously think that a machine learning or other clustering approach is going to suddenly reveal the hidden truth, obscured by a racist society, that ethnic Somalis and Japanese are basically fungible on the same scale as Swedes and Finns. In short, nobody seriously thinks that an objective person or computer, removed from their social biases, &amp;quot;doesn&amp;#39;t see race&amp;quot; and will reinvent human clustering in some manner orthogonal to the way we see it.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s like arguments over &lt;a href=\"https://s-media-cache-ak0.pinimg.com/736x/6e/52/e7/6e52e71165b3cd4527c6b5f00ac103dd.jpg\"&gt;map projections&lt;/a&gt;. Every projection has its own bias, and represents picking certain features to optimize for. But there is a shared reality underlying them all. A different map projection may draw two countries closer, or make one look more prominent - but there is no map projection that is going to suddenly put Kenya in the middle of the Americas. These abstractions are not totally divorced from reality.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;The study you link is wholly compatible with everything I have said. It starts off pointing to several other studies which found similar SIRE:cluster correlations that found little divergence between social category and genes. The Brazil study doesn&amp;#39;t directly dispute this, instead looking at the more specific case of a highly intermixed population. It also had a greatly reduced number of markers, which adds more fuzziness.&lt;/p&gt;\n\n&lt;p&gt;In this context, they found that the self-report fuzziness was substantially greater, to the point where they determined it was not sufficient. This is fine and does not contradict anything I have said here. This is because that fuzziness was contained within the same racial stereotypes - That is, their cluster analysis still had a conception of &amp;quot;African-ness&amp;quot; and &amp;quot;European-ness&amp;quot; that looked exactly as we understand them, even though this population was more evenly distributed along a gradient between them.&lt;/p&gt;\n\n&lt;p&gt;So, within this fuzzier context, the same race concept was upheld. The people who identified as &amp;quot;black&amp;quot; were indeed found to have much higher &amp;quot;African&amp;quot; ancestry on average. Those who identified as &amp;quot;white&amp;quot; were indeed closer to the &amp;quot;European&amp;quot; cluster. The people who identified as mixed, who were many in this case, were in the middle. There were large error bars all around, but the framing device of &amp;quot;race&amp;quot; as we understand it remained.&lt;/p&gt;\n\n&lt;p&gt;In the context of this discussion, then, the point as applied to machine learning remains. The computers have indeed mostly just reinvented race in their analysis of genetic data. That spectrum of stereotypes remains intact even though there is ambiguity within it. The computers have not, from their innocent, non-racist perspective, corrected our understanding of human kinds and shown us some totally new alignment of ancestry and stereotypes, cutting far across racial lines. They have, at most, just given us a slightly different map projection of the same racist world.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgal0aw", "score_hidden": false, "stickied": false, "created": 1492287326.0, "created_utc": 1492258526.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgcj3v8", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Lepidostrix", "parent_id": "t1_dgbt36z", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It seems you live a rather uncritical one.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems you live a rather uncritical one.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcj3v8", "score_hidden": false, "stickied": false, "created": 1492403444.0, "created_utc": 1492374644.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgctas0", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "falconfetus8", "parent_id": "t1_dgbt36z", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "What makes your think that?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What makes your think that?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgctas0", "score_hidden": false, "stickied": false, "created": 1492417108.0, "created_utc": 1492388308.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbt36z", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgbsv3g", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "You must live a sheltered life", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You must live a sheltered life&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbt36z", "score_hidden": false, "stickied": false, "created": 1492355504.0, "created_utc": 1492326704.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbsv3g", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgb0qpz", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;instead of using our own eyes/common knowledge.\n\nIf you're trying to use your \"own eyes and common knowledge\" don't be surprised when you're led astray.  It's a dangerous thing to assume the world conforms to your 'common sense' or 'common knowledge'.\n\nDon't be afraid to challenge things just because they're 'common knowledge'. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;instead of using our own eyes/common knowledge.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;If you&amp;#39;re trying to use your &amp;quot;own eyes and common knowledge&amp;quot; don&amp;#39;t be surprised when you&amp;#39;re led astray.  It&amp;#39;s a dangerous thing to assume the world conforms to your &amp;#39;common sense&amp;#39; or &amp;#39;common knowledge&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t be afraid to challenge things just because they&amp;#39;re &amp;#39;common knowledge&amp;#39;. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbsv3g", "score_hidden": false, "stickied": false, "created": 1492354889.0, "created_utc": 1492326089.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb0qpz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgai6so", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "None of what you said matters.\n\nAt best, you are saying that race exists but we just need biologists tod define it for us, instead of using our own eyes/common knowledge.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;None of what you said matters.&lt;/p&gt;\n\n&lt;p&gt;At best, you are saying that race exists but we just need biologists tod define it for us, instead of using our own eyes/common knowledge.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb0qpz", "score_hidden": false, "stickied": false, "created": 1492311601.0, "created_utc": 1492282801.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgai6so", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgahq2j", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Did you read that study?\n\n&gt;In summary, from a very large study of four major racial/ethnic groups within the United States and Taiwan, we found extraordinary correspondence between SIRE and genetic cluster categories but only modest geographic differentiation within each race/ethnicity group. This result indicates that studies using genetic clusters instead of racial/ethnic labels are likely to simply reproduce racial/ethnic differences, which may or may not be genetic. On the other hand, in the absence of racial/ethnic information, it is tempting to attribute any observed difference between derived genetic clusters to a genetic etiology. Therefore, researchers performing studies without racial/ethnic labels should be wary of characterizing difference between genetically defined clusters as genetic in origin, since social, cultural, economic, behavioral, and other environmental factors may result in extreme confounding.\n\nMore to the point\n&gt;Another major point of discussion has been the correspondence between genetic clusters and commonly used racial/ethnic labels. Some have argued for poor correspondence between these two entities (Lewontin 1972; Wilson et al. 2001), whereas others have suggested a strong correlation (Risch et al. 2002; Burchard et al. 2003). We have shown a nearly perfect correspondence between genetic cluster and SIRE for major ethnic groups living in the United States, with a discrepancy rate of only 0.14%. Perhaps this is not surprising for the major groupings (whites, East Asians, and African Americans), since prior studies would suggest enough genetic differentiation between these groups to produce robust clustering. On the other hand, one prior study of Hispanics did not suggest a distinct cluster for this group, possibly because of the heterogeneous origins of that Hispanic sample (Stephens et al. 2001). From the genetic perspective, Hispanics generally represent a differential mixture of European, Native American, and African ancestry, with the proportionate mix typically depending on country of origin. Our sample was from a single location in Texas and was composed of Mexican Americans. Although the genetic distance analysis suggested relative proximity to the whites in our sample, the distance was still sufficient to allow for creation of a distinct genetic cluster for this group. **Again, this is likely because of the large number of markers used in our analysis.** On the other hand, in the analysis of the full sample, the two East Asian groups\u2014Chinese and Japanese\u2014did not emerge as distinct subgroups, likely because their distance from one another was too modest to be detectable in the context of the larger sample. However, when the East Asians were analyzed separately, two clusters\u2014corresponding to Chinese and Japanese\u2014did emerge, with only a small amount of discordance (6 [1%] of 567 subjects). In contrast, cluster analysis within the three other major clusters did not produce robust, replicable subgroups, indicating a lack of further subgroups within these entities, at least in the current marker set. This observation does not eliminate the potential for confounding in these populations. First, there may be subgroups within the larger population group that are too small to detect by cluster analysis. Second, there may not be discrete subgrouping but continuous ancestral variation that could lead to stratification bias. For example, African Americans have a continuous range of European ancestry that would not be detected by cluster analysis but could strongly confound genetic case-control studies. Furthermore, our analysis likely underrepresents individuals with recent mixed ancestry (who would require more complex categorization) and other groups typically underrepresented, such as South Asians. Further study is required to evaluate the correlation between genetically determined groupings and SIRE for these individuals.\n\nYou'll also note this article is from 2005.  The year we first sequenced a human genome.  So lets see responses to this, and what ideas they draw upon.\n\nI like this one because it touches on the point of the article you studied, which was specifically for healthcare related decisions.\n\nI point you to this 2011 paper on the same exact topic of self-reported ethnicity, and it came to the same conclusion.\n\n[\"Genetic Heterogeneity of Self-Reported Ancestry Groups in an Admixed Brazilian Population\"](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3899415/).\n\nNote:\n&gt;Self-reporting of ancestry was not an appropriate methodology to cluster groups in a Brazilian population, due to high variance at the individual level. **Ancestry informative markers are more useful for quantitative measurement of biological ancestry.**\n\nBut we use way, way more markers than we delineate races, and which markers we choose themselves are related to what types of 'genetic hierarchies' we want to create, to whatever specified degree of nuance you want.\n\n\"Race\" has no taxinomic hierarchy unless you really just want to say \"everyone is black\".  You can make identifiers for very specific ethnicities, yes, but that's effectively different from what's socially meant by 'race', and studies since sequencing the genome tend to back that up, and confirm what the study you cited already realized.  \"Genetic markers themselves are more accurate than whatever people say\".  And genetic markers do not form clean and even lines. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Did you read that study?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;In summary, from a very large study of four major racial/ethnic groups within the United States and Taiwan, we found extraordinary correspondence between SIRE and genetic cluster categories but only modest geographic differentiation within each race/ethnicity group. This result indicates that studies using genetic clusters instead of racial/ethnic labels are likely to simply reproduce racial/ethnic differences, which may or may not be genetic. On the other hand, in the absence of racial/ethnic information, it is tempting to attribute any observed difference between derived genetic clusters to a genetic etiology. Therefore, researchers performing studies without racial/ethnic labels should be wary of characterizing difference between genetically defined clusters as genetic in origin, since social, cultural, economic, behavioral, and other environmental factors may result in extreme confounding.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;More to the point&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Another major point of discussion has been the correspondence between genetic clusters and commonly used racial/ethnic labels. Some have argued for poor correspondence between these two entities (Lewontin 1972; Wilson et al. 2001), whereas others have suggested a strong correlation (Risch et al. 2002; Burchard et al. 2003). We have shown a nearly perfect correspondence between genetic cluster and SIRE for major ethnic groups living in the United States, with a discrepancy rate of only 0.14%. Perhaps this is not surprising for the major groupings (whites, East Asians, and African Americans), since prior studies would suggest enough genetic differentiation between these groups to produce robust clustering. On the other hand, one prior study of Hispanics did not suggest a distinct cluster for this group, possibly because of the heterogeneous origins of that Hispanic sample (Stephens et al. 2001). From the genetic perspective, Hispanics generally represent a differential mixture of European, Native American, and African ancestry, with the proportionate mix typically depending on country of origin. Our sample was from a single location in Texas and was composed of Mexican Americans. Although the genetic distance analysis suggested relative proximity to the whites in our sample, the distance was still sufficient to allow for creation of a distinct genetic cluster for this group. &lt;strong&gt;Again, this is likely because of the large number of markers used in our analysis.&lt;/strong&gt; On the other hand, in the analysis of the full sample, the two East Asian groups\u2014Chinese and Japanese\u2014did not emerge as distinct subgroups, likely because their distance from one another was too modest to be detectable in the context of the larger sample. However, when the East Asians were analyzed separately, two clusters\u2014corresponding to Chinese and Japanese\u2014did emerge, with only a small amount of discordance (6 [1%] of 567 subjects). In contrast, cluster analysis within the three other major clusters did not produce robust, replicable subgroups, indicating a lack of further subgroups within these entities, at least in the current marker set. This observation does not eliminate the potential for confounding in these populations. First, there may be subgroups within the larger population group that are too small to detect by cluster analysis. Second, there may not be discrete subgrouping but continuous ancestral variation that could lead to stratification bias. For example, African Americans have a continuous range of European ancestry that would not be detected by cluster analysis but could strongly confound genetic case-control studies. Furthermore, our analysis likely underrepresents individuals with recent mixed ancestry (who would require more complex categorization) and other groups typically underrepresented, such as South Asians. Further study is required to evaluate the correlation between genetically determined groupings and SIRE for these individuals.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You&amp;#39;ll also note this article is from 2005.  The year we first sequenced a human genome.  So lets see responses to this, and what ideas they draw upon.&lt;/p&gt;\n\n&lt;p&gt;I like this one because it touches on the point of the article you studied, which was specifically for healthcare related decisions.&lt;/p&gt;\n\n&lt;p&gt;I point you to this 2011 paper on the same exact topic of self-reported ethnicity, and it came to the same conclusion.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3899415/\"&gt;&amp;quot;Genetic Heterogeneity of Self-Reported Ancestry Groups in an Admixed Brazilian Population&amp;quot;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Note:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Self-reporting of ancestry was not an appropriate methodology to cluster groups in a Brazilian population, due to high variance at the individual level. &lt;strong&gt;Ancestry informative markers are more useful for quantitative measurement of biological ancestry.&lt;/strong&gt;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;But we use way, way more markers than we delineate races, and which markers we choose themselves are related to what types of &amp;#39;genetic hierarchies&amp;#39; we want to create, to whatever specified degree of nuance you want.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Race&amp;quot; has no taxinomic hierarchy unless you really just want to say &amp;quot;everyone is black&amp;quot;.  You can make identifiers for very specific ethnicities, yes, but that&amp;#39;s effectively different from what&amp;#39;s socially meant by &amp;#39;race&amp;#39;, and studies since sequencing the genome tend to back that up, and confirm what the study you cited already realized.  &amp;quot;Genetic markers themselves are more accurate than whatever people say&amp;quot;.  And genetic markers do not form clean and even lines. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgai6so", "score_hidden": false, "stickied": false, "created": 1492279145.0, "created_utc": 1492250345.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 7}}], "after": null, "before": null}}, "user_reports": [], "id": "dgahq2j", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "anechoicmedia", "parent_id": "t1_dg9wmff", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Ok? But what's meant by \"black person\"? Someone with dark skin?\n\nIt's far more than skin color, as a quick glance at any albino Africans will show.  The race construct refers to broad clustering of genes which affect more than external appearance. Talking of \"the pigment of skin\" because we colloquially use the literal labels black, white, etc to refer to ancestry groups is being deliberately obtuse.\n\n&gt;Is skin color somehow directly related to violence? That seems rather unlikely, since melanin doesn't do much beyond absorb more wavelengths of light. \n\nIt's not that the surface-level traits *are themselves the cause of* other traits; It's that they are correlated with them and can be used to make predictions at scale. You aren't this dull; Don't pretend to be.\n\nRaces differ innately in a variety of traits, such as lactose tolerance. If I say that \"blacks are innately less able to process lactose on average\", nobody is confused that what I am staying is that the specific trait of \"blackness\", however defined, is *causing* differences in lactase persistence. It's just a readily identifiable group that is correlated with some other component of human variation to a non-random degree.\n\n&gt;What if you decided to look at other features? Did you know left handed people are supposedly more prone to psych disorders?\n\nWhat's wrong with that connection? You're implying it's spurious or trivial, but by definition left-handed people have at least something different about their mind than their right-handed counterparts. It's wholly plausible that there are other biological differences that go along with handedness.\n\n&gt;If you want to ignore that though and use what are already socially constructed artificial labels as your basis of algorithmic thinking, your algorithms are going to reflect those same socially created constructs. \n\nComputers don't need us to teach them the \"wrong\" ideas about race, because they will immediately independently develop analogous concepts that line up with the \"arbitrary\" socially-constructed racial categories. We know this because they already do; Computers have been throwing various cluster analysis methods at genomic data for years, and they are unpersuaded by egalitarian obscurantism that insists that blacks and whites are secretly indistinguishable under the skin. [Cluster analysis of a few hundred SNPs can correctly match someone to their self-identified racial group with over 99% accuracy.](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1196372/)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Ok? But what&amp;#39;s meant by &amp;quot;black person&amp;quot;? Someone with dark skin?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s far more than skin color, as a quick glance at any albino Africans will show.  The race construct refers to broad clustering of genes which affect more than external appearance. Talking of &amp;quot;the pigment of skin&amp;quot; because we colloquially use the literal labels black, white, etc to refer to ancestry groups is being deliberately obtuse.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Is skin color somehow directly related to violence? That seems rather unlikely, since melanin doesn&amp;#39;t do much beyond absorb more wavelengths of light. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It&amp;#39;s not that the surface-level traits &lt;em&gt;are themselves the cause of&lt;/em&gt; other traits; It&amp;#39;s that they are correlated with them and can be used to make predictions at scale. You aren&amp;#39;t this dull; Don&amp;#39;t pretend to be.&lt;/p&gt;\n\n&lt;p&gt;Races differ innately in a variety of traits, such as lactose tolerance. If I say that &amp;quot;blacks are innately less able to process lactose on average&amp;quot;, nobody is confused that what I am staying is that the specific trait of &amp;quot;blackness&amp;quot;, however defined, is &lt;em&gt;causing&lt;/em&gt; differences in lactase persistence. It&amp;#39;s just a readily identifiable group that is correlated with some other component of human variation to a non-random degree.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;What if you decided to look at other features? Did you know left handed people are supposedly more prone to psych disorders?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What&amp;#39;s wrong with that connection? You&amp;#39;re implying it&amp;#39;s spurious or trivial, but by definition left-handed people have at least something different about their mind than their right-handed counterparts. It&amp;#39;s wholly plausible that there are other biological differences that go along with handedness.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If you want to ignore that though and use what are already socially constructed artificial labels as your basis of algorithmic thinking, your algorithms are going to reflect those same socially created constructs. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Computers don&amp;#39;t need us to teach them the &amp;quot;wrong&amp;quot; ideas about race, because they will immediately independently develop analogous concepts that line up with the &amp;quot;arbitrary&amp;quot; socially-constructed racial categories. We know this because they already do; Computers have been throwing various cluster analysis methods at genomic data for years, and they are unpersuaded by egalitarian obscurantism that insists that blacks and whites are secretly indistinguishable under the skin. &lt;a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1196372/\"&gt;Cluster analysis of a few hundred SNPs can correctly match someone to their self-identified racial group with over 99% accuracy.&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgahq2j", "score_hidden": false, "stickied": false, "created": 1492277631.0, "created_utc": 1492248831.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgagyne", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "laccro", "parent_id": "t1_dga5t3q", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's not a conscious thing for people to be lazy about though... It's subconscious, but may require the person to at least consciously realize that they're wrong. Idk. I appreciate the reply!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not a conscious thing for people to be lazy about though... It&amp;#39;s subconscious, but may require the person to at least consciously realize that they&amp;#39;re wrong. Idk. I appreciate the reply!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgagyne", "score_hidden": false, "stickied": false, "created": 1492275208.0, "created_utc": 1492246408.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga5t3q", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "Sysfin", "parent_id": "t1_dg9xtlc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; but it's right more often than not. Otherwise it would change that stereotype to match the data...\n\nOnly if it has a need and opportunity to change...  people are very willing to make excuses and ignore evidence.  \"Those people are out of work because they are lazy, I am out of work because of bad luck\"  \n\nYou are correct that the brain needs to take shortcuts but it is important to understand when your brain does that to you so you can make sure it doesn't take any inappropriate shortcuts.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;but it&amp;#39;s right more often than not. Otherwise it would change that stereotype to match the data...&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Only if it has a need and opportunity to change...  people are very willing to make excuses and ignore evidence.  &amp;quot;Those people are out of work because they are lazy, I am out of work because of bad luck&amp;quot;  &lt;/p&gt;\n\n&lt;p&gt;You are correct that the brain needs to take shortcuts but it is important to understand when your brain does that to you so you can make sure it doesn&amp;#39;t take any inappropriate shortcuts.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga5t3q", "score_hidden": false, "stickied": false, "created": 1492252482.0, "created_utc": 1492223682.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgagvx8", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "laccro", "parent_id": "t1_dga0lxb", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I totally agree with your sentiment. I honestly just wish that the different qualities associated with race were just treated the same as, for example, hair color. You can have a preference that you're attracted to, you can have funny little jokes about stereotypes (like blondes, for example) but nobody actually cares...\n\n&gt;I mean, if you really want to crunch the numbers, you're probably more likely to die from medical malpractice than any member of any 'race' killing you.\n\nTo this, like I said, logic and knowledge aren't the factors of stereotypes. You're totally correct. But medical malpractice isn't in news headlines when someone is killed. You see things associating race with certain crimes in the news quite often. Those things are in the news because they're what people want to see. It's a feedback loop.\n\n&gt;I get concerned with phrases like \"purely acting rational and therefore not racist\".\n\nYeah the word rational in this context could mean so many different things depending on individuals morals. I agree. It's a tough problem to try to create something objective from our very subjective minds.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I totally agree with your sentiment. I honestly just wish that the different qualities associated with race were just treated the same as, for example, hair color. You can have a preference that you&amp;#39;re attracted to, you can have funny little jokes about stereotypes (like blondes, for example) but nobody actually cares...&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I mean, if you really want to crunch the numbers, you&amp;#39;re probably more likely to die from medical malpractice than any member of any &amp;#39;race&amp;#39; killing you.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;To this, like I said, logic and knowledge aren&amp;#39;t the factors of stereotypes. You&amp;#39;re totally correct. But medical malpractice isn&amp;#39;t in news headlines when someone is killed. You see things associating race with certain crimes in the news quite often. Those things are in the news because they&amp;#39;re what people want to see. It&amp;#39;s a feedback loop.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I get concerned with phrases like &amp;quot;purely acting rational and therefore not racist&amp;quot;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah the word rational in this context could mean so many different things depending on individuals morals. I agree. It&amp;#39;s a tough problem to try to create something objective from our very subjective minds.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgagvx8", "score_hidden": false, "stickied": false, "created": 1492274964.0, "created_utc": 1492246164.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga0lxb", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dg9xtlc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;They're not based on pure logic or knowledge, generally, so you won't just immediately start assuming that left-handed people are mentally ill, it's a pretty low correlation, if it exists at all.\n\nI mean, if you really want to crunch the numbers, you're probably more likely to die from medical malpractice than any member of any 'race' killing you.  Unless you add on other major risk factors, like, 'member of a gang'.\n\nBut my primary concern isn't with the basic idea that \"humans stereotype\", it's that \"this is always right, and good, and yields valid information about the world\".  I get concerned with phrases like \"purely acting rational and therefore not racist\".\n\nIt prevents us from challenging some basic underlying assumptions, like again, \"what do we literally mean by the word race\"?", "edited": 1492243715.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;They&amp;#39;re not based on pure logic or knowledge, generally, so you won&amp;#39;t just immediately start assuming that left-handed people are mentally ill, it&amp;#39;s a pretty low correlation, if it exists at all.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I mean, if you really want to crunch the numbers, you&amp;#39;re probably more likely to die from medical malpractice than any member of any &amp;#39;race&amp;#39; killing you.  Unless you add on other major risk factors, like, &amp;#39;member of a gang&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;But my primary concern isn&amp;#39;t with the basic idea that &amp;quot;humans stereotype&amp;quot;, it&amp;#39;s that &amp;quot;this is always right, and good, and yields valid information about the world&amp;quot;.  I get concerned with phrases like &amp;quot;purely acting rational and therefore not racist&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;It prevents us from challenging some basic underlying assumptions, like again, &amp;quot;what do we literally mean by the word race&amp;quot;?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga0lxb", "score_hidden": false, "stickied": false, "created": 1492245264.0, "created_utc": 1492216464.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 9}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9xtlc", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "laccro", "parent_id": "t1_dg9wmff", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "On your first points about skin color's relation to violence, or left handedness to mental disorders\n\nSo the thing is, that's just how the human brain **needs to** work. It cannot function without making stereotypes. The act of stereotyping exists so that the brain doesn't need to make complicated analysis of every single thing that exists. There's just not enough processing power there. In order to optimize, it must sort things into groups, and have a certain set of features associated with that group.\n\nThe brain is pretty decent at making judgements based on stereotypes, too. It's not right all the time, but it's right more often than not. Otherwise it would change that stereotype to match the data...\n\nThey're not based on pure logic or knowledge, generally, so you won't just immediately start assuming that left-handed people are mentally ill, it's a pretty low correlation, if it exists at all.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On your first points about skin color&amp;#39;s relation to violence, or left handedness to mental disorders&lt;/p&gt;\n\n&lt;p&gt;So the thing is, that&amp;#39;s just how the human brain &lt;strong&gt;needs to&lt;/strong&gt; work. It cannot function without making stereotypes. The act of stereotyping exists so that the brain doesn&amp;#39;t need to make complicated analysis of every single thing that exists. There&amp;#39;s just not enough processing power there. In order to optimize, it must sort things into groups, and have a certain set of features associated with that group.&lt;/p&gt;\n\n&lt;p&gt;The brain is pretty decent at making judgements based on stereotypes, too. It&amp;#39;s not right all the time, but it&amp;#39;s right more often than not. Otherwise it would change that stereotype to match the data...&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re not based on pure logic or knowledge, generally, so you won&amp;#39;t just immediately start assuming that left-handed people are mentally ill, it&amp;#39;s a pretty low correlation, if it exists at all.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9xtlc", "score_hidden": false, "stickied": false, "created": 1492241556.0, "created_utc": 1492212756.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 8}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga45vw", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga2rif", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;I suppose in an relativistic abstract sense someones race is only what you perceive it as. But that's a useless distinction because that's the case for everything. If something is stereotyping based on something they can detect correctly the vast majority of the time it doesn't matter. Maybe a AI would determine race to be purely a skin color attribute and disregard other physical or genetic aspects. Does that matter if it comes to a similar conclusion of probabilities of traits when compared to an average of human traits disposed to the same grouping but designated to the word \"race\" and their own determination of what that is?\n\nI mean again, what 'traits' is it looking for?  \"Things humans focus on or put importance on\".  Lets link back to cat videos or crime rates.  In terms of deaths, you're [much more likely to die from medical error](http://www.bmj.com/content/353/bmj.i2139) than crime.  But we focus on crime.  It is constantly fed to us in society.  Robots will find that.  AI will find it as much as they find cat videos.  It's a reflection of **us**.  Lets say we have algorithms designed to assess value of property.  And it is given the leeway to find that \"oh, people with these types of names are less likely to get a sale, so lets value those properties less\", and it just so happens those people belong to a single racial group.  I mean for the computer it is \"perfectly rational\", but only because human society has already made assumptions and taken actions that the computer picks up on.\n\nLiterally ignoring what we mean by the concept of \"race\" doesn't help that, it's why we're kinda forced to either recognize our definitions are faulty, or that they really might not be the useful proxy our society puts value on.\n\n&gt;Read a poem of randomly alternating iambic and dactylic pentameter. They will stick out because they have different attributes. \n\nI don't see how this relates to why it's necessarily useful to instantly judge people without personal interaction.\n\n&gt;Disagree but don't want to discuss pros &amp; cons of races traits. We don't live in the world I described luckily. We have more contextually knowledge to base off of. \n\nAlthough we put apparently a disproportionate amount of time and energy in building concepts around somewhat arbitrary labels.\n\n&gt;I'm not talking about racism. Just stereotyping. Stereotyping is necessary for reasonable navigation of the world. Racism implies belief in superiority of a race under common usage of the term which is ideology and not necessary. \n\n... Umm, but robots will pick up on racism.  I mean if people have that mentality, share it, promote it, and have those values used, again, just like cat videos, computers are **going** to pick up on it.  Train a AI to speak on 4chan and it probably won't be very pleasant to talk to.\n\n&gt;Any solutions will suffer from the issue trying to be avoided. You cannot preprogram the concept of racial ignorance into an AI and then act as if you solved racism. You have merely removed an ability to stereotype.\n\nThings like failure to program a face is because **we** stereotyped.  We failed to think \"oh, wait, this might be a bad data set\".  Not all data is built upon valid or well structured foundations, and if it's not, computers will generate whatever we want them to generate.\n\nIf you want to train AI to write college level papers, you damn well better keep those programs away from 4chan.  \n\nIt's bad practice to assume data your feeding your computers is unfiltered, again, computers are picking up on us, so anything *we* do, \"rational\" or not, will be done by computers.\n\n&gt;I'm not sure. I do know that the stereotypes I can think of are much more rational than the idea of intentionally removing comprehensible knowledge of the world to achieve racial enlightenment. \n\nFor the same reason you would keep a program designed to write business news articles away from cat videos.  Just because humans do something, or humans focus on something, does not mean that is \"rational\".  Just because a computer picks up on a stereotype doesn't make the stereotype itself inherently justified, or unquestionable.  \n\nComputers deal with statistics, but I kinda find that distinct from knowledge.  I'm reminded of the phrase [\"Some individuals use statistics as a drunk man uses lamp-posts \u2014 for support rather than for illumination.\"](http://quoteinvestigator.com/2014/01/15/stats-drunk/).\n\nComputers will do what we tell them to do, they will find all sorts of statistics, correlations, back up any stereotypes to absurd degrees, etc.  But knowledge kinda requires contextualization, it requires analysis, questioning even the input data.  \n\nOtherwise we get facial recognition software that ignores people with darker skin because programmers didn't think to sample that.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I suppose in an relativistic abstract sense someones race is only what you perceive it as. But that&amp;#39;s a useless distinction because that&amp;#39;s the case for everything. If something is stereotyping based on something they can detect correctly the vast majority of the time it doesn&amp;#39;t matter. Maybe a AI would determine race to be purely a skin color attribute and disregard other physical or genetic aspects. Does that matter if it comes to a similar conclusion of probabilities of traits when compared to an average of human traits disposed to the same grouping but designated to the word &amp;quot;race&amp;quot; and their own determination of what that is?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I mean again, what &amp;#39;traits&amp;#39; is it looking for?  &amp;quot;Things humans focus on or put importance on&amp;quot;.  Lets link back to cat videos or crime rates.  In terms of deaths, you&amp;#39;re &lt;a href=\"http://www.bmj.com/content/353/bmj.i2139\"&gt;much more likely to die from medical error&lt;/a&gt; than crime.  But we focus on crime.  It is constantly fed to us in society.  Robots will find that.  AI will find it as much as they find cat videos.  It&amp;#39;s a reflection of &lt;strong&gt;us&lt;/strong&gt;.  Lets say we have algorithms designed to assess value of property.  And it is given the leeway to find that &amp;quot;oh, people with these types of names are less likely to get a sale, so lets value those properties less&amp;quot;, and it just so happens those people belong to a single racial group.  I mean for the computer it is &amp;quot;perfectly rational&amp;quot;, but only because human society has already made assumptions and taken actions that the computer picks up on.&lt;/p&gt;\n\n&lt;p&gt;Literally ignoring what we mean by the concept of &amp;quot;race&amp;quot; doesn&amp;#39;t help that, it&amp;#39;s why we&amp;#39;re kinda forced to either recognize our definitions are faulty, or that they really might not be the useful proxy our society puts value on.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Read a poem of randomly alternating iambic and dactylic pentameter. They will stick out because they have different attributes. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t see how this relates to why it&amp;#39;s necessarily useful to instantly judge people without personal interaction.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Disagree but don&amp;#39;t want to discuss pros &amp;amp; cons of races traits. We don&amp;#39;t live in the world I described luckily. We have more contextually knowledge to base off of. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Although we put apparently a disproportionate amount of time and energy in building concepts around somewhat arbitrary labels.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m not talking about racism. Just stereotyping. Stereotyping is necessary for reasonable navigation of the world. Racism implies belief in superiority of a race under common usage of the term which is ideology and not necessary. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;... Umm, but robots will pick up on racism.  I mean if people have that mentality, share it, promote it, and have those values used, again, just like cat videos, computers are &lt;strong&gt;going&lt;/strong&gt; to pick up on it.  Train a AI to speak on 4chan and it probably won&amp;#39;t be very pleasant to talk to.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Any solutions will suffer from the issue trying to be avoided. You cannot preprogram the concept of racial ignorance into an AI and then act as if you solved racism. You have merely removed an ability to stereotype.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Things like failure to program a face is because &lt;strong&gt;we&lt;/strong&gt; stereotyped.  We failed to think &amp;quot;oh, wait, this might be a bad data set&amp;quot;.  Not all data is built upon valid or well structured foundations, and if it&amp;#39;s not, computers will generate whatever we want them to generate.&lt;/p&gt;\n\n&lt;p&gt;If you want to train AI to write college level papers, you damn well better keep those programs away from 4chan.  &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s bad practice to assume data your feeding your computers is unfiltered, again, computers are picking up on us, so anything &lt;em&gt;we&lt;/em&gt; do, &amp;quot;rational&amp;quot; or not, will be done by computers.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I&amp;#39;m not sure. I do know that the stereotypes I can think of are much more rational than the idea of intentionally removing comprehensible knowledge of the world to achieve racial enlightenment. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;For the same reason you would keep a program designed to write business news articles away from cat videos.  Just because humans do something, or humans focus on something, does not mean that is &amp;quot;rational&amp;quot;.  Just because a computer picks up on a stereotype doesn&amp;#39;t make the stereotype itself inherently justified, or unquestionable.  &lt;/p&gt;\n\n&lt;p&gt;Computers deal with statistics, but I kinda find that distinct from knowledge.  I&amp;#39;m reminded of the phrase &lt;a href=\"http://quoteinvestigator.com/2014/01/15/stats-drunk/\"&gt;&amp;quot;Some individuals use statistics as a drunk man uses lamp-posts \u2014 for support rather than for illumination.&amp;quot;&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;Computers will do what we tell them to do, they will find all sorts of statistics, correlations, back up any stereotypes to absurd degrees, etc.  But knowledge kinda requires contextualization, it requires analysis, questioning even the input data.  &lt;/p&gt;\n\n&lt;p&gt;Otherwise we get facial recognition software that ignores people with darker skin because programmers didn&amp;#39;t think to sample that.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga45vw", "score_hidden": false, "stickied": false, "created": 1492250103.0, "created_utc": 1492221303.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 12}}], "after": null, "before": null}}, "user_reports": [], "id": "dga2rif", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dga1zk9", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "I suppose in an relativistic abstract sense someones race is only what you perceive it as. But that's a useless distinction because that's the case for everything. If something is stereotyping based on something they can detect correctly the vast majority of the time it doesn't matter. Maybe a AI would determine race to be purely a skin color attribute and disregard other physical or genetic aspects. Does that matter if it comes to a similar conclusion of probabilities of traits when compared to an average of human traits disposed to the same grouping but designated to the word \"race\" and their own determination of what that is?\n\n&gt;For most of our species, I grant you, it's been very, very useful to be good at tribal mindsets. I'm just struggling to see how useful that is going forward,\n\nRead a poem of randomly alternating iambic and dactylic pentameter. They will stick out because they have different attributes. \n\n&gt; especially in the information age where many of the traits you mentioned are pretty literally irrelevant except that society, nearly any one on earth, holds some value in that mindset.\n\n\nDisagree but don't want to discuss pros &amp; cons of races traits. We don't live in the world I described luckily. We have more contextually knowledge to base off of. \n\n&gt;If I won't meet someone, won't talk to them, etc, what good does it have for me to waste my mind with opinions on someone who is fundamentally irrelevant to me?\n\nBecause it's useful to determine patterns regarding the situations and objects around you at any given point. They aren't irrelevant. \n\n &gt;But if it's just that \"yeah, humans will always pick up on what humans do, and racism is just something humans do\".... well, isn't that kinda what should be addressed? Shouldn't we at least take some care to ensure that algorithms trained to do more than recognize faces don't adopt other bad human habits? Stereotypes are not always \"purely rational\", and a computer will pick up on them \"rational\" or not so long as they exist within society.\n\nI'm not talking about racism. Just stereotyping. Stereotyping is necessary for reasonable navigation of the world. Racism implies belief in superiority of a race under common usage of the term which is ideology and not necessary. \n\n&gt;Shouldn't we at least take some care to ensure that algorithms trained to do more than recognize faces don't adopt other bad human habits?\n\nAny solutions will suffer from the issue trying to be avoided. You cannot preprogram the concept of racial ignorance into an AI and then act as if you solved racism. You have merely removed an ability to stereotype.\n\n&gt;**Stereotypes are not always \"purely rational\", and a computer will pick up on them \"rational\" or not so long as they exist within society.\n\nI'm not sure. I do know that the stereotypes I can think of are much more rational than the idea of intentionally removing comprehensible knowledge of the world to achieve  racial enlightenment. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I suppose in an relativistic abstract sense someones race is only what you perceive it as. But that&amp;#39;s a useless distinction because that&amp;#39;s the case for everything. If something is stereotyping based on something they can detect correctly the vast majority of the time it doesn&amp;#39;t matter. Maybe a AI would determine race to be purely a skin color attribute and disregard other physical or genetic aspects. Does that matter if it comes to a similar conclusion of probabilities of traits when compared to an average of human traits disposed to the same grouping but designated to the word &amp;quot;race&amp;quot; and their own determination of what that is?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;For most of our species, I grant you, it&amp;#39;s been very, very useful to be good at tribal mindsets. I&amp;#39;m just struggling to see how useful that is going forward,&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Read a poem of randomly alternating iambic and dactylic pentameter. They will stick out because they have different attributes. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;especially in the information age where many of the traits you mentioned are pretty literally irrelevant except that society, nearly any one on earth, holds some value in that mindset.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Disagree but don&amp;#39;t want to discuss pros &amp;amp; cons of races traits. We don&amp;#39;t live in the world I described luckily. We have more contextually knowledge to base off of. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If I won&amp;#39;t meet someone, won&amp;#39;t talk to them, etc, what good does it have for me to waste my mind with opinions on someone who is fundamentally irrelevant to me?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because it&amp;#39;s useful to determine patterns regarding the situations and objects around you at any given point. They aren&amp;#39;t irrelevant. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;But if it&amp;#39;s just that &amp;quot;yeah, humans will always pick up on what humans do, and racism is just something humans do&amp;quot;.... well, isn&amp;#39;t that kinda what should be addressed? Shouldn&amp;#39;t we at least take some care to ensure that algorithms trained to do more than recognize faces don&amp;#39;t adopt other bad human habits? Stereotypes are not always &amp;quot;purely rational&amp;quot;, and a computer will pick up on them &amp;quot;rational&amp;quot; or not so long as they exist within society.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m not talking about racism. Just stereotyping. Stereotyping is necessary for reasonable navigation of the world. Racism implies belief in superiority of a race under common usage of the term which is ideology and not necessary. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Shouldn&amp;#39;t we at least take some care to ensure that algorithms trained to do more than recognize faces don&amp;#39;t adopt other bad human habits?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Any solutions will suffer from the issue trying to be avoided. You cannot preprogram the concept of racial ignorance into an AI and then act as if you solved racism. You have merely removed an ability to stereotype.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;**Stereotypes are not always &amp;quot;purely rational&amp;quot;, and a computer will pick up on them &amp;quot;rational&amp;quot; or not so long as they exist within society.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I&amp;#39;m not sure. I do know that the stereotypes I can think of are much more rational than the idea of intentionally removing comprehensible knowledge of the world to achieve  racial enlightenment. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga2rif", "score_hidden": false, "stickied": false, "created": 1492248180.0, "created_utc": 1492219380.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga1zk9", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga0vod", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;I really don't want to get into a discussion on what constitutes a race, sorry. I don't think it's appropriate for this sub. I think it should be pretty easy for everyone to be able to look at a group of people and determine quickly what race they are and be accurate most of the time- if you disagree with this I'm not sure what to tell you. Additionally, it is possible to determine race by DNA quite accurately. It is also possible to determine race with eyesight/images and is also pretty accurate. \n\nIn a topic on how programs pick up on the concept of race, I think having a definition in a programming sub might be important.  In the same way that it could avoid embarrassing instances of things like when [facial tracking software couldn't track black people](http://gizmodo.com/5431190/hp-face-tracking-webcams-dont-recognize-black-people) because when it was trained, it didn't have any samples.\n\nWhich means it just didn't have a large enough base of 'sample faces' to choose from.\n\nGoogle's voice recognition is so much superior to Apple's probably thanks to Google 411 creating a giant cache of different samples.\n\nComputers will always pick up on physical human diversity, and skin color, facial features, eye color, etc, will always exist on a gradient scale.  (So will dialects as it happens)\n\nBut to the extent that we base stereotypes off these, and consider them in some way \"fundamental\"?  Computers don't get to make that determination for us.\n\nAnd yes, I pointed out, we can analyze DNA quite well.  It's why we know Albert Perry is a direct male descendant of a Y-chromosomal Adam who lived some 300k+ years ago.  That's astounding.  But it also makes it hard for \"black\" to be a single race, if, you know, at least on the father's side, both you and I and any random 'black' person from Africa are all more related to each other and to aboriginal Australians than we are to that one guy from South Carolina.  \n\nIt's why providing an actual definition that doesn't really involve just saying \"use skin color, or cultural features as a proxy\" is pretty much flat out wrong, on a genetic level.  At least if you're trying to use classifications like the word \"black\".  \n\nOur society holds value for words that don't mean what they do as far as genetics are concerned.\n\n&gt;Picking up the race of someone is much easier than determining what their dominant hand is. I certainly cannot tell what people's dominant hand is when first seeing them. I can tell their race. \n\nSo how is this any different from cat videos?  It's only reinforcing things *already present* in society and already given value in society.  \n\n&gt;And that was my point. A simple AI making simple observations&amp;predictions and improving on those. \n\n... That comment was mostly meant to be patronizing to our species.  We have a habit of delineating 'others', even when that's not really all that useful.\n\n&gt;Determining culture of some random person is not really possible as a quick approximation. Say you are totally color blind, as in - you don't see race, don't hear differences in speech, etc. How do you determine a quick approximation of someone you've never seen before and you will not speak to? It's pointless to try because there is no differentiating factors. You could introduce new factors that would then fit the role... but that's not the world we live in. \n\nWell... that's just it, how useful is any of that in today's world at this point?  We place cultural value on things that people seldom place much personal value on.  What 'quick judgments' do we need to make about others as a group based only on physical features?\n\nFor most of our species, I grant you, it's been very, **very** useful to be good at tribal mindsets.  I'm just struggling to see how useful that is going forward, especially in the information age where many of the traits you mentioned are pretty literally irrelevant *except* that society, nearly any one on earth, holds some value in that mindset.  \n\nIf I won't meet someone, won't talk to them, etc, what good does it have for me to waste my mind with opinions on someone who is fundamentally irrelevant to me?\n\nWe've created these constructs, but my entire point is that they're pretty arbitrary.  If you want to say \"there's something inherent about these statistics, computers pick up on that\", and choose a genetic angle, well... again, no, human races don't really work that way on a genetic level.\n\nBut if it's just that \"yeah, humans will always pick up on what humans do, and racism is just something humans do\".... well, isn't that kinda what should be addressed?  Shouldn't we at least take some care to ensure that algorithms trained to do more than recognize faces don't adopt other bad human habits?  Stereotypes are not always \"purely rational\", and a computer will pick up on them \"rational\" or not so long as they exist within society. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I really don&amp;#39;t want to get into a discussion on what constitutes a race, sorry. I don&amp;#39;t think it&amp;#39;s appropriate for this sub. I think it should be pretty easy for everyone to be able to look at a group of people and determine quickly what race they are and be accurate most of the time- if you disagree with this I&amp;#39;m not sure what to tell you. Additionally, it is possible to determine race by DNA quite accurately. It is also possible to determine race with eyesight/images and is also pretty accurate. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;In a topic on how programs pick up on the concept of race, I think having a definition in a programming sub might be important.  In the same way that it could avoid embarrassing instances of things like when &lt;a href=\"http://gizmodo.com/5431190/hp-face-tracking-webcams-dont-recognize-black-people\"&gt;facial tracking software couldn&amp;#39;t track black people&lt;/a&gt; because when it was trained, it didn&amp;#39;t have any samples.&lt;/p&gt;\n\n&lt;p&gt;Which means it just didn&amp;#39;t have a large enough base of &amp;#39;sample faces&amp;#39; to choose from.&lt;/p&gt;\n\n&lt;p&gt;Google&amp;#39;s voice recognition is so much superior to Apple&amp;#39;s probably thanks to Google 411 creating a giant cache of different samples.&lt;/p&gt;\n\n&lt;p&gt;Computers will always pick up on physical human diversity, and skin color, facial features, eye color, etc, will always exist on a gradient scale.  (So will dialects as it happens)&lt;/p&gt;\n\n&lt;p&gt;But to the extent that we base stereotypes off these, and consider them in some way &amp;quot;fundamental&amp;quot;?  Computers don&amp;#39;t get to make that determination for us.&lt;/p&gt;\n\n&lt;p&gt;And yes, I pointed out, we can analyze DNA quite well.  It&amp;#39;s why we know Albert Perry is a direct male descendant of a Y-chromosomal Adam who lived some 300k+ years ago.  That&amp;#39;s astounding.  But it also makes it hard for &amp;quot;black&amp;quot; to be a single race, if, you know, at least on the father&amp;#39;s side, both you and I and any random &amp;#39;black&amp;#39; person from Africa are all more related to each other and to aboriginal Australians than we are to that one guy from South Carolina.  &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s why providing an actual definition that doesn&amp;#39;t really involve just saying &amp;quot;use skin color, or cultural features as a proxy&amp;quot; is pretty much flat out wrong, on a genetic level.  At least if you&amp;#39;re trying to use classifications like the word &amp;quot;black&amp;quot;.  &lt;/p&gt;\n\n&lt;p&gt;Our society holds value for words that don&amp;#39;t mean what they do as far as genetics are concerned.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Picking up the race of someone is much easier than determining what their dominant hand is. I certainly cannot tell what people&amp;#39;s dominant hand is when first seeing them. I can tell their race. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So how is this any different from cat videos?  It&amp;#39;s only reinforcing things &lt;em&gt;already present&lt;/em&gt; in society and already given value in society.  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;And that was my point. A simple AI making simple observations&amp;amp;predictions and improving on those. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;... That comment was mostly meant to be patronizing to our species.  We have a habit of delineating &amp;#39;others&amp;#39;, even when that&amp;#39;s not really all that useful.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Determining culture of some random person is not really possible as a quick approximation. Say you are totally color blind, as in - you don&amp;#39;t see race, don&amp;#39;t hear differences in speech, etc. How do you determine a quick approximation of someone you&amp;#39;ve never seen before and you will not speak to? It&amp;#39;s pointless to try because there is no differentiating factors. You could introduce new factors that would then fit the role... but that&amp;#39;s not the world we live in. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Well... that&amp;#39;s just it, how useful is any of that in today&amp;#39;s world at this point?  We place cultural value on things that people seldom place much personal value on.  What &amp;#39;quick judgments&amp;#39; do we need to make about others as a group based only on physical features?&lt;/p&gt;\n\n&lt;p&gt;For most of our species, I grant you, it&amp;#39;s been very, &lt;strong&gt;very&lt;/strong&gt; useful to be good at tribal mindsets.  I&amp;#39;m just struggling to see how useful that is going forward, especially in the information age where many of the traits you mentioned are pretty literally irrelevant &lt;em&gt;except&lt;/em&gt; that society, nearly any one on earth, holds some value in that mindset.  &lt;/p&gt;\n\n&lt;p&gt;If I won&amp;#39;t meet someone, won&amp;#39;t talk to them, etc, what good does it have for me to waste my mind with opinions on someone who is fundamentally irrelevant to me?&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;ve created these constructs, but my entire point is that they&amp;#39;re pretty arbitrary.  If you want to say &amp;quot;there&amp;#39;s something inherent about these statistics, computers pick up on that&amp;quot;, and choose a genetic angle, well... again, no, human races don&amp;#39;t really work that way on a genetic level.&lt;/p&gt;\n\n&lt;p&gt;But if it&amp;#39;s just that &amp;quot;yeah, humans will always pick up on what humans do, and racism is just something humans do&amp;quot;.... well, isn&amp;#39;t that kinda what should be addressed?  Shouldn&amp;#39;t we at least take some care to ensure that algorithms trained to do more than recognize faces don&amp;#39;t adopt other bad human habits?  Stereotypes are not always &amp;quot;purely rational&amp;quot;, and a computer will pick up on them &amp;quot;rational&amp;quot; or not so long as they exist within society. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga1zk9", "score_hidden": false, "stickied": false, "created": 1492247102.0, "created_utc": 1492218302.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 15}}], "after": null, "before": null}}, "user_reports": [], "id": "dga0vod", "gilded": 0, "archived": false, "score": -6, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dga039e", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "I really don't want to get into a discussion on what constitutes a race, sorry. I don't think it's appropriate for this sub. I think it should be pretty easy for everyone to be able to look at a group of people and determine quickly what race they are and be accurate most of the time- if you disagree with this I'm not sure what to tell you. Additionally, it is possible to determine race by DNA quite accurately. It is also possible to determine race with eyesight/images and is also pretty accurate. \n\n&gt;I didn't 'ignore' it, I'm asking, what do you mean by a 'black person'. I'm asking this because I can accept the point of fact 'people with darker skin commit more crime on average', but that fact alone isn't really all that more interesting to me than statistics on left handed people. I'm interested in what this is really implying, especially given by your statements that \"races are genetically different\". \"There is a genetic predisposition towards actions one can deduce from stereotypes and statistics\". That idea seems decidedly false. So then what do we mean by 'black people'? If not a genetic thing, but rather, it really is just skin color, what are underlying issues?\n\n\nPicking up the race of someone is much easier than determining what their dominant hand is. I certainly cannot tell what people's dominant hand is when first seeing them. I can tell their race. \n\n\n&gt;But skin color at the very least makes it very easy to bin and label people without even looking at their face. If you want to delineate an 'other', pretty easy and quick way of doing so.\n\n\nAnd that was my point. A simple AI making simple observations&amp;predictions and improving on those. \n\n&gt;Stereotypes rise and fall constantly, which again, is probably why I'm more in favor of some 'cultural' explanation than anything 'genetic'.\n\nDetermining culture of some random person is not really possible as a quick approximation. Say you are totally color blind, as in - you don't see race, don't hear differences in speech, etc. How do you determine a quick approximation of someone you've never seen before and you will not speak to? It's pointless to try because there is no differentiating factors. You could introduce new factors that would then fit the role... but that's not the world we live in. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I really don&amp;#39;t want to get into a discussion on what constitutes a race, sorry. I don&amp;#39;t think it&amp;#39;s appropriate for this sub. I think it should be pretty easy for everyone to be able to look at a group of people and determine quickly what race they are and be accurate most of the time- if you disagree with this I&amp;#39;m not sure what to tell you. Additionally, it is possible to determine race by DNA quite accurately. It is also possible to determine race with eyesight/images and is also pretty accurate. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I didn&amp;#39;t &amp;#39;ignore&amp;#39; it, I&amp;#39;m asking, what do you mean by a &amp;#39;black person&amp;#39;. I&amp;#39;m asking this because I can accept the point of fact &amp;#39;people with darker skin commit more crime on average&amp;#39;, but that fact alone isn&amp;#39;t really all that more interesting to me than statistics on left handed people. I&amp;#39;m interested in what this is really implying, especially given by your statements that &amp;quot;races are genetically different&amp;quot;. &amp;quot;There is a genetic predisposition towards actions one can deduce from stereotypes and statistics&amp;quot;. That idea seems decidedly false. So then what do we mean by &amp;#39;black people&amp;#39;? If not a genetic thing, but rather, it really is just skin color, what are underlying issues?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Picking up the race of someone is much easier than determining what their dominant hand is. I certainly cannot tell what people&amp;#39;s dominant hand is when first seeing them. I can tell their race. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;But skin color at the very least makes it very easy to bin and label people without even looking at their face. If you want to delineate an &amp;#39;other&amp;#39;, pretty easy and quick way of doing so.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;And that was my point. A simple AI making simple observations&amp;amp;predictions and improving on those. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Stereotypes rise and fall constantly, which again, is probably why I&amp;#39;m more in favor of some &amp;#39;cultural&amp;#39; explanation than anything &amp;#39;genetic&amp;#39;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Determining culture of some random person is not really possible as a quick approximation. Say you are totally color blind, as in - you don&amp;#39;t see race, don&amp;#39;t hear differences in speech, etc. How do you determine a quick approximation of someone you&amp;#39;ve never seen before and you will not speak to? It&amp;#39;s pointless to try because there is no differentiating factors. You could introduce new factors that would then fit the role... but that&amp;#39;s not the world we live in. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga0vod", "score_hidden": false, "stickied": false, "created": 1492245618.0, "created_utc": 1492216818.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": -6}}], "after": null, "before": null}}, "user_reports": [], "id": "dga039e", "gilded": 0, "archived": false, "score": 17, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dg9xx5w", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; No it's not. Races are genetically different. You are able to run a DNA test and determine the race of someone incredibly accurately. Any person can point out which people are of which races the majority of the time. Race is not a social construct, it's a designation based on genetic &amp; physical characteristics.\n\nLets work on this because it's a rather strange characterization of biology.  Again, what is a \"race\"?  Lets say you do a genetic test on a random black individual from the deep south.  You find [they're directly related to a much older line of humans](http://www.nature.com/ejhg/journal/v22/n9/full/ejhg2013303a.html).  Albert Perry was exactly that.  But!!  That also means he's generally **less** related to a random black individual from Africa than you or I am.\n\nThat's the problem.  You can create a 'race' if you want, but they're incredibly specified and nuanced.  \"Black\" people in Africa are the most genetically diverse group of people on the planet, if we want to call \"black\" a single race, then we're kinda left with \"all human beings are ultimately black\", because the line of \"people who left Africa\" (which includes \"all other skin colors\") still left Africa **after** there were other people, including Perry's great great times whatever grandfather.\n\nSo you and I are probably more related to each other, regardless of your skin color or mine, than we are to Albert Perry.  At least on the paternal side.  \n\nHow then can Perry be the same \"race\" as another generic black person in the US if they're more related to me, a 'white' person, than they are to him? \n\nI think [Jerry Coyne](https://whyevolutionistrue.wordpress.com/2012/02/28/are-there-human-races/) does a pretty good job with the concept.  He defends the idea of a 'scientific concept of race', but it's charactarized as very different:\n\n&gt;That\u2019s pretty much unanswerable, because human variation is nested in groups, for their ancestry, which is based on evolutionary differences, is nested in groups.  So, for example, one could delimit \u201cCaucasians\u201d as a race, but within that group there are genetically different and morphologically different subgroups, including Finns, southern Europeans, Bedouins, and the like.  The number of human races delimited by biologists has ranged from three to over thirty.\n\nThe 'race' is an arbitrary distinction and label.\n\nThis paragraph is kinda the key:\n&gt;How different are the races genetically?\n\n&gt;Not very different.  As has been known for a while, DNA and other genetic analyses have shown that most of the variation in the human species occurs within a given human ethnic group, and only a small fraction between different races. That means that on average, there is more genetic difference between individuals within a race than there is between races themselves.\n\nWhich kinda explains why a \"black\" African can be more genetically distinct from another \"black\" African than they are from (anyone out of Africa) people who really only came from yet another \"black\" African line.  Humans began in Africa so it's only reasonable it has the highest genetic diversity of humans.  We spent over half of our specie's existence on that continent, and given Perry's DNA, apparently over two thirds of it was spent there.\n\n&gt;AI will develop the concept of race on its own. It doesn't need a label. It's an obvious stereotyping example that will arise with very minor intelligence.\n\n&gt;I used simple examples that a simple AI would derive itself. Then laid out examples of how a more advanced AI would uncover nuance to those. \n\nIt will really only do so if trained on **our** society.  Our media.  Etc.  The fact that it's something humans 'do' is pretty obvious, but that says nothing about underlying reality, or how valid societal assumptions are.  Some type of generalized AI would probably develop facts about phrenology if trained in the 1800s if given tons of data indicating the concept is important to society.  AI already recognizes [cats](https://www.wired.com/2012/06/google-x-neural-network/) especially well.  \n\nBut I don't think Google finding out that a neural network becomes incredibly good at finding cats reflects anything really notable about society other than 'we like cat videos online'.  Nor is a computer picking up on racial stereotypes any more interesting than 'these stereotypes exist'.\n\nMy issue is with how 'ok' we should be with that without questioning the underlying assumptions.  Are cats really super important?  Or is it society influencing AI views on cats?  Is 'race' really a fundamental concept, or is it society influencing AI views on race?\n\n&gt;You could make the same argument for my red and yellow color example. It was used for illustration. In the US black people are associated with higher rates of theft... trying to ignore this is an exercise in futility- a machine which doesn't care will uncover the exact same attributes.\n\nI didn't 'ignore' it, I'm asking, what do you mean by a 'black person'.  I'm asking this because I can accept the point of fact 'people with darker skin commit more crime on average', but that fact alone isn't really all that more interesting to me than statistics on left handed people.  I'm interested in what this is really implying, especially given by your statements that \"races are genetically different\".  \"There is a genetic predisposition towards actions one can deduce from stereotypes and statistics\".  **That** idea seems decidedly false.  So then what do we mean by 'black people'?  If not a genetic thing, but rather, it really is just skin color, what **are** underlying issues?\n\n&gt;You can argue this is for different reasons other than race, but at the end of the day it doesn't matter because this system is approximating the world based on limited information and will start off with basic approximations and work from there. Would race be the first one? I'm not sure, but probably one of the first since the difference in crime rates is very statistically significant and the ability to notice the difference is very obvious. \n\nThat, again, doesn't do any more than tell us \"these statistics are out there, and people already promote them, so AI is of course going to find it\".\n\nAgain, cat videos.  The statistics aren't false, and people make a huge deal out of it, so yes, computers are going to use those as part of the AI.  They don't have a choice.  They're computers.\n\nThe reason **why** these statistics exist though, and what to do with them, isn't generally \"accept them as justification for why stereotypes are ok\".  That seems like creating a self-fulfilling prophecy.  Like cats.\n\n&gt;No. **Race is though.** And skin color is a pretty good/simple race detector. In the case of the very simple AI which only looks at skin color to assume trustworthiness you'd be right - it'd be a shit predictor. But I'm trying to describe from a basic level to keep it easy to read. \n\nWithout race being a properly defined concept, this seems really, REALLY hard to argue.  So 'basic level' or not, what is explicitly meant by the concept of 'race' seems really central here.\n\nSo what's meant?  What explicitly is a 'race' defined as?\n\nI'm happy to take a 'cultural' definition, but so far as genetics, that's really, **really** hard to do thanks to the past decade of genetics research.\n\n&gt;I used the features I did to make it easier for people to understand my overall point. Simple attributes like color and shape are quite easy to rationalize and were in the context of ai-race-discussion. \n\nYes, and they're also part of the problem of how society views race.  Which means they'd be part of the problem of how AI views race because AI is fundamentally trained **on society**.\n\n&gt;Yeah there may be something there. As far as eye color I doubt its very significant otherwise it would already exist as a stereotype in humans. There does seem to be faces which people generally pick up on as \"sketchy\"- not sure how accurate that is but maybe something to it. \n\nStereotypes rise and fall constantly, which again, is probably why I'm more in favor of some 'cultural' explanation than anything 'genetic'.\n\nBut skin color at the very least makes it very easy to bin and label people without even looking at their face.  If you want to delineate an 'other', pretty easy and quick way of doing so. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;No it&amp;#39;s not. Races are genetically different. You are able to run a DNA test and determine the race of someone incredibly accurately. Any person can point out which people are of which races the majority of the time. Race is not a social construct, it&amp;#39;s a designation based on genetic &amp;amp; physical characteristics.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Lets work on this because it&amp;#39;s a rather strange characterization of biology.  Again, what is a &amp;quot;race&amp;quot;?  Lets say you do a genetic test on a random black individual from the deep south.  You find &lt;a href=\"http://www.nature.com/ejhg/journal/v22/n9/full/ejhg2013303a.html\"&gt;they&amp;#39;re directly related to a much older line of humans&lt;/a&gt;.  Albert Perry was exactly that.  But!!  That also means he&amp;#39;s generally &lt;strong&gt;less&lt;/strong&gt; related to a random black individual from Africa than you or I am.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s the problem.  You can create a &amp;#39;race&amp;#39; if you want, but they&amp;#39;re incredibly specified and nuanced.  &amp;quot;Black&amp;quot; people in Africa are the most genetically diverse group of people on the planet, if we want to call &amp;quot;black&amp;quot; a single race, then we&amp;#39;re kinda left with &amp;quot;all human beings are ultimately black&amp;quot;, because the line of &amp;quot;people who left Africa&amp;quot; (which includes &amp;quot;all other skin colors&amp;quot;) still left Africa &lt;strong&gt;after&lt;/strong&gt; there were other people, including Perry&amp;#39;s great great times whatever grandfather.&lt;/p&gt;\n\n&lt;p&gt;So you and I are probably more related to each other, regardless of your skin color or mine, than we are to Albert Perry.  At least on the paternal side.  &lt;/p&gt;\n\n&lt;p&gt;How then can Perry be the same &amp;quot;race&amp;quot; as another generic black person in the US if they&amp;#39;re more related to me, a &amp;#39;white&amp;#39; person, than they are to him? &lt;/p&gt;\n\n&lt;p&gt;I think &lt;a href=\"https://whyevolutionistrue.wordpress.com/2012/02/28/are-there-human-races/\"&gt;Jerry Coyne&lt;/a&gt; does a pretty good job with the concept.  He defends the idea of a &amp;#39;scientific concept of race&amp;#39;, but it&amp;#39;s charactarized as very different:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;That\u2019s pretty much unanswerable, because human variation is nested in groups, for their ancestry, which is based on evolutionary differences, is nested in groups.  So, for example, one could delimit \u201cCaucasians\u201d as a race, but within that group there are genetically different and morphologically different subgroups, including Finns, southern Europeans, Bedouins, and the like.  The number of human races delimited by biologists has ranged from three to over thirty.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The &amp;#39;race&amp;#39; is an arbitrary distinction and label.&lt;/p&gt;\n\n&lt;p&gt;This paragraph is kinda the key:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;How different are the races genetically?&lt;/p&gt;\n\n&lt;p&gt;Not very different.  As has been known for a while, DNA and other genetic analyses have shown that most of the variation in the human species occurs within a given human ethnic group, and only a small fraction between different races. That means that on average, there is more genetic difference between individuals within a race than there is between races themselves.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Which kinda explains why a &amp;quot;black&amp;quot; African can be more genetically distinct from another &amp;quot;black&amp;quot; African than they are from (anyone out of Africa) people who really only came from yet another &amp;quot;black&amp;quot; African line.  Humans began in Africa so it&amp;#39;s only reasonable it has the highest genetic diversity of humans.  We spent over half of our specie&amp;#39;s existence on that continent, and given Perry&amp;#39;s DNA, apparently over two thirds of it was spent there.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;AI will develop the concept of race on its own. It doesn&amp;#39;t need a label. It&amp;#39;s an obvious stereotyping example that will arise with very minor intelligence.&lt;/p&gt;\n\n&lt;p&gt;I used simple examples that a simple AI would derive itself. Then laid out examples of how a more advanced AI would uncover nuance to those. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It will really only do so if trained on &lt;strong&gt;our&lt;/strong&gt; society.  Our media.  Etc.  The fact that it&amp;#39;s something humans &amp;#39;do&amp;#39; is pretty obvious, but that says nothing about underlying reality, or how valid societal assumptions are.  Some type of generalized AI would probably develop facts about phrenology if trained in the 1800s if given tons of data indicating the concept is important to society.  AI already recognizes &lt;a href=\"https://www.wired.com/2012/06/google-x-neural-network/\"&gt;cats&lt;/a&gt; especially well.  &lt;/p&gt;\n\n&lt;p&gt;But I don&amp;#39;t think Google finding out that a neural network becomes incredibly good at finding cats reflects anything really notable about society other than &amp;#39;we like cat videos online&amp;#39;.  Nor is a computer picking up on racial stereotypes any more interesting than &amp;#39;these stereotypes exist&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;My issue is with how &amp;#39;ok&amp;#39; we should be with that without questioning the underlying assumptions.  Are cats really super important?  Or is it society influencing AI views on cats?  Is &amp;#39;race&amp;#39; really a fundamental concept, or is it society influencing AI views on race?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You could make the same argument for my red and yellow color example. It was used for illustration. In the US black people are associated with higher rates of theft... trying to ignore this is an exercise in futility- a machine which doesn&amp;#39;t care will uncover the exact same attributes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I didn&amp;#39;t &amp;#39;ignore&amp;#39; it, I&amp;#39;m asking, what do you mean by a &amp;#39;black person&amp;#39;.  I&amp;#39;m asking this because I can accept the point of fact &amp;#39;people with darker skin commit more crime on average&amp;#39;, but that fact alone isn&amp;#39;t really all that more interesting to me than statistics on left handed people.  I&amp;#39;m interested in what this is really implying, especially given by your statements that &amp;quot;races are genetically different&amp;quot;.  &amp;quot;There is a genetic predisposition towards actions one can deduce from stereotypes and statistics&amp;quot;.  &lt;strong&gt;That&lt;/strong&gt; idea seems decidedly false.  So then what do we mean by &amp;#39;black people&amp;#39;?  If not a genetic thing, but rather, it really is just skin color, what &lt;strong&gt;are&lt;/strong&gt; underlying issues?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You can argue this is for different reasons other than race, but at the end of the day it doesn&amp;#39;t matter because this system is approximating the world based on limited information and will start off with basic approximations and work from there. Would race be the first one? I&amp;#39;m not sure, but probably one of the first since the difference in crime rates is very statistically significant and the ability to notice the difference is very obvious. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That, again, doesn&amp;#39;t do any more than tell us &amp;quot;these statistics are out there, and people already promote them, so AI is of course going to find it&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Again, cat videos.  The statistics aren&amp;#39;t false, and people make a huge deal out of it, so yes, computers are going to use those as part of the AI.  They don&amp;#39;t have a choice.  They&amp;#39;re computers.&lt;/p&gt;\n\n&lt;p&gt;The reason &lt;strong&gt;why&lt;/strong&gt; these statistics exist though, and what to do with them, isn&amp;#39;t generally &amp;quot;accept them as justification for why stereotypes are ok&amp;quot;.  That seems like creating a self-fulfilling prophecy.  Like cats.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;No. &lt;strong&gt;Race is though.&lt;/strong&gt; And skin color is a pretty good/simple race detector. In the case of the very simple AI which only looks at skin color to assume trustworthiness you&amp;#39;d be right - it&amp;#39;d be a shit predictor. But I&amp;#39;m trying to describe from a basic level to keep it easy to read. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Without race being a properly defined concept, this seems really, REALLY hard to argue.  So &amp;#39;basic level&amp;#39; or not, what is explicitly meant by the concept of &amp;#39;race&amp;#39; seems really central here.&lt;/p&gt;\n\n&lt;p&gt;So what&amp;#39;s meant?  What explicitly is a &amp;#39;race&amp;#39; defined as?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m happy to take a &amp;#39;cultural&amp;#39; definition, but so far as genetics, that&amp;#39;s really, &lt;strong&gt;really&lt;/strong&gt; hard to do thanks to the past decade of genetics research.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I used the features I did to make it easier for people to understand my overall point. Simple attributes like color and shape are quite easy to rationalize and were in the context of ai-race-discussion. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yes, and they&amp;#39;re also part of the problem of how society views race.  Which means they&amp;#39;d be part of the problem of how AI views race because AI is fundamentally trained &lt;strong&gt;on society&lt;/strong&gt;.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Yeah there may be something there. As far as eye color I doubt its very significant otherwise it would already exist as a stereotype in humans. There does seem to be faces which people generally pick up on as &amp;quot;sketchy&amp;quot;- not sure how accurate that is but maybe something to it. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Stereotypes rise and fall constantly, which again, is probably why I&amp;#39;m more in favor of some &amp;#39;cultural&amp;#39; explanation than anything &amp;#39;genetic&amp;#39;.&lt;/p&gt;\n\n&lt;p&gt;But skin color at the very least makes it very easy to bin and label people without even looking at their face.  If you want to delineate an &amp;#39;other&amp;#39;, pretty easy and quick way of doing so. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga039e", "score_hidden": false, "stickied": false, "created": 1492244567.0, "created_utc": 1492215767.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 17}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga565j", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "MangyWendigo", "parent_id": "t1_dga4xkp", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "the answer of course is you evaluate the individual. if you look for smart people, you get them, if you choose white people, you get smart people and dumb people\n\nwe just came off our most cerebral president ever, at least since woodrow wilson. a black guy\n\nintelligence is extremely variable. you hire individuals, and individual evaluation is the only coherent approach to maximize your success\n\nyou are arguing in service of an agenda. i am arguing in the service of getting the smartest people. tactically, my approach works, yours doesn't, in service of the goal of smartest and best\n\nit's also kind of ironic because anyone smart, and white, would reject your approach. while anyone dumb, and white, embraces your approach. that says a lot about what the real point of racism is\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;the answer of course is you evaluate the individual. if you look for smart people, you get them, if you choose white people, you get smart people and dumb people&lt;/p&gt;\n\n&lt;p&gt;we just came off our most cerebral president ever, at least since woodrow wilson. a black guy&lt;/p&gt;\n\n&lt;p&gt;intelligence is extremely variable. you hire individuals, and individual evaluation is the only coherent approach to maximize your success&lt;/p&gt;\n\n&lt;p&gt;you are arguing in service of an agenda. i am arguing in the service of getting the smartest people. tactically, my approach works, yours doesn&amp;#39;t, in service of the goal of smartest and best&lt;/p&gt;\n\n&lt;p&gt;it&amp;#39;s also kind of ironic because anyone smart, and white, would reject your approach. while anyone dumb, and white, embraces your approach. that says a lot about what the real point of racism is&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga565j", "score_hidden": false, "stickied": false, "created": 1492251567.0, "created_utc": 1492222767.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga4xkp", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dga4gbq", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If 23% of white people are smart, 20% of black people are smart, and you are 75% accurate in determining how smart someone is from talking to them, and you have a black and a white candidate who both seem smart should you choose?\n\nYou could swap [white, black, smart], for anything and the answer is obvious.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If 23% of white people are smart, 20% of black people are smart, and you are 75% accurate in determining how smart someone is from talking to them, and you have a black and a white candidate who both seem smart should you choose?&lt;/p&gt;\n\n&lt;p&gt;You could swap [white, black, smart], for anything and the answer is obvious.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga4xkp", "score_hidden": false, "stickied": false, "created": 1492251219.0, "created_utc": 1492222419.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 8}}], "after": null, "before": null}}, "user_reports": [], "id": "dga4gbq", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "MangyWendigo", "parent_id": "t1_dga3503", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "that's not true\n\nif you hire white people, you wind up with stupid white people and smart white people\n\nif you hire smart people, you wind up with black and white people\n\nhow many of each? who cares. why does that have any meaning? you want smart people to run a successful business. what use is it to even look at skin color?\n\nevaluation on *individual* characteristics are highly variable and linking that to arbitrary signifiers, like skin color, has no utility\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;that&amp;#39;s not true&lt;/p&gt;\n\n&lt;p&gt;if you hire white people, you wind up with stupid white people and smart white people&lt;/p&gt;\n\n&lt;p&gt;if you hire smart people, you wind up with black and white people&lt;/p&gt;\n\n&lt;p&gt;how many of each? who cares. why does that have any meaning? you want smart people to run a successful business. what use is it to even look at skin color?&lt;/p&gt;\n\n&lt;p&gt;evaluation on &lt;em&gt;individual&lt;/em&gt; characteristics are highly variable and linking that to arbitrary signifiers, like skin color, has no utility&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga4gbq", "score_hidden": false, "stickied": false, "created": 1492250517.0, "created_utc": 1492221717.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga550k", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "Sysfin", "parent_id": "t1_dga4t6q", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "You seem to want to change the meaning to the work \"stereotype\" .  Everyone knows it means \n\" a widely held but fixed and oversimplified image or idea of a particular type of person or thing.\"\n\n\n&gt;there is a trait which you can stereotype and it fits a group... it will necessarily increase your prediction capabilities\n\nThat is the point though, a stereotype that is wrong will actually make your prediction worse, and people didn't come to these stereotypes based on thought and study but ignorance.\n\n&gt; I suppose you can find a dataset that is designed to specifically disprove whatever correlation but that's pointless.\n\nWhy?  If it the correlation is wrong then that is the point.   To show that there stereotyping doesn't work and they need to get rid of there stereotypes, in particular people are quick to stereotype on race, political, or religious group, (that team is stupid and barely human) even though the evidence ", "edited": 1492223115.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You seem to want to change the meaning to the work &amp;quot;stereotype&amp;quot; .  Everyone knows it means \n&amp;quot; a widely held but fixed and oversimplified image or idea of a particular type of person or thing.&amp;quot;&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;there is a trait which you can stereotype and it fits a group... it will necessarily increase your prediction capabilities&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That is the point though, a stereotype that is wrong will actually make your prediction worse, and people didn&amp;#39;t come to these stereotypes based on thought and study but ignorance.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I suppose you can find a dataset that is designed to specifically disprove whatever correlation but that&amp;#39;s pointless.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why?  If it the correlation is wrong then that is the point.   To show that there stereotyping doesn&amp;#39;t work and they need to get rid of there stereotypes, in particular people are quick to stereotype on race, political, or religious group, (that team is stupid and barely human) even though the evidence &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga550k", "score_hidden": false, "stickied": false, "created": 1492251522.0, "created_utc": 1492222722.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dga4t6q", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dga4j29", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Your definition of stereotype is different than mine. If there is a trait which you can stereotype and it fits a group... it will necessarily increase your prediction capabilities. I suppose you can find a dataset that is designed to specifically disprove whatever correlation but that's pointless. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Your definition of stereotype is different than mine. If there is a trait which you can stereotype and it fits a group... it will necessarily increase your prediction capabilities. I suppose you can find a dataset that is designed to specifically disprove whatever correlation but that&amp;#39;s pointless. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga4t6q", "score_hidden": false, "stickied": false, "created": 1492251040.0, "created_utc": 1492222240.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dga4j29", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Sysfin", "parent_id": "t1_dga3503", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;  Regardless, you can stereotype on race (or anything else) and have better accuracy than disregarding it completely which was my point.\n\nYou can also stereotype on race (or anything else) and have a worse accuracy.   When people do stereotypes then didn't come to that conclusion based on 10 years of peer reviewed studies, they just decided they didn't trust something based on instinct.  For example, if you hate the smell of arab food you probably will by default distrust people from Saudi Arabia.  If you love the smell of asian food then you will probably by default be more comfortable in chinatown.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Regardless, you can stereotype on race (or anything else) and have better accuracy than disregarding it completely which was my point.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You can also stereotype on race (or anything else) and have a worse accuracy.   When people do stereotypes then didn&amp;#39;t come to that conclusion based on 10 years of peer reviewed studies, they just decided they didn&amp;#39;t trust something based on instinct.  For example, if you hate the smell of arab food you probably will by default distrust people from Saudi Arabia.  If you love the smell of asian food then you will probably by default be more comfortable in chinatown.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga4j29", "score_hidden": false, "stickied": false, "created": 1492250627.0, "created_utc": 1492221827.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga3503", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dga312z", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That may be the case. Regardless, you can stereotype on race (or anything else) and have better accuracy than disregarding it completely which was my point. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That may be the case. Regardless, you can stereotype on race (or anything else) and have better accuracy than disregarding it completely which was my point. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga3503", "score_hidden": false, "stickied": false, "created": 1492248708.0, "created_utc": 1492219908.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgac1q9", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "yiliu", "parent_id": "t1_dgabqbj", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; selected\n\nYeah, that's the key word there.\n\nLook, I'm not making this shit up. We can directly compare genomes. [There's very little difference](https://en.wikipedia.org/wiki/Race_and_genetics). You better not go and read that if your sense of self worth is related to the color of your skin, though.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;selected&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah, that&amp;#39;s the key word there.&lt;/p&gt;\n\n&lt;p&gt;Look, I&amp;#39;m not making this shit up. We can directly compare genomes. &lt;a href=\"https://en.wikipedia.org/wiki/Race_and_genetics\"&gt;There&amp;#39;s very little difference&lt;/a&gt;. You better not go and read that if your sense of self worth is related to the color of your skin, though.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgac1q9", "score_hidden": false, "stickied": false, "created": 1492262785.0, "created_utc": 1492233985.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgabqbj", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dgab912", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; And a couple of tens of thousands of years is a vanishingly small amount of time from an evolutionary point of view.\n\nSo humans selected so many breeds of dogs in just a few hundreds years how? Magic? That couldn't be genetic selection no, that would have required millions of years at the very least. Right?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;And a couple of tens of thousands of years is a vanishingly small amount of time from an evolutionary point of view.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So humans selected so many breeds of dogs in just a few hundreds years how? Magic? That couldn&amp;#39;t be genetic selection no, that would have required millions of years at the very least. Right?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgabqbj", "score_hidden": false, "stickied": false, "created": 1492262162.0, "created_utc": 1492233362.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 0}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgb5q1o", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "yiliu", "parent_id": "t1_dgb18i2", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There are areas of gene expression that are relatively geographically centralized. Geneticists hesitate to call them 'races' because they blur and blend into one another, and _within_ those pockets there's _far more_ genetic diversity than _between_ them. Migration and gene drift further complicate things. Some dude in northern England might be more closely related to the last Ming emperor than a random Chinese farmer. It's not like species where you can draw relatively neat lines between different groups and say \"this is clearly one group and this is another\". Most people in the southern US have a significant amount of sub-Saharan African genes, but many look completely white. What race are they? Genes flow back and forth through Eurasia. What 'race' do they belong to?\n\nThere are _visible_ differences, and we fixate on those. They tend to be fairly clustered. Culturally, we fixate on those and call them 'races', but they don't correspond to deep differences. Two people who look completely different--that English dude and Chinese farmer--might be more similar in non-visible ways than two guys in nearby villages in Africa. But we fixate on the visible aspects and completely ignore the other similarities and differences.\n\nWant evidence that race is primarily a cultural construct? You picked east asians being short. My son will be half east-asian, and is on target to be well over six feet tall. Most people will no longer categorize him as east asian _because he is tall_, not because he's not _significantly_ east-asian. Barack Obama had a white mother who raised him along with his white grandparants in Hawaii, and yet he was considered the first Black president by _everybody_. Apparently white + white = white, black + black = black, but black + white = black? There's no _genetic_ basis for that. It's a cultural concept.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There are areas of gene expression that are relatively geographically centralized. Geneticists hesitate to call them &amp;#39;races&amp;#39; because they blur and blend into one another, and &lt;em&gt;within&lt;/em&gt; those pockets there&amp;#39;s &lt;em&gt;far more&lt;/em&gt; genetic diversity than &lt;em&gt;between&lt;/em&gt; them. Migration and gene drift further complicate things. Some dude in northern England might be more closely related to the last Ming emperor than a random Chinese farmer. It&amp;#39;s not like species where you can draw relatively neat lines between different groups and say &amp;quot;this is clearly one group and this is another&amp;quot;. Most people in the southern US have a significant amount of sub-Saharan African genes, but many look completely white. What race are they? Genes flow back and forth through Eurasia. What &amp;#39;race&amp;#39; do they belong to?&lt;/p&gt;\n\n&lt;p&gt;There are &lt;em&gt;visible&lt;/em&gt; differences, and we fixate on those. They tend to be fairly clustered. Culturally, we fixate on those and call them &amp;#39;races&amp;#39;, but they don&amp;#39;t correspond to deep differences. Two people who look completely different--that English dude and Chinese farmer--might be more similar in non-visible ways than two guys in nearby villages in Africa. But we fixate on the visible aspects and completely ignore the other similarities and differences.&lt;/p&gt;\n\n&lt;p&gt;Want evidence that race is primarily a cultural construct? You picked east asians being short. My son will be half east-asian, and is on target to be well over six feet tall. Most people will no longer categorize him as east asian &lt;em&gt;because he is tall&lt;/em&gt;, not because he&amp;#39;s not &lt;em&gt;significantly&lt;/em&gt; east-asian. Barack Obama had a white mother who raised him along with his white grandparants in Hawaii, and yet he was considered the first Black president by &lt;em&gt;everybody&lt;/em&gt;. Apparently white + white = white, black + black = black, but black + white = black? There&amp;#39;s no &lt;em&gt;genetic&lt;/em&gt; basis for that. It&amp;#39;s a cultural concept.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb5q1o", "score_hidden": false, "stickied": false, "created": 1492318319.0, "created_utc": 1492289519.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb18i2", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgab912", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; There's far more variation between individuals in a population than between different 'races'\n\nThis is a fallacy that actually admits races exist and are relevant.\n\nYou actually say there is variation between races, you just think it is insignificant. But you admit it exists. Therefore, you admitted race exists.\n\nThe fact that there is more variation within races than outside of them is totally irrelevant. You admitted race exists, so you lost the argument right there.\n\n&gt; It's just that the variations between races tend to be cosmetic, and thus are amenable to stereotyping.\n\nCosmetic differences are part of stereotypes. So, are you saying physiological stereotypes are valid, but psychological ones aren't? That seems to be your admission.\n\nSo, east asians being short is a valid stereotype, because it's a \"cosmetic\" difference, but east asians having high IQ is an invalid stereotype, because it's not cosmetic? Even though we can give IQ tests, and they do have high IQs?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;There&amp;#39;s far more variation between individuals in a population than between different &amp;#39;races&amp;#39;&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is a fallacy that actually admits races exist and are relevant.&lt;/p&gt;\n\n&lt;p&gt;You actually say there is variation between races, you just think it is insignificant. But you admit it exists. Therefore, you admitted race exists.&lt;/p&gt;\n\n&lt;p&gt;The fact that there is more variation within races than outside of them is totally irrelevant. You admitted race exists, so you lost the argument right there.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;It&amp;#39;s just that the variations between races tend to be cosmetic, and thus are amenable to stereotyping.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Cosmetic differences are part of stereotypes. So, are you saying physiological stereotypes are valid, but psychological ones aren&amp;#39;t? That seems to be your admission.&lt;/p&gt;\n\n&lt;p&gt;So, east asians being short is a valid stereotype, because it&amp;#39;s a &amp;quot;cosmetic&amp;quot; difference, but east asians having high IQ is an invalid stereotype, because it&amp;#39;s not cosmetic? Even though we can give IQ tests, and they do have high IQs?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb18i2", "score_hidden": false, "stickied": false, "created": 1492312248.0, "created_utc": 1492283448.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dgab912", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "yiliu", "parent_id": "t1_dga6khg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Uhh...no. Evolution is totally a thing. And a couple of tens of thousands of years is a vanishingly small amount of time from an evolutionary point of view.\n\nThere's far more variation between individuals in a population than between different 'races'. It's just that the variations between races tend to be cosmetic, and thus are amenable to stereotyping. As I said, two random towns in sub-Saharan Africa will have more genetic diversity than all non-African people in the world.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Uhh...no. Evolution is totally a thing. And a couple of tens of thousands of years is a vanishingly small amount of time from an evolutionary point of view.&lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s far more variation between individuals in a population than between different &amp;#39;races&amp;#39;. It&amp;#39;s just that the variations between races tend to be cosmetic, and thus are amenable to stereotyping. As I said, two random towns in sub-Saharan Africa will have more genetic diversity than all non-African people in the world.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgab912", "score_hidden": false, "stickied": false, "created": 1492261266.0, "created_utc": 1492232466.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgab49k", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dgaaizt", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I never met anybody who said that humans are as diverse as dog breeds though...\n\nWe evolved differently enough that we can recognize with a high enough probability ethnic groups (= races) at first glance. Somehow it is acceptable to say that Kenyans from the rift valley have been selected by their environment to be the best long runners in the world, or that Northern Europeans have stronger frames allowing them to excel in power lifting, but is unacceptable to remind that the QI average varies too, along with every other human traits.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I never met anybody who said that humans are as diverse as dog breeds though...&lt;/p&gt;\n\n&lt;p&gt;We evolved differently enough that we can recognize with a high enough probability ethnic groups (= races) at first glance. Somehow it is acceptable to say that Kenyans from the rift valley have been selected by their environment to be the best long runners in the world, or that Northern Europeans have stronger frames allowing them to excel in power lifting, but is unacceptable to remind that the QI average varies too, along with every other human traits.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgab49k", "score_hidden": false, "stickied": false, "created": 1492261025.0, "created_utc": 1492232225.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgb84ji", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "RoundDuckMan", "parent_id": "t1_dgb1cid", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Still not as different like dog breeds. Dog breeds look almost like separate species. Almost completely different body structures. Those on the other hand are mostly different face and skin color-wise.\n\n\nAlso your history is uhh... *interesting*, to put it right...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Still not as different like dog breeds. Dog breeds look almost like separate species. Almost completely different body structures. Those on the other hand are mostly different face and skin color-wise.&lt;/p&gt;\n\n&lt;p&gt;Also your history is uhh... &lt;em&gt;interesting&lt;/em&gt;, to put it right...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb84ji", "score_hidden": false, "stickied": false, "created": 1492321651.0, "created_utc": 1492292851.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb1cid", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgaaizt", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Google a picture of an Australian aboriginal and compare it to a person from the Netherlands.\n\n\"Wildly different\" is an understatement.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Google a picture of an Australian aboriginal and compare it to a person from the Netherlands.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Wildly different&amp;quot; is an understatement.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb1cid", "score_hidden": false, "stickied": false, "created": 1492312394.0, "created_utc": 1492283594.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaaizt", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "RoundDuckMan", "parent_id": "t1_dga6khg", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Maybe not, but maybe we aren't the kind that evolved that differently. I mean, there's differences, but not much. They're certainly not as wildly different like dog breeds.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe not, but maybe we aren&amp;#39;t the kind that evolved that differently. I mean, there&amp;#39;s differences, but not much. They&amp;#39;re certainly not as wildly different like dog breeds.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaaizt", "score_hidden": false, "stickied": false, "created": 1492259983.0, "created_utc": 1492231183.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6khg", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dga312z", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "And evolution is a myth right? Evolving in completely different environments for ages and we are still all the same, right?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And evolution is a myth right? Evolving in completely different environments for ages and we are still all the same, right?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga6khg", "score_hidden": false, "stickied": false, "created": 1492253576.0, "created_utc": 1492224776.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga312z", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "yiliu", "parent_id": "t1_dg9xx5w", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; No it's not. Races are genetically different.\n\nRaces are only a _tiny_ bit genetically different. There's way more genetic diversity in single countries in Africa than in all countries outside of Africa. That's not the reason for the correlations with crime, poverty, etc. That was because _we_ categorized by race and then (in America) enslaved and oppressed some of the races. The correlation is on us, it's not down to genetics.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;No it&amp;#39;s not. Races are genetically different.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Races are only a &lt;em&gt;tiny&lt;/em&gt; bit genetically different. There&amp;#39;s way more genetic diversity in single countries in Africa than in all countries outside of Africa. That&amp;#39;s not the reason for the correlations with crime, poverty, etc. That was because &lt;em&gt;we&lt;/em&gt; categorized by race and then (in America) enslaved and oppressed some of the races. The correlation is on us, it&amp;#39;s not down to genetics.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga312z", "score_hidden": false, "stickied": false, "created": 1492248556.0, "created_utc": 1492219756.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 11}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga6g1a", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dg9xx5w", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "+1. Your argumentation is not poop at all ;)\n\nI always try to explain to people that stereotypes are good and healthy as our minds cannot work and understand the world without them. Lots of people have this stupid idea that stereotypes are bad! They are only as bad as you make them out to be.\n\nKeep up the good work.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;+1. Your argumentation is not poop at all ;)&lt;/p&gt;\n\n&lt;p&gt;I always try to explain to people that stereotypes are good and healthy as our minds cannot work and understand the world without them. Lots of people have this stupid idea that stereotypes are bad! They are only as bad as you make them out to be.&lt;/p&gt;\n\n&lt;p&gt;Keep up the good work.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga6g1a", "score_hidden": false, "stickied": false, "created": 1492253393.0, "created_utc": 1492224593.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgag43g", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "ManifestedLurker", "parent_id": "t1_dgaeks6", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Now it is true that human beings have some markers that are indicative o human beings. None of them is \"race-specific\" because there are no fucking races there. The biologically simplest definition for a \"race\" is when you can have (viable) offspring - and this is the case for mankind.\n\nAre just going to argue semantics? Just because it's PC to define human races away and pretend that everyone is the same so a 2nd Hitler cannot arrise from forbidden knowledge, doesn't mean you can find statistical difference between groups that share physical differences or share a \"soup\" of \"human\" genes in a special proportion.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Now it is true that human beings have some markers that are indicative o human beings. None of them is &amp;quot;race-specific&amp;quot; because there are no fucking races there. The biologically simplest definition for a &amp;quot;race&amp;quot; is when you can have (viable) offspring - and this is the case for mankind.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Are just going to argue semantics? Just because it&amp;#39;s PC to define human races away and pretend that everyone is the same so a 2nd Hitler cannot arrise from forbidden knowledge, doesn&amp;#39;t mean you can find statistical difference between groups that share physical differences or share a &amp;quot;soup&amp;quot; of &amp;quot;human&amp;quot; genes in a special proportion.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgag43g", "score_hidden": false, "stickied": false, "created": 1492272611.0, "created_utc": 1492243811.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgcj8ej", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Lepidostrix", "parent_id": "t1_dgbzxzj", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Well a consensus among the informed would be nice. But most geneticists do not subscribe to this reductive model of race.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well a consensus among the informed would be nice. But most geneticists do not subscribe to this reductive model of race.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcj8ej", "score_hidden": false, "stickied": false, "created": 1492403611.0, "created_utc": 1492374811.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbzxzj", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "kodadd", "parent_id": "t1_dgaeks6", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;That is not a valid definition of a \"race\".\n\nWhat makes a valid definition of anything?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;That is not a valid definition of a &amp;quot;race&amp;quot;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What makes a valid definition of anything?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbzxzj", "score_hidden": false, "stickied": false, "created": 1492376234.0, "created_utc": 1492347434.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgcokjh", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "deltaSquee", "parent_id": "t1_dgaeks6", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Just so you know, I'm on your side, so this is a purely academic question:\n\nWould haplogroups be the closest thing to \"race\" in biology?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just so you know, I&amp;#39;m on your side, so this is a purely academic question:&lt;/p&gt;\n\n&lt;p&gt;Would haplogroups be the closest thing to &amp;quot;race&amp;quot; in biology?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcokjh", "score_hidden": false, "stickied": false, "created": 1492410631.0, "created_utc": 1492381831.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaeks6", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "shevegen", "parent_id": "t1_dg9xx5w", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "&gt; No it's not. Races are genetically different. You are able to run a DNA test and determine the\n&gt; race of someone incredibly accurately. Any person can point out which people are of which\n&gt; races the majority of the time. Race is not a social construct, it's a designation based\n&gt; on genetic &amp; physical characteristics.\n\nNo, that is flat out rubbish.\n\nYou are clearly not a biologist or geneticist.\n\nhttps://en.wikipedia.org/wiki/Race_(biology)\nhttps://en.wikipedia.org/wiki/Race_(human_categorization)\n\nNow to your claims:\n\n&gt; Races are genetically different.\n\nJust about every individual being is genetically different from one another simply\ndue to point mutations alone. To state that \"races are genetically different\" is\na statement that has no bearing whatsoever on its own.\n\n&gt; You are able to run a DNA test and determine the race of someone incredibly\n&gt; accurately.\n\nWhat the fuck is a \"DNA test\"? I assume you mean either RFLP restriction\ndigests or PCR testing.\n\nI hate to break it to you but if you know the genome sequence or the sequence\nfor where you design your PCR primers, you can run a PCR test on EVERYTHING\nthat has a DNA genome (and via cDNA you can do the same for RNA genomes\nbut the latter can be found only in some viruses).\n\nYou can \"determine\" whatever you want to through PCR - the thing is that a PCR\nwill only amplify \"what is already there\" (if we exclude other errors that may\nhappen during a PCR run or preparation).\n\nSo typically, you will group together a \"common hierarchy\" of markers. For \nbacteria, it is usually done to amplify ribosomal subunits (or rather the genes\ncoding for it, in particular 16S rRNA).\n\nNow it is true that human beings have some markers that are indicative o\nhuman beings. None of them is \"race-specific\" because there are no fucking\nraces there. The biologically simplest definition for a \"race\" is when you can\nhave (viable) offspring - and this is the case for mankind.\n\nYou want to group it by colour? That is rubbish. \"Colour\" is a minor difference\nin regards to melanin and tyrosine. Sure you may find differences in the \nactivity and amount of enzymes expressed - that is not a definition of a \n\"race\" at all whatsoever.\n\nEven then, the grouping by mankind into the \"tree of life\" is opinionated.\n\nYou don't find viruses in the \"tree of life\" even though they are very important\nfor evolution and gene shuffling. You also can not easily define species in\nbacteria considering the vast exchange of DNA. DNA knows no boundaries\nhere - the reason why \"higher\" living systems aren't as easily changed by\nforeign DNA is because they have had to develop means to counter \n\"selfish\" DNA (bacteria also defend against foreign DNA of course, see \nCRISPR-Cas, which is just stealing from bacteria and slapping a patent\non it to monetize it. Bacteria invented it.).\n\n&gt; Any person can point out which people are of which races the majority of\n&gt; the time\n\nThat is not a valid definition of a \"race\".\n\nAre you going the pseudo-scientist route?\n\n&gt; Race is not a social construct, it's a designation based on genetic\n&gt; &amp; physical characteristics.\n\nAgain, that is totally rubbish and flat out wrong. You evidently do not know\nanything about biology or how races are defined. Even wikipedia above\nwould have educated you about this.\n\nSimply read what zaoldyeck wrote.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;No it&amp;#39;s not. Races are genetically different. You are able to run a DNA test and determine the\nrace of someone incredibly accurately. Any person can point out which people are of which\nraces the majority of the time. Race is not a social construct, it&amp;#39;s a designation based\non genetic &amp;amp; physical characteristics.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No, that is flat out rubbish.&lt;/p&gt;\n\n&lt;p&gt;You are clearly not a biologist or geneticist.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://en.wikipedia.org/wiki/Race_(biology)\"&gt;https://en.wikipedia.org/wiki/Race_(biology)&lt;/a&gt;\n&lt;a href=\"https://en.wikipedia.org/wiki/Race_(human_categorization)\"&gt;https://en.wikipedia.org/wiki/Race_(human_categorization)&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;Now to your claims:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Races are genetically different.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Just about every individual being is genetically different from one another simply\ndue to point mutations alone. To state that &amp;quot;races are genetically different&amp;quot; is\na statement that has no bearing whatsoever on its own.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;You are able to run a DNA test and determine the race of someone incredibly\naccurately.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;What the fuck is a &amp;quot;DNA test&amp;quot;? I assume you mean either RFLP restriction\ndigests or PCR testing.&lt;/p&gt;\n\n&lt;p&gt;I hate to break it to you but if you know the genome sequence or the sequence\nfor where you design your PCR primers, you can run a PCR test on EVERYTHING\nthat has a DNA genome (and via cDNA you can do the same for RNA genomes\nbut the latter can be found only in some viruses).&lt;/p&gt;\n\n&lt;p&gt;You can &amp;quot;determine&amp;quot; whatever you want to through PCR - the thing is that a PCR\nwill only amplify &amp;quot;what is already there&amp;quot; (if we exclude other errors that may\nhappen during a PCR run or preparation).&lt;/p&gt;\n\n&lt;p&gt;So typically, you will group together a &amp;quot;common hierarchy&amp;quot; of markers. For \nbacteria, it is usually done to amplify ribosomal subunits (or rather the genes\ncoding for it, in particular 16S rRNA).&lt;/p&gt;\n\n&lt;p&gt;Now it is true that human beings have some markers that are indicative o\nhuman beings. None of them is &amp;quot;race-specific&amp;quot; because there are no fucking\nraces there. The biologically simplest definition for a &amp;quot;race&amp;quot; is when you can\nhave (viable) offspring - and this is the case for mankind.&lt;/p&gt;\n\n&lt;p&gt;You want to group it by colour? That is rubbish. &amp;quot;Colour&amp;quot; is a minor difference\nin regards to melanin and tyrosine. Sure you may find differences in the \nactivity and amount of enzymes expressed - that is not a definition of a \n&amp;quot;race&amp;quot; at all whatsoever.&lt;/p&gt;\n\n&lt;p&gt;Even then, the grouping by mankind into the &amp;quot;tree of life&amp;quot; is opinionated.&lt;/p&gt;\n\n&lt;p&gt;You don&amp;#39;t find viruses in the &amp;quot;tree of life&amp;quot; even though they are very important\nfor evolution and gene shuffling. You also can not easily define species in\nbacteria considering the vast exchange of DNA. DNA knows no boundaries\nhere - the reason why &amp;quot;higher&amp;quot; living systems aren&amp;#39;t as easily changed by\nforeign DNA is because they have had to develop means to counter \n&amp;quot;selfish&amp;quot; DNA (bacteria also defend against foreign DNA of course, see \nCRISPR-Cas, which is just stealing from bacteria and slapping a patent\non it to monetize it. Bacteria invented it.).&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Any person can point out which people are of which races the majority of\nthe time&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That is not a valid definition of a &amp;quot;race&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Are you going the pseudo-scientist route?&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Race is not a social construct, it&amp;#39;s a designation based on genetic\n&amp;amp; physical characteristics.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Again, that is totally rubbish and flat out wrong. You evidently do not know\nanything about biology or how races are defined. Even wikipedia above\nwould have educated you about this.&lt;/p&gt;\n\n&lt;p&gt;Simply read what zaoldyeck wrote.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaeks6", "score_hidden": false, "stickied": false, "created": 1492268478.0, "created_utc": 1492239678.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9xx5w", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dg9wmff", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;I mean... kinda including 'race' as a concept at all will act as a selection bias. And that's not including what goes on with potential p hacking of 'racial' data.\n\nAI will develop the concept of race on its own. It doesn't need a label. It's an obvious stereotyping example that will arise with very minor intelligence. \n\nI used simple examples that a simple AI would derive itself. Then laid out examples of how a more advanced AI would uncover nuance to those. \n\n&gt;Consider. \"Black people commit more crime on average\".\nOk? But what's meant by \"black person\"? Someone with dark skin?\n\nYou could make the same argument for my red and yellow color example. It was used for illustration. In the US black people are associated with higher rates of theft... trying to ignore this is an exercise in futility- a machine which doesn't care will uncover the exact same attributes. You can argue this is for different reasons other than race, but at the end of the day it doesn't matter because this system is approximating the world based on limited information and will start off with basic approximations and work from there. Would race be the first one? I'm not sure, but probably one of the first since the difference in crime rates is very statistically significant and the ability to notice the difference is very obvious. \n\n&gt;Is skin color somehow directly related to violence? That seems rather unlikely, since melanin doesn't do much beyond absorb more wavelengths of light.\n\nNo. Race is though. And skin color is a pretty good/simple race detector. In the case of the very simple AI which only looks at skin color to assume trustworthiness you'd be right - it'd be a shit predictor. But I'm trying to describe from a basic level to keep it easy to read. \n\n&gt;If you want to ignore that though and use what are already socially constructed artificial labels as your basis of algorithmic thinking, your algorithms are going to reflect those same socially created constructs.\n\nThis isn't how really any sort of AI is developed. Any general AI that relies on labels is certain to be limited. I'm talking about unsupervised learning [of stereotypes]. \n\n&gt;At the heart of the matter is the fact that race is a kinda arbitrary concept in our culture\n\nNo it's not. Races are genetically different. You are able to run a DNA test and determine the race of someone incredibly accurately. Any person can point out which people are of which races the majority of the time. Race is not a social construct, it's a designation based on genetic &amp; physical characteristics.\n\n\n---\n\n&gt;What if you decided to look at other features? Did you know left handed people are supposedly more prone to psych disorders?\n\nI used the features I did to make it easier for people to understand my overall point. Simple attributes like color and shape are quite easy to rationalize and were in the context of ai-race-discussion. \n\n\n&gt;I wonder what interesting correlations we'd pick up with eye color as a bin, or facial features, etc.\n\nYeah there may be something there. As far as eye color I doubt its very significant otherwise it would already exist as a stereotype in humans. There does seem to be faces which people generally pick up on as \"sketchy\"- not sure how accurate that is but maybe something to it. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I mean... kinda including &amp;#39;race&amp;#39; as a concept at all will act as a selection bias. And that&amp;#39;s not including what goes on with potential p hacking of &amp;#39;racial&amp;#39; data.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;AI will develop the concept of race on its own. It doesn&amp;#39;t need a label. It&amp;#39;s an obvious stereotyping example that will arise with very minor intelligence. &lt;/p&gt;\n\n&lt;p&gt;I used simple examples that a simple AI would derive itself. Then laid out examples of how a more advanced AI would uncover nuance to those. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Consider. &amp;quot;Black people commit more crime on average&amp;quot;.\nOk? But what&amp;#39;s meant by &amp;quot;black person&amp;quot;? Someone with dark skin?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You could make the same argument for my red and yellow color example. It was used for illustration. In the US black people are associated with higher rates of theft... trying to ignore this is an exercise in futility- a machine which doesn&amp;#39;t care will uncover the exact same attributes. You can argue this is for different reasons other than race, but at the end of the day it doesn&amp;#39;t matter because this system is approximating the world based on limited information and will start off with basic approximations and work from there. Would race be the first one? I&amp;#39;m not sure, but probably one of the first since the difference in crime rates is very statistically significant and the ability to notice the difference is very obvious. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Is skin color somehow directly related to violence? That seems rather unlikely, since melanin doesn&amp;#39;t do much beyond absorb more wavelengths of light.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No. Race is though. And skin color is a pretty good/simple race detector. In the case of the very simple AI which only looks at skin color to assume trustworthiness you&amp;#39;d be right - it&amp;#39;d be a shit predictor. But I&amp;#39;m trying to describe from a basic level to keep it easy to read. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If you want to ignore that though and use what are already socially constructed artificial labels as your basis of algorithmic thinking, your algorithms are going to reflect those same socially created constructs.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This isn&amp;#39;t how really any sort of AI is developed. Any general AI that relies on labels is certain to be limited. I&amp;#39;m talking about unsupervised learning [of stereotypes]. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;At the heart of the matter is the fact that race is a kinda arbitrary concept in our culture&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No it&amp;#39;s not. Races are genetically different. You are able to run a DNA test and determine the race of someone incredibly accurately. Any person can point out which people are of which races the majority of the time. Race is not a social construct, it&amp;#39;s a designation based on genetic &amp;amp; physical characteristics.&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;What if you decided to look at other features? Did you know left handed people are supposedly more prone to psych disorders?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I used the features I did to make it easier for people to understand my overall point. Simple attributes like color and shape are quite easy to rationalize and were in the context of ai-race-discussion. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I wonder what interesting correlations we&amp;#39;d pick up with eye color as a bin, or facial features, etc.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah there may be something there. As far as eye color I doubt its very significant otherwise it would already exist as a stereotype in humans. There does seem to be faces which people generally pick up on as &amp;quot;sketchy&amp;quot;- not sure how accurate that is but maybe something to it. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9xx5w", "score_hidden": false, "stickied": false, "created": 1492241689.0, "created_utc": 1492212889.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbtpgc", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "I_AM_ALWAYS_ANGRY", "parent_id": "t1_dgbstlh", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Yeah I agree, and I think you nailed it with your very last statement.\n\n&gt; What we mean by the word 'race' really isn't as easy as people believe.\n\nThis is the biggest problem of them all.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah I agree, and I think you nailed it with your very last statement.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;What we mean by the word &amp;#39;race&amp;#39; really isn&amp;#39;t as easy as people believe.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is the biggest problem of them all.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbtpgc", "score_hidden": false, "stickied": false, "created": 1492357199.0, "created_utc": 1492328399.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbstlh", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dgapv0b", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Melanin is not the only difference in a black person so your thinking is flawed. Black people are more prone to heart diseases, they have higher levels of testosterone, blacks are three times more likely to die of asthma than white Americans, Despite lower tobacco exposure, black men are 50% more likely than white men to get lung cancer, Diabetes is 60% more common in black Americans than in white Americans. Blacks are up to 2.5 times more likely to suffer a limb amputation and up to 5.6 times more likely to suffer kidney disease than other people with diabetes.\n\n... Umm, aside from limb amputation, which I don't even know where to find those statistics... I don't think I've ever come across statistics on limb amputation on any topic in general, so that's a new one for me... but aside from that, what do those statistics mean?\n\nFor example, \"heart disease\" or \"testosterone levels\".  For example, [R145C](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3943837/).\n\nYou find this gene mutation in 17% of sub-Saharan African populations derived subgroups in Qatar.  You also find 5% of African Americans in New York share this trait.  \n\nThe rest of African Americans don't.  You can play this with gene, after gene, after gene, and you'll get different 'populations' to occur.\n\nLets look at a different mutation associated with heart disease, [9P21](http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1000899).  Markers here appear shared with everyone from Caucasians to [North Indians](https://www.ncbi.nlm.nih.gov/pubmed/20718794) but interestingly enough, African Americans also have a higher percentage of people who carry a gene that [suppresses the effect of 9P21](https://www.ncbi.nlm.nih.gov/pubmed/21270820).\n\nThe process of doing this analysis is literally PCR, it's taking identifying markers we already care about (such as: this gene appears to regulate a function where a single nucleotide change appears to carry significant results) and amplify it by just copying it over and over again.\n\nWhen we do this and do tests on people, we find a wide range of diversity.  People share genes in very very diverse ways.  When talking about something like heart disease, it's literally useless to say \"well, this person is black, therefore, higher risk\" if they're from a population where no, they're not from a higher risk... equivalently, it'd be stupid for a Caucasian person, or Asian, or Arab, etc, to make the same kind of comment about not worrying about their own risk factors.  People can get quite surprised about what genes manage to make it into their bodies.\n\n&gt;Now the question is if they are prone to all these physical traits, can it be possible, objectively speaking, that the way black people think or behave in general is also different? Why would it be bad to point it out?\n\nBecause those types of things are generally driven by **very** complex interactions of genetics, and very seldom can be boiled down to \"mutation causing change in amount of this protein created, therefore, causing this effect which leads to heart disease\".\n\nAnd even with heart disease you have subgroups and subpopulations who have specific markers but there are still so many different potential sites and mutations that we can track which makes it pretty much impossible to say \"this is a single race with this one mutation\".  Cause that never happens, anywhere.  'Races' aren't genetic monocultures, as has been pointed out, there's generally more genetic diversity *within* ethnic groups than between.\n\nWhat we mean by the word 'race' really isn't as easy as people believe. \n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Melanin is not the only difference in a black person so your thinking is flawed. Black people are more prone to heart diseases, they have higher levels of testosterone, blacks are three times more likely to die of asthma than white Americans, Despite lower tobacco exposure, black men are 50% more likely than white men to get lung cancer, Diabetes is 60% more common in black Americans than in white Americans. Blacks are up to 2.5 times more likely to suffer a limb amputation and up to 5.6 times more likely to suffer kidney disease than other people with diabetes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;... Umm, aside from limb amputation, which I don&amp;#39;t even know where to find those statistics... I don&amp;#39;t think I&amp;#39;ve ever come across statistics on limb amputation on any topic in general, so that&amp;#39;s a new one for me... but aside from that, what do those statistics mean?&lt;/p&gt;\n\n&lt;p&gt;For example, &amp;quot;heart disease&amp;quot; or &amp;quot;testosterone levels&amp;quot;.  For example, &lt;a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3943837/\"&gt;R145C&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;You find this gene mutation in 17% of sub-Saharan African populations derived subgroups in Qatar.  You also find 5% of African Americans in New York share this trait.  &lt;/p&gt;\n\n&lt;p&gt;The rest of African Americans don&amp;#39;t.  You can play this with gene, after gene, after gene, and you&amp;#39;ll get different &amp;#39;populations&amp;#39; to occur.&lt;/p&gt;\n\n&lt;p&gt;Lets look at a different mutation associated with heart disease, &lt;a href=\"http://journals.plos.org/plosgenetics/article?id=10.1371/journal.pgen.1000899\"&gt;9P21&lt;/a&gt;.  Markers here appear shared with everyone from Caucasians to &lt;a href=\"https://www.ncbi.nlm.nih.gov/pubmed/20718794\"&gt;North Indians&lt;/a&gt; but interestingly enough, African Americans also have a higher percentage of people who carry a gene that &lt;a href=\"https://www.ncbi.nlm.nih.gov/pubmed/21270820\"&gt;suppresses the effect of 9P21&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;The process of doing this analysis is literally PCR, it&amp;#39;s taking identifying markers we already care about (such as: this gene appears to regulate a function where a single nucleotide change appears to carry significant results) and amplify it by just copying it over and over again.&lt;/p&gt;\n\n&lt;p&gt;When we do this and do tests on people, we find a wide range of diversity.  People share genes in very very diverse ways.  When talking about something like heart disease, it&amp;#39;s literally useless to say &amp;quot;well, this person is black, therefore, higher risk&amp;quot; if they&amp;#39;re from a population where no, they&amp;#39;re not from a higher risk... equivalently, it&amp;#39;d be stupid for a Caucasian person, or Asian, or Arab, etc, to make the same kind of comment about not worrying about their own risk factors.  People can get quite surprised about what genes manage to make it into their bodies.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Now the question is if they are prone to all these physical traits, can it be possible, objectively speaking, that the way black people think or behave in general is also different? Why would it be bad to point it out?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Because those types of things are generally driven by &lt;strong&gt;very&lt;/strong&gt; complex interactions of genetics, and very seldom can be boiled down to &amp;quot;mutation causing change in amount of this protein created, therefore, causing this effect which leads to heart disease&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;And even with heart disease you have subgroups and subpopulations who have specific markers but there are still so many different potential sites and mutations that we can track which makes it pretty much impossible to say &amp;quot;this is a single race with this one mutation&amp;quot;.  Cause that never happens, anywhere.  &amp;#39;Races&amp;#39; aren&amp;#39;t genetic monocultures, as has been pointed out, there&amp;#39;s generally more genetic diversity &lt;em&gt;within&lt;/em&gt; ethnic groups than between.&lt;/p&gt;\n\n&lt;p&gt;What we mean by the word &amp;#39;race&amp;#39; really isn&amp;#39;t as easy as people believe. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbstlh", "score_hidden": false, "stickied": false, "created": 1492354781.0, "created_utc": 1492325981.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgapv0b", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "I_AM_ALWAYS_ANGRY", "parent_id": "t1_dg9wmff", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Is skin color somehow directly related to violence? That seems rather unlikely, since melanin doesn't do much beyond absorb more wavelengths of light. \n\nMelanin is not the only difference in a black person so your thinking is flawed. Black people are more prone to heart diseases, they have higher levels of testosterone, blacks are three times more likely to die of asthma than white Americans, Despite lower tobacco exposure, black men are 50% more likely than white men to get lung cancer, Diabetes is 60% more common in black Americans than in white Americans. Blacks are up to 2.5 times more likely to suffer a limb amputation and up to 5.6 times more likely to suffer kidney disease than other people with diabetes.\n\nTo say that the only difference between whites and blacks is just the skin color is just bad science. \n\nNow the question is if they are prone to all these physical traits, can it be possible, objectively speaking, that the way black people think or behave in general is also different? Why would it be bad to point it out?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Is skin color somehow directly related to violence? That seems rather unlikely, since melanin doesn&amp;#39;t do much beyond absorb more wavelengths of light. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Melanin is not the only difference in a black person so your thinking is flawed. Black people are more prone to heart diseases, they have higher levels of testosterone, blacks are three times more likely to die of asthma than white Americans, Despite lower tobacco exposure, black men are 50% more likely than white men to get lung cancer, Diabetes is 60% more common in black Americans than in white Americans. Blacks are up to 2.5 times more likely to suffer a limb amputation and up to 5.6 times more likely to suffer kidney disease than other people with diabetes.&lt;/p&gt;\n\n&lt;p&gt;To say that the only difference between whites and blacks is just the skin color is just bad science. &lt;/p&gt;\n\n&lt;p&gt;Now the question is if they are prone to all these physical traits, can it be possible, objectively speaking, that the way black people think or behave in general is also different? Why would it be bad to point it out?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgapv0b", "score_hidden": false, "stickied": false, "created": 1492296454.0, "created_utc": 1492267654.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgabu24", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga98tk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;I agree with you that the WHY is the most interesting part of statistics. Like, trying to understand why things are like this or like that is a really interesting matter, I totally agree. But that is irrelevant in regard to stereotypes.\n\nI don't think it is.  Isn't stereotyping just another form of categorical lumping?  Good or bad, it seems the same type of principle as p-hacking, it yields limited actionable information especially in lieu of some larger contextual model.\n\n&gt;If I was American, and saw a group of black youths entering my store, I would pay more attention to what they are doing based on the accurate stereotype that they are way more likely to steal. It would be interesting to know why, for sure, but here I am running a business, and being stolen might mean not being able to feed my family correctly so I do not care.\n\nI mean, I don't think I would fault you as a human, but even here, I'd once again begin to question basic assumptions.  (I hold little sacred)\n\nSay you're a computer, and able to perform near instant risk-calculations.  \"What's the likelihood of an individual stealing from me\".  Fine.  \"Oh, look, black, all things being equal, that person has increased probability, hence, surveillance warranted\".\n\nBut humans aren't rational actors.  *You* (in this scenario) might be a perfectly 'rational' AI, but you're limited only by your input data.  \"Likelihood of theft from a random individual\".\n\nSo for a moment, imagine this group of youths takes offense.  And decides to beat you up over it.  Well suddenly you could be forced to no longer be able to work in your store, you'd have to pay for someone else to run it as you're in the hospital for god knows how many injuries.  \n\nSo how do you add that to your calculation?\n\nWhat if instead of beating you up, they're more likely to just steal out of spite?  What's the chance of you catching them?  If you catch them what effort would you have to exert to deal with it?  What are potential costs?  What's the probability of someone else taking the opportunity of you distracted to steal?  Would that be weighed by other racial information based on who else is in the store?  How granular is this input set?  Are people with Filipino attributes weighted differently from people with Chinese attributes? \n\nI think the reason I wouldn't fault you is because humans aren't perfectly rational.  But when designing algorithms to deal with scenarios, it's kinda vital we consider input data, and recognize that we're designing these things from our *own* biased perspective.  What you account for is going to change what the program does, and it's going to be directed by human motivation and actions. \n\nIt's the \"does\" part that's most important, computers \"do\" a lot, so how we design them, and how decisions of what data sets to include or not and how that impacts the decisions they make is *important*.  It really shouldn't be casually brushed aside because these really are the types of discussions programmers need to be aware of consciously when designing any system involving humans. \n\nI used the facial recognition software failure as an example of what happens when programmers aren't, and when a failure of sampling yields hilariously biased results. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I agree with you that the WHY is the most interesting part of statistics. Like, trying to understand why things are like this or like that is a really interesting matter, I totally agree. But that is irrelevant in regard to stereotypes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t think it is.  Isn&amp;#39;t stereotyping just another form of categorical lumping?  Good or bad, it seems the same type of principle as p-hacking, it yields limited actionable information especially in lieu of some larger contextual model.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;If I was American, and saw a group of black youths entering my store, I would pay more attention to what they are doing based on the accurate stereotype that they are way more likely to steal. It would be interesting to know why, for sure, but here I am running a business, and being stolen might mean not being able to feed my family correctly so I do not care.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I mean, I don&amp;#39;t think I would fault you as a human, but even here, I&amp;#39;d once again begin to question basic assumptions.  (I hold little sacred)&lt;/p&gt;\n\n&lt;p&gt;Say you&amp;#39;re a computer, and able to perform near instant risk-calculations.  &amp;quot;What&amp;#39;s the likelihood of an individual stealing from me&amp;quot;.  Fine.  &amp;quot;Oh, look, black, all things being equal, that person has increased probability, hence, surveillance warranted&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;But humans aren&amp;#39;t rational actors.  &lt;em&gt;You&lt;/em&gt; (in this scenario) might be a perfectly &amp;#39;rational&amp;#39; AI, but you&amp;#39;re limited only by your input data.  &amp;quot;Likelihood of theft from a random individual&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;So for a moment, imagine this group of youths takes offense.  And decides to beat you up over it.  Well suddenly you could be forced to no longer be able to work in your store, you&amp;#39;d have to pay for someone else to run it as you&amp;#39;re in the hospital for god knows how many injuries.  &lt;/p&gt;\n\n&lt;p&gt;So how do you add that to your calculation?&lt;/p&gt;\n\n&lt;p&gt;What if instead of beating you up, they&amp;#39;re more likely to just steal out of spite?  What&amp;#39;s the chance of you catching them?  If you catch them what effort would you have to exert to deal with it?  What are potential costs?  What&amp;#39;s the probability of someone else taking the opportunity of you distracted to steal?  Would that be weighed by other racial information based on who else is in the store?  How granular is this input set?  Are people with Filipino attributes weighted differently from people with Chinese attributes? &lt;/p&gt;\n\n&lt;p&gt;I think the reason I wouldn&amp;#39;t fault you is because humans aren&amp;#39;t perfectly rational.  But when designing algorithms to deal with scenarios, it&amp;#39;s kinda vital we consider input data, and recognize that we&amp;#39;re designing these things from our &lt;em&gt;own&lt;/em&gt; biased perspective.  What you account for is going to change what the program does, and it&amp;#39;s going to be directed by human motivation and actions. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s the &amp;quot;does&amp;quot; part that&amp;#39;s most important, computers &amp;quot;do&amp;quot; a lot, so how we design them, and how decisions of what data sets to include or not and how that impacts the decisions they make is &lt;em&gt;important&lt;/em&gt;.  It really shouldn&amp;#39;t be casually brushed aside because these really are the types of discussions programmers need to be aware of consciously when designing any system involving humans. &lt;/p&gt;\n\n&lt;p&gt;I used the facial recognition software failure as an example of what happens when programmers aren&amp;#39;t, and when a failure of sampling yields hilariously biased results. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgabu24", "score_hidden": false, "stickied": false, "created": 1492262366.0, "created_utc": 1492233566.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgaafh9", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "RoundDuckMan", "parent_id": "t1_dga98tk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I think there's a better way though to stereotype than go \"there's black people in my store, be suspicious.\" For example, if a black person that seems to be a farmer or a more 'plain' person. You might not care. But if they're wearing bandannas, and lots of basketball-style clothing, they seem to be the kind that are in the cities, and do likely a lot of crime.\n\n\nEDIT: This isn't to say blacks with basketball-style clothing are bad, it's just an attempt to pull the focus away from race itself. Another way is just treat people on a individual basis anyways. Stereotypes are bullshit when dealing with sentient beings.", "edited": 1492326582.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think there&amp;#39;s a better way though to stereotype than go &amp;quot;there&amp;#39;s black people in my store, be suspicious.&amp;quot; For example, if a black person that seems to be a farmer or a more &amp;#39;plain&amp;#39; person. You might not care. But if they&amp;#39;re wearing bandannas, and lots of basketball-style clothing, they seem to be the kind that are in the cities, and do likely a lot of crime.&lt;/p&gt;\n\n&lt;p&gt;EDIT: This isn&amp;#39;t to say blacks with basketball-style clothing are bad, it&amp;#39;s just an attempt to pull the focus away from race itself. Another way is just treat people on a individual basis anyways. Stereotypes are bullshit when dealing with sentient beings.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaafh9", "score_hidden": false, "stickied": false, "created": 1492259809.0, "created_utc": 1492231009.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga98tk", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dga8wkh", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I agree with you that the WHY is the most interesting part of statistics. Like, trying to understand why things are like this or like that is a really interesting matter, I totally agree. But that is irrelevant in regard to stereotypes.\n\nIf I was American, and saw a group of black youths entering my store, I would pay more attention to what they are doing based on the accurate stereotype that they are way more likely to steal. It would be interesting to know why, for sure, but here I am running a business, and being stolen might mean not being able to feed my family correctly so I do not care.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree with you that the WHY is the most interesting part of statistics. Like, trying to understand why things are like this or like that is a really interesting matter, I totally agree. But that is irrelevant in regard to stereotypes.&lt;/p&gt;\n\n&lt;p&gt;If I was American, and saw a group of black youths entering my store, I would pay more attention to what they are doing based on the accurate stereotype that they are way more likely to steal. It would be interesting to know why, for sure, but here I am running a business, and being stolen might mean not being able to feed my family correctly so I do not care.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga98tk", "score_hidden": false, "stickied": false, "created": 1492257774.0, "created_utc": 1492228974.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga8wkh", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga86k5", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Maybe I understood you incorrectly, but that's what I got from your message.\n\nThen I think you did indeed understand me incorrectly.\n\n&gt;There are strong correlations between races and crimes in the USA (I say in the USA because the situation is obviously different elsewhere). It seemed to me you don't like the reality, so what you do is you try to argue that genetically, skin colour has no influence over lawlessness. Well, of course! But that doesn't change the *fact that the correlation exists, and that for example black people steal more than others (again, in the USA)*.\n\nThe problem isn't necessarily \"these facts exist\".  Again that's no more important to me than \"google's neural network found cat videos\".  It's what we *do* with information and correlations, and why they're promoted.  \n\nYou say \"well of course\" skin color has no influence over lawlessness, but the ideas that it *does* is highly present in society.  As is the focusing on crime rates as being a big problem in society (despite numbers indicating otherwise).  Computers will train themselves on these biases just as much as human society does, and the big problems can arise when those algorithms become responsible for more than just things like failures in basic facial recognition.\n\nThe \"why\" really is usually the only interesting point of statistics.  It's why statistics are done, because otherwise you're just left with p-hacking.\n\nI can recognize objective facts as being objective facts, but in lieu of any contextual model, a statistic is pretty meaningless to me.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Maybe I understood you incorrectly, but that&amp;#39;s what I got from your message.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Then I think you did indeed understand me incorrectly.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;There are strong correlations between races and crimes in the USA (I say in the USA because the situation is obviously different elsewhere). It seemed to me you don&amp;#39;t like the reality, so what you do is you try to argue that genetically, skin colour has no influence over lawlessness. Well, of course! But that doesn&amp;#39;t change the &lt;em&gt;fact that the correlation exists, and that for example black people steal more than others (again, in the USA)&lt;/em&gt;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The problem isn&amp;#39;t necessarily &amp;quot;these facts exist&amp;quot;.  Again that&amp;#39;s no more important to me than &amp;quot;google&amp;#39;s neural network found cat videos&amp;quot;.  It&amp;#39;s what we &lt;em&gt;do&lt;/em&gt; with information and correlations, and why they&amp;#39;re promoted.  &lt;/p&gt;\n\n&lt;p&gt;You say &amp;quot;well of course&amp;quot; skin color has no influence over lawlessness, but the ideas that it &lt;em&gt;does&lt;/em&gt; is highly present in society.  As is the focusing on crime rates as being a big problem in society (despite numbers indicating otherwise).  Computers will train themselves on these biases just as much as human society does, and the big problems can arise when those algorithms become responsible for more than just things like failures in basic facial recognition.&lt;/p&gt;\n\n&lt;p&gt;The &amp;quot;why&amp;quot; really is usually the only interesting point of statistics.  It&amp;#39;s why statistics are done, because otherwise you&amp;#39;re just left with p-hacking.&lt;/p&gt;\n\n&lt;p&gt;I can recognize objective facts as being objective facts, but in lieu of any contextual model, a statistic is pretty meaningless to me.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga8wkh", "score_hidden": false, "stickied": false, "created": 1492257210.0, "created_utc": 1492228410.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dga86k5", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dga6qfa", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Maybe I understood you incorrectly, but that's what I got from your message.\n\nThere are strong correlations between races and crimes in the USA (I say in the USA because the situation is obviously different elsewhere). It seemed to me you don't like the reality, so what you do is you try to argue that genetically, skin colour has no influence over lawlessness. Well, of course! But that doesn't change the fact that the correlation exists, and that for example black people steal more than others (again, in the USA).\n\nPlease understand, *stereotypes are not about the WHY*. Whatever the reasons, be they racial, social or environmental, stereotypes will be true and useful if and only if they relate to real observable data.\n\nTrying to argue the WHY because you don't like the statistical reality is the same as burying your head into the sand IMHO. That's how I understood your answer.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe I understood you incorrectly, but that&amp;#39;s what I got from your message.&lt;/p&gt;\n\n&lt;p&gt;There are strong correlations between races and crimes in the USA (I say in the USA because the situation is obviously different elsewhere). It seemed to me you don&amp;#39;t like the reality, so what you do is you try to argue that genetically, skin colour has no influence over lawlessness. Well, of course! But that doesn&amp;#39;t change the fact that the correlation exists, and that for example black people steal more than others (again, in the USA).&lt;/p&gt;\n\n&lt;p&gt;Please understand, &lt;em&gt;stereotypes are not about the WHY&lt;/em&gt;. Whatever the reasons, be they racial, social or environmental, stereotypes will be true and useful if and only if they relate to real observable data.&lt;/p&gt;\n\n&lt;p&gt;Trying to argue the WHY because you don&amp;#39;t like the statistical reality is the same as burying your head into the sand IMHO. That&amp;#39;s how I understood your answer.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga86k5", "score_hidden": false, "stickied": false, "created": 1492256037.0, "created_utc": 1492227237.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6qfa", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dga627w", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Where in the hell did I say that?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Where in the hell did I say that?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga6qfa", "score_hidden": false, "stickied": false, "created": 1492253811.0, "created_utc": 1492225011.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dga627w", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dg9wmff", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Are you saying the statistics about crime and races are all fake in the USA? Your head seems to be buried deep into the sand.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Are you saying the statistics about crime and races are all fake in the USA? Your head seems to be buried deep into the sand.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga627w", "score_hidden": false, "stickied": false, "created": 1492252843.0, "created_utc": 1492224043.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9wmff", "gilded": 0, "archived": false, "score": 35, "report_reasons": null, "author": "zaoldyeck", "parent_id": "t1_dg9ohsk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;If someone wants to make the argument that statistics can be inherently racist like the \"scientific racism\" crowd then be my guest, however I think the notion (outside of a few specific instances) is absolute insane. \n\nI mean... kinda including 'race' as a concept at all will act as a selection bias.  And that's not including what goes on with potential p hacking of 'racial' data. \n\nSaying \"stereotypes are reduced to data that's purely ration\" doesn't make much sense if they're still based on failed assumptions.\n\nConsider.  \"Black people commit more crime on average\".\n\nOk?  But what's meant by \"black person\"?  Someone with dark skin?\n\nIs skin color somehow directly related to violence?  That seems rather unlikely, since melanin doesn't do much beyond absorb more wavelengths of light. \n\nWhat if you decided to look at other features?  Did you know [left handed people are supposedly more prone to psych disorders](http://news.yale.edu/2013/10/31/left-handed-people-more-likely-have-psychotic-disorders-such-schizophrenia-yale-study)?\n\nI wonder what interesting correlations we'd pick up with eye color as a bin, or facial features, etc. \n\nAt the heart of the matter is the fact that race is a kinda arbitrary concept in our culture.  You might find statistics that are weird or demand explanation, but almost invariably, those explanations revolve around some type of societal problem or another where knowing skin color or eye color does little to address the issue. \n\nIf you want to ignore that though and use what are already socially constructed artificial labels as your basis of algorithmic thinking, your algorithms are going to reflect those same socially created constructs. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;If someone wants to make the argument that statistics can be inherently racist like the &amp;quot;scientific racism&amp;quot; crowd then be my guest, however I think the notion (outside of a few specific instances) is absolute insane. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I mean... kinda including &amp;#39;race&amp;#39; as a concept at all will act as a selection bias.  And that&amp;#39;s not including what goes on with potential p hacking of &amp;#39;racial&amp;#39; data. &lt;/p&gt;\n\n&lt;p&gt;Saying &amp;quot;stereotypes are reduced to data that&amp;#39;s purely ration&amp;quot; doesn&amp;#39;t make much sense if they&amp;#39;re still based on failed assumptions.&lt;/p&gt;\n\n&lt;p&gt;Consider.  &amp;quot;Black people commit more crime on average&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;Ok?  But what&amp;#39;s meant by &amp;quot;black person&amp;quot;?  Someone with dark skin?&lt;/p&gt;\n\n&lt;p&gt;Is skin color somehow directly related to violence?  That seems rather unlikely, since melanin doesn&amp;#39;t do much beyond absorb more wavelengths of light. &lt;/p&gt;\n\n&lt;p&gt;What if you decided to look at other features?  Did you know &lt;a href=\"http://news.yale.edu/2013/10/31/left-handed-people-more-likely-have-psychotic-disorders-such-schizophrenia-yale-study\"&gt;left handed people are supposedly more prone to psych disorders&lt;/a&gt;?&lt;/p&gt;\n\n&lt;p&gt;I wonder what interesting correlations we&amp;#39;d pick up with eye color as a bin, or facial features, etc. &lt;/p&gt;\n\n&lt;p&gt;At the heart of the matter is the fact that race is a kinda arbitrary concept in our culture.  You might find statistics that are weird or demand explanation, but almost invariably, those explanations revolve around some type of societal problem or another where knowing skin color or eye color does little to address the issue. &lt;/p&gt;\n\n&lt;p&gt;If you want to ignore that though and use what are already socially constructed artificial labels as your basis of algorithmic thinking, your algorithms are going to reflect those same socially created constructs. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9wmff", "score_hidden": false, "stickied": false, "created": 1492239970.0, "created_utc": 1492211170.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 35}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgawjjx", "gilded": 0, "archived": false, "score": -4, "report_reasons": null, "author": "grateful_PoC", "parent_id": "t1_dgat2s9", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Please refrain from using ableist slurs.  Thank you.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Please refrain from using ableist slurs.  Thank you.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgawjjx", "score_hidden": false, "stickied": false, "created": 1492305880.0, "created_utc": 1492277080.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": -4}}], "after": null, "before": null}}, "user_reports": [], "id": "dgat2s9", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "kinderdemon", "parent_id": "t1_dg9ohsk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Stereotyping rationally: anyone who posts to T_D is a fucking idiot.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Stereotyping rationally: anyone who posts to T_D is a fucking idiot.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgat2s9", "score_hidden": false, "stickied": false, "created": 1492301067.0, "created_utc": 1492272267.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga1z67", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dga1klo", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Identifying statistically what stereotypes we actually have is a worthwhile endeavor.\n\nAgreed. \n\n\nAt the same time, (and separate from above point) common stereotypes are basically a distributed decentralized approximation mechanism. That is really going to be hard to beat, I'm not even sure if its possible to do so. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Identifying statistically what stereotypes we actually have is a worthwhile endeavor.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Agreed. &lt;/p&gt;\n\n&lt;p&gt;At the same time, (and separate from above point) common stereotypes are basically a distributed decentralized approximation mechanism. That is really going to be hard to beat, I&amp;#39;m not even sure if its possible to do so. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga1z67", "score_hidden": false, "stickied": false, "created": 1492247088.0, "created_utc": 1492218288.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgabjf5", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dgaaxfc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If by world you mean Occidental countries then yes, probably. But it's IMHO more because the economy has not been going too bad for a while.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If by world you mean Occidental countries then yes, probably. But it&amp;#39;s IMHO more because the economy has not been going too bad for a while.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgabjf5", "score_hidden": false, "stickied": false, "created": 1492261803.0, "created_utc": 1492233003.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaaxfc", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "RoundDuckMan", "parent_id": "t1_dgaaq4t", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Yeah, it's not much of a thing now, but that thing did plague Jews for many years. The reason it isn't as bad now is because the world isn't as religious.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, it&amp;#39;s not much of a thing now, but that thing did plague Jews for many years. The reason it isn&amp;#39;t as bad now is because the world isn&amp;#39;t as religious.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaaxfc", "score_hidden": false, "stickied": false, "created": 1492260684.0, "created_utc": 1492231884.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaaq4t", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dgaa8oc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Sometimes, probably. About \"Jews are Jesus-haters\", it's not a stereotype that is uphold where I grew up but I can see why it is a thing as some Jews hate Christians and vice versa.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sometimes, probably. About &amp;quot;Jews are Jesus-haters&amp;quot;, it&amp;#39;s not a stereotype that is uphold where I grew up but I can see why it is a thing as some Jews hate Christians and vice versa.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaaq4t", "score_hidden": false, "stickied": false, "created": 1492260333.0, "created_utc": 1492231533.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaa8oc", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "RoundDuckMan", "parent_id": "t1_dga7dei", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I don't think so. Sometimes it becomes tradition/part of culture, like \"Jews are Jesus-haters.\"", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think so. Sometimes it becomes tradition/part of culture, like &amp;quot;Jews are Jesus-haters.&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaa8oc", "score_hidden": false, "stickied": false, "created": 1492259483.0, "created_utc": 1492230683.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga7dei", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Shautieh", "parent_id": "t1_dga1klo", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; There are a whole lot of stereotypes embedded in literature, in media, even in language, that are no longer accurate--and some that were never particularly correct.\n\nThis is true, but when a stereotype loses its meaning and utility, then I think it will naturally disappear after a while. A few generations at most.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;There are a whole lot of stereotypes embedded in literature, in media, even in language, that are no longer accurate--and some that were never particularly correct.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This is true, but when a stereotype loses its meaning and utility, then I think it will naturally disappear after a while. A few generations at most.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga7dei", "score_hidden": false, "stickied": false, "created": 1492254767.0, "created_utc": 1492225967.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dga1klo", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "yiliu", "parent_id": "t1_dg9ohsk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Stereotypes aren't in themselves negative, but stereotypes tend to persist in society even when they're no longer accurate. There are a whole lot of stereotypes embedded in literature, in media, even in language, that are no longer accurate--and some that were never particularly correct.\n\nPlus, there's a problem with feedback. If the stereotype is that women make bad programmers (because there aren't any female programmers), then that will discourage women from becoming programmers and companies from hiring women, thus reinforcing an inaccurate stereotype.\n\nYou're right that stereotypes are required for intelligence, but that doesn't mean we should be uncritical about them. In fact, it mean we should be _especially aware_ of them, since inaccurate stereotypes make for a bad model of the underlying reality. Identifying statistically _what stereotypes we actually have_ is a worthwhile endeavor.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Stereotypes aren&amp;#39;t in themselves negative, but stereotypes tend to persist in society even when they&amp;#39;re no longer accurate. There are a whole lot of stereotypes embedded in literature, in media, even in language, that are no longer accurate--and some that were never particularly correct.&lt;/p&gt;\n\n&lt;p&gt;Plus, there&amp;#39;s a problem with feedback. If the stereotype is that women make bad programmers (because there aren&amp;#39;t any female programmers), then that will discourage women from becoming programmers and companies from hiring women, thus reinforcing an inaccurate stereotype.&lt;/p&gt;\n\n&lt;p&gt;You&amp;#39;re right that stereotypes are required for intelligence, but that doesn&amp;#39;t mean we should be uncritical about them. In fact, it mean we should be &lt;em&gt;especially aware&lt;/em&gt; of them, since inaccurate stereotypes make for a bad model of the underlying reality. Identifying statistically &lt;em&gt;what stereotypes we actually have&lt;/em&gt; is a worthwhile endeavor.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga1klo", "score_hidden": false, "stickied": false, "created": 1492246544.0, "created_utc": 1492217744.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga509z", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "Tekmo", "parent_id": "t1_dg9ohsk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The issue here is that it's very difficult to obtain a \"pure observation\".  The data that you use to train the algorithm can very easily be corrupted by human prejudice.\n\nFor example, suppose you train an algorithm to decide which resumes to interview based on the resumes of people who get promoted at the company.  The problem is that your company's promotion practices might be biased (i.e. perhaps whites or males tend to be favored for promotion beyond their merit) so you're just training your algorithm to faithfully mimic your promotion bias.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The issue here is that it&amp;#39;s very difficult to obtain a &amp;quot;pure observation&amp;quot;.  The data that you use to train the algorithm can very easily be corrupted by human prejudice.&lt;/p&gt;\n\n&lt;p&gt;For example, suppose you train an algorithm to decide which resumes to interview based on the resumes of people who get promoted at the company.  The problem is that your company&amp;#39;s promotion practices might be biased (i.e. perhaps whites or males tend to be favored for promotion beyond their merit) so you&amp;#39;re just training your algorithm to faithfully mimic your promotion bias.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga509z", "score_hidden": false, "stickied": false, "created": 1492251328.0, "created_utc": 1492222528.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgd9rq4", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "duhace", "parent_id": "t1_dgd9ldi", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "if you want to seriously research the issue I'd start with places like the SPLC, who've spent decades actually studying and fighting back against racism and racists.\n\nas for \"oh it was just a mistake\", this mistake would have landed this kid in jail had he not had as strong an alibi as he did. there are a lot of falsely accused in our prisons (not just black people, but good god there's a lot of falsely accused black people in our prisons). at this level of crime, if you're in a minority group police will automatically assume your guilt and work to make sure you go to jail. and a black person, who is far less likely to have adequate legal representation, will frequently get pushed into a plea deal by their public defender that gets them a record. that transforms mistakes into \"actual\" mugging convictions. \n\ni get that you'd like to imagine that people are a lot more rational and aren't reporting black people for crimes they didn't actually commit, but it's actually a really frequent occurence that black people have the cops called on them for no reason. it was bad enough my black friends didn't want to go anywhere near a rich area of town with me for fear the cops would be called on them.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;if you want to seriously research the issue I&amp;#39;d start with places like the SPLC, who&amp;#39;ve spent decades actually studying and fighting back against racism and racists.&lt;/p&gt;\n\n&lt;p&gt;as for &amp;quot;oh it was just a mistake&amp;quot;, this mistake would have landed this kid in jail had he not had as strong an alibi as he did. there are a lot of falsely accused in our prisons (not just black people, but good god there&amp;#39;s a lot of falsely accused black people in our prisons). at this level of crime, if you&amp;#39;re in a minority group police will automatically assume your guilt and work to make sure you go to jail. and a black person, who is far less likely to have adequate legal representation, will frequently get pushed into a plea deal by their public defender that gets them a record. that transforms mistakes into &amp;quot;actual&amp;quot; mugging convictions. &lt;/p&gt;\n\n&lt;p&gt;i get that you&amp;#39;d like to imagine that people are a lot more rational and aren&amp;#39;t reporting black people for crimes they didn&amp;#39;t actually commit, but it&amp;#39;s actually a really frequent occurence that black people have the cops called on them for no reason. it was bad enough my black friends didn&amp;#39;t want to go anywhere near a rich area of town with me for fear the cops would be called on them.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgd9rq4", "score_hidden": false, "stickied": false, "created": 1492445351.0, "created_utc": 1492416551.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd9ldi", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "snobocracy", "parent_id": "t1_dgd9761", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I knew about the other two incidents you linked, but this one is new. Love the language in the article by the way: \"Coleman was no match for MacDonald\u2019s overpowering demands which wreaked of white privilege\" - Lol.\n  \nCases like this must be such a tiny portion of the entire picture. I can't imagine that there are too many reported muggings out there that were just a misunderstanding. Like I said, I'll need to look into the data, but even assuming that 10% of reported muggings are mistaken reports, there's still probably a huge discrepency there.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I knew about the other two incidents you linked, but this one is new. Love the language in the article by the way: &amp;quot;Coleman was no match for MacDonald\u2019s overpowering demands which wreaked of white privilege&amp;quot; - Lol.&lt;/p&gt;\n\n&lt;p&gt;Cases like this must be such a tiny portion of the entire picture. I can&amp;#39;t imagine that there are too many reported muggings out there that were just a misunderstanding. Like I said, I&amp;#39;ll need to look into the data, but even assuming that 10% of reported muggings are mistaken reports, there&amp;#39;s still probably a huge discrepency there.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgd9ldi", "score_hidden": false, "stickied": false, "created": 1492444774.0, "created_utc": 1492415974.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd9761", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "duhace", "parent_id": "t1_dgd9466", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "[You'd be surprised](https://www.myautism.org/15-year-old-autism-accused-mugging/)\n\nwhat constitutes an attempted mugging depends on the person reporting the crime, and as you can see, people are much quicker to assume that a black person is/was trying to mug them even if they're in no danger!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://www.myautism.org/15-year-old-autism-accused-mugging/\"&gt;You&amp;#39;d be surprised&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;what constitutes an attempted mugging depends on the person reporting the crime, and as you can see, people are much quicker to assume that a black person is/was trying to mug them even if they&amp;#39;re in no danger!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgd9761", "score_hidden": false, "stickied": false, "created": 1492443570.0, "created_utc": 1492414770.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd9466", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "snobocracy", "parent_id": "t1_dgd91oc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Interesting.  \n  \nSo if I were to look into the data, and only apply what I said to things like muggings (which, really shouldn't have this kind of ambiguity; you know when you've been mugged and you know the race of the mugger), would you expect to find a representative number of blacks and whites?  \n  \nI have to be honest, I'll need to look this up, but I don't think you will.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Interesting.  &lt;/p&gt;\n\n&lt;p&gt;So if I were to look into the data, and only apply what I said to things like muggings (which, really shouldn&amp;#39;t have this kind of ambiguity; you know when you&amp;#39;ve been mugged and you know the race of the mugger), would you expect to find a representative number of blacks and whites?  &lt;/p&gt;\n\n&lt;p&gt;I have to be honest, I&amp;#39;ll need to look this up, but I don&amp;#39;t think you will.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgd9466", "score_hidden": false, "stickied": false, "created": 1492443324.0, "created_utc": 1492414524.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd91oc", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "duhace", "parent_id": "t1_dgd8w8j", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "You just said the reason. Just like judges and juries are more likely to see the worst of a person if they're black (and give them the benefit of the doubt if they're white), people suspect black people of committing crimes and report said crimes far more often than they do white people. [A good example is the incident where a black professor was arrested for breaking into his own home.](https://www.theguardian.com/world/2009/jul/21/henry-louis-gates-jr-arrest-harvard). [Here's a video showing the effect directly with a both a black person and a white person faking trying to steal a bike.](https://www.youtube.com/watch?v=fCPnoO8D3Oc) The black guy is getting questioned on what he's doing almost immediately, while the white guy was actually helped!\n\nbasically, the reporting problem comes down to the fact that people are both far more likely to report black people for committing a crime, and they are also more likely to report black people for committing a crime even when they aren't! ", "edited": 1492414552.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You just said the reason. Just like judges and juries are more likely to see the worst of a person if they&amp;#39;re black (and give them the benefit of the doubt if they&amp;#39;re white), people suspect black people of committing crimes and report said crimes far more often than they do white people. &lt;a href=\"https://www.theguardian.com/world/2009/jul/21/henry-louis-gates-jr-arrest-harvard\"&gt;A good example is the incident where a black professor was arrested for breaking into his own home.&lt;/a&gt;. &lt;a href=\"https://www.youtube.com/watch?v=fCPnoO8D3Oc\"&gt;Here&amp;#39;s a video showing the effect directly with a both a black person and a white person faking trying to steal a bike.&lt;/a&gt; The black guy is getting questioned on what he&amp;#39;s doing almost immediately, while the white guy was actually helped!&lt;/p&gt;\n\n&lt;p&gt;basically, the reporting problem comes down to the fact that people are both far more likely to report black people for committing a crime, and they are also more likely to report black people for committing a crime even when they aren&amp;#39;t! &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgd91oc", "score_hidden": false, "stickied": false, "created": 1492443122.0, "created_utc": 1492414322.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd8w8j", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "snobocracy", "parent_id": "t1_dgacyyr", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This is a great explanation for why blacks may be convicted of more crimes than whites. The concept of racist juries and judges, being biased against black defendents is sufficient to explain the gap in black/white incarceration rates.\n  \nWhat it doesn't explain though (and I've never heard a good explanation for), is why victimization reports also place blacks ahead of whites. When people report a robbery or a mugging, and they tell the police the race of the person they witnessed committing the crime (assuming they did witness it), it turns out that blacks are still hugely over-represented here too.  \nWhat's the deal there?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is a great explanation for why blacks may be convicted of more crimes than whites. The concept of racist juries and judges, being biased against black defendents is sufficient to explain the gap in black/white incarceration rates.&lt;/p&gt;\n\n&lt;p&gt;What it doesn&amp;#39;t explain though (and I&amp;#39;ve never heard a good explanation for), is why victimization reports also place blacks ahead of whites. When people report a robbery or a mugging, and they tell the police the race of the person they witnessed committing the crime (assuming they did witness it), it turns out that blacks are still hugely over-represented here too.&lt;br/&gt;\nWhat&amp;#39;s the deal there?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgd8w8j", "score_hidden": false, "stickied": false, "created": 1492442689.0, "created_utc": 1492413889.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgacyyr", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "duhace", "parent_id": "t1_dg9ohsk", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Except the human in your example is not forming a stereotype based off a situation he experienced, or someone else experienced, but from a falsity spread by racists. For example, your statistic that convinces your hypothetical newly born racist is based off a society that sees fit to show leniency to white criminals, and assume criminality of black people. Black people are overrepresented because our society is structured for that exact result. And it was structured that way a long time ago by men who wanted to hold other men in bondage and needed a good excuse for why that is something that should be allowed.\n\nStereotyping has a bad connotation because while it is a vital part of AI and a first step towards trying to make sense of the world, as humans we've moved past it. We are supposed to challenge our stereotypes and find the truth, rather than leave stereotypes unquestioned, like less intelligent animals might.", "edited": 1492236361.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Except the human in your example is not forming a stereotype based off a situation he experienced, or someone else experienced, but from a falsity spread by racists. For example, your statistic that convinces your hypothetical newly born racist is based off a society that sees fit to show leniency to white criminals, and assume criminality of black people. Black people are overrepresented because our society is structured for that exact result. And it was structured that way a long time ago by men who wanted to hold other men in bondage and needed a good excuse for why that is something that should be allowed.&lt;/p&gt;\n\n&lt;p&gt;Stereotyping has a bad connotation because while it is a vital part of AI and a first step towards trying to make sense of the world, as humans we&amp;#39;ve moved past it. We are supposed to challenge our stereotypes and find the truth, rather than leave stereotypes unquestioned, like less intelligent animals might.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgacyyr", "score_hidden": false, "stickied": false, "created": 1492264748.0, "created_utc": 1492235948.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dga1baz", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "Boba-Black-Sheep", "parent_id": "t1_dg9zuej", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "So I have some data set. In it, I can see a bunch of characteristics of people, including the size of their loan and whether they paid it back or defaulted. I train some model on this data (one of infinite possible models) that will then tell me how likely a new person is to pay back their loan. This model isn't perfect, and makes errors sometimes (ie: saying I should give a loan to someone who will default, or vice-versa).\n\nImagine now that this trained model consistently gives less loans to black people who would in fact have paid back their loan. 95% of white people who would successfully pay back their loan get one, but only 70% of black people. This is because of imperfections in the model - sure, assuming we lived in a world where we could perfectly predict every single individuals loan repayment, this whole discussion is pointless - but we don't - so it isn't. But I'm not trying to hammer some huge social justice hammer here - what I'm trying to do is ensure that people are given shit based on their actual merit (ie: their actual ability to pay back the loan) - not the correlated bias from these characteristic labels.\n\nThe effect of the proposed solution is just about better distributing where the errors in classification in the model happen (and who pays for them) - why is it a preferable world in which the MISTAKES YOUR MODEL MAKES disproportionately target any one group?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So I have some data set. In it, I can see a bunch of characteristics of people, including the size of their loan and whether they paid it back or defaulted. I train some model on this data (one of infinite possible models) that will then tell me how likely a new person is to pay back their loan. This model isn&amp;#39;t perfect, and makes errors sometimes (ie: saying I should give a loan to someone who will default, or vice-versa).&lt;/p&gt;\n\n&lt;p&gt;Imagine now that this trained model consistently gives less loans to black people who would in fact have paid back their loan. 95% of white people who would successfully pay back their loan get one, but only 70% of black people. This is because of imperfections in the model - sure, assuming we lived in a world where we could perfectly predict every single individuals loan repayment, this whole discussion is pointless - but we don&amp;#39;t - so it isn&amp;#39;t. But I&amp;#39;m not trying to hammer some huge social justice hammer here - what I&amp;#39;m trying to do is ensure that people are given shit based on their actual merit (ie: their actual ability to pay back the loan) - not the correlated bias from these characteristic labels.&lt;/p&gt;\n\n&lt;p&gt;The effect of the proposed solution is just about better distributing where the errors in classification in the model happen (and who pays for them) - why is it a preferable world in which the MISTAKES YOUR MODEL MAKES disproportionately target any one group?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga1baz", "score_hidden": false, "stickied": false, "created": 1492246202.0, "created_utc": 1492217402.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9zuej", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dg9yrk1", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;What the metric proposed in the paper does is try to equalize the true positive rate between groups - it's literally about being 'correctly classified'.\n\n\nNo it isn't. It is fundamentally opposed to being correctly classified because it's intention is to drop data to fit with the paper writers views on which attributes are OK to stereotype and which aren't. \n\nTake this quote from the blog post:\n\n&gt;When group membership coincides with a sensitive attribute, such as race, gender, disability, or religion, this situation can lead to unjust or prejudicial outcomes.\n\nThey are intentionally hiding the true aspects of these traits upon the dataset in order to impose their own view of how the world should be. But their view is wrong, and they advocate hiding data to make it appear as if they aren't wrong -- deceitful. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;What the metric proposed in the paper does is try to equalize the true positive rate between groups - it&amp;#39;s literally about being &amp;#39;correctly classified&amp;#39;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;No it isn&amp;#39;t. It is fundamentally opposed to being correctly classified because it&amp;#39;s intention is to drop data to fit with the paper writers views on which attributes are OK to stereotype and which aren&amp;#39;t. &lt;/p&gt;\n\n&lt;p&gt;Take this quote from the blog post:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;When group membership coincides with a sensitive attribute, such as race, gender, disability, or religion, this situation can lead to unjust or prejudicial outcomes.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;They are intentionally hiding the true aspects of these traits upon the dataset in order to impose their own view of how the world should be. But their view is wrong, and they advocate hiding data to make it appear as if they aren&amp;#39;t wrong -- deceitful. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9zuej", "score_hidden": false, "stickied": false, "created": 1492244248.0, "created_utc": 1492215448.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9yrk1", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Boba-Black-Sheep", "parent_id": "t1_dg9yh42", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Okay, let's drop the ideological stuff because it's out of place here.\n\nWhat the metric proposed in the paper does is try to equalize the true positive rate between groups - it's literally about being 'correctly classified'.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Okay, let&amp;#39;s drop the ideological stuff because it&amp;#39;s out of place here.&lt;/p&gt;\n\n&lt;p&gt;What the metric proposed in the paper does is try to equalize the true positive rate between groups - it&amp;#39;s literally about being &amp;#39;correctly classified&amp;#39;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9yrk1", "score_hidden": false, "stickied": false, "created": 1492242802.0, "created_utc": 1492214002.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9yh42", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dg9xood", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;There exists a large number of groups who are currently, in the vast majority of civil, functional societies, given some protection against discrimination based on their class\n\nI don't think there should be any laws that give benefit to or suppress any race. That's a separate point outside of /r/progamming however and I don't want to go into that. \n\n&gt;By implementing the (efficient) solution to equalizing these biases provided in the paper, you enable a large class of much-better-than-fallible-often-racist-human to be applied to problems they simply legally weren't previously\n\nIF a society is unable to treat people fairly, why then would you trust people of that society to hire people of that society to create rules which discriminate (positively or negatively) based on race? It makes 0 sense. \n\n&gt;Do you think the basic idea that people should be at least CORRECTLY CLASSIFIED at the same rate, regardless of their race/other immutable characteristics is somehow morally disgusting?\n\n\nThat wasn't what I said at all. I said that having a person determine how others(AI) should consider others based on their race is disgusting. Certainly you'd agree with me if you saw the negative aspect of this, I think you are only considering the potentially positive aspects of it. \n\nAlso, the \"correctly classified\" part is wrong. If you have attributes which are associated with negative or positive traits then those traits are associated with you. Correctly classified would be taking these into account, not ignoring them because they don't fit whatever agenda you have. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;There exists a large number of groups who are currently, in the vast majority of civil, functional societies, given some protection against discrimination based on their class&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I don&amp;#39;t think there should be any laws that give benefit to or suppress any race. That&amp;#39;s a separate point outside of &lt;a href=\"/r/progamming\"&gt;/r/progamming&lt;/a&gt; however and I don&amp;#39;t want to go into that. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;By implementing the (efficient) solution to equalizing these biases provided in the paper, you enable a large class of much-better-than-fallible-often-racist-human to be applied to problems they simply legally weren&amp;#39;t previously&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;IF a society is unable to treat people fairly, why then would you trust people of that society to hire people of that society to create rules which discriminate (positively or negatively) based on race? It makes 0 sense. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Do you think the basic idea that people should be at least CORRECTLY CLASSIFIED at the same rate, regardless of their race/other immutable characteristics is somehow morally disgusting?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;That wasn&amp;#39;t what I said at all. I said that having a person determine how others(AI) should consider others based on their race is disgusting. Certainly you&amp;#39;d agree with me if you saw the negative aspect of this, I think you are only considering the potentially positive aspects of it. &lt;/p&gt;\n\n&lt;p&gt;Also, the &amp;quot;correctly classified&amp;quot; part is wrong. If you have attributes which are associated with negative or positive traits then those traits are associated with you. Correctly classified would be taking these into account, not ignoring them because they don&amp;#39;t fit whatever agenda you have. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9yh42", "score_hidden": false, "stickied": false, "created": 1492242412.0, "created_utc": 1492213612.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9xood", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "Boba-Black-Sheep", "parent_id": "t1_dg9wuzi", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I think I actually misread your third from last paragraph - but regardless, I think you're being a little extreme.\n\n1) There exists a large number of groups who are currently, in the vast majority of civil, functional societies, given some protection against discrimination based on their class (whether that be race, gender, sexuality, whatever). By implementing the (efficient) solution to equalizing these biases provided in the paper, you enable a large class of much-better-than-fallible-often-racist-human to be applied to problems they simply legally weren't previously.\n\n2) I don't see why anything mentioned in the paper is \"hideous and degrading\"? What specific outcomes are you objecting to? Do you think the basic idea that **people should be at least CORRECTLY CLASSIFIED at the same rate**, regardless of their race/other immutable characteristics is somehow morally disgusting?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think I actually misread your third from last paragraph - but regardless, I think you&amp;#39;re being a little extreme.&lt;/p&gt;\n\n&lt;p&gt;1) There exists a large number of groups who are currently, in the vast majority of civil, functional societies, given some protection against discrimination based on their class (whether that be race, gender, sexuality, whatever). By implementing the (efficient) solution to equalizing these biases provided in the paper, you enable a large class of much-better-than-fallible-often-racist-human to be applied to problems they simply legally weren&amp;#39;t previously.&lt;/p&gt;\n\n&lt;p&gt;2) I don&amp;#39;t see why anything mentioned in the paper is &amp;quot;hideous and degrading&amp;quot;? What specific outcomes are you objecting to? Do you think the basic idea that &lt;strong&gt;people should be at least CORRECTLY CLASSIFIED at the same rate&lt;/strong&gt;, regardless of their race/other immutable characteristics is somehow morally disgusting?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9xood", "score_hidden": false, "stickied": false, "created": 1492241378.0, "created_utc": 1492212578.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9wuzi", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dg9wh9n", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I'm familiar with this paper. If you could, please point out how you disagree (with me). This paper is exactly the solution I pointed out here:\n\n&gt; have a machines views on race dictated by whomever writes the rules\n\nThe paper could be used as an example in the dictionary for obscuritism, ie- intentionally hiding a very simple (and wrong) concept behind a bunch of complex writing. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m familiar with this paper. If you could, please point out how you disagree (with me). This paper is exactly the solution I pointed out here:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;have a machines views on race dictated by whomever writes the rules&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The paper could be used as an example in the dictionary for obscuritism, ie- intentionally hiding a very simple (and wrong) concept behind a bunch of complex writing. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9wuzi", "score_hidden": false, "stickied": false, "created": 1492240286.0, "created_utc": 1492211486.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgasjo9", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "McSchwartz", "parent_id": "t1_dgao5dn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "You're right, I thought it was advocating for the \"Equalized Odds\" method, but it appears to advocating for the \"Equal opportunity\" method. I was explaining their \"Equalized Odds\" method, which, directly quoted, says:\n\n&gt;Equalized odds requires both the fraction of non-defaulters that qualify for loans and the fraction of defaulters that qualify for loans to be constant across groups.\n\nThe paper, after the Case study: FICO scores section, discusses several methods. \"Equal opportunity\" is defined as:\n\n&gt;Equal opportunity picks for each group a threshold such that the fraction of non-defaulting\ngroup members that qualify for loans is the same.\n\nIt also says that this method receives 92.8% of maximum profit.\n\n&gt;we find that a race blind threshold gets 99.3% of the maximal profit, equal opportunity gets 92.8%, equalized odds gets 80.2%, and demographic parity gets 69.8%.\n\nThe profit maximizing one is race blind. A caveat with this method is this:\n\n&gt;Under max-profit and race-blind thresholds, we find that black people that would not default have a significantly harder time qualifying for loans than others [people of other races that would not default]. Under demographic parity, the situation is reversed.\n\nBut I will say that I'm not smart enough to figure out anything before the Case study: FICO scores section, it all looks like Greek to me. So I might be getting something wrong.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re right, I thought it was advocating for the &amp;quot;Equalized Odds&amp;quot; method, but it appears to advocating for the &amp;quot;Equal opportunity&amp;quot; method. I was explaining their &amp;quot;Equalized Odds&amp;quot; method, which, directly quoted, says:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Equalized odds requires both the fraction of non-defaulters that qualify for loans and the fraction of defaulters that qualify for loans to be constant across groups.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The paper, after the Case study: FICO scores section, discusses several methods. &amp;quot;Equal opportunity&amp;quot; is defined as:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Equal opportunity picks for each group a threshold such that the fraction of non-defaulting\ngroup members that qualify for loans is the same.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It also says that this method receives 92.8% of maximum profit.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;we find that a race blind threshold gets 99.3% of the maximal profit, equal opportunity gets 92.8%, equalized odds gets 80.2%, and demographic parity gets 69.8%.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The profit maximizing one is race blind. A caveat with this method is this:&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Under max-profit and race-blind thresholds, we find that black people that would not default have a significantly harder time qualifying for loans than others [people of other races that would not default]. Under demographic parity, the situation is reversed.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;But I will say that I&amp;#39;m not smart enough to figure out anything before the Case study: FICO scores section, it all looks like Greek to me. So I might be getting something wrong.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgasjo9", "score_hidden": false, "stickied": false, "created": 1492300332.0, "created_utc": 1492271532.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgayadw", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Boba-Black-Sheep", "parent_id": "t1_dgao5dn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There's already a large amount of existing regulation on the books that prevents banks from having policy that discriminates against these protected groups under the purview of existing anti-discrimination laws - I think one immediate application is that this system (or one like it) can allow banks to actually employ these kinds of black-box predictive models while ensuring they aren't liable.\n\nI think the moral question underpinning the equal opportunity approach is: \"Is it acceptable for someone who deserves a loan based on merit, be denied that loan because of their membership to a particular group?\", and as you point out - it's also about where you think the responsibility for this equality lies.\n\nThe other interesting benefit of the approach is that it incentives the loan-decider to invest in better predictors (more data, etc.), because the optimal predictor satisfies the condition, as a way of increasing their profit instead of making larger generalizations that have negative repercussions for deserving individuals.\n\nI definitely don't think this paper is the final solution to solving any of these problems, nor does it discuss the moral justification in any real detail - but the vast majority of objections in this thread are just not accurate.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s already a large amount of existing regulation on the books that prevents banks from having policy that discriminates against these protected groups under the purview of existing anti-discrimination laws - I think one immediate application is that this system (or one like it) can allow banks to actually employ these kinds of black-box predictive models while ensuring they aren&amp;#39;t liable.&lt;/p&gt;\n\n&lt;p&gt;I think the moral question underpinning the equal opportunity approach is: &amp;quot;Is it acceptable for someone who deserves a loan based on merit, be denied that loan because of their membership to a particular group?&amp;quot;, and as you point out - it&amp;#39;s also about where you think the responsibility for this equality lies.&lt;/p&gt;\n\n&lt;p&gt;The other interesting benefit of the approach is that it incentives the loan-decider to invest in better predictors (more data, etc.), because the optimal predictor satisfies the condition, as a way of increasing their profit instead of making larger generalizations that have negative repercussions for deserving individuals.&lt;/p&gt;\n\n&lt;p&gt;I definitely don&amp;#39;t think this paper is the final solution to solving any of these problems, nor does it discuss the moral justification in any real detail - but the vast majority of objections in this thread are just not accurate.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgayadw", "score_hidden": false, "stickied": false, "created": 1492308243.0, "created_utc": 1492279443.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgcz8gu", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Might-be-crazy", "parent_id": "t1_dgao5dn", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; I think the real contention here is when people suggest businesses have some moral imperative to do the less profitable thing in order to adhere to their version of \"fairness\".\n\nPrecisely.  People don't always seem to understand that banks, corporations, really most/all institutions seek to operate objectively (i.e. max profit) instead of subjectively (i.e. interpretations of 'fairness').\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I think the real contention here is when people suggest businesses have some moral imperative to do the less profitable thing in order to adhere to their version of &amp;quot;fairness&amp;quot;.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Precisely.  People don&amp;#39;t always seem to understand that banks, corporations, really most/all institutions seek to operate objectively (i.e. max profit) instead of subjectively (i.e. interpretations of &amp;#39;fairness&amp;#39;).&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcz8gu", "score_hidden": false, "stickied": false, "created": 1492425092.0, "created_utc": 1492396292.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgao5dn", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Drisku11", "parent_id": "t1_dga9d9z", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I think what your saying lies somewhere between what they call equalized odds and equal opportunity. Equal opportunity, which is what the press release talked about, leads to a higher false positive rate for some races, which is easiest to see on the right of figure 10.\n\nBasically, equal opportunity casts a wider net for some races, reducing profitably (by having more false positives) in order to be \"fair\" (by having fewer false negatives). No one would care if they could just increase accuracy across the board (well, I'm sure certain people would still claim it's unfair, but they would be more obviously wrong).\n\nI think the real contention here is when people suggest businesses have some moral imperative to do the less profitable thing in order to adhere to their version of \"fairness\". IMO if people want to subsidize high risk individuals in the name of racial equality or whatever, then they should at least be honest about it and do it through welfare, not force financial institutions to give them bad loans. From that perspective, maybe this sort of analysis could be useful for governments to decide who should qualify for their subsidies, but it doesn't seem directly useful to e.g. a bank.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think what your saying lies somewhere between what they call equalized odds and equal opportunity. Equal opportunity, which is what the press release talked about, leads to a higher false positive rate for some races, which is easiest to see on the right of figure 10.&lt;/p&gt;\n\n&lt;p&gt;Basically, equal opportunity casts a wider net for some races, reducing profitably (by having more false positives) in order to be &amp;quot;fair&amp;quot; (by having fewer false negatives). No one would care if they could just increase accuracy across the board (well, I&amp;#39;m sure certain people would still claim it&amp;#39;s unfair, but they would be more obviously wrong).&lt;/p&gt;\n\n&lt;p&gt;I think the real contention here is when people suggest businesses have some moral imperative to do the less profitable thing in order to adhere to their version of &amp;quot;fairness&amp;quot;. IMO if people want to subsidize high risk individuals in the name of racial equality or whatever, then they should at least be honest about it and do it through welfare, not force financial institutions to give them bad loans. From that perspective, maybe this sort of analysis could be useful for governments to decide who should qualify for their subsidies, but it doesn&amp;#39;t seem directly useful to e.g. a bank.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgao5dn", "score_hidden": false, "stickied": false, "created": 1492293683.0, "created_utc": 1492264883.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga9d9z", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "McSchwartz", "parent_id": "t1_dga4fix", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "https://arxiv.org/pdf/1610.02413.pdf\n\nIt looks like they're optimizing for equal accuracy across races. Accuracy being the rate of false positives and the rate of false negatives.\n\nAnd by false positive I mean someone who qualified for a loan who then defaulted; and false negative being someone who didn't qualify for a loan who wouldn't have defaulted.", "edited": 1492229629.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/1610.02413.pdf\"&gt;https://arxiv.org/pdf/1610.02413.pdf&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It looks like they&amp;#39;re optimizing for equal accuracy across races. Accuracy being the rate of false positives and the rate of false negatives.&lt;/p&gt;\n\n&lt;p&gt;And by false positive I mean someone who qualified for a loan who then defaulted; and false negative being someone who didn&amp;#39;t qualify for a loan who wouldn&amp;#39;t have defaulted.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga9d9z", "score_hidden": false, "stickied": false, "created": 1492257974.0, "created_utc": 1492229174.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dga4fix", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Drisku11", "parent_id": "t1_dg9wh9n", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "So basically they're optimizing for recall instead of precision? That seems like a pretty stupid thing to do for a business owner. Having bad recall means you lose out on the potential to make money (assuming you don't have somewhere else to invest that money). Having bad precision means you lose money.\n\nIn any case, neither seems less \"biased\" than the other. One of then just seems to make more business sense.", "edited": 1492222440.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So basically they&amp;#39;re optimizing for recall instead of precision? That seems like a pretty stupid thing to do for a business owner. Having bad recall means you lose out on the potential to make money (assuming you don&amp;#39;t have somewhere else to invest that money). Having bad precision means you lose money.&lt;/p&gt;\n\n&lt;p&gt;In any case, neither seems less &amp;quot;biased&amp;quot; than the other. One of then just seems to make more business sense.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga4fix", "score_hidden": false, "stickied": false, "created": 1492250486.0, "created_utc": 1492221686.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9wh9n", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Boba-Black-Sheep", "parent_id": "t1_dg9ohsk", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Hey, this isn't actually really true. You should check out this post (and the associated paper) out of Google Brain last year:\n\nhttps://research.googleblog.com/2016/10/equality-of-opportunity-in-machine.html\n\nedit: I encourage people to read the whole thread below, he simply does not understand the paper.", "edited": 1492278811.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hey, this isn&amp;#39;t actually really true. You should check out this post (and the associated paper) out of Google Brain last year:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://research.googleblog.com/2016/10/equality-of-opportunity-in-machine.html\"&gt;https://research.googleblog.com/2016/10/equality-of-opportunity-in-machine.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;edit: I encourage people to read the whole thread below, he simply does not understand the paper.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9wh9n", "score_hidden": false, "stickied": false, "created": 1492239778.0, "created_utc": 1492210978.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ohsk", "gilded": 0, "archived": false, "score": 114, "report_reasons": null, "author": "probably-poop", "parent_id": "t1_dg9g7wb", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Stereotyping has a negative connotation, but it truly is essential for any sort of intelligence. You get burnt by something bright red/yellow, you learn those things are dangerous. You eat an apple, now a pear looks like its worth a try to eat. You notice black people are more likely to commit theft, you consider locking your car doors or keeping items out of view.\n\nNone of these things are bad, they're approximations of the world. I think at some point people muddied the idea of stereotyping and associated it with something negative instead of taking it at face value. \n\nWith intentional restriction of stereotyping you end up with someone who cannot distinguish what traits are associated with pain, what traits are associated with pleasure, and what traits are associated with property rights (lack of better phrasing). \n\nCertainly with stereotyping this does not mean that something intelligent would be unable to distinguish the difference between crayons and fire, a fruit from a plastic fruit (or rotten one), and a [black man](http://8297-presscdn-0-77.pagely.netdna-cdn.com/wp-content/uploads/2015/09/DamonTweedy_alt1_StocksPhotography_HiRes-1024x819.jpg) vs someone who [dresses/talks like a criminal](https://i.ytimg.com/vi/LyefQxRMV2w/hqdefault.jpg). \n\nThe first order stereotype isn't wrong. It's just a base to work off of and further refine. Trying to repress an approximation which arises out of pure observation is foolish. \n\nStereotyping isn't the issue. Stereotype, revise stereotypes, become more granular, you'll end up with something that is purely acting rational (and therefore not racist). \n\nIf these people are aiming the eliminate statistical observations based on race that are unpleasant, they will fail terribly. The only ways to eliminate this is to either eliminate the ability to stereotype rationally, or to have a machines views on race dictated by whomever writes the rules- in my mind a truly hideous and degrading idea, or outside of the box- improve situations where different races are statistically different than others... which is basically an impossible feat in itself.\n\nIf someone wants to make the argument that statistics can be inherently racist like the \"scientific racism\" crowd then be my guest, however I think the notion (outside of a few specific instances) is absolute insane. \n\n---\n\ntldr; keep your bots off of neonazi and communist sites and it should end up mostly ok, though may express correlations you find unpleasant. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Stereotyping has a negative connotation, but it truly is essential for any sort of intelligence. You get burnt by something bright red/yellow, you learn those things are dangerous. You eat an apple, now a pear looks like its worth a try to eat. You notice black people are more likely to commit theft, you consider locking your car doors or keeping items out of view.&lt;/p&gt;\n\n&lt;p&gt;None of these things are bad, they&amp;#39;re approximations of the world. I think at some point people muddied the idea of stereotyping and associated it with something negative instead of taking it at face value. &lt;/p&gt;\n\n&lt;p&gt;With intentional restriction of stereotyping you end up with someone who cannot distinguish what traits are associated with pain, what traits are associated with pleasure, and what traits are associated with property rights (lack of better phrasing). &lt;/p&gt;\n\n&lt;p&gt;Certainly with stereotyping this does not mean that something intelligent would be unable to distinguish the difference between crayons and fire, a fruit from a plastic fruit (or rotten one), and a &lt;a href=\"http://8297-presscdn-0-77.pagely.netdna-cdn.com/wp-content/uploads/2015/09/DamonTweedy_alt1_StocksPhotography_HiRes-1024x819.jpg\"&gt;black man&lt;/a&gt; vs someone who &lt;a href=\"https://i.ytimg.com/vi/LyefQxRMV2w/hqdefault.jpg\"&gt;dresses/talks like a criminal&lt;/a&gt;. &lt;/p&gt;\n\n&lt;p&gt;The first order stereotype isn&amp;#39;t wrong. It&amp;#39;s just a base to work off of and further refine. Trying to repress an approximation which arises out of pure observation is foolish. &lt;/p&gt;\n\n&lt;p&gt;Stereotyping isn&amp;#39;t the issue. Stereotype, revise stereotypes, become more granular, you&amp;#39;ll end up with something that is purely acting rational (and therefore not racist). &lt;/p&gt;\n\n&lt;p&gt;If these people are aiming the eliminate statistical observations based on race that are unpleasant, they will fail terribly. The only ways to eliminate this is to either eliminate the ability to stereotype rationally, or to have a machines views on race dictated by whomever writes the rules- in my mind a truly hideous and degrading idea, or outside of the box- improve situations where different races are statistically different than others... which is basically an impossible feat in itself.&lt;/p&gt;\n\n&lt;p&gt;If someone wants to make the argument that statistics can be inherently racist like the &amp;quot;scientific racism&amp;quot; crowd then be my guest, however I think the notion (outside of a few specific instances) is absolute insane. &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;tldr; keep your bots off of neonazi and communist sites and it should end up mostly ok, though may express correlations you find unpleasant. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9ohsk", "score_hidden": false, "stickied": false, "created": 1492229571.0, "created_utc": 1492200771.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 114}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9g7wb", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "cyberst0rm", "parent_id": "t1_dg9cia8", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "and all of that is just stereotyping", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;and all of that is just stereotyping&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9g7wb", "score_hidden": false, "stickied": false, "created": 1492219700.0, "created_utc": 1492190900.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 25}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga9pg9", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "KronktheKronk", "parent_id": "t1_dg9cia8", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "More like \"statistical evidence that our societies are different\"", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;More like &amp;quot;statistical evidence that our societies are different&amp;quot;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga9pg9", "score_hidden": false, "stickied": false, "created": 1492258557.0, "created_utc": 1492229757.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga0tp0", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "addher", "parent_id": "t1_dg9ptio", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Fair enough, but there are a lot of mentions of \"machine learning\" I see that could better be served by gathering randomized sample data and then using basic statistical methods.\n\nTranslation isn't one of them, but it's also pretty damn far from being actual artificial intelligence. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair enough, but there are a lot of mentions of &amp;quot;machine learning&amp;quot; I see that could better be served by gathering randomized sample data and then using basic statistical methods.&lt;/p&gt;\n\n&lt;p&gt;Translation isn&amp;#39;t one of them, but it&amp;#39;s also pretty damn far from being actual artificial intelligence. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga0tp0", "score_hidden": false, "stickied": false, "created": 1492245546.0, "created_utc": 1492216746.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgad6b9", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "mujjingun", "parent_id": "t1_dg9ptio", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's not my \"definition\" per se, but that's how the word is frequently used these days, including the article.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not my &amp;quot;definition&amp;quot; per se, but that&amp;#39;s how the word is frequently used these days, including the article.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgad6b9", "score_hidden": false, "stickied": false, "created": 1492265194.0, "created_utc": 1492236394.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ptio", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "respeckKnuckles", "parent_id": "t1_dg9cia8", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Your definition of \"artificial intelligence\" is too narrow there. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Your definition of &amp;quot;artificial intelligence&amp;quot; is too narrow there. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9ptio", "score_hidden": false, "stickied": false, "created": 1492231168.0, "created_utc": 1492202368.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 0}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgap86r", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Zenitram", "parent_id": "t1_dg9cia8", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There is a reason people are biased, and it typically is statistically based.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is a reason people are biased, and it typically is statistically based.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgap86r", "score_hidden": false, "stickied": false, "created": 1492295479.0, "created_utc": 1492266679.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"author_cakeday": true, "subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgb0rz1", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Enamex", "parent_id": "t1_dgav3b7", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; casual\n\n*causal\n\nSorry, it changed the meaning too much.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;casual&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;*causal&lt;/p&gt;\n\n&lt;p&gt;Sorry, it changed the meaning too much.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb0rz1", "score_hidden": false, "stickied": false, "created": 1492311648.0, "created_utc": 1492282848.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgav3b7", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "0polymer0", "parent_id": "t1_dgaq5k4", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Because its strange to view \"race\" as a causal mechanism. Rather than a group of beliefs or actions. If statistics are weighting claims on things like skin color, when the real problem is something else, then if somebody with that skin color comes along that doesn't have that \"something else\" they could get falsely filtered.\n\nThat's the idea as I understand it. Some people think fitting against race is racist for reasons similar to the above, in their minds, race doesn't exist. ", "edited": 1492283779.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because its strange to view &amp;quot;race&amp;quot; as a causal mechanism. Rather than a group of beliefs or actions. If statistics are weighting claims on things like skin color, when the real problem is something else, then if somebody with that skin color comes along that doesn&amp;#39;t have that &amp;quot;something else&amp;quot; they could get falsely filtered.&lt;/p&gt;\n\n&lt;p&gt;That&amp;#39;s the idea as I understand it. Some people think fitting against race is racist for reasons similar to the above, in their minds, race doesn&amp;#39;t exist. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgav3b7", "score_hidden": false, "stickied": false, "created": 1492303903.0, "created_utc": 1492275103.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaq5k4", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "I_AM_ALWAYS_ANGRY", "parent_id": "t1_dg9cia8", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; \"statistical evidence that our society is biased\". \n\nWhy is it so taboo to address the problem when it comes to a racial group problem? Why do we have to say \"Society is biased\" instead of, for example, \"Hispanics are more likely to commit crime?\", I'm hispanic, when I moved to the US, I lived in the stereotypical \"Hispanic Comunity\" and the crimerate was through the roof, every time some shit happened, it was one of my own which really saddened me, was it \"Us being oppresed\"? nope, objectively speaking, hispanics were commiting more crimes than any other race in that area. So where do we draw the line between, bias and facts? Yes I'm hispanic. \n\nBoricua pa que tu lo sepas.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;&amp;quot;statistical evidence that our society is biased&amp;quot;. &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Why is it so taboo to address the problem when it comes to a racial group problem? Why do we have to say &amp;quot;Society is biased&amp;quot; instead of, for example, &amp;quot;Hispanics are more likely to commit crime?&amp;quot;, I&amp;#39;m hispanic, when I moved to the US, I lived in the stereotypical &amp;quot;Hispanic Comunity&amp;quot; and the crimerate was through the roof, every time some shit happened, it was one of my own which really saddened me, was it &amp;quot;Us being oppresed&amp;quot;? nope, objectively speaking, hispanics were commiting more crimes than any other race in that area. So where do we draw the line between, bias and facts? Yes I&amp;#39;m hispanic. &lt;/p&gt;\n\n&lt;p&gt;Boricua pa que tu lo sepas.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaq5k4", "score_hidden": false, "stickied": false, "created": 1492296906.0, "created_utc": 1492268106.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9cia8", "gilded": 0, "archived": false, "score": 333, "report_reasons": null, "author": "mujjingun", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "The thing is, \"Machine Learning\" and \"Artificial Intelligence\" are nothing more than buzzwords for a complex statistical model. So \"AI programs exhibit racial and gender biases\" just means \"statistical evidence that our society is biased\". ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The thing is, &amp;quot;Machine Learning&amp;quot; and &amp;quot;Artificial Intelligence&amp;quot; are nothing more than buzzwords for a complex statistical model. So &amp;quot;AI programs exhibit racial and gender biases&amp;quot; just means &amp;quot;statistical evidence that our society is biased&amp;quot;. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9cia8", "score_hidden": false, "stickied": false, "created": 1492215499.0, "created_utc": 1492186699.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 333}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9d958", "gilded": 0, "archived": false, "score": 60, "report_reasons": null, "author": "ArkyBeagle", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This just in: iterative noise reduction reinforces static bias in the data sets. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This just in: iterative noise reduction reinforces static bias in the data sets. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9d958", "score_hidden": false, "stickied": false, "created": 1492216326.0, "created_utc": 1492187526.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 60}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga0gh7", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "addher", "parent_id": "t1_dg9n9ms", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That's the subheadline. OP quoted both so I don't blame them, but the actual article should do better. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s the subheadline. OP quoted both so I don&amp;#39;t blame them, but the actual article should do better. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga0gh7", "score_hidden": false, "stickied": false, "created": 1492245053.0, "created_utc": 1492216253.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9n9ms", "gilded": 0, "archived": false, "score": 14, "report_reasons": null, "author": "sakarri", "parent_id": "t1_dg9c80l", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "But what you said is exactly what the headline said so I don't see what's misleading about it.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But what you said is exactly what the headline said so I don&amp;#39;t see what&amp;#39;s misleading about it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9n9ms", "score_hidden": false, "stickied": false, "created": 1492228096.0, "created_utc": 1492199296.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 14}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9wcj5", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "NoMoreNicksLeft", "parent_id": "t1_dg9mfia", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "What's \"intelligent\"? \n\nSome people use it to mean something like \"conscious\". No one who talks about AI uses the word in that way. Intelligence-without-consciousness is a real thing.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What&amp;#39;s &amp;quot;intelligent&amp;quot;? &lt;/p&gt;\n\n&lt;p&gt;Some people use it to mean something like &amp;quot;conscious&amp;quot;. No one who talks about AI uses the word in that way. Intelligence-without-consciousness is a real thing.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9wcj5", "score_hidden": false, "stickied": false, "created": 1492239600.0, "created_utc": 1492210800.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9mfia", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "nemec", "parent_id": "t1_dg9c80l", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "It's only misleading if you mistakenly believe artificial intelligence is actually 'intelligent' (see [this](https://www.reddit.com/r/programming/comments/65d47v/ai_programs_exhibit_racial_and_gender_biases/dg9cia8/))", "edited": 1492201692.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s only misleading if you mistakenly believe artificial intelligence is actually &amp;#39;intelligent&amp;#39; (see &lt;a href=\"https://www.reddit.com/r/programming/comments/65d47v/ai_programs_exhibit_racial_and_gender_biases/dg9cia8/\"&gt;this&lt;/a&gt;)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9mfia", "score_hidden": false, "stickied": false, "created": 1492227090.0, "created_utc": 1492198290.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 25}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbr502", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "addher", "parent_id": "t1_dgb1k4o", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That's the entire point. It's not built on a racist model. Any prejudice comes in when it's calibrated. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That&amp;#39;s the entire point. It&amp;#39;s not built on a racist model. Any prejudice comes in when it&amp;#39;s calibrated. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbr502", "score_hidden": false, "stickied": false, "created": 1492350726.0, "created_utc": 1492321926.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb1k4o", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dg9c80l", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If AI determines that black people like Hip Hop, is it a \"racist\" AI built on a \"biased\" model?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If AI determines that black people like Hip Hop, is it a &amp;quot;racist&amp;quot; AI built on a &amp;quot;biased&amp;quot; model?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb1k4o", "score_hidden": false, "stickied": false, "created": 1492312675.0, "created_utc": 1492283875.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgap97r", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Zenitram", "parent_id": "t1_dg9c80l", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Because AI isn't a thing at all. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because AI isn&amp;#39;t a thing at all. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgap97r", "score_hidden": false, "stickied": false, "created": 1492295526.0, "created_utc": 1492266726.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9c80l", "gilded": 0, "archived": false, "score": 83, "report_reasons": null, "author": "addher", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This is a misleading headline. Mining data sets that are made by humans will make a biased model. This isn't \"AI taking on a life of its own,\" it's quite the opposite. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is a misleading headline. Mining data sets that are made by humans will make a biased model. This isn&amp;#39;t &amp;quot;AI taking on a life of its own,&amp;quot; it&amp;#39;s quite the opposite. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9c80l", "score_hidden": false, "stickied": false, "created": 1492215194.0, "created_utc": 1492186394.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 83}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbrhpj", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgbo2j3", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "What do you mean by \"biased society?\" ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What do you mean by &amp;quot;biased society?&amp;quot; &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbrhpj", "score_hidden": false, "stickied": false, "created": 1492351512.0, "created_utc": 1492322712.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbo2j3", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Chii", "parent_id": "t1_dgb1l1r", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "but the coder didn't write that into the code, it's emergent from the sampling and data, which, if carefully selected to be randomized across society, will mean that we do have a biased society!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;but the coder didn&amp;#39;t write that into the code, it&amp;#39;s emergent from the sampling and data, which, if carefully selected to be randomized across society, will mean that we do have a biased society!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbo2j3", "score_hidden": false, "stickied": false, "created": 1492344984.0, "created_utc": 1492316184.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgcho0s", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dgbx0o2", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Data are never \"pure\". We always have noise, errors mistakes that slightly clouds the metrics.\n\nIt isn't noise, or an error though. Black people *do* like Hip Hop. The AI just detected it. That's my point.\n\n&gt; My experience with coders is that they are as scientific as an integrist priest.\n\nCoders aren't \"computer scientists.\" What coders are doing isn't really \"science.\" It's more like engineering or a trade than science.\n\n&gt; I have been scolded multiple times in CS for having critical thinking and cleaning data.\n\nMaybe you had bad teachers.\n\nI agree a lot of CS academia is filled with idiots.\n\n&gt; The problem in CS is not in the tools, nor exactly in the data, it is the fact that the S in computer Science is a complete utter BS lie.\n\nMaybe. I'm not sure. \n\nI think there should be more focus on software engineering than computer science. Most of what people learn in CS isn't relevant to a job. There's a lot of math and proofs, etc. I think \"software engineering\" or \"software development\" should be the focus instead of CS. I'm not sure how good those programs are because they're less common.\n\n&gt; I am totally distrusting most the machine learning hype, because of its lack of scientific mind.\n\nYeah, so am I. I actually work in a closely related industry and have seen it from the inside. I do think it is an interesting industry, but the hype is just a bit bigger than the reality. \n\nThere's offices in SF full of morons who don't know how to code (and also don't have a scientific mind) getting paid $100k+ to fuck around with python libraries.\n\n&gt; Without this, AI is basically non scientific and an intellectual fraud.\n\nI wouldn't go that far. The technology is getting better. There is incremental progress, which is typical in engineering.\n\nAnd you're actually not completely correct. AI research does have stuff like margin of errors and other statistics related to their algorithms. They also have experiments that show how the algorithm reacts to certain stimuli, etc.\n\nSo, AI isn't totally unscientific. A lot of \"CS\" is unscientific, because a lot of it is really software engineering.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Data are never &amp;quot;pure&amp;quot;. We always have noise, errors mistakes that slightly clouds the metrics.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It isn&amp;#39;t noise, or an error though. Black people &lt;em&gt;do&lt;/em&gt; like Hip Hop. The AI just detected it. That&amp;#39;s my point.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My experience with coders is that they are as scientific as an integrist priest.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Coders aren&amp;#39;t &amp;quot;computer scientists.&amp;quot; What coders are doing isn&amp;#39;t really &amp;quot;science.&amp;quot; It&amp;#39;s more like engineering or a trade than science.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I have been scolded multiple times in CS for having critical thinking and cleaning data.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Maybe you had bad teachers.&lt;/p&gt;\n\n&lt;p&gt;I agree a lot of CS academia is filled with idiots.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The problem in CS is not in the tools, nor exactly in the data, it is the fact that the S in computer Science is a complete utter BS lie.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Maybe. I&amp;#39;m not sure. &lt;/p&gt;\n\n&lt;p&gt;I think there should be more focus on software engineering than computer science. Most of what people learn in CS isn&amp;#39;t relevant to a job. There&amp;#39;s a lot of math and proofs, etc. I think &amp;quot;software engineering&amp;quot; or &amp;quot;software development&amp;quot; should be the focus instead of CS. I&amp;#39;m not sure how good those programs are because they&amp;#39;re less common.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;I am totally distrusting most the machine learning hype, because of its lack of scientific mind.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Yeah, so am I. I actually work in a closely related industry and have seen it from the inside. I do think it is an interesting industry, but the hype is just a bit bigger than the reality. &lt;/p&gt;\n\n&lt;p&gt;There&amp;#39;s offices in SF full of morons who don&amp;#39;t know how to code (and also don&amp;#39;t have a scientific mind) getting paid $100k+ to fuck around with python libraries.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Without this, AI is basically non scientific and an intellectual fraud.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I wouldn&amp;#39;t go that far. The technology is getting better. There is incremental progress, which is typical in engineering.&lt;/p&gt;\n\n&lt;p&gt;And you&amp;#39;re actually not completely correct. AI research does have stuff like margin of errors and other statistics related to their algorithms. They also have experiments that show how the algorithm reacts to certain stimuli, etc.&lt;/p&gt;\n\n&lt;p&gt;So, AI isn&amp;#39;t totally unscientific. A lot of &amp;quot;CS&amp;quot; is unscientific, because a lot of it is really software engineering.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgcho0s", "score_hidden": false, "stickied": false, "created": 1492401594.0, "created_utc": 1492372794.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbx0o2", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "SFJulie", "parent_id": "t1_dgb1l1r", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I used to make science in a lab with gloves, glasses, instruments, computers.\n\nData are never \"pure\". We always have noise, errors mistakes that slightly clouds the metrics.\n\nOne of the most time consuming and boring part of science is understanding the setup, confronting it to reality/what is expected, retreating your data to clean them.\n\nMy experience with coders is that they are as scientific as an integrist priest.\n\nThey tend to believe so much in the greatness of their tools they lack a tad of critical thinking regarding their results.\n\nI have been scolded multiple times in CS for having critical thinking and cleaning data.\n\nThe problem in CS is not in the tools, nor exactly in the data, it is the fact that the S in computer Science is a complete utter BS lie.\n\nThey lack any scientific mindset, and see the time to clean data, check, doubt as a hinder that prevent progress.\n\nI am totally distrusting most the machine learning hype, because of its lack of scientific mind.\n\nFor instance, not a single article tends to talk about a very important point in science which is the margin of errors, and the costs in true/false detection. \n\nWithout this, AI is basically non scientific and an intellectual fraud.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I used to make science in a lab with gloves, glasses, instruments, computers.&lt;/p&gt;\n\n&lt;p&gt;Data are never &amp;quot;pure&amp;quot;. We always have noise, errors mistakes that slightly clouds the metrics.&lt;/p&gt;\n\n&lt;p&gt;One of the most time consuming and boring part of science is understanding the setup, confronting it to reality/what is expected, retreating your data to clean them.&lt;/p&gt;\n\n&lt;p&gt;My experience with coders is that they are as scientific as an integrist priest.&lt;/p&gt;\n\n&lt;p&gt;They tend to believe so much in the greatness of their tools they lack a tad of critical thinking regarding their results.&lt;/p&gt;\n\n&lt;p&gt;I have been scolded multiple times in CS for having critical thinking and cleaning data.&lt;/p&gt;\n\n&lt;p&gt;The problem in CS is not in the tools, nor exactly in the data, it is the fact that the S in computer Science is a complete utter BS lie.&lt;/p&gt;\n\n&lt;p&gt;They lack any scientific mindset, and see the time to clean data, check, doubt as a hinder that prevent progress.&lt;/p&gt;\n\n&lt;p&gt;I am totally distrusting most the machine learning hype, because of its lack of scientific mind.&lt;/p&gt;\n\n&lt;p&gt;For instance, not a single article tends to talk about a very important point in science which is the margin of errors, and the costs in true/false detection. &lt;/p&gt;\n\n&lt;p&gt;Without this, AI is basically non scientific and an intellectual fraud.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbx0o2", "score_hidden": false, "stickied": false, "created": 1492368183.0, "created_utc": 1492339383.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb1l1r", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dg9dyif", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If AI determines that black people like Hip Hop, is that evidence of bias in the learning data or the coder being racist?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If AI determines that black people like Hip Hop, is that evidence of bias in the learning data or the coder being racist?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb1l1r", "score_hidden": false, "stickied": false, "created": 1492312708.0, "created_utc": 1492283908.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9dyif", "gilded": 0, "archived": false, "score": 38, "report_reasons": null, "author": "SFJulie", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "AI are just reflecting the bias of their learning data.\nBe it data chosen by a coder being racist without knowing it, or be it with a social reality that will give biased sample.\n\nGarbage In Garbage Out ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;AI are just reflecting the bias of their learning data.\nBe it data chosen by a coder being racist without knowing it, or be it with a social reality that will give biased sample.&lt;/p&gt;\n\n&lt;p&gt;Garbage In Garbage Out &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9dyif", "score_hidden": false, "stickied": false, "created": 1492217123.0, "created_utc": 1492188323.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 38}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9ccnu", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "CaptainAdjective", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This news is hundreds of years old in any humanities subject.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This news is hundreds of years old in any humanities subject.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9ccnu", "score_hidden": false, "stickied": false, "created": 1492215328.0, "created_utc": 1492186528.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgb1lhr", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "1-1_1_-1-_1_3_12", "parent_id": "t1_dg9p7op", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Maybe blacks act differently during trials?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe blacks act differently during trials?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb1lhr", "score_hidden": false, "stickied": false, "created": 1492312726.0, "created_utc": 1492283926.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9p7op", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "CaptainMurphy111", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "I vaguely remember something about American courts using an A.I. to help calculate the harshness of the judgement and it was giving Blacks much harsher sentences even though race wasn't specifically used as an input.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I vaguely remember something about American courts using an A.I. to help calculate the harshness of the judgement and it was giving Blacks much harsher sentences even though race wasn&amp;#39;t specifically used as an input.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9p7op", "score_hidden": false, "stickied": false, "created": 1492230438.0, "created_utc": 1492201638.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9tj5g", "gilded": 0, "archived": false, "score": 10, "report_reasons": null, "author": "LossFor", "parent_id": "t1_dg9a4tb", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "If only there were any field dedicated to examining, studying, debating, archiving, and criticizing human notions of morality and ethics at large...\n\nFund STEM! Cut all those other non-productive colleges!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If only there were any field dedicated to examining, studying, debating, archiving, and criticizing human notions of morality and ethics at large...&lt;/p&gt;\n\n&lt;p&gt;Fund STEM! Cut all those other non-productive colleges!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9tj5g", "score_hidden": false, "stickied": false, "created": 1492235843.0, "created_utc": 1492207043.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 10}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgb9xpv", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ArkyBeagle", "parent_id": "t1_dgae551", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "At least at this writing, the is-ought problem exists. And it's anything but clear that consciousness even  exists objectively. \n\nThis puts his statements in the \"luminiferous aether\" realm. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;At least at this writing, the is-ought problem exists. And it&amp;#39;s anything but clear that consciousness even  exists objectively. &lt;/p&gt;\n\n&lt;p&gt;This puts his statements in the &amp;quot;luminiferous aether&amp;quot; realm. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgb9xpv", "score_hidden": false, "stickied": false, "created": 1492324201.0, "created_utc": 1492295401.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgae551", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "renatoathaydes", "parent_id": "t1_dg9d6pd", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "There is an argument for objective morals: https://www.youtube.com/watch?v=Hj9oB4zpHww", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There is an argument for objective morals: &lt;a href=\"https://www.youtube.com/watch?v=Hj9oB4zpHww\"&gt;https://www.youtube.com/watch?v=Hj9oB4zpHww&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgae551", "score_hidden": false, "stickied": false, "created": 1492267403.0, "created_utc": 1492238603.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9dz1p", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "tambry", "parent_id": "t1_dg9d6pd", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Fixed that, thank you.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fixed that, thank you.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9dz1p", "score_hidden": false, "stickied": false, "created": 1492217140.0, "created_utc": 1492188340.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9d6pd", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "ArkyBeagle", "parent_id": "t1_dg9a4tb", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Fairly? Try \"nearly completely\". ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fairly? Try &amp;quot;nearly completely&amp;quot;. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9d6pd", "score_hidden": false, "stickied": false, "created": 1492216250.0, "created_utc": 1492187450.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9a4tb", "gilded": 0, "archived": false, "score": 26, "report_reasons": null, "author": "tambry", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; A danger would be if you had an AI system that didn\u2019t have an explicit part that was driven by moral ideas, that would be bad\n\nThere's no such things as morals for a computer. It will do exactly as it was programmed to do. Except if you want to program morals, but there's no way that could possibly go wrong, right?\n\nMight also be worth noting that morals are ~~fairly~~ subjective.", "edited": 1492188323.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;A danger would be if you had an AI system that didn\u2019t have an explicit part that was driven by moral ideas, that would be bad&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;There&amp;#39;s no such things as morals for a computer. It will do exactly as it was programmed to do. Except if you want to program morals, but there&amp;#39;s no way that could possibly go wrong, right?&lt;/p&gt;\n\n&lt;p&gt;Might also be worth noting that morals are &lt;del&gt;fairly&lt;/del&gt; subjective.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9a4tb", "score_hidden": false, "stickied": false, "created": 1492212806.0, "created_utc": 1492184006.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 26}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgahco9", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "SentientEnglishman", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This will just give credence to people who don't understand the field. There are already too many people demanding things that make no sense of computer scientists just because it upsets them. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This will just give credence to people who don&amp;#39;t understand the field. There are already too many people demanding things that make no sense of computer scientists just because it upsets them. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgahco9", "score_hidden": false, "stickied": false, "created": 1492276443.0, "created_utc": 1492247643.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9a2hs", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "BadGoyWithAGun", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Microsoft was too far ahead of its time, but Tay.ai running everything is clearly the future.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Microsoft was too far ahead of its time, but Tay.ai running everything is clearly the future.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9a2hs", "score_hidden": false, "stickied": false, "created": 1492212730.0, "created_utc": 1492183930.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9x69a", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "QueenLa3fah", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Sounds like both a serious problem and an interesting tool to potentially combat prejudices we as a society don't notice. Some examples would be cool though. The article was vague besides the one mention that men were more associated with math and science and women more with arts, humanities and the home. Not to sound mean, but I could have told you these prejudice associations exist within our society.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Sounds like both a serious problem and an interesting tool to potentially combat prejudices we as a society don&amp;#39;t notice. Some examples would be cool though. The article was vague besides the one mention that men were more associated with math and science and women more with arts, humanities and the home. Not to sound mean, but I could have told you these prejudice associations exist within our society.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9x69a", "score_hidden": false, "stickied": false, "created": 1492240710.0, "created_utc": 1492211910.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9p0fj", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "autotldr", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "This is the best tl;dr I could make, [original](https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals) reduced by 88%. (I'm a bot)\n*****\n&gt; The research, published in the journal Science, focuses on a machine learning tool known as &amp;quot;Word embedding&amp;quot;, which is already transforming the way computers interpret speech and text.\n\n&gt; In the mathematical &amp;quot;Language space&amp;quot;, words for flowers are clustered closer to words linked to pleasantness, while words for insects are closer to words linked to unpleasantness, reflecting common views on the relative merits of insects versus flowers.\n\n&gt; The AI system was more likely to associate European American names with pleasant words such as &amp;quot;Gift&amp;quot; or &amp;quot;Happy&amp;quot;, while African American names were more commonly associated with unpleasant words.\n\n\n*****\n[**Extended Summary**](http://np.reddit.com/r/autotldr/comments/65ez1t/xpost_rcogsci_ai_programs_exhibit_racial_and/) | [FAQ](http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/ \"Version 1.65, ~102257 tl;drs so far.\") | [Theory](http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/) | [Feedback](http://np.reddit.com/message/compose?to=%23autotldr \"PM's and comments are monitored, constructive feedback is welcome.\") | *Top* *keywords*: **Word**^#1 **algorithm**^#2 **language**^#3 **biases**^#4 **machine**^#5", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the best tl;dr I could make, &lt;a href=\"https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals\"&gt;original&lt;/a&gt; reduced by 88%. (I&amp;#39;m a bot)&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;The research, published in the journal Science, focuses on a machine learning tool known as &amp;quot;Word embedding&amp;quot;, which is already transforming the way computers interpret speech and text.&lt;/p&gt;\n\n&lt;p&gt;In the mathematical &amp;quot;Language space&amp;quot;, words for flowers are clustered closer to words linked to pleasantness, while words for insects are closer to words linked to unpleasantness, reflecting common views on the relative merits of insects versus flowers.&lt;/p&gt;\n\n&lt;p&gt;The AI system was more likely to associate European American names with pleasant words such as &amp;quot;Gift&amp;quot; or &amp;quot;Happy&amp;quot;, while African American names were more commonly associated with unpleasant words.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;&lt;a href=\"http://np.reddit.com/r/autotldr/comments/65ez1t/xpost_rcogsci_ai_programs_exhibit_racial_and/\"&gt;&lt;strong&gt;Extended Summary&lt;/strong&gt;&lt;/a&gt; | &lt;a href=\"http://np.reddit.com/r/autotldr/comments/31b9fm/faq_autotldr_bot/\" title=\"Version 1.65, ~102257 tl;drs so far.\"&gt;FAQ&lt;/a&gt; | &lt;a href=\"http://np.reddit.com/r/autotldr/comments/31bfht/theory_autotldr_concept/\"&gt;Theory&lt;/a&gt; | &lt;a href=\"http://np.reddit.com/message/compose?to=%23autotldr\" title=\"PM&amp;#39;s and comments are monitored, constructive feedback is welcome.\"&gt;Feedback&lt;/a&gt; | &lt;em&gt;Top&lt;/em&gt; &lt;em&gt;keywords&lt;/em&gt;: &lt;strong&gt;Word&lt;/strong&gt;&lt;sup&gt;#1&lt;/sup&gt; &lt;strong&gt;algorithm&lt;/strong&gt;&lt;sup&gt;#2&lt;/sup&gt; &lt;strong&gt;language&lt;/strong&gt;&lt;sup&gt;#3&lt;/sup&gt; &lt;strong&gt;biases&lt;/strong&gt;&lt;sup&gt;#4&lt;/sup&gt; &lt;strong&gt;machine&lt;/strong&gt;&lt;sup&gt;#5&lt;/sup&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9p0fj", "score_hidden": false, "stickied": false, "created": 1492230194.0, "created_utc": 1492201394.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dga7v1h", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Wozzle90", "parent_id": "t1_dga6xt0", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "That is an excellent diagram. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That is an excellent diagram. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga7v1h", "score_hidden": false, "stickied": false, "created": 1492255538.0, "created_utc": 1492226738.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6xt0", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "kamatsu", "parent_id": "t1_dg9zi69", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Comments in this thread are basically arguing [this](https://pbs.twimg.com/media/C3RcI-hVUAA_VM5.jpg). Ugh.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Comments in this thread are basically arguing &lt;a href=\"https://pbs.twimg.com/media/C3RcI-hVUAA_VM5.jpg\"&gt;this&lt;/a&gt;. Ugh.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dga6xt0", "score_hidden": false, "stickied": false, "created": 1492254109.0, "created_utc": 1492225309.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 8}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9zi69", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Wozzle90", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Abandon these comments, all ye who enter. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Abandon these comments, all ye who enter. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9zi69", "score_hidden": false, "stickied": false, "created": 1492243795.0, "created_utc": 1492214995.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgasi9o", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "sir0k0", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "AI programs are simply showing the world as it is.\nThat's what some people can't accept.\nThe statistical and physical reality of this world. Which does not match with their own stereotypes.\n\nIt reminds me of this internet survey which was carried out as part of the documentary \"Are All Men Pedophiles?\". \nMen were shown pictures of females without being informed of their age and asked if they found them sexually desirable or not. Girls about 14 got the highest ratings.\nIn a more serious and academical study, men were asked to manipulate a computer generated female face until they thought it was ideal and the most attractive. The face they all came up with had the dimensions seen in the faces of girls in their early teens - about 13.\n\nAs our society couldn't accept the fact that 14yo girls were (statistically) the most sexually attractive women, they financed bullshit biased studies claiming that women in their 30s were the most attractive ...", "edited": 1492272735.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;AI programs are simply showing the world as it is.\nThat&amp;#39;s what some people can&amp;#39;t accept.\nThe statistical and physical reality of this world. Which does not match with their own stereotypes.&lt;/p&gt;\n\n&lt;p&gt;It reminds me of this internet survey which was carried out as part of the documentary &amp;quot;Are All Men Pedophiles?&amp;quot;. \nMen were shown pictures of females without being informed of their age and asked if they found them sexually desirable or not. Girls about 14 got the highest ratings.\nIn a more serious and academical study, men were asked to manipulate a computer generated female face until they thought it was ideal and the most attractive. The face they all came up with had the dimensions seen in the faces of girls in their early teens - about 13.&lt;/p&gt;\n\n&lt;p&gt;As our society couldn&amp;#39;t accept the fact that 14yo girls were (statistically) the most sexually attractive women, they financed bullshit biased studies claiming that women in their 30s were the most attractive ...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgasi9o", "score_hidden": false, "stickied": false, "created": 1492300279.0, "created_utc": 1492271479.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9arjh", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "KayRice", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Skipped it when I saw it was a mainstream news site that won't cover the topic more than a few quips to keep me on the page while ads are blasted.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Skipped it when I saw it was a mainstream news site that won&amp;#39;t cover the topic more than a few quips to keep me on the page while ads are blasted.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9arjh", "score_hidden": false, "stickied": false, "created": 1492213542.0, "created_utc": 1492184742.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgatfl0", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "corysama", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "https://weaponsofmathdestructionbook.com is about this and how it is causing governments to accidentally recursively reinforce stereotypes and biases in laws and enforcement.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://weaponsofmathdestructionbook.com\"&gt;https://weaponsofmathdestructionbook.com&lt;/a&gt; is about this and how it is causing governments to accidentally recursively reinforce stereotypes and biases in laws and enforcement.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgatfl0", "score_hidden": false, "stickied": false, "created": 1492301554.0, "created_utc": 1492272754.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgba27i", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "GreenTeaOnMyDesk", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Another word for bias is: information", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Another word for bias is: information&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgba27i", "score_hidden": false, "stickied": false, "created": 1492324380.0, "created_utc": 1492295580.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dge2m6d", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Yelnik", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Oh lord, keep the psychotic regressive leftists away from my programming please.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh lord, keep the psychotic regressive leftists away from my programming please.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dge2m6d", "score_hidden": false, "stickied": false, "created": 1492489907.0, "created_utc": 1492461107.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgaj1b5", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "vattenpuss", "parent_id": "t1_dgagh0m", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Not exactly what? I did not write that any algorithms were racist.\n\n&gt; In many approaches you do not put explicit things like gender or race, but the algorithm might discover them on its own if they improve its scores.\n\nIt doesn't matter if we are explicit or not, humans create the data, and humans pick data to feed the machines. Biases in humans who create the data and in the humans who select the data to train on will be encoded in the programs.\n\n&gt;  So it is not easy to debias a dataset.\n\nExactly.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not exactly what? I did not write that any algorithms were racist.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;In many approaches you do not put explicit things like gender or race, but the algorithm might discover them on its own if they improve its scores.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;It doesn&amp;#39;t matter if we are explicit or not, humans create the data, and humans pick data to feed the machines. Biases in humans who create the data and in the humans who select the data to train on will be encoded in the programs.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;So it is not easy to debias a dataset.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Exactly.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaj1b5", "score_hidden": false, "stickied": false, "created": 1492281843.0, "created_utc": 1492253043.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgagh0m", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "cybelechild", "parent_id": "t1_dg9a2nr", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Not exactly. These algorithms are not sexist, or racist or anything. They are just a set of instructions that discover patterns in the data you feed them. In many approaches you do not put explicit things like gender or race, but the algorithm might discover them on its own if they improve its scores. And while there is indeed a problem with bias in the data, there is also the question what differences are due to bias proper, and what simply reflect the state of reality. So it is not easy to debias a dataset. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not exactly. These algorithms are not sexist, or racist or anything. They are just a set of instructions that discover patterns in the data you feed them. In many approaches you do not put explicit things like gender or race, but the algorithm might discover them on its own if they improve its scores. And while there is indeed a problem with bias in the data, there is also the question what differences are due to bias proper, and what simply reflect the state of reality. So it is not easy to debias a dataset. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgagh0m", "score_hidden": false, "stickied": false, "created": 1492273671.0, "created_utc": 1492244871.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9a2nr", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "vattenpuss", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "This is the first interesting machine learning discussion I have seen in a *very* long time.\n\nI have no idea what the best lessons we can learn from this is, but we can obviously learn a lot about many types of prejudice that we don't think of on a daily basis.\n\nI don't know why I'm surprised about the research and didn't see this coming, it's so obvious that we will teach machines bad habits if we train them on our own bad behavior. I guess I have some deeply ingrained prejudices myself about researchers in computing.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the first interesting machine learning discussion I have seen in a &lt;em&gt;very&lt;/em&gt; long time.&lt;/p&gt;\n\n&lt;p&gt;I have no idea what the best lessons we can learn from this is, but we can obviously learn a lot about many types of prejudice that we don&amp;#39;t think of on a daily basis.&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t know why I&amp;#39;m surprised about the research and didn&amp;#39;t see this coming, it&amp;#39;s so obvious that we will teach machines bad habits if we train them on our own bad behavior. I guess I have some deeply ingrained prejudices myself about researchers in computing.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9a2nr", "score_hidden": false, "stickied": false, "created": 1492212736.0, "created_utc": 1492183936.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 0}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9qizd", "gilded": 0, "archived": false, "score": -8, "report_reasons": null, "author": "TiCL", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "Deploy SJW bots!!!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Deploy SJW bots!!!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9qizd", "score_hidden": false, "stickied": false, "created": 1492232023.0, "created_utc": 1492203223.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -8}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9dg2j", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "OneBigBug", "parent_id": "t1_dg9cjoo", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "What the article about and what your comment were about are very different things. I was responding to your comment (before you edited it).\n\nIf we're purely discussing the article, your comment is largely irrelevant. Word embeddings aren't \"training models based on sex\", they're just looking at what words are typically associated with each other. They are sex-blind, and only expose connections as they are formed based on natural language. They don't understand the words, no one made any sex-based models. The only way to not \"train models based on sex\" as it applies to this article would be to strip out all writings which use gendered pronouns and all names. Good luck with that. The article is saying \"hey, we found some sex-based words have associations which imply something bad about us.\" That's it.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What the article about and what your comment were about are very different things. I was responding to your comment (before you edited it).&lt;/p&gt;\n\n&lt;p&gt;If we&amp;#39;re purely discussing the article, your comment is largely irrelevant. Word embeddings aren&amp;#39;t &amp;quot;training models based on sex&amp;quot;, they&amp;#39;re just looking at what words are typically associated with each other. They are sex-blind, and only expose connections as they are formed based on natural language. They don&amp;#39;t understand the words, no one made any sex-based models. The only way to not &amp;quot;train models based on sex&amp;quot; as it applies to this article would be to strip out all writings which use gendered pronouns and all names. Good luck with that. The article is saying &amp;quot;hey, we found some sex-based words have associations which imply something bad about us.&amp;quot; That&amp;#39;s it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9dg2j", "score_hidden": false, "stickied": false, "created": 1492216545.0, "created_utc": 1492187745.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 12}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9cjoo", "gilded": 0, "archived": false, "score": -10, "report_reasons": null, "author": "bro-away-", "parent_id": "t1_dg9bxgc", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt;Not the same person, but it seems to me that the meaning was that, for example, women's interests tend to be humanities focused, so you're reinforcing prior generations' tendencies regardless, even if you just use the first 5 topics she follows. Because those topic interests are informed by prior generations' tendencies. Even if you ignore the little \"F\" or \"M\", you're going to be reinforcing the biases anyway simply by giving people what they want.\n\nThe article isn't about gender roles based on choices the person has made in life, it's about the bias what machine learning has concluded from their data.   Throwing your hands in the air and saying \"well, gender roles exist in society anyway so let's embrace whatever the AI sees fit\" adds nothing to the discussion at hand.  The article wouldn't have been written if this were the conclusion.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Not the same person, but it seems to me that the meaning was that, for example, women&amp;#39;s interests tend to be humanities focused, so you&amp;#39;re reinforcing prior generations&amp;#39; tendencies regardless, even if you just use the first 5 topics she follows. Because those topic interests are informed by prior generations&amp;#39; tendencies. Even if you ignore the little &amp;quot;F&amp;quot; or &amp;quot;M&amp;quot;, you&amp;#39;re going to be reinforcing the biases anyway simply by giving people what they want.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The article isn&amp;#39;t about gender roles based on choices the person has made in life, it&amp;#39;s about the bias what machine learning has concluded from their data.   Throwing your hands in the air and saying &amp;quot;well, gender roles exist in society anyway so let&amp;#39;s embrace whatever the AI sees fit&amp;quot; adds nothing to the discussion at hand.  The article wouldn&amp;#39;t have been written if this were the conclusion.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9cjoo", "score_hidden": false, "stickied": false, "created": 1492215543.0, "created_utc": 1492186743.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": -10}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9bxgc", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "OneBigBug", "parent_id": "t1_dg9bg9v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Not the same person, but it seems to me that the meaning was that, for example, women's interests tend to be humanities focused, so you're reinforcing prior generations' tendencies regardless, even if you just use the first 5 topics she follows. Because those topic interests are informed by prior generations' tendencies. Even if you ignore the little \"F\" or \"M\", you're going to be reinforcing the biases anyway simply by giving people what they want.\n\nAt a certain point, if our society decides it is unacceptable that men are more interested in engineering (or whatever) than women, we have to commit to the decision that we're going to be giving them stuff they (as a general collective) don't really want, and that it is not generally the fault of extant tech megacorps that they don't want it.\n\nNot only is it against the interests of these social media giants to not give people what they want, I'm not sure that it is more morally sound to intentionally be less good at predicting what they want in the interest of steering them in a particular direction.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not the same person, but it seems to me that the meaning was that, for example, women&amp;#39;s interests tend to be humanities focused, so you&amp;#39;re reinforcing prior generations&amp;#39; tendencies regardless, even if you just use the first 5 topics she follows. Because those topic interests are informed by prior generations&amp;#39; tendencies. Even if you ignore the little &amp;quot;F&amp;quot; or &amp;quot;M&amp;quot;, you&amp;#39;re going to be reinforcing the biases anyway simply by giving people what they want.&lt;/p&gt;\n\n&lt;p&gt;At a certain point, if our society decides it is unacceptable that men are more interested in engineering (or whatever) than women, we have to commit to the decision that we&amp;#39;re going to be giving them stuff they (as a general collective) don&amp;#39;t really want, and that it is not generally the fault of extant tech megacorps that they don&amp;#39;t want it.&lt;/p&gt;\n\n&lt;p&gt;Not only is it against the interests of these social media giants to not give people what they want, I&amp;#39;m not sure that it is more morally sound to intentionally be less good at predicting what they want in the interest of steering them in a particular direction.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9bxgc", "score_hidden": false, "stickied": false, "created": 1492214874.0, "created_utc": 1492186074.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 11}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9bg9v", "gilded": 0, "archived": false, "score": -9, "report_reasons": null, "author": "bro-away-", "parent_id": "t1_dg9aocr", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Give concrete examples if you make this claim.  Other than name and sex where are all the implicit biases for sex?   Should be simple to give an example if it's chock-full...\n\n&gt;and people's behaviours are also informed/oriented by existing biases rather than being neutral\n\nThis isn't up to the AI to correct for.  If a female joins your social network and immediately begins liking tons of pages about cooking, the future suggestions will be cooking.  The AI can't go back in time and not push this person toward a typical gender role...", "edited": 1492186162.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Give concrete examples if you make this claim.  Other than name and sex where are all the implicit biases for sex?   Should be simple to give an example if it&amp;#39;s chock-full...&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;and people&amp;#39;s behaviours are also informed/oriented by existing biases rather than being neutral&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;This isn&amp;#39;t up to the AI to correct for.  If a female joins your social network and immediately begins liking tons of pages about cooking, the future suggestions will be cooking.  The AI can&amp;#39;t go back in time and not push this person toward a typical gender role...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9bg9v", "score_hidden": false, "stickied": false, "created": 1492214336.0, "created_utc": 1492185536.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": -9}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9aocr", "gilded": 0, "archived": false, "score": 20, "report_reasons": null, "author": "masklinn", "parent_id": "t1_dg9aj8k", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Simple solution : don't train models based on sex or you'll just be reinforcing the prior generations tendencies on the next.\n\nThe problem is that many data corpus are chock-full of implicit bias, and people's behaviours are also informed/oriented by existing biases rather than being neutral. You don't have to explicitly train models based on sex to hit the issue.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Simple solution : don&amp;#39;t train models based on sex or you&amp;#39;ll just be reinforcing the prior generations tendencies on the next.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;The problem is that many data corpus are chock-full of implicit bias, and people&amp;#39;s behaviours are also informed/oriented by existing biases rather than being neutral. You don&amp;#39;t have to explicitly train models based on sex to hit the issue.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9aocr", "score_hidden": false, "stickied": false, "created": 1492213440.0, "created_utc": 1492184640.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 20}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgal6ko", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "pipocaQuemada", "parent_id": "t1_dg9aj8k", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; The research, published in the journal Science, focuses on a machine learning tool known as \u201cword embedding\u201d\n\nThey're not training models based on sex.\n\nThey're taking large amounts of text and seeing how words are used.  A famous example of this sort of approach to computational linguistics is that king - man + woman = queen, or Paris - France + US = Washington DC.  \n\nThis is acknowledging that this sort of approach will learn some of the biases in the underlying data set.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The research, published in the journal Science, focuses on a machine learning tool known as \u201cword embedding\u201d&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;They&amp;#39;re not training models based on sex.&lt;/p&gt;\n\n&lt;p&gt;They&amp;#39;re taking large amounts of text and seeing how words are used.  A famous example of this sort of approach to computational linguistics is that king - man + woman = queen, or Paris - France + US = Washington DC.  &lt;/p&gt;\n\n&lt;p&gt;This is acknowledging that this sort of approach will learn some of the biases in the underlying data set.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgal6ko", "score_hidden": false, "stickied": false, "created": 1492287746.0, "created_utc": 1492258946.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgagjcs", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "cybelechild", "parent_id": "t1_dg9aj8k", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "&gt; Don't train models based on sex or you'll just be reinforcing the prior generations tendencies on the next.\n\nIn models like word2vec you do not train a model based on sex. You just feed it a ton of text on all kinds of topics, and it learns a bunch of numbers that define each word. Because of language and its use, things like \"woman\" and \"female\" end up having numbers that are closer to each other than say \"woman\" and \"dog\". In some cases these will capture actual bias, in others they will reflect real(-ish) distributions. So the thing does not become biased itself, it just gets really good at reflecting an already biased society. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Don&amp;#39;t train models based on sex or you&amp;#39;ll just be reinforcing the prior generations tendencies on the next.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;In models like word2vec you do not train a model based on sex. You just feed it a ton of text on all kinds of topics, and it learns a bunch of numbers that define each word. Because of language and its use, things like &amp;quot;woman&amp;quot; and &amp;quot;female&amp;quot; end up having numbers that are closer to each other than say &amp;quot;woman&amp;quot; and &amp;quot;dog&amp;quot;. In some cases these will capture actual bias, in others they will reflect real(-ish) distributions. So the thing does not become biased itself, it just gets really good at reflecting an already biased society. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgagjcs", "score_hidden": false, "stickied": false, "created": 1492273873.0, "created_utc": 1492245073.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9aj8k", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "bro-away-", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "&gt;The words \u201cfemale\u201d and \u201cwoman\u201d were more closely associated with arts and humanities occupations and with the home, while \u201cmale\u201d and \u201cman\u201d were closer to maths and engineering professions\n\nDon't train models based on sex or you'll just be reinforcing the prior generations tendencies on the next. \n\nExample : if a girl joins twitter, is she suggested people to follow (partially) based on being a girl or based on something like the first 5 topics she follows?  \n\nYes there are fewer female engineers than male but AI shouldn't push anyone into a direction that is going to have bias by sex.\n\nIt's actually a pretty fucked up scenario I've not ever considered.   Another reason not to give big tech companies more information than you need to :)", "edited": 1492186971.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;The words \u201cfemale\u201d and \u201cwoman\u201d were more closely associated with arts and humanities occupations and with the home, while \u201cmale\u201d and \u201cman\u201d were closer to maths and engineering professions&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Don&amp;#39;t train models based on sex or you&amp;#39;ll just be reinforcing the prior generations tendencies on the next. &lt;/p&gt;\n\n&lt;p&gt;Example : if a girl joins twitter, is she suggested people to follow (partially) based on being a girl or based on something like the first 5 topics she follows?  &lt;/p&gt;\n\n&lt;p&gt;Yes there are fewer female engineers than male but AI shouldn&amp;#39;t push anyone into a direction that is going to have bias by sex.&lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s actually a pretty fucked up scenario I&amp;#39;ve not ever considered.   Another reason not to give big tech companies more information than you need to :)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9aj8k", "score_hidden": false, "stickied": false, "created": 1492213277.0, "created_utc": 1492184477.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgaa28e", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "RoundDuckMan", "parent_id": "t1_dg9p3rl", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "What makes you think that? They pretty much do that, due to biases in language.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What makes you think that? They pretty much do that, due to biases in language.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgaa28e", "score_hidden": false, "stickied": false, "created": 1492259172.0, "created_utc": 1492230372.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9p3rl", "gilded": 0, "archived": false, "score": -3, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 1, "body": "[deleted]", "edited": 1492237497.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9p3rl", "score_hidden": false, "stickied": false, "created": 1492230306.0, "created_utc": 1492201506.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dgbd44c", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "TheYokai", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "Isn't the solution to this to not include any data involving race or gender? Like, if I have a database of people, if I simply do not factor in race or gender into my algorithms, then it can no longer exhibit those biases, right? I understand that in cases where the data collection itself is biased, then it can exhibit this behavior without knowing, but there's got to be a better way to qualify what data could be considered biased or not, right?\n\nI'd love to hear a more in-depth talk about this. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Isn&amp;#39;t the solution to this to not include any data involving race or gender? Like, if I have a database of people, if I simply do not factor in race or gender into my algorithms, then it can no longer exhibit those biases, right? I understand that in cases where the data collection itself is biased, then it can exhibit this behavior without knowing, but there&amp;#39;s got to be a better way to qualify what data could be considered biased or not, right?&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;d love to hear a more in-depth talk about this. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dgbd44c", "score_hidden": false, "stickied": false, "created": 1492328803.0, "created_utc": 1492300003.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 0}}, {"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2fwo", "removal_reason": null, "link_id": "t3_65d47v", "likes": null, "replies": "", "user_reports": [], "id": "dg9pku9", "gilded": 0, "archived": false, "score": -8, "report_reasons": null, "author": "2e3dabe5", "parent_id": "t1_dg9f9fw", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "oy veyyyy", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;oy veyyyy&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9pku9", "score_hidden": false, "stickied": false, "created": 1492230877.0, "created_utc": 1492202077.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -8}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9f9fw", "gilded": 0, "archived": false, "score": -15, "report_reasons": null, "author": "Oldern", "parent_id": "t3_65d47v", "subreddit_name_prefixed": "r/programming", "controversiality": 0, "body": "But I thought that such things do not exist and we should just MAN UP :D ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But I thought that such things do not exist and we should just MAN UP :D &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "programming", "name": "t1_dg9f9fw", "score_hidden": false, "stickied": false, "created": 1492218599.0, "created_utc": 1492189799.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -15}}], "after": null, "before": null}}]