[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "DepthHub", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "64y285", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 196, "report_reasons": null, "author": "HerpDerpImARedditor", "saved": false, "mod_reports": [], "name": "t3_64y285", "subreddit_name_prefixed": "r/DepthHub", "approved_by": null, "over_18": false, "domain": "reddit.com", "hidden": false, "thumbnail": "", "subreddit_id": "t5_2rmpy", "edited": false, "link_flair_css_class": null, "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/DepthHub/comments/64y285/urandomrecombination_eloquently_discusses_how/", "num_reports": null, "locked": false, "stickied": false, "created": 1492031691.0, "url": "https://www.reddit.com/r/todayilearned/comments/64tapt/til_most_birds_cant_move_their_eyes_which_are_not/dg5lhx2/", "author_flair_text": null, "quarantine": false, "title": "/u/randomrecombination eloquently discusses how digital cameras capture color", "created_utc": 1492002891.0, "distinguished": null, "media": null, "upvote_ratio": 0.86, "num_comments": 3, "visited": false, "subreddit_type": "public", "ups": 196}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2rmpy", "removal_reason": null, "link_id": "t3_64y285", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2rmpy", "removal_reason": null, "link_id": "t3_64y285", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2rmpy", "removal_reason": null, "link_id": "t3_64y285", "likes": null, "replies": "", "user_reports": [], "id": "dg78mnk", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "C0R4x", "parent_id": "t1_dg6zhau", "subreddit_name_prefixed": "r/DepthHub", "controversiality": 0, "body": "&gt; If you ever buy a laser pointer, get green- a red dot or anything else will be impossible to see from a hundred meters, but you can hit things from ten km away with a 5mW green laser.     \n\nIf you do buy a green laser pointer, buy a proper one, not some cheap Chinese import. Green lasers are \"double pumped\", which practically means that the laser first produces IR, which is then halved in wavelength, producing green. In cheap Chinese lasers, a bunch of that IR light leaks through. Meaning that you're shooting a bunch of invisible light out the front, which is generally not a good thing for anything with eyes in the neighbourhood.    ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;If you ever buy a laser pointer, get green- a red dot or anything else will be impossible to see from a hundred meters, but you can hit things from ten km away with a 5mW green laser.     &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;If you do buy a green laser pointer, buy a proper one, not some cheap Chinese import. Green lasers are &amp;quot;double pumped&amp;quot;, which practically means that the laser first produces IR, which is then halved in wavelength, producing green. In cheap Chinese lasers, a bunch of that IR light leaks through. Meaning that you&amp;#39;re shooting a bunch of invisible light out the front, which is generally not a good thing for anything with eyes in the neighbourhood.    &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "DepthHub", "name": "t1_dg78mnk", "score_hidden": false, "stickied": false, "created": 1492093271.0, "created_utc": 1492064471.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg6zhau", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "hwillis", "parent_id": "t1_dg6w4w3", "subreddit_name_prefixed": "r/DepthHub", "controversiality": 0, "body": "Addendum to your fun fact: [This image](https://en.m.wikipedia.org/wiki/High_color#/media/File%3A7bit-each.svg) is great for demonstrating the human sensitivity to green.  There are clearly visible discontinuities in the green gradient that are much harder to see in red and nearly invisible in blue.  If you ever buy a laser pointer, get green- a red dot or anything else will be impossible to see from a hundred meters, but you can hit things from ten km away with a 5mW green laser.\n\nDropping that green pixel effectively buys you a second camera with 25% resolution, which is great for computers.  With equal resolution, a black and white camera will give much more information to a computer.  This confused me at first, and it's pretty natural to assume that differentiation of objects by color is incredibly powerful.  However it's easily demonstrated that even in human vision it's way more important to preserve intensity (black and white) information.  You need very few color pixels to tell if things have different colors, but you need a LOT of intensity pixels to find corners and features.\n\nIn a very fundamental way color is actually inherently limiting.  A color pixel has to strip out every other color of light and leave a window that approximates the human eye.  A camera can even catch some near infrared in addition to normal colors, so you lose a ton, like 3/4 of the information that you could be using.  Of course you mix up all that information anyway, but since colors will tend to be somewhat correlated you're still ending up with much more information.  Not to mention that color is hugely affected by reflections or even just normal variations.  For most computer vision problems you care about finding positions and orientation, and recognizing by shape.  In a lot of situations color is a cop-outs.\n\nAlso random: I'd dropkick a baby to get a specialized camera for computer vision.  Something with an extremely high ratio of black and white to color pixels, and a much higher pixel density towards the center of the sensor.  Best case now is multiple cameras and/or stupid expensive custom lenses.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Addendum to your fun fact: &lt;a href=\"https://en.m.wikipedia.org/wiki/High_color#/media/File%3A7bit-each.svg\"&gt;This image&lt;/a&gt; is great for demonstrating the human sensitivity to green.  There are clearly visible discontinuities in the green gradient that are much harder to see in red and nearly invisible in blue.  If you ever buy a laser pointer, get green- a red dot or anything else will be impossible to see from a hundred meters, but you can hit things from ten km away with a 5mW green laser.&lt;/p&gt;\n\n&lt;p&gt;Dropping that green pixel effectively buys you a second camera with 25% resolution, which is great for computers.  With equal resolution, a black and white camera will give much more information to a computer.  This confused me at first, and it&amp;#39;s pretty natural to assume that differentiation of objects by color is incredibly powerful.  However it&amp;#39;s easily demonstrated that even in human vision it&amp;#39;s way more important to preserve intensity (black and white) information.  You need very few color pixels to tell if things have different colors, but you need a LOT of intensity pixels to find corners and features.&lt;/p&gt;\n\n&lt;p&gt;In a very fundamental way color is actually inherently limiting.  A color pixel has to strip out every other color of light and leave a window that approximates the human eye.  A camera can even catch some near infrared in addition to normal colors, so you lose a ton, like 3/4 of the information that you could be using.  Of course you mix up all that information anyway, but since colors will tend to be somewhat correlated you&amp;#39;re still ending up with much more information.  Not to mention that color is hugely affected by reflections or even just normal variations.  For most computer vision problems you care about finding positions and orientation, and recognizing by shape.  In a lot of situations color is a cop-outs.&lt;/p&gt;\n\n&lt;p&gt;Also random: I&amp;#39;d dropkick a baby to get a specialized camera for computer vision.  Something with an extremely high ratio of black and white to color pixels, and a much higher pixel density towards the center of the sensor.  Best case now is multiple cameras and/or stupid expensive custom lenses.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "DepthHub", "name": "t1_dg6zhau", "score_hidden": false, "stickied": false, "created": 1492078596.0, "created_utc": 1492049796.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 8}}], "after": null, "before": null}}, "user_reports": [], "id": "dg6w4w3", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "whiskey_bud", "parent_id": "t3_64y285", "subreddit_name_prefixed": "r/DepthHub", "controversiality": 0, "body": "I think the response is largely correct, but I really don't think it's a good explanation for the whole concept of \"how a camera captures color\". There is no mention of Bayer filters, demozaicing algorithms, chroma interpretation, etc. He also uses a whole bunch of words to basic say \"if you image wavelengths of light that aren't in the visible spectrum, it will render the colors off to the human eye\". \n\nA really good intro to explaining chroma reconstruction in digital cameras would have to start with an explanation of pixel technologies, and how pixels capture photons, but have no way of knowing what their wavelengths are once they're converted to electrical energy. Enter the color filter, which help us reconstruct chroma (via demosaicing and interpolation), but yields a pretty nasty decrease in overall sensitivity (since each pixel is all of a sudden only sensitive to light in a certain band). There is a whole science (more like an art, in my opinion) of reconstructing color from this disparate chroma data, which allows it to be most natural to the human eye. In the camera phone world, all the big players (Apple, Sony, etc.) have whole teams of people that \"color tune\" the camera software in the ISP (Image Signal Processor) so that it gives the best color result, from partial data. Actually each team takes a slightly different approach, and you can see it in side-by-side image comparisons captured with the different phones.\n\nI also don't really agree CCD's are being phased out...don't get me wrong, CCD sensor shipments are definitely fewer than CMOS these days. But the advantages of CCD (namely global shutter, among other things) mean that certain industries and applications will be willing to take the size and cost hit for them vs. CMOS.\n\nFun fact: Bayer patterns are typically RGGB (two green pixels for each red and blue pixel). Why is that? It's because the human visual cortex is more sensitive to the green channel, making it the most important channel to accurately reproduce. For cameras that aren't viewed by humans (think computer vision, etc.) you'll sometimes see RGCB (red, green, clear, blue), which hurts you in green channel color performance, but gives you way better sensitivity on that fourth pixel. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think the response is largely correct, but I really don&amp;#39;t think it&amp;#39;s a good explanation for the whole concept of &amp;quot;how a camera captures color&amp;quot;. There is no mention of Bayer filters, demozaicing algorithms, chroma interpretation, etc. He also uses a whole bunch of words to basic say &amp;quot;if you image wavelengths of light that aren&amp;#39;t in the visible spectrum, it will render the colors off to the human eye&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;A really good intro to explaining chroma reconstruction in digital cameras would have to start with an explanation of pixel technologies, and how pixels capture photons, but have no way of knowing what their wavelengths are once they&amp;#39;re converted to electrical energy. Enter the color filter, which help us reconstruct chroma (via demosaicing and interpolation), but yields a pretty nasty decrease in overall sensitivity (since each pixel is all of a sudden only sensitive to light in a certain band). There is a whole science (more like an art, in my opinion) of reconstructing color from this disparate chroma data, which allows it to be most natural to the human eye. In the camera phone world, all the big players (Apple, Sony, etc.) have whole teams of people that &amp;quot;color tune&amp;quot; the camera software in the ISP (Image Signal Processor) so that it gives the best color result, from partial data. Actually each team takes a slightly different approach, and you can see it in side-by-side image comparisons captured with the different phones.&lt;/p&gt;\n\n&lt;p&gt;I also don&amp;#39;t really agree CCD&amp;#39;s are being phased out...don&amp;#39;t get me wrong, CCD sensor shipments are definitely fewer than CMOS these days. But the advantages of CCD (namely global shutter, among other things) mean that certain industries and applications will be willing to take the size and cost hit for them vs. CMOS.&lt;/p&gt;\n\n&lt;p&gt;Fun fact: Bayer patterns are typically RGGB (two green pixels for each red and blue pixel). Why is that? It&amp;#39;s because the human visual cortex is more sensitive to the green channel, making it the most important channel to accurately reproduce. For cameras that aren&amp;#39;t viewed by humans (think computer vision, etc.) you&amp;#39;ll sometimes see RGCB (red, green, clear, blue), which hurts you in green channel color performance, but gives you way better sensitivity on that fourth pixel. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "DepthHub", "name": "t1_dg6w4w3", "score_hidden": false, "stickied": false, "created": 1492074449.0, "created_utc": 1492045649.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 15}}], "after": null, "before": null}}]