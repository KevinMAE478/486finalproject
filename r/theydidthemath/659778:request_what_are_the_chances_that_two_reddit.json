[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "theydidthemath", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;This is if each person has 80 subscriptions&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "This is if each person has 80 subscriptions", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "", "id": "659778", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 28, "report_reasons": null, "author": "ChrisHansenBait", "saved": false, "mod_reports": [], "name": "t3_659778", "subreddit_name_prefixed": "r/theydidthemath", "approved_by": null, "over_18": false, "domain": "self.theydidthemath", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2x23b", "edited": false, "link_flair_css_class": "request", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/theydidthemath/comments/659778/request_what_are_the_chances_that_two_reddit/", "num_reports": null, "locked": false, "stickied": false, "created": 1492155883.0, "url": "https://www.reddit.com/r/theydidthemath/comments/659778/request_what_are_the_chances_that_two_reddit/", "author_flair_text": null, "quarantine": false, "title": "[Request] What are the chances that two Reddit users have exactly the same subscriptions lists?", "created_utc": 1492127083.0, "distinguished": null, "media": null, "upvote_ratio": 0.81, "num_comments": 19, "visited": false, "subreddit_type": "public", "ups": 28}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg9ce7p", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "kmrst", "parent_id": "t1_dg8yn6j", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Not to mention not all users immediately edit their subs. I know a guy who has had an account for years and hasn't changed off the defaults. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not to mention not all users immediately edit their subs. I know a guy who has had an account for years and hasn&amp;#39;t changed off the defaults. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg9ce7p", "score_hidden": false, "stickied": false, "created": 1492215374.0, "created_utc": 1492186574.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8yn6j", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "hypervelocityvomit", "parent_id": "t1_dg8irdr", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "&gt; none of it is really random since users start out with the defaults\n\nSo it's almost 100% certain that two redditors with the default settings exist, at any given time.  \nIf we say that reddit gains 1% new redditors monthly, that'd be 2400,000 - or 80,000 daily, slightly less than the number of seconds per day.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;none of it is really random since users start out with the defaults&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;So it&amp;#39;s almost 100% certain that two redditors with the default settings exist, at any given time.&lt;br/&gt;\nIf we say that reddit gains 1% new redditors monthly, that&amp;#39;d be 2400,000 - or 80,000 daily, slightly less than the number of seconds per day.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8yn6j", "score_hidden": false, "stickied": false, "created": 1492191244.0, "created_utc": 1492162444.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8irdr", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "Dirtydeedsinc", "parent_id": "t1_dg8gljx", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Unfortunately none of it is really random since users start out with the defaults and then add/subtract based on hobbies, interests, seeing a sub mentioned in another sub, sub or the day, etc...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unfortunately none of it is really random since users start out with the defaults and then add/subtract based on hobbies, interests, seeing a sub mentioned in another sub, sub or the day, etc...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8irdr", "score_hidden": false, "stickied": false, "created": 1492160278.0, "created_utc": 1492131478.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 15}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg8wsr9", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "hilburn", "parent_id": "t1_dg8ws5d", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Like I need more distractions from work!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Like I need more distractions from work!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8wsr9", "score_hidden": false, "stickied": false, "created": 1492185344.0, "created_utc": 1492156544.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg8x5kk", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "hilburn", "parent_id": "t1_dg8ws5d", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Also, I'm prepared to bet 50p that there's at least one match up with porn subs...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Also, I&amp;#39;m prepared to bet 50p that there&amp;#39;s at least one match up with porn subs...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8x5kk", "score_hidden": false, "stickied": false, "created": 1492186416.0, "created_utc": 1492157616.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8ws5d", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ActualMathematician", "parent_id": "t1_dg8wo77", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "DO IT!  I've seen you do data magic in the past...\n\nThat will be an interesting exercise and result. \n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;DO IT!  I&amp;#39;ve seen you do data magic in the past...&lt;/p&gt;\n\n&lt;p&gt;That will be an interesting exercise and result. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8ws5d", "score_hidden": false, "stickied": false, "created": 1492185292.0, "created_utc": 1492156492.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8wo77", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "hilburn", "parent_id": "t1_dg8gljx", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "I'm really tempted to see if I can mine the Google BigQuery data to find 2 people who regularly comment on the same 80 subs...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m really tempted to see if I can mine the Google BigQuery data to find 2 people who regularly comment on the same 80 subs...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8wo77", "score_hidden": false, "stickied": false, "created": 1492184972.0, "created_utc": 1492156172.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg94498", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "bluemandan", "parent_id": "t1_dg8gljx", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Aren't there something like 49 default subreddits?\n\nSo wouldn't we really only be looking at 31 random subs + the 49 default subs?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Aren&amp;#39;t there something like 49 default subreddits?&lt;/p&gt;\n\n&lt;p&gt;So wouldn&amp;#39;t we really only be looking at 31 random subs + the 49 default subs?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg94498", "score_hidden": false, "stickied": false, "created": 1492204723.0, "created_utc": 1492175923.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg97frz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "landon9560", "parent_id": "t1_dg8gljx", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "I wonder what would happen if you factor in the NSFW accounts. (the ones that people have for NSFW subreddits, so nothing shows up on their normal account.)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I wonder what would happen if you factor in the NSFW accounts. (the ones that people have for NSFW subreddits, so nothing shows up on their normal account.)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg97frz", "score_hidden": false, "stickied": false, "created": 1492209474.0, "created_utc": 1492180674.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8gljx", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "ActualMathematician", "parent_id": "t3_659778", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Redditmetrics shows 1,060,782 subs as of today.\n\nWere a user to *randomly* select 80 distinct subs to subscribe to, there are ~1.56 x 10^363 ways to do that.\n\nTherefore, two *specific* Reddit users would have ~6.41 x 10^-364 probability of having the same sub list given the random selection assumption.\n\nThat *any* pair of the ~240,000,000 Reddit users would share the same sub list of 80 if all randomly selected their lists is ~ 1.85 x 10^-347\n\nBoth cases effectively zero.\n\nIn reality, no way to calculate this - it depends on each user's participation (few would randomly pick subs), sub tastes, number of subs, how long each sub has been active, etc. etc.\n\n", "edited": 1492128783.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Redditmetrics shows 1,060,782 subs as of today.&lt;/p&gt;\n\n&lt;p&gt;Were a user to &lt;em&gt;randomly&lt;/em&gt; select 80 distinct subs to subscribe to, there are ~1.56 x 10&lt;sup&gt;363&lt;/sup&gt; ways to do that.&lt;/p&gt;\n\n&lt;p&gt;Therefore, two &lt;em&gt;specific&lt;/em&gt; Reddit users would have ~6.41 x 10&lt;sup&gt;-364&lt;/sup&gt; probability of having the same sub list given the random selection assumption.&lt;/p&gt;\n\n&lt;p&gt;That &lt;em&gt;any&lt;/em&gt; pair of the ~240,000,000 Reddit users would share the same sub list of 80 if all randomly selected their lists is ~ 1.85 x 10&lt;sup&gt;-347&lt;/sup&gt;&lt;/p&gt;\n\n&lt;p&gt;Both cases effectively zero.&lt;/p&gt;\n\n&lt;p&gt;In reality, no way to calculate this - it depends on each user&amp;#39;s participation (few would randomly pick subs), sub tastes, number of subs, how long each sub has been active, etc. etc.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8gljx", "score_hidden": false, "stickied": false, "created": 1492157315.0, "created_utc": 1492128515.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 12}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg9dso0", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "hilburn", "parent_id": "t1_dg9dcmt", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "If reddit actually made the subscription lists available then it would be easier to gather the original dataset - and it would be more accurate than my estimate of \"well if they have commented there at least 5 times they're subscribed there\" as there are going to be many subs (for example /r/WritingPrompts) where the subscribers to commenters ratio is going to be very skewed.\n\nIt wouldn't necessarily be quicker overall though, the comparisons are what takes the (estimated) 37 hours of processing time.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If reddit actually made the subscription lists available then it would be easier to gather the original dataset - and it would be more accurate than my estimate of &amp;quot;well if they have commented there at least 5 times they&amp;#39;re subscribed there&amp;quot; as there are going to be many subs (for example &lt;a href=\"/r/WritingPrompts\"&gt;/r/WritingPrompts&lt;/a&gt;) where the subscribers to commenters ratio is going to be very skewed.&lt;/p&gt;\n\n&lt;p&gt;It wouldn&amp;#39;t necessarily be quicker overall though, the comparisons are what takes the (estimated) 37 hours of processing time.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg9dso0", "score_hidden": false, "stickied": false, "created": 1492216940.0, "created_utc": 1492188140.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9dcmt", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "ChrisHansenBait", "parent_id": "t1_dg90tx9", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Wow. Dude thank you so much. This is so very cool. Would it be easier if you had a user's subscription list and then searched from there? For example, I unsubbed to all the generic subs and then started my sub list from nothing. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Wow. Dude thank you so much. This is so very cool. Would it be easier if you had a user&amp;#39;s subscription list and then searched from there? For example, I unsubbed to all the generic subs and then started my sub list from nothing. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg9dcmt", "score_hidden": false, "stickied": false, "created": 1492216436.0, "created_utc": 1492187636.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg9dmsq", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ChrisHansenBait", "parent_id": "t1_dg90tx9", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Oh and those 199 pairs of users that you found should go on dates", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh and those 199 pairs of users that you found should go on dates&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg9dmsq", "score_hidden": false, "stickied": false, "created": 1492216757.0, "created_utc": 1492187957.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dg9vr9w", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ActualMathematician", "parent_id": "t1_dg90tx9", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "&gt; no matches at all\n\nNot surprised. Nice work.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;no matches at all&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Not surprised. Nice work.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg9vr9w", "score_hidden": false, "stickied": false, "created": 1492238809.0, "created_utc": 1492210009.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg90tx9", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "hilburn", "parent_id": "t3_659778", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "Ok OP:\n\nSo the full query I ran was:\n\n    SELECT author,  subs\n    FROM (\n        SELECT author, count(subreddit) as num_subs, group_concat(subreddit, ',') as subs\n        FROM (\n              SELECT author, subreddit, count(score) AS sub_comments \n              FROM [fh-bigquery:reddit_comments.all_starting_201501]   \n              GROUP BY author, subreddit \n        )\n        GROUP BY author \n        WHERE sub_comments &gt;= 5\n    )\n    WHERE num_subs &gt;= 80\n\nYou have to start at the middle and work out to understand what it does, but fundamentally:\n\n1. Count every comment made by each user per subreddit\n2. Counts the number of subreddits where a user has made at least 5 comments, and creates a comma separated list of all of those subreddits\n3. Outputs every user and list of subreddits where the length of that list is at least 80\n\nI then exported that table into Python so I could look for matching groups of 80 subreddits\n\nI first stripped every known bot from the list, as they would heavily skew the results (as well as checking the remaining highest scoring users manually) - this left me with approx 15,000 users who commented reasonable regularly in &gt; 80 subreddits (at which point we can assume that they are subscribed to that sub) \n\nThen finally ran some code to check if people matched up:\n\n    subs = [[user_a, set(user_a_subs)], [user_b, set(user_b_subs)]...]\n    results = []\n    len_subs = len(subs)\n    for i in xrange(0, len_subs-1):\n        for j in xrange(i+1, len_subs):\n            inter = subs[i][1].intersection(subs[j][1])\n            if len(inter) &gt;= 80:\n                results.append([subs[i][0], subs[j][0], inter])\n\nWhich is hideous and took a very long time to complete, finding **199 pairs of users who have at least 80 subs in common**, the first match it spat out (I won't share the names) was:\n\n4chan, AdviceAnimals, AskReddit, BlackPeopleTwitter, CrappyDesign, CringeAnarchy, DIY, FloridaMan, Futurology, IAmA, ImGoingToHellForThis, Jokes, Justrolledintotheshop, LifeProTips, MURICA, MensRights, Music, OldSchoolCool, OutOfTheLoop, PerfectTiming, PoliticalHumor, RoastMe, SandersForPresident, Showerthoughts, The_Donald, Tinder, TumblrInAction, Unexpected, UpliftingNews, WTF, YouShouldKnow, announcements, atheism, aww, canada, conspiracy, creepy, cringe, cringepics, explainlikeimfive, facepalm, funny, gaming, gifs, hockey, iamverysmart, instant_regret, interestingasfuck, lifehacks, me_irl, mildlyinteresting, motorcycles, movies, nba, news, nonononoyes, nottheonion, oddlysatisfying, pics, politics, pussypassdenied, quityourbullshit, rage, reactiongifs, sadcringe, shittyfoodporn, sports, standupshots, starterpacks, technology, television, thatHappened, tifu, todayilearned, trashy, trees, tumblr, videos, whitepeoplegifs, woahdude, worldnews\n\nWith 81 shared subreddits\n\nThen I realised I misread the question and you wanted *identical* subscription lists, so I changed the code a bit:\n\n    subs = [[user_a, set(user_a_subs)], [user_b, set(user_b_subs)]...]\n    results = []\n    len_subs = len(subs)\n    for i in xrange(0, len_subs-1):\n        for j in xrange(i+1, len_subs):\n            if subs[i][1] == subs[j][1]:\n                results.append([subs[i][0], subs[j][0], subs[i][1]])\n\nFor which there are **no matches at all**\n\nSo then I wondered: what is the minimum number of subs that *do* have a matching pair of users...\n\n    results2 = []\n    for n_subs in xrange(79, 1, -1):\n        reduced_subs = [r for r in subs if len(r[1]) == n_subs]\n        len_subs = len(reduced_subs)\n        for i in xrange(0, len_subs-1):\n            for j in xrange(i+1, len_subs):\n                if reduced_subs[i][1] == reduced_subs[j][1]:\n                    results2.append([reduced_subs[i][0], reduced_subs[j][0], reduced_subs[j][1]])\n                    print reduced_subs[j][1]\n    print len(results2)\n\nThis is a bit more complex as the dataset is a *lot* bigger - it's the same as the earlier query, but with the `WHERE num_subs&gt;=80` criterion exchanged for `WHERE num_subs&lt;80` - and I needed to do some optimisation. To give you an idea of how much more data this is: the downloaded .csv file for the &gt;80 subs was 22MB - for all the users, it was 482MB, with 400x as many people in it. Yes, optimisation needed - and the easiest win is that it's only worth checking if sets are equal if they have the same length. \n\nSo it loops through all the records and pulls out all the records of a certain length, then checks all of them against each other.\n\nIt starts reasonably quickly - the first 180,000 users are checked in a little over 3.5 minutes. The next 190,000 take 9.5. The next 193,000 takes 24 mins. The next - 42 mins... you see where this is going right? I'm going to leave this running all weekend and see if it spits anything out by Monday\n\nPing for /u/ActualMathematician so he can see the unholy mess he caused", "edited": 1492187008.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ok OP:&lt;/p&gt;\n\n&lt;p&gt;So the full query I ran was:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;SELECT author,  subs\nFROM (\n    SELECT author, count(subreddit) as num_subs, group_concat(subreddit, &amp;#39;,&amp;#39;) as subs\n    FROM (\n          SELECT author, subreddit, count(score) AS sub_comments \n          FROM [fh-bigquery:reddit_comments.all_starting_201501]   \n          GROUP BY author, subreddit \n    )\n    GROUP BY author \n    WHERE sub_comments &amp;gt;= 5\n)\nWHERE num_subs &amp;gt;= 80\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;You have to start at the middle and work out to understand what it does, but fundamentally:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Count every comment made by each user per subreddit&lt;/li&gt;\n&lt;li&gt;Counts the number of subreddits where a user has made at least 5 comments, and creates a comma separated list of all of those subreddits&lt;/li&gt;\n&lt;li&gt;Outputs every user and list of subreddits where the length of that list is at least 80&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;I then exported that table into Python so I could look for matching groups of 80 subreddits&lt;/p&gt;\n\n&lt;p&gt;I first stripped every known bot from the list, as they would heavily skew the results (as well as checking the remaining highest scoring users manually) - this left me with approx 15,000 users who commented reasonable regularly in &amp;gt; 80 subreddits (at which point we can assume that they are subscribed to that sub) &lt;/p&gt;\n\n&lt;p&gt;Then finally ran some code to check if people matched up:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;subs = [[user_a, set(user_a_subs)], [user_b, set(user_b_subs)]...]\nresults = []\nlen_subs = len(subs)\nfor i in xrange(0, len_subs-1):\n    for j in xrange(i+1, len_subs):\n        inter = subs[i][1].intersection(subs[j][1])\n        if len(inter) &amp;gt;= 80:\n            results.append([subs[i][0], subs[j][0], inter])\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;Which is hideous and took a very long time to complete, finding &lt;strong&gt;199 pairs of users who have at least 80 subs in common&lt;/strong&gt;, the first match it spat out (I won&amp;#39;t share the names) was:&lt;/p&gt;\n\n&lt;p&gt;4chan, AdviceAnimals, AskReddit, BlackPeopleTwitter, CrappyDesign, CringeAnarchy, DIY, FloridaMan, Futurology, IAmA, ImGoingToHellForThis, Jokes, Justrolledintotheshop, LifeProTips, MURICA, MensRights, Music, OldSchoolCool, OutOfTheLoop, PerfectTiming, PoliticalHumor, RoastMe, SandersForPresident, Showerthoughts, The_Donald, Tinder, TumblrInAction, Unexpected, UpliftingNews, WTF, YouShouldKnow, announcements, atheism, aww, canada, conspiracy, creepy, cringe, cringepics, explainlikeimfive, facepalm, funny, gaming, gifs, hockey, iamverysmart, instant_regret, interestingasfuck, lifehacks, me_irl, mildlyinteresting, motorcycles, movies, nba, news, nonononoyes, nottheonion, oddlysatisfying, pics, politics, pussypassdenied, quityourbullshit, rage, reactiongifs, sadcringe, shittyfoodporn, sports, standupshots, starterpacks, technology, television, thatHappened, tifu, todayilearned, trashy, trees, tumblr, videos, whitepeoplegifs, woahdude, worldnews&lt;/p&gt;\n\n&lt;p&gt;With 81 shared subreddits&lt;/p&gt;\n\n&lt;p&gt;Then I realised I misread the question and you wanted &lt;em&gt;identical&lt;/em&gt; subscription lists, so I changed the code a bit:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;subs = [[user_a, set(user_a_subs)], [user_b, set(user_b_subs)]...]\nresults = []\nlen_subs = len(subs)\nfor i in xrange(0, len_subs-1):\n    for j in xrange(i+1, len_subs):\n        if subs[i][1] == subs[j][1]:\n            results.append([subs[i][0], subs[j][0], subs[i][1]])\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;For which there are &lt;strong&gt;no matches at all&lt;/strong&gt;&lt;/p&gt;\n\n&lt;p&gt;So then I wondered: what is the minimum number of subs that &lt;em&gt;do&lt;/em&gt; have a matching pair of users...&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;results2 = []\nfor n_subs in xrange(79, 1, -1):\n    reduced_subs = [r for r in subs if len(r[1]) == n_subs]\n    len_subs = len(reduced_subs)\n    for i in xrange(0, len_subs-1):\n        for j in xrange(i+1, len_subs):\n            if reduced_subs[i][1] == reduced_subs[j][1]:\n                results2.append([reduced_subs[i][0], reduced_subs[j][0], reduced_subs[j][1]])\n                print reduced_subs[j][1]\nprint len(results2)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This is a bit more complex as the dataset is a &lt;em&gt;lot&lt;/em&gt; bigger - it&amp;#39;s the same as the earlier query, but with the &lt;code&gt;WHERE num_subs&amp;gt;=80&lt;/code&gt; criterion exchanged for &lt;code&gt;WHERE num_subs&amp;lt;80&lt;/code&gt; - and I needed to do some optimisation. To give you an idea of how much more data this is: the downloaded .csv file for the &amp;gt;80 subs was 22MB - for all the users, it was 482MB, with 400x as many people in it. Yes, optimisation needed - and the easiest win is that it&amp;#39;s only worth checking if sets are equal if they have the same length. &lt;/p&gt;\n\n&lt;p&gt;So it loops through all the records and pulls out all the records of a certain length, then checks all of them against each other.&lt;/p&gt;\n\n&lt;p&gt;It starts reasonably quickly - the first 180,000 users are checked in a little over 3.5 minutes. The next 190,000 take 9.5. The next 193,000 takes 24 mins. The next - 42 mins... you see where this is going right? I&amp;#39;m going to leave this running all weekend and see if it spits anything out by Monday&lt;/p&gt;\n\n&lt;p&gt;Ping for &lt;a href=\"/u/ActualMathematician\"&gt;/u/ActualMathematician&lt;/a&gt; so he can see the unholy mess he caused&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg90tx9", "score_hidden": false, "stickied": false, "created": 1492197997.0, "created_utc": 1492169197.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_659778", "likes": null, "replies": "", "user_reports": [], "id": "dgaj2ni", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "odnish", "parent_id": "t1_dg8t6sw", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "What I meant was create another user and subscribe to the same subreddits that I'm already subscribed to.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What I meant was create another user and subscribe to the same subreddits that I&amp;#39;m already subscribed to.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dgaj2ni", "score_hidden": false, "stickied": false, "created": 1492281961.0, "created_utc": 1492253161.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8t6sw", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Yackabo", "parent_id": "t1_dg8p1fm", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "It probably has happened where alts/throwaways were just left with the default subs. Numerous times perhaps.\n\nEDIT: Just saw the 80 disclaimer, doubt there have ever been 80 default subs..", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It probably has happened where alts/throwaways were just left with the default subs. Numerous times perhaps.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Just saw the 80 disclaimer, doubt there have ever been 80 default subs..&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8t6sw", "score_hidden": false, "stickied": false, "created": 1492176451.0, "created_utc": 1492147651.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg8p1fm", "gilded": 0, "archived": false, "score": -3, "report_reasons": null, "author": "odnish", "parent_id": "t3_659778", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "There's a really easy way to answer this question. All we need to do is contrive two Redditch users with the same subscription list and them we can say the probability is 1. I leave the construction task as an exercise for the reader.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s a really easy way to answer this question. All we need to do is contrive two Redditch users with the same subscription list and them we can say the probability is 1. I leave the construction task as an exercise for the reader.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dg8p1fm", "score_hidden": false, "stickied": false, "created": 1492169241.0, "created_utc": 1492140441.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -3}}], "after": null, "before": null}}]