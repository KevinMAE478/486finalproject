[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "theydidthemath", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;So I recently learned about the wonderful place that is The Library of Babel, which contains one copy of every possible book that&amp;#39;s 410 pages long in random order. They also have a image gallery with every possible picture of a certain size and palette, and, for the topic of this post, a twitter bot called the Permuda Triangle, which is going through and posting every possible tweet, in order. It had reached &amp;quot;bj op&amp;quot; when i checked last week.&lt;/p&gt;\n\n&lt;p&gt;Now, what makes the twitter bot different is that, while the library and gallery seem to be artfully created encryption algoritms, where the contents of the book is derived from the name of it&amp;#39;s location or the image is generated from its number, the twitter bot is actually posting all the permutations. Which means they must be saved somewhere.&lt;/p&gt;\n\n&lt;p&gt;Now, assuming it uses all the printable ascii characters, and that the last N letters of a tweet being space being equivalent to the tweet being N letters shorter, there are 95&lt;sup&gt;140&lt;/sup&gt; possible tweets as far as I can tell. (That last assumption is probably wrong, bonus points for calculating the number of possible tweets shoter than 140 symbols.)&lt;/p&gt;\n\n&lt;p&gt;Assuming there was enough time in the universe for the bot to complete its herculean task, and twitter is still in business then, how much storage space would be required to store all of the Permuda Triangle tweets?&lt;/p&gt;\n\n&lt;p&gt;Bonus: How much physical space would all the storage take?&lt;/p&gt;\n\n&lt;p&gt;Edit: Looking at the bot&amp;#39;s outbut again it seems to be just using the lowercase letters + # and space, except for the last letter which is just the lowercase letters. I&amp;#39;d still be curious to know the needed storage space both for the bot&amp;#39;s output and all possible tweets.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "So I recently learned about the wonderful place that is The Library of Babel, which contains one copy of every possible book that's 410 pages long in random order. They also have a image gallery with every possible picture of a certain size and palette, and, for the topic of this post, a twitter bot called the Permuda Triangle, which is going through and posting every possible tweet, in order. It had reached \"bj op\" when i checked last week.\n\nNow, what makes the twitter bot different is that, while the library and gallery seem to be artfully created encryption algoritms, where the contents of the book is derived from the name of it's location or the image is generated from its number, the twitter bot is actually posting all the permutations. Which means they must be saved somewhere.\n\nNow, assuming it uses all the printable ascii characters, and that the last N letters of a tweet being space being equivalent to the tweet being N letters shorter, there are 95^140 possible tweets as far as I can tell. (That last assumption is probably wrong, bonus points for calculating the number of possible tweets shoter than 140 symbols.)\n\nAssuming there was enough time in the universe for the bot to complete its herculean task, and twitter is still in business then, how much storage space would be required to store all of the Permuda Triangle tweets?\n\nBonus: How much physical space would all the storage take?\n\nEdit: Looking at the bot's outbut again it seems to be just using the lowercase letters + # and space, except for the last letter which is just the lowercase letters. I'd still be curious to know the needed storage space both for the bot's output and all possible tweets.", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "", "id": "65wo20", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 6, "report_reasons": null, "author": "LeopoldVonComarre", "saved": false, "mod_reports": [], "name": "t3_65wo20", "subreddit_name_prefixed": "r/theydidthemath", "approved_by": null, "over_18": false, "domain": "self.theydidthemath", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2x23b", "edited": 1492455447.0, "link_flair_css_class": "request", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/theydidthemath/comments/65wo20/request_how_much_storage_space_would_95140_tweets/", "num_reports": null, "locked": false, "stickied": false, "created": 1492475964.0, "url": "https://www.reddit.com/r/theydidthemath/comments/65wo20/request_how_much_storage_space_would_95140_tweets/", "author_flair_text": null, "quarantine": false, "title": "[Request] How much storage space would 95^140 tweets with accompanying metadata take?", "created_utc": 1492447164.0, "distinguished": null, "media": null, "upvote_ratio": 0.75, "num_comments": 3, "visited": false, "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_65wo20", "likes": null, "replies": "", "user_reports": [], "id": "dgdv1o6", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "NinjaJc01", "parent_id": "t3_65wo20", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "So let's make some assumptions:\n\n* They're stored as 7 bit ASCII, and no file headers or anything\n\n* Each character takes a byte\n\n* The person doing the storing can afford 10TB drives, and lots of them\n\n* Each tweet is 140 characters. I am not hugely good at permutation maths, so this makes it possible for me to calculate.\n\nQuick excel maths says with 95140 tweets, it'd only take 101MB, which can fit easily on a micro SD card. (I think you might have missed a power symbol)\n\nNow, 95^140 tweets. This is a VERY big number. If each tweet is exactly 140 characters, and each character is 8 bits, all of those tweets would be 7.2181028607286E+258 Yottabytes. This is larger than the whole internet.\n\nBut let's do some maths for the size requirements.\n\nEach hard drive is 10TB. You can fit 90 of them in 4U of rack space. That's 900TB for every 4U. Dividing the number of terabytes by 900, gives us 8.61153214610927E+264 90 bay storage units. That's 7.82866558737206E+263 44U data center grade racks. All filled with hard drives. This is stupendously large. It's greater than 10,000,000,000 googol server racks. \nTL;DR: More than enough to fill the planet, and have made no dent in the amount of space needed.\n\nEDIT: Alternatively, 60TB SSDs are supposedly coming soon. Assuming the same density (90 drives in 4U), it'd be *only* 1.30477759789534E+263 44U racks. That number is still larger than 1 sextillion googol.", "edited": 1492463128.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So let&amp;#39;s make some assumptions:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;p&gt;They&amp;#39;re stored as 7 bit ASCII, and no file headers or anything&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Each character takes a byte&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;The person doing the storing can afford 10TB drives, and lots of them&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;Each tweet is 140 characters. I am not hugely good at permutation maths, so this makes it possible for me to calculate.&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Quick excel maths says with 95140 tweets, it&amp;#39;d only take 101MB, which can fit easily on a micro SD card. (I think you might have missed a power symbol)&lt;/p&gt;\n\n&lt;p&gt;Now, 95&lt;sup&gt;140&lt;/sup&gt; tweets. This is a VERY big number. If each tweet is exactly 140 characters, and each character is 8 bits, all of those tweets would be 7.2181028607286E+258 Yottabytes. This is larger than the whole internet.&lt;/p&gt;\n\n&lt;p&gt;But let&amp;#39;s do some maths for the size requirements.&lt;/p&gt;\n\n&lt;p&gt;Each hard drive is 10TB. You can fit 90 of them in 4U of rack space. That&amp;#39;s 900TB for every 4U. Dividing the number of terabytes by 900, gives us 8.61153214610927E+264 90 bay storage units. That&amp;#39;s 7.82866558737206E+263 44U data center grade racks. All filled with hard drives. This is stupendously large. It&amp;#39;s greater than 10,000,000,000 googol server racks. \nTL;DR: More than enough to fill the planet, and have made no dent in the amount of space needed.&lt;/p&gt;\n\n&lt;p&gt;EDIT: Alternatively, 60TB SSDs are supposedly coming soon. Assuming the same density (90 drives in 4U), it&amp;#39;d be &lt;em&gt;only&lt;/em&gt; 1.30477759789534E+263 44U racks. That number is still larger than 1 sextillion googol.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dgdv1o6", "score_hidden": false, "stickied": false, "created": 1492481377.0, "created_utc": 1492452577.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 5}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_65wo20", "likes": null, "replies": "", "user_reports": [], "id": "dgdv86e", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "ihasaccount", "parent_id": "t3_65wo20", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "napkin calculation here\n\nthere are only an estimated 10^186 planck volumes in the observable universe, so you only have 10^45 times more planck volumes for the tweets if each tweet took up just 1 bit, and we could store 1 bit in 1 planck volume (obviously not true).\n\n im guessing a typical tweet, along with metadata, is probably on order of kB (10^3 bits). additionally, the amount of space it currently takes to store a bit is on order of nanometers (10^26 planck lengths).\n\ntherefore, storing 10^141 tweets should take up about \n10^(141+3+26-186) = 10^-16 of the observable universe.\n\nthis is equal to 5000 milky way galaxies.\n\nhttp://www.wolframalpha.com/input/?i=(10%5E(-16)*volume+of+observable+universe)%2F(volume+of+milky+way)", "edited": 1492453155.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;napkin calculation here&lt;/p&gt;\n\n&lt;p&gt;there are only an estimated 10&lt;sup&gt;186&lt;/sup&gt; planck volumes in the observable universe, so you only have 10&lt;sup&gt;45&lt;/sup&gt; times more planck volumes for the tweets if each tweet took up just 1 bit, and we could store 1 bit in 1 planck volume (obviously not true).&lt;/p&gt;\n\n&lt;p&gt;im guessing a typical tweet, along with metadata, is probably on order of kB (10&lt;sup&gt;3&lt;/sup&gt; bits). additionally, the amount of space it currently takes to store a bit is on order of nanometers (10&lt;sup&gt;26&lt;/sup&gt; planck lengths).&lt;/p&gt;\n\n&lt;p&gt;therefore, storing 10&lt;sup&gt;141&lt;/sup&gt; tweets should take up about \n10&lt;sup&gt;141+3+26-186&lt;/sup&gt; = 10&lt;sup&gt;-16&lt;/sup&gt; of the observable universe.&lt;/p&gt;\n\n&lt;p&gt;this is equal to 5000 milky way galaxies.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"http://www.wolframalpha.com/input/?i=(10%5E(-16)*volume+of+observable+universe)%2F(volume+of+milky+way)\"&gt;http://www.wolframalpha.com/input/?i=(10%5E(-16)*volume+of+observable+universe)%2F(volume+of+milky+way)&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dgdv86e", "score_hidden": false, "stickied": false, "created": 1492481580.0, "created_utc": 1492452780.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2x23b", "removal_reason": null, "link_id": "t3_65wo20", "likes": null, "replies": "", "user_reports": [], "id": "dgdwfjm", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "emilfranord", "parent_id": "t3_65wo20", "subreddit_name_prefixed": "r/theydidthemath", "controversiality": 0, "body": "3 tasks: \n\n1) The maximum number of unique tweets, from the bot.\n\n2) The data size of that file.\n\n3) The physical hard drive space required. \n\n------\n1)\nThere are 26 letters, \"+\", \"#\" and \" \". If we assume \"nothing\" and \"space\" is the same character the total is then 29 characters. \nThere are 140 characters in a tweet. Then the amount is 29^140 = 5.44 * 10^204\n\n----\n2) \nASCII is the best, in this case, because a character is always one byte long. \n\nTherefore the answer is 5.44 * 10^204 byte or 5.44 * 10^186 exabyte or 5.44 * 10^192 TB\n\n----\n3)\nIt will take 5.44 * 10^192 1TB drives to hold that data. An 8TB drive takes up about 0.39 liter. (0.1 gallon).\nIf you fill up an Olympic-size swimming pool with 8TB drives, it holds 5.28*10^7 TB. \nIt's going to take 1.03\u00d7 10^185 pools. \n\n\nTL;DR It's a lot of data.\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;3 tasks: &lt;/p&gt;\n\n&lt;p&gt;1) The maximum number of unique tweets, from the bot.&lt;/p&gt;\n\n&lt;p&gt;2) The data size of that file.&lt;/p&gt;\n\n&lt;p&gt;3) The physical hard drive space required. &lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;1)\nThere are 26 letters, &amp;quot;+&amp;quot;, &amp;quot;#&amp;quot; and &amp;quot; &amp;quot;. If we assume &amp;quot;nothing&amp;quot; and &amp;quot;space&amp;quot; is the same character the total is then 29 characters. \nThere are 140 characters in a tweet. Then the amount is 29&lt;sup&gt;140&lt;/sup&gt; = 5.44 * 10&lt;sup&gt;204&lt;/sup&gt;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;2) \nASCII is the best, in this case, because a character is always one byte long. &lt;/p&gt;\n\n&lt;p&gt;Therefore the answer is 5.44 * 10&lt;sup&gt;204&lt;/sup&gt; byte or 5.44 * 10&lt;sup&gt;186&lt;/sup&gt; exabyte or 5.44 * 10&lt;sup&gt;192&lt;/sup&gt; TB&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;3)\nIt will take 5.44 * 10&lt;sup&gt;192&lt;/sup&gt; 1TB drives to hold that data. An 8TB drive takes up about 0.39 liter. (0.1 gallon).\nIf you fill up an Olympic-size swimming pool with 8TB drives, it holds 5.28*10&lt;sup&gt;7&lt;/sup&gt; TB. \nIt&amp;#39;s going to take 1.03\u00d7 10&lt;sup&gt;185&lt;/sup&gt; pools. &lt;/p&gt;\n\n&lt;p&gt;TL;DR It&amp;#39;s a lot of data.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "theydidthemath", "name": "t1_dgdwfjm", "score_hidden": false, "stickied": false, "created": 1492482933.0, "created_utc": 1492454133.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}]