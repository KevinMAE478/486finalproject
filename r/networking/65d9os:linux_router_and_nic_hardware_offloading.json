[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "networking", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Hi.&lt;/p&gt;\n\n&lt;p&gt;I am preparing a box with a single socket E3-1240v5 CPU to act as a ipv4 BGP router to terminate a 10Gb link (The throughput will be about 3Gbit/s, 400K Pkt/s, spread among 3 tagged vlans. Single NIC sfp+ socket will be used).&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;Debian Jessie &lt;/li&gt;\n&lt;li&gt;Kernel 4.9 from backports&lt;/li&gt;\n&lt;li&gt;Bird for BGP and OSPF&lt;br/&gt;&lt;/li&gt;\n&lt;li&gt;No iptables conntrack used, just stateless iptable rules to restrict access to services on the router, like ssh and snmp.&lt;/li&gt;\n&lt;li&gt;Intel 82599ES NIC&lt;/li&gt;\n&lt;li&gt;Latest ixgbe 5.0.4 driver from source&lt;/li&gt;\n&lt;li&gt;CPU HyperThreading disabled&lt;/li&gt;\n&lt;li&gt;CPU VT-d disabled&lt;/li&gt;\n&lt;li&gt;CPU c-states disabled&lt;/li&gt;\n&lt;li&gt;Linux CPU scaling governor set to performance &lt;/li&gt;\n&lt;li&gt;irqbalance disabled&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;4 RSS NIC interface TxRx queues each queue pinned manually to single cpu core (via irq smp_affinity)&lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;/etc/sysctl.conf modifications:&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.ip_early_demux = 0&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.conf.default.rp_filter=0&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.conf.all.rp_filter=0&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.ip_forward=1&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.conf.all.arp_filter = 1&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.conf.default.arp_filter = 1&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.conf.all.arp_ignore = 2&lt;/p&gt;\n\n&lt;p&gt;net.ipv4.conf.default.arp_ignore = 2 &lt;/p&gt;&lt;/li&gt;\n&lt;li&gt;&lt;p&gt;ethtool modifications: &lt;/p&gt;\n\n&lt;p&gt;ethtool -A eth0 autoneg off rx off tx off # flow control disabled&lt;/p&gt;\n\n&lt;p&gt;ethtool -G eth0 rx 4096 tx 4096 #increase ring buffer size&lt;/p&gt;\n\n&lt;p&gt;ethtool -K eth0 lro off #lro disabled&lt;/p&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;My question is this, which additional HW NIC offload features should be disabled apart from the obvious ones (like LRO which is incompatible with packet forwarding) to be beneficial to a router?&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;There is not much information online about this matter, and if there is such information it usually talks about Linux in terms of an application server, in which case NIC HW offload features are desirable because they improve throughput at the cost of latency.&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Should I also disable the following (via ethtool):&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;tso [tcp-segmentation-offload]&lt;/li&gt;\n&lt;li&gt;gso [generic-segmentation-offload]&lt;/li&gt;\n&lt;li&gt;gro [generic-receive-offload]&lt;/li&gt;\n&lt;li&gt;ufo [udp-fragmentation-offload]&lt;/li&gt;\n&lt;li&gt;sg [scatter-gather]&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;What about:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;tx [tx-checksumming]&lt;/li&gt;\n&lt;li&gt;rx [rx-checksumming]&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;or even:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;rx-vlan-offload&lt;/li&gt;\n&lt;li&gt;tx-vlan-offload&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Are there any other things that are recommended to change when Linux is used as a pure router?&lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Thank you.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "Hi.\n \nI am preparing a box with a single socket E3-1240v5 CPU to act as a ipv4 BGP router to terminate a 10Gb link (The throughput will be about 3Gbit/s, 400K Pkt/s, spread among 3 tagged vlans. Single NIC sfp+ socket will be used).\n\n- Debian Jessie \n- Kernel 4.9 from backports\n- Bird for BGP and OSPF  \n- No iptables conntrack used, just stateless iptable rules to restrict access to services on the router, like ssh and snmp.\n- Intel 82599ES NIC\n- Latest ixgbe 5.0.4 driver from source\n- CPU HyperThreading disabled\n- CPU VT-d disabled\n- CPU c-states disabled\n- Linux CPU scaling governor set to performance \n- irqbalance disabled\n- 4 RSS NIC interface TxRx queues each queue pinned manually to single cpu core (via irq smp_affinity)\n\n- /etc/sysctl.conf modifications:\n\n      net.ipv4.ip_early_demux = 0\n\n      net.ipv4.conf.default.rp_filter=0\n\n      net.ipv4.conf.all.rp_filter=0\n\n      net.ipv4.ip_forward=1\n\n      net.ipv4.conf.all.arp_filter = 1\n\n      net.ipv4.conf.default.arp_filter = 1\n\n      net.ipv4.conf.all.arp_ignore = 2\n\n      net.ipv4.conf.default.arp_ignore = 2 \n\n- ethtool modifications: \n\n     ethtool -A eth0 autoneg off rx off tx off # flow control disabled\n\n     ethtool -G eth0 rx 4096 tx 4096 #increase ring buffer size\n\n     ethtool -K eth0 lro off #lro disabled\n\n&amp;nbsp;\n\nMy question is this, which additional HW NIC offload features should be disabled apart from the obvious ones (like LRO which is incompatible with packet forwarding) to be beneficial to a router?\n\n&amp;nbsp;\n\nThere is not much information online about this matter, and if there is such information it usually talks about Linux in terms of an application server, in which case NIC HW offload features are desirable because they improve throughput at the cost of latency.\n\n&amp;nbsp;\n\nShould I also disable the following (via ethtool):\n\n- tso [tcp-segmentation-offload]\n- gso [generic-segmentation-offload]\n- gro [generic-receive-offload]\n- ufo [udp-fragmentation-offload]\n- sg [scatter-gather]\n\nWhat about:\n\n- tx [tx-checksumming]\n- rx [rx-checksumming]\n\nor even:\n\n- rx-vlan-offload\n- tx-vlan-offload\n\n&amp;nbsp;\n\nAre there any other things that are recommended to change when Linux is used as a pure router?\n\n&amp;nbsp;\n\nThank you.", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "65d9os", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 36, "report_reasons": null, "author": "icecrown_glacier_htm", "saved": false, "mod_reports": [], "name": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "approved_by": null, "over_18": false, "domain": "self.networking", "hidden": false, "thumbnail": "", "subreddit_id": "t5_2qkaf", "edited": 1492204768.0, "link_flair_css_class": null, "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/networking/comments/65d9os/linux_router_and_nic_hardware_offloading/", "num_reports": null, "locked": false, "stickied": false, "created": 1492213553.0, "url": "https://www.reddit.com/r/networking/comments/65d9os/linux_router_and_nic_hardware_offloading/", "author_flair_text": null, "quarantine": false, "title": "Linux router and NIC hardware offloading", "created_utc": 1492184753.0, "distinguished": null, "media": null, "upvote_ratio": 0.88, "num_comments": 27, "visited": false, "subreddit_type": "public", "ups": 36}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dga6ciz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "thegreattriscuit", "parent_id": "t1_dga6acj", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Fair point.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair point.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dga6ciz", "score_hidden": false, "stickied": false, "created": 1492253250.0, "created_utc": 1492224450.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6acj", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "My-RFC1918-Dont-Lie", "parent_id": "t1_dg9ya9r", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "I agree, but with hardware optimization you can end up bald from pulling all your hair out. You're much more likely to run into a bug related to proprietary vendor-specific NIC offload feature than you are the Linux kernel.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I agree, but with hardware optimization you can end up bald from pulling all your hair out. You&amp;#39;re much more likely to run into a bug related to proprietary vendor-specific NIC offload feature than you are the Linux kernel.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dga6acj", "score_hidden": false, "stickied": false, "created": 1492253164.0, "created_utc": 1492224364.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ya9r", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "thegreattriscuit", "parent_id": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "I can't any offer any *concrete* advice... but I'd always suggest measuring before you optimize.  \n\nDon't apply or disable a given feature or optimization \"because the internet said so\" (I know, it's clear you're actually doing legit research, but still...).  Use those as starting points maybe, but I'd still measure before and after results.\n\nAnd hell, before you do *any* of that, make sure you've established an actual latency budget.  Even if feature X adds 0.5ms of latency, if you're okay with 2ms and are getting 1ms, is it worth your engineering time to optimize?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I can&amp;#39;t any offer any &lt;em&gt;concrete&lt;/em&gt; advice... but I&amp;#39;d always suggest measuring before you optimize.  &lt;/p&gt;\n\n&lt;p&gt;Don&amp;#39;t apply or disable a given feature or optimization &amp;quot;because the internet said so&amp;quot; (I know, it&amp;#39;s clear you&amp;#39;re actually doing legit research, but still...).  Use those as starting points maybe, but I&amp;#39;d still measure before and after results.&lt;/p&gt;\n\n&lt;p&gt;And hell, before you do &lt;em&gt;any&lt;/em&gt; of that, make sure you&amp;#39;ve established an actual latency budget.  Even if feature X adds 0.5ms of latency, if you&amp;#39;re okay with 2ms and are getting 1ms, is it worth your engineering time to optimize?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9ya9r", "score_hidden": false, "stickied": false, "created": 1492242157.0, "created_utc": 1492213357.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dgacd1m", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "whitebox_linux_geek", "parent_id": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "You are over thinking the problem.   Run the defaults and optimize when you have more data. ", "edited": 1492234989.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You are over thinking the problem.   Run the defaults and optimize when you have more data. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dgacd1m", "score_hidden": false, "stickied": false, "created": 1492263429.0, "created_utc": 1492234629.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9ws7y", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "Xzariner", "parent_id": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "We did 3Gbit on l7 loadbalance on haproxy with minimal tuning (just bumping kernel settings for TCP connections) and still some free CPU left (slower than yours). You could probably do 10Gbit easily without most of the tuning.\n\nYou will probably be fine without touching anything\n\n&gt; irqbalance disabled\n\nGood, that causes problems with some NIC drivers too\n\n&gt; 4 RSS NIC interface TxRx queues each queue pinned manually to single cpu core (via irq smp_affinity)\n\ndon't bother, just doing `irqbalance --oneshot` on boot\n\n&gt; No iptables conntrack used, just stateless iptable rules to restrict access to services on the router, like ssh and snmp.\n\nmake sure to actually unload the module or use NOTRACK, just be sure. Altho I dont think that with that level of traffic no conntrack is neccesary.\n\n&gt; My question is this, which additional HW NIC offload features should be disabled apart from the obvious ones (like LRO which is incompatible with packet forwarding) to be beneficial to a router?\n\nGenerally most of them need to be disabled if you want to use machine to sniff traffic. Others occasionally need to be disabled if there are bugs in drivers in somewhere else but honestly only time I needed to fiddle with them is on suricata capture box\n\n&gt; Are there any other things that are recommended to change when Linux is used as a pure router?\n\nWhatever you use everywhere else. But Debian works just fine", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We did 3Gbit on l7 loadbalance on haproxy with minimal tuning (just bumping kernel settings for TCP connections) and still some free CPU left (slower than yours). You could probably do 10Gbit easily without most of the tuning.&lt;/p&gt;\n\n&lt;p&gt;You will probably be fine without touching anything&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;irqbalance disabled&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Good, that causes problems with some NIC drivers too&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;4 RSS NIC interface TxRx queues each queue pinned manually to single cpu core (via irq smp_affinity)&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;don&amp;#39;t bother, just doing &lt;code&gt;irqbalance --oneshot&lt;/code&gt; on boot&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;No iptables conntrack used, just stateless iptable rules to restrict access to services on the router, like ssh and snmp.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;make sure to actually unload the module or use NOTRACK, just be sure. Altho I dont think that with that level of traffic no conntrack is neccesary.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;My question is this, which additional HW NIC offload features should be disabled apart from the obvious ones (like LRO which is incompatible with packet forwarding) to be beneficial to a router?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Generally most of them need to be disabled if you want to use machine to sniff traffic. Others occasionally need to be disabled if there are bugs in drivers in somewhere else but honestly only time I needed to fiddle with them is on suricata capture box&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Are there any other things that are recommended to change when Linux is used as a pure router?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Whatever you use everywhere else. But Debian works just fine&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9ws7y", "score_hidden": false, "stickied": false, "created": 1492240185.0, "created_utc": 1492211385.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9scy7", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Nerd_runner", "parent_id": "t1_dg9cv62", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "We all pass trough this process reinventing the wheel. Until you either need help or you need to teach. I think we all can learn a lot from this, until it's time to go corp.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We all pass trough this process reinventing the wheel. Until you either need help or you need to teach. I think we all can learn a lot from this, until it&amp;#39;s time to go corp.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9scy7", "score_hidden": false, "stickied": false, "created": 1492234332.0, "created_utc": 1492205532.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dgahmmx", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Xzariner", "parent_id": "t1_dg9y3it", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "I guess we'll wait till Debian Stretch to upgrade our loadbalancers then, thanks.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I guess we&amp;#39;ll wait till Debian Stretch to upgrade our loadbalancers then, thanks.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dgahmmx", "score_hidden": false, "stickied": false, "created": 1492277322.0, "created_utc": 1492248522.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9y3it", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "candl", "parent_id": "t1_dg9wzfz", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "It affects Linux versions from 3.6 up to 4.3. It is using per-packet balancing instead of per-flow in those versions. Vyos is using 3.13 (affected). It is because of removal of route cache in Linux 3.6 (which was slow and susceptible to ddos, but provided per-flow balancing). It is fixed since version [4.4](https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=07355737a8badd951e6b72aa8609a2d6eed0a7e7).", "edited": 1492213815.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It affects Linux versions from 3.6 up to 4.3. It is using per-packet balancing instead of per-flow in those versions. Vyos is using 3.13 (affected). It is because of removal of route cache in Linux 3.6 (which was slow and susceptible to ddos, but provided per-flow balancing). It is fixed since version &lt;a href=\"https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=07355737a8badd951e6b72aa8609a2d6eed0a7e7\"&gt;4.4&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9y3it", "score_hidden": false, "stickied": false, "created": 1492241914.0, "created_utc": 1492213114.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9wzfz", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "Xzariner", "parent_id": "t1_dg9d40d", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "&gt; Vyos has broken ECMP due to an older Kernel\n\nCare to elaborate ? ECMP works just fine for us with ye olde centos 6 2.6.32 kernel and it worked fine previously with 2.6.18", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Vyos has broken ECMP due to an older Kernel&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Care to elaborate ? ECMP works just fine for us with ye olde centos 6 2.6.32 kernel and it worked fine previously with 2.6.18&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9wzfz", "score_hidden": false, "stickied": false, "created": 1492240456.0, "created_utc": 1492211656.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9nl9v", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Martin8412", "parent_id": "t1_dg9d40d", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "You could always look into what settings VyOS would apply for your specific network card if you are in doubt and use those as guidelines. Though be sure to change things that might be different between software versions.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You could always look into what settings VyOS would apply for your specific network card if you are in doubt and use those as guidelines. Though be sure to change things that might be different between software versions.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9nl9v", "score_hidden": false, "stickied": false, "created": 1492228486.0, "created_utc": 1492199686.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9t26y", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "xevz", "parent_id": "t1_dg9d40d", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "There's actually third party support for VRFs in VyOS. It does require patching Quagga though.\n\nhttps://github.com/upa/vrf-vyatta\n\nEDIT: Or at least for Vyatta, might need some work before it's usable in VyOS.\n\nEDIT2: Oh, no BGP, nevermind. :(", "edited": 1492207116.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;There&amp;#39;s actually third party support for VRFs in VyOS. It does require patching Quagga though.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://github.com/upa/vrf-vyatta\"&gt;https://github.com/upa/vrf-vyatta&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;EDIT: Or at least for Vyatta, might need some work before it&amp;#39;s usable in VyOS.&lt;/p&gt;\n\n&lt;p&gt;EDIT2: Oh, no BGP, nevermind. :(&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9t26y", "score_hidden": false, "stickied": false, "created": 1492235234.0, "created_utc": 1492206434.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9txmt", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "xevz", "parent_id": "t1_dg9todn", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Some Googling show that some work for [Puppet](https://github.com/DNH-Computing/puppet-vyos) has been done, but nothing for Chef.\n\nAlthought, it's just a Debian based Linux distribution, in which you can get shell access, so theoretically you could just install either of them and go, but you won't get any fancy integration.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Some Googling show that some work for &lt;a href=\"https://github.com/DNH-Computing/puppet-vyos\"&gt;Puppet&lt;/a&gt; has been done, but nothing for Chef.&lt;/p&gt;\n\n&lt;p&gt;Althought, it&amp;#39;s just a Debian based Linux distribution, in which you can get shell access, so theoretically you could just install either of them and go, but you won&amp;#39;t get any fancy integration.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9txmt", "score_hidden": false, "stickied": false, "created": 1492236368.0, "created_utc": 1492207568.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9todn", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "hi11111", "parent_id": "t1_dg9t073", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Fair enough, but does vyos run the chef client?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair enough, but does vyos run the chef client?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9todn", "score_hidden": false, "stickied": false, "created": 1492236029.0, "created_utc": 1492207229.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9t073", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "xevz", "parent_id": "t1_dg9g1bc", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "https://docs.ansible.com/ansible/vyos_config_module.html\n\n... and [friends](https://docs.ansible.com/ansible/list_of_network_modules.html#vyos).", "edited": 1492207202.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://docs.ansible.com/ansible/vyos_config_module.html\"&gt;https://docs.ansible.com/ansible/vyos_config_module.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;... and &lt;a href=\"https://docs.ansible.com/ansible/list_of_network_modules.html#vyos\"&gt;friends&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9t073", "score_hidden": false, "stickied": false, "created": 1492235163.0, "created_utc": 1492206363.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9g1bc", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "hi11111", "parent_id": "t1_dg9d40d", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "C. Can manage config and updates more easily with chef, ansible, etc.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;C. Can manage config and updates more easily with chef, ansible, etc.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9g1bc", "score_hidden": false, "stickied": false, "created": 1492219487.0, "created_utc": 1492190687.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9d40d", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "icecrown_glacier_htm", "parent_id": "t1_dg9cv62", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "a) Bird (I have some configurations which may be difficult or impossible to replicate with Quagga (multiple routing tables, etc))\n\nb) Vyos has broken ECMP due to an older Kernel\n\nVyos doesn't come with any optimizations from what I can tell, it's just a neatly done package with a great CLI. \n\nSo the same question would apply to Vyos.\n\nI am actually using Vyos as a router for virtual machines and might eventually migrate if a stable version with a newer Kernel (&gt;= 4.4) gets released.", "edited": 1492189501.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;a) Bird (I have some configurations which may be difficult or impossible to replicate with Quagga (multiple routing tables, etc))&lt;/p&gt;\n\n&lt;p&gt;b) Vyos has broken ECMP due to an older Kernel&lt;/p&gt;\n\n&lt;p&gt;Vyos doesn&amp;#39;t come with any optimizations from what I can tell, it&amp;#39;s just a neatly done package with a great CLI. &lt;/p&gt;\n\n&lt;p&gt;So the same question would apply to Vyos.&lt;/p&gt;\n\n&lt;p&gt;I am actually using Vyos as a router for virtual machines and might eventually migrate if a stable version with a newer Kernel (&amp;gt;= 4.4) gets released.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9d40d", "score_hidden": false, "stickied": false, "created": 1492216165.0, "created_utc": 1492187365.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dgahfcs", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Xzariner", "parent_id": "t1_dga66zk", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "And ability to run tcpdump directly on router without having to fuck around with port mirroring makes debugging so much easier", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And ability to run tcpdump directly on router without having to fuck around with port mirroring makes debugging so much easier&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dgahfcs", "score_hidden": false, "stickied": false, "created": 1492276681.0, "created_utc": 1492247881.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga66zk", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "My-RFC1918-Dont-Lie", "parent_id": "t1_dg9wz47", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "This 100x times. Most in the sub are Networking professionals (duh) primarily, and perhaps systems people second. They forget that there exists shops where you have a bunch of multi-disciplined individuals whose strengths are Linux servers and networking protocol understanding.\n\nI like VyOS and EdgeOS, but my team fits more naturally on straight up Linux VMs with net.ipv4.ip_forward turned on running Quagga and iptables.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This 100x times. Most in the sub are Networking professionals (duh) primarily, and perhaps systems people second. They forget that there exists shops where you have a bunch of multi-disciplined individuals whose strengths are Linux servers and networking protocol understanding.&lt;/p&gt;\n\n&lt;p&gt;I like VyOS and EdgeOS, but my team fits more naturally on straight up Linux VMs with net.ipv4.ip_forward turned on running Quagga and iptables.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dga66zk", "score_hidden": false, "stickied": false, "created": 1492253033.0, "created_utc": 1492224233.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9wz47", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "Xzariner", "parent_id": "t1_dg9cv62", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Having \"just a linux box\" is actually much easier to manage if you already have a bunch of linux machines and use some kind of CM for it.\n\nYou basically have to learn new CLI from scratch , learn its quirks etc. which is fine if you come from networking background but doesn't make sense if you come from linux background.\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Having &amp;quot;just a linux box&amp;quot; is actually much easier to manage if you already have a bunch of linux machines and use some kind of CM for it.&lt;/p&gt;\n\n&lt;p&gt;You basically have to learn new CLI from scratch , learn its quirks etc. which is fine if you come from networking background but doesn&amp;#39;t make sense if you come from linux background.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9wz47", "score_hidden": false, "stickied": false, "created": 1492240444.0, "created_utc": 1492211644.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9cv62", "gilded": 0, "archived": false, "score": 8, "report_reasons": null, "author": "Gesha24", "parent_id": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Just wondering - what's your motivation for using Linux distribution and customizing it to your needs, rather than using specialized package like VyOS?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just wondering - what&amp;#39;s your motivation for using Linux distribution and customizing it to your needs, rather than using specialized package like VyOS?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9cv62", "score_hidden": false, "stickied": false, "created": 1492215890.0, "created_utc": 1492187090.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 8}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9yk7c", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "gonzopancho", "parent_id": "t1_dg9ngf4", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "'hyperthreading' is a stunt to leverage the write queues coming out of the CPU.\n\nFor some applications (such as crypto) it helps.   Most DPDK apps leverage it to good effect.\n\nBut many OS schedulers don't quite get it, and then you can see negative impact.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;#39;hyperthreading&amp;#39; is a stunt to leverage the write queues coming out of the CPU.&lt;/p&gt;\n\n&lt;p&gt;For some applications (such as crypto) it helps.   Most DPDK apps leverage it to good effect.&lt;/p&gt;\n\n&lt;p&gt;But many OS schedulers don&amp;#39;t quite get it, and then you can see negative impact.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9yk7c", "score_hidden": false, "stickied": false, "created": 1492242526.0, "created_utc": 1492213726.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9o1bd", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "TronLightyear", "parent_id": "t1_dg9ngf4", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "TIL\n\nThanks!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;TIL&lt;/p&gt;\n\n&lt;p&gt;Thanks!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9o1bd", "score_hidden": false, "stickied": false, "created": 1492229016.0, "created_utc": 1492200216.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ngf4", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "Martin8412", "parent_id": "t1_dg9ixr6", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Because it can increase latency for single threaded applications such as routing. It has something to do with the partitioning of CPU resources such as the TLB.. That is at least the claim by some people. I've seen it mentioned before when optimizing Linux or BSD for routing. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Because it can increase latency for single threaded applications such as routing. It has something to do with the partitioning of CPU resources such as the TLB.. That is at least the claim by some people. I&amp;#39;ve seen it mentioned before when optimizing Linux or BSD for routing. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9ngf4", "score_hidden": false, "stickied": false, "created": 1492228322.0, "created_utc": 1492199522.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ixr6", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "TronLightyear", "parent_id": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Why disable hyper threading?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Why disable hyper threading?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9ixr6", "score_hidden": false, "stickied": false, "created": 1492222883.0, "created_utc": 1492194083.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qkaf", "removal_reason": null, "link_id": "t3_65d9os", "likes": null, "replies": "", "user_reports": [], "id": "dg9yoc9", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "NetStrikeForce", "parent_id": "t1_dg9x8e4", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "lol, fair enough!\n\nIn all fairness I still remember the [drama with Emulex and VMQs on Windows 2012R2](https://hyper-v.nu/archives/hvredevoort/2015/03/update-emulex-vmq-issuethey-finally-did-it/)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;lol, fair enough!&lt;/p&gt;\n\n&lt;p&gt;In all fairness I still remember the &lt;a href=\"https://hyper-v.nu/archives/hvredevoort/2015/03/update-emulex-vmq-issuethey-finally-did-it/\"&gt;drama with Emulex and VMQs on Windows 2012R2&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9yoc9", "score_hidden": false, "stickied": false, "created": 1492242685.0, "created_utc": 1492213885.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9x8e4", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "Xzariner", "parent_id": "t1_dg9p9c8", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "when it comes to NICs, it's \"dodgy until proven otherwise\" (except intel I guess).\n\nWant to lose all VLANs because actual nic vendor's developers \"contributed\" to kernel by adding some bugs ? Use Brocade!\n\nWant your card to start randomly losing packets just because you forgot to disable irqbalance daemon ? Use Emulex !", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;when it comes to NICs, it&amp;#39;s &amp;quot;dodgy until proven otherwise&amp;quot; (except intel I guess).&lt;/p&gt;\n\n&lt;p&gt;Want to lose all VLANs because actual nic vendor&amp;#39;s developers &amp;quot;contributed&amp;quot; to kernel by adding some bugs ? Use Brocade!&lt;/p&gt;\n\n&lt;p&gt;Want your card to start randomly losing packets just because you forgot to disable irqbalance daemon ? Use Emulex !&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9x8e4", "score_hidden": false, "stickied": false, "created": 1492240786.0, "created_utc": 1492211986.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9p9c8", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "NetStrikeForce", "parent_id": "t3_65d9os", "subreddit_name_prefixed": "r/networking", "controversiality": 0, "body": "Unless the NIC driver is dodgy I'd say you might not want to disable any offloads.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Unless the NIC driver is dodgy I&amp;#39;d say you might not want to disable any offloads.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "networking", "name": "t1_dg9p9c8", "score_hidden": false, "stickied": false, "created": 1492230491.0, "created_utc": 1492201691.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}]