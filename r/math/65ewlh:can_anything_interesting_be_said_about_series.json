[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "math", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Particularly, if we have a fixed probability space, we can get an L_2-space of real-valued random variables quotiented by a.s.-equality, defining [;||X|| = (\\mathbb{E}(X^2))^{1/2};]. This behaves, as far as I know, basically like we expect it to -- it is a norm, we can do projections, getting best linear estimators, and so on.&lt;/p&gt;\n\n&lt;p&gt;In the analogous case of an L_2-space of functions, we can also do things like Fourier series or other similar series expansions. This is, obviously, something that has been studied a lot, since it is really useful, and is something one sees in lots of places.&lt;/p&gt;\n\n&lt;p&gt;Yet I haven&amp;#39;t seen any similar series things in the random variable case. So, am I just ignorant, or is this something that doesn&amp;#39;t exist or isn&amp;#39;t as interesting? If it doesn&amp;#39;t work, why? If it works, what do useful orthogonal bases and series look like?&lt;/p&gt;\n\n&lt;p&gt;If it doesn&amp;#39;t work, is it perhaps something about choosing the right probability space to build upon, or about there being too many indivisible probability distributions? (If the latter, can we perhaps choose some other notion than addition of random variables that makes it work better?)&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "Particularly, if we have a fixed probability space, we can get an L_2-space of real-valued random variables quotiented by a.s.-equality, defining [;||X|| = (\\mathbb{E}(X\\^2))\\^{1/2};]. This behaves, as far as I know, basically like we expect it to -- it is a norm, we can do projections, getting best linear estimators, and so on.\n\nIn the analogous case of an L_2-space of functions, we can also do things like Fourier series or other similar series expansions. This is, obviously, something that has been studied a lot, since it is really useful, and is something one sees in lots of places.\n\nYet I haven't seen any similar series things in the random variable case. So, am I just ignorant, or is this something that doesn't exist or isn't as interesting? If it doesn't work, why? If it works, what do useful orthogonal bases and series look like?\n\nIf it doesn't work, is it perhaps something about choosing the right probability space to build upon, or about there being too many indivisible probability distributions? (If the latter, can we perhaps choose some other notion than addition of random variables that makes it work better?)", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "65ewlh", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 3, "report_reasons": null, "author": "GLukacs_ClassWars", "saved": false, "mod_reports": [], "name": "t3_65ewlh", "subreddit_name_prefixed": "r/math", "approved_by": null, "over_18": false, "domain": "self.math", "hidden": false, "thumbnail": "", "subreddit_id": "t5_2qh0n", "edited": false, "link_flair_css_class": null, "author_flair_css_class": "", "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/math/comments/65ewlh/can_anything_interesting_be_said_about_series/", "num_reports": null, "locked": false, "stickied": false, "created": 1492229460.0, "url": "https://www.reddit.com/r/math/comments/65ewlh/can_anything_interesting_be_said_about_series/", "author_flair_text": "Probability", "quarantine": false, "title": "Can anything interesting be said about \"series expansions\" of random variables?", "created_utc": 1492200660.0, "distinguished": null, "media": null, "upvote_ratio": 0.81, "num_comments": 7, "visited": false, "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": "", "user_reports": [], "id": "dgcs0co", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "sleeps_with_crazy", "parent_id": "t1_dgcri1b", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": "If the objective is to compute things using them then I'd expect the best choice would be a collection of Gaussian variables.  If we just let X_n be the Gaussian with mean 0 and variance n then that collection ought to be able to separate points.  (I didn't check this but if not then surely something similar could be done).  I'm not sure what you're trying to do though, so it's hard to guess what the best plan is.\n\n&gt;Or perhaps whether they can be chosen so that the approximations one gets by truncating the series are optimal in some suitable sense?\n\nI would expect that the suitable sense would be that the partial sums converge weakly to the original distribution, but this goes back to what I said earlier.  Weak convergence just means the Fourier transforms converge so if you want to impose that as the suitable condition then you should just use the sines and cosines.  I'm not sure you can ask for the partial sums to converge in any stronger sense without losing any hope of proving they ever converge.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If the objective is to compute things using them then I&amp;#39;d expect the best choice would be a collection of Gaussian variables.  If we just let X_n be the Gaussian with mean 0 and variance n then that collection ought to be able to separate points.  (I didn&amp;#39;t check this but if not then surely something similar could be done).  I&amp;#39;m not sure what you&amp;#39;re trying to do though, so it&amp;#39;s hard to guess what the best plan is.&lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Or perhaps whether they can be chosen so that the approximations one gets by truncating the series are optimal in some suitable sense?&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I would expect that the suitable sense would be that the partial sums converge weakly to the original distribution, but this goes back to what I said earlier.  Weak convergence just means the Fourier transforms converge so if you want to impose that as the suitable condition then you should just use the sines and cosines.  I&amp;#39;m not sure you can ask for the partial sums to converge in any stronger sense without losing any hope of proving they ever converge.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dgcs0co", "score_hidden": false, "stickied": false, "created": 1492415339.0, "created_utc": 1492386539.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgcri1b", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "GLukacs_ClassWars", "parent_id": "t1_dgbv3f1", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": "Well, yes, I'm obviously aware that there's a general theory of doing such things, or I wouldn't be asking the question.\n\nHowever, giving that answer feels a bit like introducing Fourier series without ever mentioning sines or cosines. Without knowing that there is a nice basis like that we can work with, the theoretical existence of series with respect to bases isn't very interesting.\n\nThe obvious follow-up question is, then, whether we can choose our spanning set so that the involved random variables are nice -- e.g. all have finite moments of some order, or all have distribution or density function we can write in elementary terms, or some other property that makes them nice to work with? Or perhaps whether they can be chosen so that the approximations one gets by truncating the series are optimal in some suitable sense? (The \"suitable sense\" probably being something like \"for all orthonormal bases with nice properties X, the distance between the truncated series and the variable in metric Y is minimised by this base\".)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Well, yes, I&amp;#39;m obviously aware that there&amp;#39;s a general theory of doing such things, or I wouldn&amp;#39;t be asking the question.&lt;/p&gt;\n\n&lt;p&gt;However, giving that answer feels a bit like introducing Fourier series without ever mentioning sines or cosines. Without knowing that there is a nice basis like that we can work with, the theoretical existence of series with respect to bases isn&amp;#39;t very interesting.&lt;/p&gt;\n\n&lt;p&gt;The obvious follow-up question is, then, whether we can choose our spanning set so that the involved random variables are nice -- e.g. all have finite moments of some order, or all have distribution or density function we can write in elementary terms, or some other property that makes them nice to work with? Or perhaps whether they can be chosen so that the approximations one gets by truncating the series are optimal in some suitable sense? (The &amp;quot;suitable sense&amp;quot; probably being something like &amp;quot;for all orthonormal bases with nice properties X, the distance between the truncated series and the variable in metric Y is minimised by this base&amp;quot;.)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dgcri1b", "score_hidden": false, "stickied": false, "created": 1492414666.0, "created_utc": 1492385866.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbv3f1", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "sleeps_with_crazy", "parent_id": "t1_dgal1kf", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": "You can certainly do that if you want to.  Pick any collection of random variables that spans L^(2) and you can write the rest as infinite series of them, this is just Stone-Weierstrauss.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can certainly do that if you want to.  Pick any collection of random variables that spans L&lt;sup&gt;2&lt;/sup&gt; and you can write the rest as infinite series of them, this is just Stone-Weierstrauss.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dgbv3f1", "score_hidden": false, "stickied": false, "created": 1492361549.0, "created_utc": 1492332749.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgal1kf", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "GLukacs_ClassWars", "parent_id": "t1_dg9ojvb", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": "I think we're talking somewhat past each other here. What I'm interested in is doing something like a Fourier series -- so instead of writing something like\n\n      [;f(x)=\\frac{a_0}{2}+\\sum _{n=1} ^\\infty (a_n\\cos(nx)+b_n\\sin(nx));]\n\ngetting approximations by truncating the sum, I'm wondering if I can write a random variable X as\n\n      [;X=\\sum _{n=0} ^\\infty a_n X_n;]\n\nwith the X_n being some suitable set of random variables, getting approximations of X by truncating that sum.\n\nMaybe it's just my relative lack of analysis knowledge, but it isn't entirely obvious for me how to do this based on the non-probability interpretation. Especially not if we want the X_n to be a nice family of random variables we can actually compute things about.\n\nActually, I can't even think of a way to make that work around indecomposable distributions...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think we&amp;#39;re talking somewhat past each other here. What I&amp;#39;m interested in is doing something like a Fourier series -- so instead of writing something like&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  [;f(x)=\\frac{a_0}{2}+\\sum _{n=1} ^\\infty (a_n\\cos(nx)+b_n\\sin(nx));]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;getting approximations by truncating the sum, I&amp;#39;m wondering if I can write a random variable X as&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;  [;X=\\sum _{n=0} ^\\infty a_n X_n;]\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;with the X_n being some suitable set of random variables, getting approximations of X by truncating that sum.&lt;/p&gt;\n\n&lt;p&gt;Maybe it&amp;#39;s just my relative lack of analysis knowledge, but it isn&amp;#39;t entirely obvious for me how to do this based on the non-probability interpretation. Especially not if we want the X_n to be a nice family of random variables we can actually compute things about.&lt;/p&gt;\n\n&lt;p&gt;Actually, I can&amp;#39;t even think of a way to make that work around indecomposable distributions...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dgal1kf", "score_hidden": false, "stickied": false, "created": 1492287410.0, "created_utc": 1492258610.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ojvb", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "sleeps_with_crazy", "parent_id": "t3_65ewlh", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": "Random variables *are* measurable functions.  Expectation *is* an integral.  They are literally the same thing.  The L^(2) space you defined is literally L^(2)(S,P) where S is the sample space and P is the probabiity measure.  Expectation is the integral with respect to P.\n\nEverything from analysis applies to random variables.\n\nThe Fourier transform of a random variable is its characteristic function.  Weak convergence of random variables is convergence of the Fourier transforms of the variables; this is the fundamental idea behind the Central Limit Theorem.", "edited": 1492201472.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Random variables &lt;em&gt;are&lt;/em&gt; measurable functions.  Expectation &lt;em&gt;is&lt;/em&gt; an integral.  They are literally the same thing.  The L&lt;sup&gt;2&lt;/sup&gt; space you defined is literally L&lt;sup&gt;2&lt;/sup&gt;(S,P) where S is the sample space and P is the probabiity measure.  Expectation is the integral with respect to P.&lt;/p&gt;\n\n&lt;p&gt;Everything from analysis applies to random variables.&lt;/p&gt;\n\n&lt;p&gt;The Fourier transform of a random variable is its characteristic function.  Weak convergence of random variables is convergence of the Fourier transforms of the variables; this is the fundamental idea behind the Central Limit Theorem.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dg9ojvb", "score_hidden": false, "stickied": false, "created": 1492229640.0, "created_utc": 1492200840.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 12}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": "", "user_reports": [], "id": "dg9urv5", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "gioaogionny", "parent_id": "t3_65ewlh", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": " What you are looking for is Wiener Chaos, which is the basis of a big part of modern stochastic analysis - stichastic diff. equations, for instance", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What you are looking for is Wiener Chaos, which is the basis of a big part of modern stochastic analysis - stichastic diff. equations, for instance&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dg9urv5", "score_hidden": false, "stickied": false, "created": 1492237481.0, "created_utc": 1492208681.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qh0n", "removal_reason": null, "link_id": "t3_65ewlh", "likes": null, "replies": "", "user_reports": [], "id": "dgc7i8h", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Aftermath12345", "parent_id": "t3_65ewlh", "subreddit_name_prefixed": "r/math", "controversiality": 0, "body": "As mentionned below,\n\none such representation is the Wiener-Ito chaos expansion :\n\nA L^2 random variable that is mesurable with respect to the \\sigma-algebra of a Brownian motion at time T has a unique representation as a series of iterated stochastic integrals with respect to Brownian motions on [0,T].\n\nYou can use the representation to make sense of a stochastic derivative (Malliavin derivative) with respect to the Brownian motion, and also its adjoint operator, the Shorohod integral. It has applications in Stochastic PDE, in particular for the pricing of derivatives in financial math.\n\nThe most accessible source (yet rigorous) on this subject is the book by Oksendal on Malliavin calculus.", "edited": 1492359948.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;As mentionned below,&lt;/p&gt;\n\n&lt;p&gt;one such representation is the Wiener-Ito chaos expansion :&lt;/p&gt;\n\n&lt;p&gt;A L&lt;sup&gt;2&lt;/sup&gt; random variable that is mesurable with respect to the \\sigma-algebra of a Brownian motion at time T has a unique representation as a series of iterated stochastic integrals with respect to Brownian motions on [0,T].&lt;/p&gt;\n\n&lt;p&gt;You can use the representation to make sense of a stochastic derivative (Malliavin derivative) with respect to the Brownian motion, and also its adjoint operator, the Shorohod integral. It has applications in Stochastic PDE, in particular for the pricing of derivatives in financial math.&lt;/p&gt;\n\n&lt;p&gt;The most accessible source (yet rigorous) on this subject is the book by Oksendal on Malliavin calculus.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "math", "name": "t1_dgc7i8h", "score_hidden": false, "stickied": false, "created": 1492388182.0, "created_utc": 1492359382.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}]