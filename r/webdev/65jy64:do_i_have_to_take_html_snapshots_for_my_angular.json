[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "webdev", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://developers.google.com/webmasters/ajax-crawling/docs/learn-more\"&gt;https://developers.google.com/webmasters/ajax-crawling/docs/learn-more&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;But this article is outdated. So wondering if this is still needed ?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "https://developers.google.com/webmasters/ajax-crawling/docs/learn-more.\n\nBut this article is outdated. So wondering if this is still needed ?", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "65jy64", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 28, "report_reasons": null, "author": "ezio52", "saved": false, "mod_reports": [], "name": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "approved_by": null, "over_18": false, "domain": "self.webdev", "hidden": false, "preview": {"images": [{"source": {"url": "https://i.redditmedia.com/3OLs-i7T3ClI5MByz7-7b4Lmd9wKUbd0R_UfU_al0uA.jpg?s=341fb061beae30c512f13bfedcc14f05", "width": 400, "height": 267}, "resolutions": [{"url": "https://i.redditmedia.com/3OLs-i7T3ClI5MByz7-7b4Lmd9wKUbd0R_UfU_al0uA.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=108&amp;s=d417cc6a16f4fe058d43bbec1c07f901", "width": 108, "height": 72}, {"url": "https://i.redditmedia.com/3OLs-i7T3ClI5MByz7-7b4Lmd9wKUbd0R_UfU_al0uA.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=216&amp;s=7d4a9e388495dbe7bac4b68dd7f705e0", "width": 216, "height": 144}, {"url": "https://i.redditmedia.com/3OLs-i7T3ClI5MByz7-7b4Lmd9wKUbd0R_UfU_al0uA.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=320&amp;s=14a03c7500313c6428b77465530c08c4", "width": 320, "height": 213}], "variants": {}, "id": "bRJp16q7SKlO-KQe_noO7Vi5LtWPljNuNsoKGynuVj4"}], "enabled": false}, "thumbnail": "self", "subreddit_id": "t5_2qs0q", "edited": false, "link_flair_css_class": null, "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "post_hint": "self", "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/webdev/comments/65jy64/do_i_have_to_take_html_snapshots_for_my_angular/", "num_reports": null, "locked": false, "stickied": false, "created": 1492302540.0, "url": "https://www.reddit.com/r/webdev/comments/65jy64/do_i_have_to_take_html_snapshots_for_my_angular/", "author_flair_text": null, "quarantine": false, "title": "Do I have to take html snapshots for my Angular website to make it crawable?", "created_utc": 1492273740.0, "distinguished": null, "media": null, "upvote_ratio": 0.82, "num_comments": 29, "visited": false, "subreddit_type": "public", "ups": 28}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgblf67", "gilded": 0, "archived": false, "score": 12, "report_reasons": null, "author": "could-of-bot", "parent_id": "t1_dgblf44", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "It's either could **HAVE** or could**'VE**, but never could **OF**. \n\n See [Grammar Errors](http://www.grammarerrors.com/grammar/could-of-would-of-should-of/) for more information.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s either could &lt;strong&gt;HAVE&lt;/strong&gt; or could&lt;strong&gt;&amp;#39;VE&lt;/strong&gt;, but never could &lt;strong&gt;OF&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;See &lt;a href=\"http://www.grammarerrors.com/grammar/could-of-would-of-should-of/\"&gt;Grammar Errors&lt;/a&gt; for more information.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgblf67", "score_hidden": false, "stickied": false, "created": 1492340797.0, "created_utc": 1492311997.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 12}}], "after": null, "before": null}}, "user_reports": [], "id": "dgblf44", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "RemeJuan", "parent_id": "t1_dgbdok1", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "They are plain html an js, what is the complication you facing? You can host those practically everywhere, up until about a year ago you could of hosted it on Dropbox. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They are plain html an js, what is the complication you facing? You can host those practically everywhere, up until about a year ago you could of hosted it on Dropbox. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgblf44", "score_hidden": false, "stickied": false, "created": 1492340795.0, "created_utc": 1492311995.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbsq2c", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Crecket", "parent_id": "t1_dgbdok1", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Deploy as in putting my new versions online? My most basic setup uses [Flightplan](https://github.com/pstadler/flightplan). All it does is connect to to my target server and then run git pull/npm build script. \n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Deploy as in putting my new versions online? My most basic setup uses &lt;a href=\"https://github.com/pstadler/flightplan\"&gt;Flightplan&lt;/a&gt;. All it does is connect to to my target server and then run git pull/npm build script. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbsq2c", "score_hidden": false, "stickied": false, "created": 1492354524.0, "created_utc": 1492325724.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbdok1", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "upular21", "parent_id": "t1_dgb4zt7", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Quick question: how do you deploy your react apps? I'm trying to deploy ok my own server, do you do that or do you use heroku or the likes?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Quick question: how do you deploy your react apps? I&amp;#39;m trying to deploy ok my own server, do you do that or do you use heroku or the likes?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbdok1", "score_hidden": false, "stickied": false, "created": 1492329577.0, "created_utc": 1492300777.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbc110", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "HuskyPants", "parent_id": "t1_dgb4zt7", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "This is our issue. We are basically going to add the pre-rendered page to the sitemap after it has been called and cached. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is our issue. We are basically going to add the pre-rendered page to the sitemap after it has been called and cached. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbc110", "score_hidden": false, "stickied": false, "created": 1492327267.0, "created_utc": 1492298467.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb4zt7", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "Crecket", "parent_id": "t1_dgavjle", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "You can use the Search console to check how google indexes your page. For the most part it always renders my React apps just fine. It only goes wrong if you for example do a API call before showing things or do something to delay the rendering significantly", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can use the Search console to check how google indexes your page. For the most part it always renders my React apps just fine. It only goes wrong if you for example do a API call before showing things or do something to delay the rendering significantly&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgb4zt7", "score_hidden": false, "stickied": false, "created": 1492317337.0, "created_utc": 1492288537.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbnuo3", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "qmic", "parent_id": "t1_dgavjle", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Google is rendering js, but not handling properly hash links", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Google is rendering js, but not handling properly hash links&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbnuo3", "score_hidden": false, "stickied": false, "created": 1492344611.0, "created_utc": 1492315811.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgavjle", "gilded": 0, "archived": false, "score": 16, "report_reasons": null, "author": "kamescg", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "From what I've read and come to understand is \"no\" you don't need to take HTML snapshots - for the most part.\n\nGoogle will \"potentially\" render a Javascript application and treat it as a traditional HTML document to be indexed. That being said, I've heard this only occurs for site with significant traffic. I could be wrong.\n\nGoogle does this, but other search engines might not...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;From what I&amp;#39;ve read and come to understand is &amp;quot;no&amp;quot; you don&amp;#39;t need to take HTML snapshots - for the most part.&lt;/p&gt;\n\n&lt;p&gt;Google will &amp;quot;potentially&amp;quot; render a Javascript application and treat it as a traditional HTML document to be indexed. That being said, I&amp;#39;ve heard this only occurs for site with significant traffic. I could be wrong.&lt;/p&gt;\n\n&lt;p&gt;Google does this, but other search engines might not...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgavjle", "score_hidden": false, "stickied": false, "created": 1492304520.0, "created_utc": 1492275720.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 16}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbykge", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "dweezil22", "parent_id": "t1_dgbnmns", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Agreed totally. There are good reasons to do server side renders, and hell it might even be a good idea here, but the thought of adding an entire server side infrastructure just for the sake of a search crawler seems nuts.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Agreed totally. There are good reasons to do server side renders, and hell it might even be a good idea here, but the thought of adding an entire server side infrastructure just for the sake of a search crawler seems nuts.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbykge", "score_hidden": false, "stickied": false, "created": 1492372893.0, "created_utc": 1492344093.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbnmns", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "kevinkace", "parent_id": "t1_dgbh81s", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "You're right about the additional requirements, but SSR has additional benefits, eg faster rendering, &amp; (at least partial) support for JS disabled clients. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You&amp;#39;re right about the additional requirements, but SSR has additional benefits, eg faster rendering, &amp;amp; (at least partial) support for JS disabled clients. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbnmns", "score_hidden": false, "stickied": false, "created": 1492344233.0, "created_utc": 1492315433.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbh81s", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "dweezil22", "parent_id": "t1_dgaxnl9", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Making your app isomorophic just for the sake of search crawling seems like a big technical investment for a rather random gain... If nothing else that means you're going to need a dedicated server side for the pre-render, which you wouldn't necessarily otherwise need in an Angular app.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Making your app isomorophic just for the sake of search crawling seems like a big technical investment for a rather random gain... If nothing else that means you&amp;#39;re going to need a dedicated server side for the pre-render, which you wouldn&amp;#39;t necessarily otherwise need in an Angular app.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbh81s", "score_hidden": false, "stickied": false, "created": 1492334635.0, "created_utc": 1492305835.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbkml7", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "everythingisthrown", "parent_id": "t1_dgb8gjs", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Yup. prerender.io if I'm not mistaken", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yup. prerender.io if I&amp;#39;m not mistaken&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbkml7", "score_hidden": false, "stickied": false, "created": 1492339640.0, "created_utc": 1492310840.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgce7sr", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "blackmanrgh", "parent_id": "t1_dgce6kh", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "No worries! Cheers for your help anyway, I think I'll do that! ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No worries! Cheers for your help anyway, I think I&amp;#39;ll do that! &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgce7sr", "score_hidden": false, "stickied": false, "created": 1492397042.0, "created_utc": 1492368242.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgce6kh", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "numinm", "parent_id": "t1_dgcdmjd", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Hmm.. Not too sure about that sorry, I'm sure you could make an issue about it on Github!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hmm.. Not too sure about that sorry, I&amp;#39;m sure you could make an issue about it on Github!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgce6kh", "score_hidden": false, "stickied": false, "created": 1492396998.0, "created_utc": 1492368198.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgcdmjd", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "blackmanrgh", "parent_id": "t1_dgcckpw", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Yeah that makes sense! I'm currently working on a site, using Vue and the WP Rest API, and I'm wondering how easy it will be to make the pages that are added in the CMS crawl-able? Is there a way to dynamically add routes to the pre-render plugin as the pages/posts are added?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah that makes sense! I&amp;#39;m currently working on a site, using Vue and the WP Rest API, and I&amp;#39;m wondering how easy it will be to make the pages that are added in the CMS crawl-able? Is there a way to dynamically add routes to the pre-render plugin as the pages/posts are added?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgcdmjd", "score_hidden": false, "stickied": false, "created": 1492396241.0, "created_utc": 1492367441.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgcckpw", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "numinm", "parent_id": "t1_dgc1bxw", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Yes! Though I have some pages that are very dynamic which sadly doesn't work well with the pre-render. But besides that the pre-render works great for more static pages, eg \"About\", FAQ etc", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yes! Though I have some pages that are very dynamic which sadly doesn&amp;#39;t work well with the pre-render. But besides that the pre-render works great for more static pages, eg &amp;quot;About&amp;quot;, FAQ etc&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgcckpw", "score_hidden": false, "stickied": false, "created": 1492394836.0, "created_utc": 1492366036.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgc1bxw", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "blackmanrgh", "parent_id": "t1_dgc1a8h", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Ahh right! So, in your opinion, does the pre-render plugin do a good job of making your site more crawl-able?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ahh right! So, in your opinion, does the pre-render plugin do a good job of making your site more crawl-able?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgc1bxw", "score_hidden": false, "stickied": false, "created": 1492378969.0, "created_utc": 1492350169.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgc1a8h", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "numinm", "parent_id": "t1_dgb8gjs", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Yeah sorry, I meant for server side rendering. I use the pretender vue plugin!!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah sorry, I meant for server side rendering. I use the pretender vue plugin!!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgc1a8h", "score_hidden": false, "stickied": false, "created": 1492378880.0, "created_utc": 1492350080.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb8gjs", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "blackmanrgh", "parent_id": "t1_dgb78ff", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Really? I was under the impression that you just have to add your routes to the pre-render plugin and then you're good to go...", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Really? I was under the impression that you just have to add your routes to the pre-render plugin and then you&amp;#39;re good to go...&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgb8gjs", "score_hidden": false, "stickied": false, "created": 1492322107.0, "created_utc": 1492293307.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb78ff", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "numinm", "parent_id": "t1_dgaxnl9", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Not OP, but would that usually end up being a re-write of my client side app?\n\nI use Vue which has SSR capabilities and I've read a few guides on it, but doesn't seem possible for me to do without redoing all of my client side work.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Not OP, but would that usually end up being a re-write of my client side app?&lt;/p&gt;\n\n&lt;p&gt;I use Vue which has SSR capabilities and I&amp;#39;ve read a few guides on it, but doesn&amp;#39;t seem possible for me to do without redoing all of my client side work.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgb78ff", "score_hidden": false, "stickied": false, "created": 1492320434.0, "created_utc": 1492291634.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaxnl9", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "igeligel", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Ever thought about Server-Side Rendering or Prerendering?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ever thought about Server-Side Rendering or Prerendering?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgaxnl9", "score_hidden": false, "stickied": false, "created": 1492307387.0, "created_utc": 1492278587.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 11}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgavxup", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "RemeJuan", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Only google does, but other sites do not, likes on Facebook, Twitter etc will only ever be for the home page. Most services do not attempt to render js frameworks before scraping meta data. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Only google does, but other sites do not, likes on Facebook, Twitter etc will only ever be for the home page. Most services do not attempt to render js frameworks before scraping meta data. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgavxup", "score_hidden": false, "stickied": false, "created": 1492305066.0, "created_utc": 1492276266.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbfpjr", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "imnotonit", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "prerender.io", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;prerender.io&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbfpjr", "score_hidden": false, "stickied": false, "created": 1492332485.0, "created_utc": 1492303685.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbi04u", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "J_tt", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "For my current job we're using Netlify (with prerendering turned on). It works quite well.\n\nWe're using Angular (1), Firebase, and lazy loading with Angular AMD and requireJS.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For my current job we&amp;#39;re using Netlify (with prerendering turned on). It works quite well.&lt;/p&gt;\n\n&lt;p&gt;We&amp;#39;re using Angular (1), Firebase, and lazy loading with Angular AMD and requireJS.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbi04u", "score_hidden": false, "stickied": false, "created": 1492335769.0, "created_utc": 1492306969.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbi9av", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Lakelava", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "Google can run your JavaScript, but other crawlers won't. Some web pages use the text in the description to render the link for your page. If you have JavaScript there, the link won't look nice.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Google can run your JavaScript, but other crawlers won&amp;#39;t. Some web pages use the text in the description to render the link for your page. If you have JavaScript there, the link won&amp;#39;t look nice.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbi9av", "score_hidden": false, "stickied": false, "created": 1492336134.0, "created_utc": 1492307334.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbjkz6", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Fidodo", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "While Google crawls JS only sites, one question I have that I would be worried about is do they crawl it as often.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;While Google crawls JS only sites, one question I have that I would be worried about is do they crawl it as often.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbjkz6", "score_hidden": false, "stickied": false, "created": 1492338090.0, "created_utc": 1492309290.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbnvj0", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "qmic", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "I think you should we had many problems with indexing without it. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think you should we had many problems with indexing without it. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbnvj0", "score_hidden": false, "stickied": false, "created": 1492344655.0, "created_utc": 1492315855.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qs0q", "removal_reason": null, "link_id": "t3_65jy64", "likes": null, "replies": "", "user_reports": [], "id": "dgbw37h", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "amunak", "parent_id": "t1_dgbcxzr", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "No for Google. There are many benefits to sending actual, complete markup to clients.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No for Google. There are many benefits to sending actual, complete markup to clients.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbw37h", "score_hidden": false, "stickied": false, "created": 1492364971.0, "created_utc": 1492336171.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbcxzr", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "ElvarP", "parent_id": "t3_65jy64", "subreddit_name_prefixed": "r/webdev", "controversiality": 0, "body": "https://webmasters.googleblog.com/2015/10/deprecating-our-ajax-crawling-scheme.html\n\nthis should answer your question.\n\ntl;dr: no.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&lt;a href=\"https://webmasters.googleblog.com/2015/10/deprecating-our-ajax-crawling-scheme.html\"&gt;https://webmasters.googleblog.com/2015/10/deprecating-our-ajax-crawling-scheme.html&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;this should answer your question.&lt;/p&gt;\n\n&lt;p&gt;tl;dr: no.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "webdev", "name": "t1_dgbcxzr", "score_hidden": false, "stickied": false, "created": 1492328569.0, "created_utc": 1492299769.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}]