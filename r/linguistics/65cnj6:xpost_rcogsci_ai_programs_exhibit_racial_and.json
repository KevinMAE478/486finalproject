[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "linguistics", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "[Pop Article]", "id": "65cnj6", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 282, "report_reasons": null, "author": "Rhazior", "saved": false, "mod_reports": [], "name": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "approved_by": null, "over_18": false, "domain": "theguardian.com", "hidden": false, "preview": {"images": [{"source": {"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?s=bbd8a932643ece7ab18857f06623b60f", "width": 1200, "height": 630}, "resolutions": [{"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=108&amp;s=c6389acb56c8d63636e41488a4999bae", "width": 108, "height": 56}, {"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=216&amp;s=a92a2a4f814abf6f13594afdf360ee37", "width": 216, "height": 113}, {"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=320&amp;s=08d5225015066f3372c6dfa13dff8bd1", "width": 320, "height": 168}, {"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=640&amp;s=83ebf635d2773471be71724a25ec2638", "width": 640, "height": 336}, {"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=960&amp;s=55431dea618458e91deea414d16b130b", "width": 960, "height": 504}, {"url": "https://i.redditmedia.com/g8Bco-hvMpPkHckVw4EOjKNx1pBJ-H1Pdc8rFbfoJOw.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=1080&amp;s=dd9a2b410014f326fbd3b4d88aed4070", "width": 1080, "height": 567}], "variants": {}, "id": "4SuZ2ulzCw1k_LW3G3BSlbGVJADuM6wv3t0qb3zYq-0"}], "enabled": false}, "thumbnail": "https://b.thumbs.redditmedia.com/jdIMnNkU0Z8Dmg3VEZojLx0F5kUKUyg6rbccYt7GrKw.jpg", "subreddit_id": "t5_2qhos", "edited": false, "link_flair_css_class": "article", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "post_hint": "link", "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/linguistics/comments/65cnj6/xpost_rcogsci_ai_programs_exhibit_racial_and/", "num_reports": null, "locked": false, "stickied": false, "created": 1492207077.0, "url": "https://www.theguardian.com/technology/2017/apr/13/ai-programs-exhibit-racist-and-sexist-biases-research-reveals", "author_flair_text": null, "quarantine": false, "title": "[x-post /r/Cogsci] AI programs exhibit racial and gender biases, research reveals: \"Machine learning algorithms are picking up deeply ingrained race and gender prejudices concealed within the patterns of language use, scientists say\"", "created_utc": 1492178277.0, "distinguished": null, "media": null, "upvote_ratio": 0.91, "num_comments": 54, "visited": false, "subreddit_type": "public", "ups": 282}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "more"}], "after": null, "before": null}}, "user_reports": [], "id": "dgc4drd", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgc49bi", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc4drd", "score_hidden": false, "stickied": false, "created": 1492383878.0, "created_utc": 1492355078.0, "depth": 9, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgc49bi", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgc44g9", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc49bi", "score_hidden": false, "stickied": false, "created": 1492383690.0, "created_utc": 1492354890.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgc44g9", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dgc41gw", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc44g9", "score_hidden": false, "stickied": false, "created": 1492383488.0, "created_utc": 1492354688.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgc41gw", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9khe0", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc41gw", "score_hidden": false, "stickied": false, "created": 1492383362.0, "created_utc": 1492354562.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9khe0", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9js3v", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9khe0", "score_hidden": false, "stickied": false, "created": 1492224738.0, "created_utc": 1492195938.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dg9jyah", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9js3v", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9jyah", "score_hidden": false, "stickied": false, "created": 1492224101.0, "created_utc": 1492195301.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9js3v", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9ir7w", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9js3v", "score_hidden": false, "stickied": false, "created": 1492223896.0, "created_utc": 1492195096.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9ir7w", "gilded": 0, "archived": false, "score": 28, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dg9g1bw", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Cognitive bias and basic sociological theory really should be part of standard primary education. Too many people think that their brain can do things that it simply can't", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cognitive bias and basic sociological theory really should be part of standard primary education. Too many people think that their brain can do things that it simply can&amp;#39;t&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9ir7w", "score_hidden": false, "stickied": false, "created": 1492222668.0, "created_utc": 1492193868.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 28}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dg9ldxi", "gilded": 0, "archived": false, "score": 11, "report_reasons": null, "author": "best_of_badgers", "parent_id": "t1_dg9l6ug", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Fair enough. :) \n\nI do think that you're underestimating our ability to study the outcomes of these biases in social situations. That's literally what behavioral economics does. Obviously the answer is going to be complex, and not always strictly deterministic, and we can't always generalize from group behavior to individual behavior. However, that doesn't mean we should just throw up our hands and stop trying. \n\nI do agree that the IAT is not a good tool for this, but behavioral econ has a lot of other tools.\n\nHave a good day!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair enough. :) &lt;/p&gt;\n\n&lt;p&gt;I do think that you&amp;#39;re underestimating our ability to study the outcomes of these biases in social situations. That&amp;#39;s literally what behavioral economics does. Obviously the answer is going to be complex, and not always strictly deterministic, and we can&amp;#39;t always generalize from group behavior to individual behavior. However, that doesn&amp;#39;t mean we should just throw up our hands and stop trying. &lt;/p&gt;\n\n&lt;p&gt;I do agree that the IAT is not a good tool for this, but behavioral econ has a lot of other tools.&lt;/p&gt;\n\n&lt;p&gt;Have a good day!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9ldxi", "score_hidden": false, "stickied": false, "created": 1492225832.0, "created_utc": 1492197032.0, "depth": 8, "mod_reports": [], "subreddit_type": "public", "ups": 11}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9l6ug", "gilded": 0, "archived": false, "score": -2, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9kubf", "subreddit_name_prefixed": "r/linguistics", "controversiality": 1, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9l6ug", "score_hidden": false, "stickied": false, "created": 1492225591.0, "created_utc": 1492196791.0, "depth": 7, "mod_reports": [], "subreddit_type": "public", "ups": -2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9kubf", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "best_of_badgers", "parent_id": "t1_dg9k7sg", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "We humans have [an absurdly large variety](http://rationalwiki.org/wiki/List_of_cognitive_biases) of implicit and cognitive biases.\n\nMost of the time, they're \"shortcuts\" (heuristics) that our brains use to save energy. *Most* of these shortcuts are useful *most* of the time, or we wouldn't have evolved them. However, there are lots of problems out there with a solution that is simple, obvious, and wrong, and those are often the \"shortcuts\" our brains take. The fields of cognitive psychology and behavioral economics study these shortcuts and try to figure out better ways to structure our systems and our markets so that people don't make as many mistakes.\n\nFor example, did you know that \"free\" is a special price in economics? People are actually pretty good at making rational economic decisions based on prices, unless one of those prices is \"free\", in which case our usual heuristics go all kinds of out the window. It kinda makes our brains divide by zero or something.\n\nYou can override a lot of these biases with conscious effort and with good systems that force you to consider them. However (and this is a big however), one of the more interesting results of cognitive psych is that our willpower seems to have a limited supply. The classic experiment is where they asked people to either do a difficult puzzle or sit around doing nothing during an experiment. They then sneakily offered the people the temptation of taking a chocolate chip cookie. The people who had just \"spent\" their willpower doing the difficult puzzle were less able to resist the cookie temptation and their brain's natural heuristic of \"food = good\" kicked in. All this means is that we can only make so many well thought out decisions in a day, and after making enough of them, our brains get tired and start resorting to shortcuts. (They've found substantial differences in the results of court trials before and after a break.)\n\nI don't think anybody here is going as far as you are with the land grabs and reparations thing. That's because we're focusing on science, and not ideology. ;)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;We humans have &lt;a href=\"http://rationalwiki.org/wiki/List_of_cognitive_biases\"&gt;an absurdly large variety&lt;/a&gt; of implicit and cognitive biases.&lt;/p&gt;\n\n&lt;p&gt;Most of the time, they&amp;#39;re &amp;quot;shortcuts&amp;quot; (heuristics) that our brains use to save energy. &lt;em&gt;Most&lt;/em&gt; of these shortcuts are useful &lt;em&gt;most&lt;/em&gt; of the time, or we wouldn&amp;#39;t have evolved them. However, there are lots of problems out there with a solution that is simple, obvious, and wrong, and those are often the &amp;quot;shortcuts&amp;quot; our brains take. The fields of cognitive psychology and behavioral economics study these shortcuts and try to figure out better ways to structure our systems and our markets so that people don&amp;#39;t make as many mistakes.&lt;/p&gt;\n\n&lt;p&gt;For example, did you know that &amp;quot;free&amp;quot; is a special price in economics? People are actually pretty good at making rational economic decisions based on prices, unless one of those prices is &amp;quot;free&amp;quot;, in which case our usual heuristics go all kinds of out the window. It kinda makes our brains divide by zero or something.&lt;/p&gt;\n\n&lt;p&gt;You can override a lot of these biases with conscious effort and with good systems that force you to consider them. However (and this is a big however), one of the more interesting results of cognitive psych is that our willpower seems to have a limited supply. The classic experiment is where they asked people to either do a difficult puzzle or sit around doing nothing during an experiment. They then sneakily offered the people the temptation of taking a chocolate chip cookie. The people who had just &amp;quot;spent&amp;quot; their willpower doing the difficult puzzle were less able to resist the cookie temptation and their brain&amp;#39;s natural heuristic of &amp;quot;food = good&amp;quot; kicked in. All this means is that we can only make so many well thought out decisions in a day, and after making enough of them, our brains get tired and start resorting to shortcuts. (They&amp;#39;ve found substantial differences in the results of court trials before and after a break.)&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think anybody here is going as far as you are with the land grabs and reparations thing. That&amp;#39;s because we&amp;#39;re focusing on science, and not ideology. ;)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9kubf", "score_hidden": false, "stickied": false, "created": 1492225172.0, "created_utc": 1492196372.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 25}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9k7sg", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9jr5v", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[deleted]", "edited": 1492196047.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9k7sg", "score_hidden": false, "stickied": false, "created": 1492224417.0, "created_utc": 1492195617.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9jr5v", "gilded": 0, "archived": false, "score": 25, "report_reasons": null, "author": "best_of_badgers", "parent_id": "t1_dg9imu7", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I stopped reading after the \"neo-Marxist\" sentence. What's funny about all this is that in your original post you actually provided two examples of implicit biases. Marketing very successfully uses implicit bias, so it would be big news to that billions of dollars industry if implicit / cognitive bias didn't exist. All of which leads me to believe that you don't know what you're talking about.\n\nI believe you're confusing implicit bias with Harvard's Implicit Association Test. I did work with the IAT in undergrad (wrote my own, in fact), and I haven't heard much about it since then. It's hardly the darling of psychology or behavioral economics that you're making it out to be.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I stopped reading after the &amp;quot;neo-Marxist&amp;quot; sentence. What&amp;#39;s funny about all this is that in your original post you actually provided two examples of implicit biases. Marketing very successfully uses implicit bias, so it would be big news to that billions of dollars industry if implicit / cognitive bias didn&amp;#39;t exist. All of which leads me to believe that you don&amp;#39;t know what you&amp;#39;re talking about.&lt;/p&gt;\n\n&lt;p&gt;I believe you&amp;#39;re confusing implicit bias with Harvard&amp;#39;s Implicit Association Test. I did work with the IAT in undergrad (wrote my own, in fact), and I haven&amp;#39;t heard much about it since then. It&amp;#39;s hardly the darling of psychology or behavioral economics that you&amp;#39;re making it out to be.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9jr5v", "score_hidden": false, "stickied": false, "created": 1492223865.0, "created_utc": 1492195065.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 25}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9imu7", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9g1bw", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[deleted]", "edited": 1492194183.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9imu7", "score_hidden": false, "stickied": false, "created": 1492222526.0, "created_utc": 1492193726.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9g1bw", "gilded": 0, "archived": false, "score": 53, "report_reasons": null, "author": "best_of_badgers", "parent_id": "t1_dg9f76c", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "&gt; Many implicit biases can be explained by novelty response or preference for the familiar, which are well documented phenomena.\n\n\"Novelty response\" and \"preference for the familiar\", when they generate \"disparate outcomes\" for people of certain groups, are prejudiced by definition. We're not talking about choosing a familiar brand of jelly over an unfamiliar brand. We're talking about humans and human lives. If people have a \"preference for the familiar\", and that (yes) implicit preference biases them toward, say, renting good housing to people who look or act like themselves, it's a problem for people who don't. This is especially the case if, for historic reasons, most landlords are white men.\n\nEdit: It also occurred to me that you may not realize what \"implicit\" means. It just means that you aren't doing it on purpose. An explicit bias is one that you can talk about, a deliberate (even if small) preference for one type of jelly over another. Maybe you like the taste, I don't know. But odds are you won't be able to tell me why you prefer the store brand over Smuckers. It's because you're familiar with the store brand, but you won't realize this consciously. That's an implicit, not explicit, bias. People generally strongly oppose the idea that they even have implicit biases, but marketers laugh at them and sell them more soap.\n\nEdit2: \"Yeah but I prefer the taste of the store brand,\" you say. \"My bias toward it is explicit!\" Let's switch the labels on the shelf and see what happens.", "edited": 1492191395.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;Many implicit biases can be explained by novelty response or preference for the familiar, which are well documented phenomena.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;quot;Novelty response&amp;quot; and &amp;quot;preference for the familiar&amp;quot;, when they generate &amp;quot;disparate outcomes&amp;quot; for people of certain groups, are prejudiced by definition. We&amp;#39;re not talking about choosing a familiar brand of jelly over an unfamiliar brand. We&amp;#39;re talking about humans and human lives. If people have a &amp;quot;preference for the familiar&amp;quot;, and that (yes) implicit preference biases them toward, say, renting good housing to people who look or act like themselves, it&amp;#39;s a problem for people who don&amp;#39;t. This is especially the case if, for historic reasons, most landlords are white men.&lt;/p&gt;\n\n&lt;p&gt;Edit: It also occurred to me that you may not realize what &amp;quot;implicit&amp;quot; means. It just means that you aren&amp;#39;t doing it on purpose. An explicit bias is one that you can talk about, a deliberate (even if small) preference for one type of jelly over another. Maybe you like the taste, I don&amp;#39;t know. But odds are you won&amp;#39;t be able to tell me why you prefer the store brand over Smuckers. It&amp;#39;s because you&amp;#39;re familiar with the store brand, but you won&amp;#39;t realize this consciously. That&amp;#39;s an implicit, not explicit, bias. People generally strongly oppose the idea that they even have implicit biases, but marketers laugh at them and sell them more soap.&lt;/p&gt;\n\n&lt;p&gt;Edit2: &amp;quot;Yeah but I prefer the taste of the store brand,&amp;quot; you say. &amp;quot;My bias toward it is explicit!&amp;quot; Let&amp;#39;s switch the labels on the shelf and see what happens.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9g1bw", "score_hidden": false, "stickied": false, "created": 1492219488.0, "created_utc": 1492190688.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 53}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgaq9t0", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dga7m7u", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "And Syntax (at least the American/Chomskian form of it) is basically just math. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;And Syntax (at least the American/Chomskian form of it) is basically just math. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgaq9t0", "score_hidden": false, "stickied": false, "created": 1492297084.0, "created_utc": 1492268284.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dga7m7u", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "squirreltalk", "parent_id": "t1_dga5j1i", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Much of it is closer to prototypical science. But much of it is also closer to prototypical philosophy. Take pragmatics. Much of it comes from philosophers like Wittgenstein and Grice. Who then *inspired* scientists. Wittgenstein inspired Eleanor Rosch, for example. Grice inspired plenty of contemporary experimental pragmaticians.", "edited": 1492226937.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Much of it is closer to prototypical science. But much of it is also closer to prototypical philosophy. Take pragmatics. Much of it comes from philosophers like Wittgenstein and Grice. Who then &lt;em&gt;inspired&lt;/em&gt; scientists. Wittgenstein inspired Eleanor Rosch, for example. Grice inspired plenty of contemporary experimental pragmaticians.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dga7m7u", "score_hidden": false, "stickied": false, "created": 1492255147.0, "created_utc": 1492226347.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dga5j1i", "gilded": 0, "archived": false, "score": 13, "report_reasons": null, "author": "ilovethosedogs", "parent_id": "t1_dg9zi9h", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Linguistics is science.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Linguistics is science.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dga5j1i", "score_hidden": false, "stickied": false, "created": 1492252095.0, "created_utc": 1492223295.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 13}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dga7y9h", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "squirreltalk", "parent_id": "t1_dga6bdz", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "This comes up in /r/askphilosophy from time to time. Here's a semi-recent thread about this:\n\nhttps://www.reddit.com/r/askphilosophy/comments/4p6fwu/why_does_the_thought_of_philosophy_not_being/", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This comes up in &lt;a href=\"/r/askphilosophy\"&gt;/r/askphilosophy&lt;/a&gt; from time to time. Here&amp;#39;s a semi-recent thread about this:&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://www.reddit.com/r/askphilosophy/comments/4p6fwu/why_does_the_thought_of_philosophy_not_being/\"&gt;https://www.reddit.com/r/askphilosophy/comments/4p6fwu/why_does_the_thought_of_philosophy_not_being/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dga7y9h", "score_hidden": false, "stickied": false, "created": 1492255677.0, "created_utc": 1492226877.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgaqruv", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dga6bdz", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Careful with your use of \"knowledge\". To people who haven't had particular training in the sciences, it is assumed that \"science\" is a generic term for \"knowledge\" or \"smart-people stuff\". \n\nIn reality it means something very specific, a very particular and narrowly applied method of acquiring knowledge, particularly effective at acquiring knowledge about the universe. But it is not the only way. It is possible to learn new things that don't have to do with the universe or people or the world we live in at all, but are a consequence of existence, logic, society, and the concept of knowledge itself. \n\nPhilosophy tells us how to conduct research ethically, what rights are and what it means to have them and respect them. The very definition of science and the reason that we know science works comes from philosophy. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Careful with your use of &amp;quot;knowledge&amp;quot;. To people who haven&amp;#39;t had particular training in the sciences, it is assumed that &amp;quot;science&amp;quot; is a generic term for &amp;quot;knowledge&amp;quot; or &amp;quot;smart-people stuff&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;In reality it means something very specific, a very particular and narrowly applied method of acquiring knowledge, particularly effective at acquiring knowledge about the universe. But it is not the only way. It is possible to learn new things that don&amp;#39;t have to do with the universe or people or the world we live in at all, but are a consequence of existence, logic, society, and the concept of knowledge itself. &lt;/p&gt;\n\n&lt;p&gt;Philosophy tells us how to conduct research ethically, what rights are and what it means to have them and respect them. The very definition of science and the reason that we know science works comes from philosophy. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgaqruv", "score_hidden": false, "stickied": false, "created": 1492297824.0, "created_utc": 1492269024.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}, "user_reports": [], "id": "dga6bdz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ilovethosedogs", "parent_id": "t1_dg9zi9h", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "On a separate note, I'm genuinely not sure of what new tangible knowledge that philosophy proper has provided since the respective scientific fields have split away from it.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;On a separate note, I&amp;#39;m genuinely not sure of what new tangible knowledge that philosophy proper has provided since the respective scientific fields have split away from it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dga6bdz", "score_hidden": false, "stickied": false, "created": 1492253204.0, "created_utc": 1492224404.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9zi9h", "gilded": 0, "archived": false, "score": 14, "report_reasons": null, "author": "squirreltalk", "parent_id": "t1_dg9f76c", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "&gt; It's especially easy to dismiss it when it's full of feminist vocabulary because you know you're not hearing science, you're hearing an ideological narrative generated by gender studies departments who explicitly state their political agenda in their mission statements.\n\nYour argument against the validity of feminism and gender studies seems premised on the idea that science is the only path to knowledge, when I'd argue that math, philosophy, and sometimes even linguistics prove otherwise. (And this is all leaving aside the tricky problem of how to even demarcate science from other knowledge-generating enterprises....) Similarly, the second half of your statement seems to imply that gender studies departments have their minds made up a priori, in the absence of evidence or reason, and then simply spout that off. That is, you seem to think that they just make stuff up. Can you give more evidence that this is systematically true of gender studies departments and methods?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;It&amp;#39;s especially easy to dismiss it when it&amp;#39;s full of feminist vocabulary because you know you&amp;#39;re not hearing science, you&amp;#39;re hearing an ideological narrative generated by gender studies departments who explicitly state their political agenda in their mission statements.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Your argument against the validity of feminism and gender studies seems premised on the idea that science is the only path to knowledge, when I&amp;#39;d argue that math, philosophy, and sometimes even linguistics prove otherwise. (And this is all leaving aside the tricky problem of how to even demarcate science from other knowledge-generating enterprises....) Similarly, the second half of your statement seems to imply that gender studies departments have their minds made up a priori, in the absence of evidence or reason, and then simply spout that off. That is, you seem to think that they just make stuff up. Can you give more evidence that this is systematically true of gender studies departments and methods?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9zi9h", "score_hidden": false, "stickied": false, "created": 1492243799.0, "created_utc": 1492214999.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 14}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9f76c", "gilded": 0, "archived": false, "score": 20, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9dk5n", "subreddit_name_prefixed": "r/linguistics", "controversiality": 1, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9f76c", "score_hidden": false, "stickied": false, "created": 1492218526.0, "created_utc": 1492189726.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 20}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9dk5n", "gilded": 0, "archived": false, "score": 64, "report_reasons": null, "author": "WigglyHypersurface", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Although this fact complicates up the use of word vectors in practice, it also opens up a lot of new and interesting ways to measure and talk about implicit biases. I think this is going to be important moving forward, as it seems a lot of people deny that implicit biases exist, or that they have negative consequences. Anecdotally, when my female friends talk about implicit biases, and especially when using feminist jargon, people get really dismissive. But when I, a man, talk about implicit biases using statistical jargon about word embeddings, people listen.\n\nI think a good next step is also developing newer version of the implicit association test which somehow incorporate information from word embeddings - not exactly sure how to do this, but I feel like there must be a way.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Although this fact complicates up the use of word vectors in practice, it also opens up a lot of new and interesting ways to measure and talk about implicit biases. I think this is going to be important moving forward, as it seems a lot of people deny that implicit biases exist, or that they have negative consequences. Anecdotally, when my female friends talk about implicit biases, and especially when using feminist jargon, people get really dismissive. But when I, a man, talk about implicit biases using statistical jargon about word embeddings, people listen.&lt;/p&gt;\n\n&lt;p&gt;I think a good next step is also developing newer version of the implicit association test which somehow incorporate information from word embeddings - not exactly sure how to do this, but I feel like there must be a way.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9dk5n", "score_hidden": false, "stickied": false, "created": 1492216675.0, "created_utc": 1492187875.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 64}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dg9o0r0", "gilded": 0, "archived": false, "score": 17, "report_reasons": null, "author": "unknownmosquito", "parent_id": "t1_dg9b23h", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I just want to echo your sentiments about the algorithms involved, because they're spot on. \n\nThey very often _are_ shaped by the implicit biases and even explicit beliefs of the data scientists involved. They choose what features are weighted and even what data should be fed in or left out, as you said, and all of this effects the algorithms' output.\n\nResults from Big Data algorithmic analysis should be scrutinized with the same skepticism as regular statistical data, which we all know can and often is manipulated to support a narrative. This stuff is no different. I'm a software engineer (though I'm not a data scientist, so others definitely know more than me on this topic) and it's frustrating that people think these algorithms are above scrutiny just because they're algorithms.\n\nThe algorithms reflect their authors. How could they possibly not?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I just want to echo your sentiments about the algorithms involved, because they&amp;#39;re spot on. &lt;/p&gt;\n\n&lt;p&gt;They very often &lt;em&gt;are&lt;/em&gt; shaped by the implicit biases and even explicit beliefs of the data scientists involved. They choose what features are weighted and even what data should be fed in or left out, as you said, and all of this effects the algorithms&amp;#39; output.&lt;/p&gt;\n\n&lt;p&gt;Results from Big Data algorithmic analysis should be scrutinized with the same skepticism as regular statistical data, which we all know can and often is manipulated to support a narrative. This stuff is no different. I&amp;#39;m a software engineer (though I&amp;#39;m not a data scientist, so others definitely know more than me on this topic) and it&amp;#39;s frustrating that people think these algorithms are above scrutiny just because they&amp;#39;re algorithms.&lt;/p&gt;\n\n&lt;p&gt;The algorithms reflect their authors. How could they possibly not?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9o0r0", "score_hidden": false, "stickied": false, "created": 1492228998.0, "created_utc": 1492200198.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 17}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgau81y", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "k10_ftw", "parent_id": "t1_dgapfgi", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I was talking about academic research. For example, the sem eval paraphrase dataset is a standardized  corpus for comparing NLP approaches to the task of automatically identifying paraphrases in context. The dataset is simply too small for deep learning. Many similar corpora exist and being used for training and evaluating models.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I was talking about academic research. For example, the sem eval paraphrase dataset is a standardized  corpus for comparing NLP approaches to the task of automatically identifying paraphrases in context. The dataset is simply too small for deep learning. Many similar corpora exist and being used for training and evaluating models.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgau81y", "score_hidden": false, "stickied": false, "created": 1492302666.0, "created_utc": 1492273866.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgcq0lx", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgcm4xj", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Oh, yeah, totally. We have a weekly \"NLP reading group\" and it seems like almost half the papers that we read are about trying to find interpretability in deep-learning models. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh, yeah, totally. We have a weekly &amp;quot;NLP reading group&amp;quot; and it seems like almost half the papers that we read are about trying to find interpretability in deep-learning models. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgcq0lx", "score_hidden": false, "stickied": false, "created": 1492412627.0, "created_utc": 1492383827.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgcm4xj", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "VordeMan", "parent_id": "t1_dgapfgi", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I think it's important to also note the strong sequence of fairly recent (last couple years) approaches towards interpretability in deep learning (though, I'll grant you, the push is stronger in images than it is in NLP).", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think it&amp;#39;s important to also note the strong sequence of fairly recent (last couple years) approaches towards interpretability in deep learning (though, I&amp;#39;ll grant you, the push is stronger in images than it is in NLP).&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgcm4xj", "score_hidden": false, "stickied": false, "created": 1492407394.0, "created_utc": 1492378594.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgapfgi", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dg9nuuy", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Yeah, thus the \"research systems\" part. I know that in the \"real world\" everybody tries to use interpretable models all the time, but not in academia. If you run down the list of ACL papers, they're like 90% deep learning. \n\nEdit: ACL not ALC. I wonder if I'll ever stop making this mistake. ALC is a small conference in Arizona that my friends organize, so it is often closer to my mind. ", "edited": 1492270387.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Yeah, thus the &amp;quot;research systems&amp;quot; part. I know that in the &amp;quot;real world&amp;quot; everybody tries to use interpretable models all the time, but not in academia. If you run down the list of ACL papers, they&amp;#39;re like 90% deep learning. &lt;/p&gt;\n\n&lt;p&gt;Edit: ACL not ALC. I wonder if I&amp;#39;ll ever stop making this mistake. ALC is a small conference in Arizona that my friends organize, so it is often closer to my mind. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgapfgi", "score_hidden": false, "stickied": false, "created": 1492295798.0, "created_utc": 1492266998.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9nuuy", "gilded": 0, "archived": false, "score": 20, "report_reasons": null, "author": "k10_ftw", "parent_id": "t1_dg9b23h", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "&gt; especially if the system is using deep learning which is infamously uninterpretable, and most natural language research systems these days do.\n\nWith a masters in language/AI, you *know* this isn't true.  NLP has a wide variety of ML approaches for a wide variety of tasks.  In fact, research continues on approaches other than deep learning because some researchers oppose the 'black box' approach &amp; they value the benefits of having a human-interpretable language models.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;especially if the system is using deep learning which is infamously uninterpretable, and most natural language research systems these days do.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;With a masters in language/AI, you &lt;em&gt;know&lt;/em&gt; this isn&amp;#39;t true.  NLP has a wide variety of ML approaches for a wide variety of tasks.  In fact, research continues on approaches other than deep learning because some researchers oppose the &amp;#39;black box&amp;#39; approach &amp;amp; they value the benefits of having a human-interpretable language models.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9nuuy", "score_hidden": false, "stickied": false, "created": 1492228801.0, "created_utc": 1492200001.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 20}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgc3x4s", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgc3cga", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "&gt; People are not morally correct. They are not going to be morally correct at any point in the near future, either. Because if they were, that in itself would be a moral failure of a culture (that somewhat resembles the Borg from Star Trek).\n&gt; The result of people attempting to pretend that they are, while participating in a corporate-centric culture for sustenance, is inevitably the Drumpfs, Le Pens, and David Camerons of the world.\n\nI am not telling you that people are morally correct, I'm telling you that actions are, and people are far more likely to choose the morally correct action, especially when their livelihoods are on the line. \n\nBefore you compare me to Trump and Le Pen, remember that you're arguing in favor of using dumb machine learning to make sure black people can't get loans. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;People are not morally correct. They are not going to be morally correct at any point in the near future, either. Because if they were, that in itself would be a moral failure of a culture (that somewhat resembles the Borg from Star Trek).\nThe result of people attempting to pretend that they are, while participating in a corporate-centric culture for sustenance, is inevitably the Drumpfs, Le Pens, and David Camerons of the world.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;I am not telling you that people are morally correct, I&amp;#39;m telling you that actions are, and people are far more likely to choose the morally correct action, especially when their livelihoods are on the line. &lt;/p&gt;\n\n&lt;p&gt;Before you compare me to Trump and Le Pen, remember that you&amp;#39;re arguing in favor of using dumb machine learning to make sure black people can&amp;#39;t get loans. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc3x4s", "score_hidden": false, "stickied": false, "created": 1492383181.0, "created_utc": 1492354381.0, "depth": 6, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgc3cga", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Y3808", "parent_id": "t1_dgaq61p", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "People are not morally correct.  They are not going to be morally correct at any point in the near future, either. Because if they were, that in itself would be a moral failure of a culture (that somewhat resembles the Borg from Star Trek).\n\nThe result of people attempting to pretend that they are, while participating in a corporate-centric culture for sustenance, is inevitably the Trumps, Le Pens, and David Camerons of the world.\n\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;People are not morally correct.  They are not going to be morally correct at any point in the near future, either. Because if they were, that in itself would be a moral failure of a culture (that somewhat resembles the Borg from Star Trek).&lt;/p&gt;\n\n&lt;p&gt;The result of people attempting to pretend that they are, while participating in a corporate-centric culture for sustenance, is inevitably the Trumps, Le Pens, and David Camerons of the world.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc3cga", "score_hidden": false, "stickied": false, "created": 1492382299.0, "created_utc": 1492353499.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaq61p", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgacxfu", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "&gt; In response to your first post in the thread, what makes you think that \"they,\" for lack of a better label, care about the discriminatory output of algorithms? \n\nThey care because it's morally correct, and it's also the law. Did Facebook whine and complain when it was discovered that they were serving certain housing ads to black people in violation of the Fair Housing Act? \n\nNo, they fixed their system and moved on. \n\nIn your Pepsi example, how could you possibly think that Pepsi \"doesn't care\"? Are they still running the ad? No, of course they're not! Even if you think corporations are mindless profit seeking automatons, this move was obviously not profitable for them. \n\nThere is a reason that MBa degrees all around the world require \"business ethics\" classes. If you violate business ethics, the consequences are far, far worse than a lack of job satisfaction. \n\n&gt;Is it really bad? I mean, we are getting into a philosophical argument rather than a practical one, but practically speaking, it is not your task to make a machine that is ethically superior to a person, is it? Because philosophically it is impossible for you to do so. You cannot make a machine that accurately analyzes data about humans and have it spit out ethically perfect results, because humans are not ethically perfect and neither is the data they will generate. Garbage in, garbage out. Secondly, people who create algorithms are not qualified to define ethically superior, so nothing you create that is lesser than yourself can be qualified to do so either. No one is qualified, it is an ongoing debate.\n\nYou're confusing \"bad\" with \"incorrect\". Is the model wrong? No. Is the model bad? Yes. Because it's not just data. It's people. You can't base your decisions on a person based on factors that they are not in control over, like race and gender. \n\nIt's not a question of whether the model predicts the data properly, it's a question of the effects of that model on the real world once you start using it. \n\nThe present direction of research is to make models that do not discriminate while also maintaining very high classification accuracy. It's hard, but not impossible. \n\n&gt; Replace king, noble, and peasant with employer, politician, and employee and tell me how 2017 is even slightly different than 1381. If you think polishing the data that an algorithm spits out can fix the above, you have a hopeless task before you.\n\n\"problems exist and persist, therefore it's not worth your effort to try to solve them\". \n\nPerceptions like this are exactly why gross inequality has existed for so long. There is no law of the universe that says it has to be this way. We human beings made it this way. And we can make it a different way. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;In response to your first post in the thread, what makes you think that &amp;quot;they,&amp;quot; for lack of a better label, care about the discriminatory output of algorithms? &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;They care because it&amp;#39;s morally correct, and it&amp;#39;s also the law. Did Facebook whine and complain when it was discovered that they were serving certain housing ads to black people in violation of the Fair Housing Act? &lt;/p&gt;\n\n&lt;p&gt;No, they fixed their system and moved on. &lt;/p&gt;\n\n&lt;p&gt;In your Pepsi example, how could you possibly think that Pepsi &amp;quot;doesn&amp;#39;t care&amp;quot;? Are they still running the ad? No, of course they&amp;#39;re not! Even if you think corporations are mindless profit seeking automatons, this move was obviously not profitable for them. &lt;/p&gt;\n\n&lt;p&gt;There is a reason that MBa degrees all around the world require &amp;quot;business ethics&amp;quot; classes. If you violate business ethics, the consequences are far, far worse than a lack of job satisfaction. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Is it really bad? I mean, we are getting into a philosophical argument rather than a practical one, but practically speaking, it is not your task to make a machine that is ethically superior to a person, is it? Because philosophically it is impossible for you to do so. You cannot make a machine that accurately analyzes data about humans and have it spit out ethically perfect results, because humans are not ethically perfect and neither is the data they will generate. Garbage in, garbage out. Secondly, people who create algorithms are not qualified to define ethically superior, so nothing you create that is lesser than yourself can be qualified to do so either. No one is qualified, it is an ongoing debate.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;You&amp;#39;re confusing &amp;quot;bad&amp;quot; with &amp;quot;incorrect&amp;quot;. Is the model wrong? No. Is the model bad? Yes. Because it&amp;#39;s not just data. It&amp;#39;s people. You can&amp;#39;t base your decisions on a person based on factors that they are not in control over, like race and gender. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s not a question of whether the model predicts the data properly, it&amp;#39;s a question of the effects of that model on the real world once you start using it. &lt;/p&gt;\n\n&lt;p&gt;The present direction of research is to make models that do not discriminate while also maintaining very high classification accuracy. It&amp;#39;s hard, but not impossible. &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Replace king, noble, and peasant with employer, politician, and employee and tell me how 2017 is even slightly different than 1381. If you think polishing the data that an algorithm spits out can fix the above, you have a hopeless task before you.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&amp;quot;problems exist and persist, therefore it&amp;#39;s not worth your effort to try to solve them&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;Perceptions like this are exactly why gross inequality has existed for so long. There is no law of the universe that says it has to be this way. We human beings made it this way. And we can make it a different way. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgaq61p", "score_hidden": false, "stickied": false, "created": 1492296925.0, "created_utc": 1492268125.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dgacxfu", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "[deleted]", "parent_id": "t1_dg9hwsf", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": 1492238711.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgacxfu", "score_hidden": false, "stickied": false, "created": 1492264656.0, "created_utc": 1492235856.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9hwsf", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dg9g812", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I'm wary of doxxing myself, but you could probably figure it out from my comment history anyway, so whatever. \n\nI study at the University of Arizona. The course in question is \"computational data science\" by Carlos Scheidigger, whose research involves this discrimination question. It's organized into three parts, one on managing Big Data, one on kernelization, and the third one on data ethics. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m wary of doxxing myself, but you could probably figure it out from my comment history anyway, so whatever. &lt;/p&gt;\n\n&lt;p&gt;I study at the University of Arizona. The course in question is &amp;quot;computational data science&amp;quot; by Carlos Scheidigger, whose research involves this discrimination question. It&amp;#39;s organized into three parts, one on managing Big Data, one on kernelization, and the third one on data ethics. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9hwsf", "score_hidden": false, "stickied": false, "created": 1492221665.0, "created_utc": 1492192865.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 15}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9g812", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "CptMacHammer", "parent_id": "t1_dg9b23h", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "What university are you taking that class at?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;What university are you taking that class at?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9g812", "score_hidden": false, "stickied": false, "created": 1492219705.0, "created_utc": 1492190905.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9b23h", "gilded": 0, "archived": false, "score": 74, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Finishing up a masters in language and AI here. I'm doing a whole class on avoiding this kind of problem. It's really, really, really hard. \n\nNobody feeds race into the algorithms as a feature, because that's stupid, but the unfortunate truth is that race correlates with other things, and those things can accidentally be learned by the machine to be a \"proxy feature\" for race. That's really bad, and also really hard to diagnose and even harder to repair, especially if the system is using deep learning which is infamously uninterpretable, and most natural language research systems these days do. \n\nRemember when Facebook got in trouble for serving different housing ads to black people? Their ad targeting system doesn't know people's race, but they do know their names, where they live, the people in their personal network, their interests, the kinds of ads they've clicked on before, etc. Those things on their own are totally benign, but added together, they can be used to deduce race. Depending on the task, you will then often find racial bias in the output.  \n\n\n&amp;nbsp;\n\n\nEdit: A lot of people think that good intent is enough to justify discrimination, and it's okay if algorithms discriminate because they don't have intent, they're just algorithms, they crunch numbers. \n\nFirst of all, fuck you. Second of all, that's not how the government defines discrimination, whether you like it or not. \n\nSince intent is impossible to prove in most cases, and also doesn't really solve the deeply ingrained societal problems, discrimination is defined in terms of \"disparate impact\".  The magic number is 0.8. You take the positive rate of each of the protected classes and the unprotected class. Positive rate is PositiveCount/(PositiveCount+NegativeCount). If you're a hiring manager, that means NumJobOffered/NumApplicants. Then you take the protected PR, and divide it by the unprotected PR. If the difference between them is less than 0.8, then your system is discriminating. \n\nUnfortunately, that rule is extremely hard to apply to non-classification tasks, like language models and regression tasks like how much money to offer in a loan. So the field is still wide open, if you like math and you want to make the world a better place, this is a good field to make your fame and fortune. ", "edited": 1492186080.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Finishing up a masters in language and AI here. I&amp;#39;m doing a whole class on avoiding this kind of problem. It&amp;#39;s really, really, really hard. &lt;/p&gt;\n\n&lt;p&gt;Nobody feeds race into the algorithms as a feature, because that&amp;#39;s stupid, but the unfortunate truth is that race correlates with other things, and those things can accidentally be learned by the machine to be a &amp;quot;proxy feature&amp;quot; for race. That&amp;#39;s really bad, and also really hard to diagnose and even harder to repair, especially if the system is using deep learning which is infamously uninterpretable, and most natural language research systems these days do. &lt;/p&gt;\n\n&lt;p&gt;Remember when Facebook got in trouble for serving different housing ads to black people? Their ad targeting system doesn&amp;#39;t know people&amp;#39;s race, but they do know their names, where they live, the people in their personal network, their interests, the kinds of ads they&amp;#39;ve clicked on before, etc. Those things on their own are totally benign, but added together, they can be used to deduce race. Depending on the task, you will then often find racial bias in the output.  &lt;/p&gt;\n\n&lt;p&gt;&amp;nbsp;&lt;/p&gt;\n\n&lt;p&gt;Edit: A lot of people think that good intent is enough to justify discrimination, and it&amp;#39;s okay if algorithms discriminate because they don&amp;#39;t have intent, they&amp;#39;re just algorithms, they crunch numbers. &lt;/p&gt;\n\n&lt;p&gt;First of all, fuck you. Second of all, that&amp;#39;s not how the government defines discrimination, whether you like it or not. &lt;/p&gt;\n\n&lt;p&gt;Since intent is impossible to prove in most cases, and also doesn&amp;#39;t really solve the deeply ingrained societal problems, discrimination is defined in terms of &amp;quot;disparate impact&amp;quot;.  The magic number is 0.8. You take the positive rate of each of the protected classes and the unprotected class. Positive rate is PositiveCount/(PositiveCount+NegativeCount). If you&amp;#39;re a hiring manager, that means NumJobOffered/NumApplicants. Then you take the protected PR, and divide it by the unprotected PR. If the difference between them is less than 0.8, then your system is discriminating. &lt;/p&gt;\n\n&lt;p&gt;Unfortunately, that rule is extremely hard to apply to non-classification tasks, like language models and regression tasks like how much money to offer in a loan. So the field is still wide open, if you like math and you want to make the world a better place, this is a good field to make your fame and fortune. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9b23h", "score_hidden": false, "stickied": false, "created": 1492213884.0, "created_utc": 1492185084.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 74}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgailgx", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "millionsofcats", "parent_id": "t1_dgad2c3", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "This doesn't have anything to do with Whorfianism, which is the idea that your language influences your thoughts. This is about algorithms (which don't think) picking up on racial and gender prejudices in their data (which isn't language, but what is being said with language).", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This doesn&amp;#39;t have anything to do with Whorfianism, which is the idea that your language influences your thoughts. This is about algorithms (which don&amp;#39;t think) picking up on racial and gender prejudices in their data (which isn&amp;#39;t language, but what is being said with language).&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgailgx", "score_hidden": false, "stickied": false, "created": 1492280455.0, "created_utc": 1492251655.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgar3i7", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgad2c3", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "It's not a property of language or semantics at all, but an artifact of the way that language gets used. \n\nTo a machine learning algorithm, the two are indistinguishable, since the whole point of machine learning is to study the underlying structure by means of manifestation and usage. The machine can't tell the difference (unless it's some super complicated beysian thing with priors and hyperpriors and stuff). \n\nThe Whorfian fallacy is in assuming that manifestation always necessarily belies not just underlying structure, but also deeper cognitive patterns in the fundamental function of the mind. \n\nThe Whorfian argument goes \"this language uses a passive argument structure more often than my language does, therefore the people who speak it are passive\". \n\nThe machine learning algorithm's pattern goes \"this speech stream contains racism and race-divided tendencies, therefore the language contains racism and race-divided tendencies\". And that is correct behavior for the algorithm. But it's bad behavior for the people who want to use the algorithm. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s not a property of language or semantics at all, but an artifact of the way that language gets used. &lt;/p&gt;\n\n&lt;p&gt;To a machine learning algorithm, the two are indistinguishable, since the whole point of machine learning is to study the underlying structure by means of manifestation and usage. The machine can&amp;#39;t tell the difference (unless it&amp;#39;s some super complicated beysian thing with priors and hyperpriors and stuff). &lt;/p&gt;\n\n&lt;p&gt;The Whorfian fallacy is in assuming that manifestation always necessarily belies not just underlying structure, but also deeper cognitive patterns in the fundamental function of the mind. &lt;/p&gt;\n\n&lt;p&gt;The Whorfian argument goes &amp;quot;this language uses a passive argument structure more often than my language does, therefore the people who speak it are passive&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;The machine learning algorithm&amp;#39;s pattern goes &amp;quot;this speech stream contains racism and race-divided tendencies, therefore the language contains racism and race-divided tendencies&amp;quot;. And that is correct behavior for the algorithm. But it&amp;#39;s bad behavior for the people who want to use the algorithm. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgar3i7", "score_hidden": false, "stickied": false, "created": 1492298281.0, "created_utc": 1492269481.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgad2c3", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "pnotp", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "(not a linguist) how is this different than Whorfianism? Seems like it's not really a property of language but of semantics", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;(not a linguist) how is this different than Whorfianism? Seems like it&amp;#39;s not really a property of language but of semantics&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgad2c3", "score_hidden": false, "stickied": false, "created": 1492264948.0, "created_utc": 1492236148.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgcdd8p", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Choosing_is_a_sin", "parent_id": "t1_dg9yits", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I don't really understand this comment. Obvious and deeply ingrained are not opposed.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t really understand this comment. Obvious and deeply ingrained are not opposed.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgcdd8p", "score_hidden": false, "stickied": false, "created": 1492395899.0, "created_utc": 1492367099.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgcezmm", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dg9yits", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "\"deeply ingrained\" doesn't mean \"hard to see\" it means \"hard to avoid/remove\". \n\nThe metaphor is that of dirt or impurities in a plank of wood. It's worked their way **in**to the **grain**. \n\n(the actual etymology has to do with dying wooden furniture, but the use of \"grain\" to mean \"red dye\" is long out of use)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;deeply ingrained&amp;quot; doesn&amp;#39;t mean &amp;quot;hard to see&amp;quot; it means &amp;quot;hard to avoid/remove&amp;quot;. &lt;/p&gt;\n\n&lt;p&gt;The metaphor is that of dirt or impurities in a plank of wood. It&amp;#39;s worked their way &lt;strong&gt;in&lt;/strong&gt;to the &lt;strong&gt;grain&lt;/strong&gt;. &lt;/p&gt;\n\n&lt;p&gt;(the actual etymology has to do with dying wooden furniture, but the use of &amp;quot;grain&amp;quot; to mean &amp;quot;red dye&amp;quot; is long out of use)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgcezmm", "score_hidden": false, "stickied": false, "created": 1492398086.0, "created_utc": 1492369286.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9yits", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Iwantmyflag", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Deeply ingrained? More like obvious.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Deeply ingrained? More like obvious.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9yits", "score_hidden": false, "stickied": false, "created": 1492242476.0, "created_utc": 1492213676.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dg9vosb", "gilded": 0, "archived": false, "score": -4, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 1, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9vosb", "score_hidden": false, "stickied": false, "created": 1492238716.0, "created_utc": 1492209916.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -4}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgc2zb4", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgbxsua", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "No, not whatsoever. \n\nMachine learning is a set of algorithms that identify patterns and tendencies by looking at examples. \n\nObviously if there is bias in the source, there will be bias in the model. \n\nIt's the responsibility of the designer to make sure that whatever bias appears is not harmful, and anyone who works in AI seriously is extremely concerned about it. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, not whatsoever. &lt;/p&gt;\n\n&lt;p&gt;Machine learning is a set of algorithms that identify patterns and tendencies by looking at examples. &lt;/p&gt;\n\n&lt;p&gt;Obviously if there is bias in the source, there will be bias in the model. &lt;/p&gt;\n\n&lt;p&gt;It&amp;#39;s the responsibility of the designer to make sure that whatever bias appears is not harmful, and anyone who works in AI seriously is extremely concerned about it. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgc2zb4", "score_hidden": false, "stickied": false, "created": 1492381733.0, "created_utc": 1492352933.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgbxsua", "gilded": 0, "archived": false, "score": 0, "report_reasons": null, "author": "rmc", "parent_id": "t1_dgar475", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": ".... This paper is sorta supporting this claim? That a lot of AI stuff is getting racist? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;.... This paper is sorta supporting this claim? That a lot of AI stuff is getting racist? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgbxsua", "score_hidden": false, "stickied": false, "created": 1492370714.0, "created_utc": 1492341914.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 0}}], "after": null, "before": null}}, "user_reports": [], "id": "dgar475", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dg9mvi5", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "If that were true, why would this paper exist? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If that were true, why would this paper exist? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgar475", "score_hidden": false, "stickied": false, "created": 1492298310.0, "created_utc": 1492269510.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9mvi5", "gilded": 0, "archived": false, "score": -15, "report_reasons": null, "author": "rmc", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "A lot of machine learning is just ethics laundering.\n\nIt allows you to do racist things, all while pretending to have no idea. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A lot of machine learning is just ethics laundering.&lt;/p&gt;\n\n&lt;p&gt;It allows you to do racist things, all while pretending to have no idea. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9mvi5", "score_hidden": false, "stickied": false, "created": 1492227623.0, "created_utc": 1492198823.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -15}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dgb17ow", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgaxry0", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "\"genders and races are equal in ability\" doesn't need to be backed up. That's what \"null hyphothesis\" means. It's how science works. You assume that things are unrelated until you can prove with a degree of statistical significance that they are. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;&amp;quot;genders and races are equal in ability&amp;quot; doesn&amp;#39;t need to be backed up. That&amp;#39;s what &amp;quot;null hyphothesis&amp;quot; means. It&amp;#39;s how science works. You assume that things are unrelated until you can prove with a degree of statistical significance that they are. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgb17ow", "score_hidden": false, "stickied": false, "created": 1492312218.0, "created_utc": 1492283418.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaxry0", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "crochet_du_gauche", "parent_id": "t1_dgapt2c", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "But you are the one making an assertion. I am not claiming to have any hypothesis about what causes performance disparity. I'm not even saying I disagree with you -- just asking what's the research that backs up your positive claim.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;But you are the one making an assertion. I am not claiming to have any hypothesis about what causes performance disparity. I&amp;#39;m not even saying I disagree with you -- just asking what&amp;#39;s the research that backs up your positive claim.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgaxry0", "score_hidden": false, "stickied": false, "created": 1492307553.0, "created_utc": 1492278753.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgapt2c", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dgac5zp", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "... it's the null hypothesis. The burden is on you to prove that there's a difference. As far as I know, in all but a few subtleties, equality holds scientifically. \n\nAlso, the comment I was replying to said \"black people and women have lower iqs and are known not to work hard and they can't talk right so the ai is just learning the truth\"\n\nor something along those lines. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;... it&amp;#39;s the null hypothesis. The burden is on you to prove that there&amp;#39;s a difference. As far as I know, in all but a few subtleties, equality holds scientifically. &lt;/p&gt;\n\n&lt;p&gt;Also, the comment I was replying to said &amp;quot;black people and women have lower iqs and are known not to work hard and they can&amp;#39;t talk right so the ai is just learning the truth&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;or something along those lines. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgapt2c", "score_hidden": false, "stickied": false, "created": 1492296372.0, "created_utc": 1492267572.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgac5zp", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "crochet_du_gauche", "parent_id": "t1_dg9b8kj", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Is this assertion backed up by research?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Is this assertion backed up by research?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dgac5zp", "score_hidden": false, "stickied": false, "created": 1492263027.0, "created_utc": 1492234227.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9b8kj", "gilded": 0, "archived": false, "score": 21, "report_reasons": null, "author": "HannasAnarion", "parent_id": "t1_dg9aqu3", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Don't confuse cause and effect. Racial prejudice comes first, performance disparity is a result of unequal security and opportunity, except in a few easily identifiable edge cases, like upper body strength in men vs women.  ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Don&amp;#39;t confuse cause and effect. Racial prejudice comes first, performance disparity is a result of unequal security and opportunity, except in a few easily identifiable edge cases, like upper body strength in men vs women.  &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9b8kj", "score_hidden": false, "stickied": false, "created": 1492214088.0, "created_utc": 1492185288.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 21}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dg9qs8q", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "anarchism4thewin", "parent_id": "t1_dg9b9m9", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "How do you know?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;How do you know?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9qs8q", "score_hidden": false, "stickied": false, "created": 1492232341.0, "created_utc": 1492203541.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": -7}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9b9m9", "gilded": 0, "archived": false, "score": 15, "report_reasons": null, "author": "theJohann", "parent_id": "t1_dg9aqu3", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "I'm hoping you know that those differences are not biological, right? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m hoping you know that those differences are not biological, right? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9b9m9", "score_hidden": false, "stickied": false, "created": 1492214120.0, "created_utc": 1492185320.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 15}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9aqu3", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[removed]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[removed]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9aqu3", "score_hidden": false, "stickied": false, "created": 1492213519.0, "created_utc": 1492184719.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2qhos", "removal_reason": null, "link_id": "t3_65cnj6", "likes": null, "replies": "", "user_reports": [], "id": "dg9wq7j", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "lvxferre", "parent_id": "t1_dg9o1sf", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "Cortana has to do with Windows interface or something like that, the \"nazi Twitter bot\" is Tay. And its pro-Nazism sentences weren't due to *implicit* prejudice, but people actually feeding it Nazi bullshit like \"gas the kikes\" or \"Hitler did nothing wrong\".\n\nThe algorithms from the original post are doing something different - they aren't being fed prejudice itself, but raw data. And based on that raw data, they're developing correlations we humans interpret as prejudice, like certain word associations. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cortana has to do with Windows interface or something like that, the &amp;quot;nazi Twitter bot&amp;quot; is Tay. And its pro-Nazism sentences weren&amp;#39;t due to &lt;em&gt;implicit&lt;/em&gt; prejudice, but people actually feeding it Nazi bullshit like &amp;quot;gas the kikes&amp;quot; or &amp;quot;Hitler did nothing wrong&amp;quot;.&lt;/p&gt;\n\n&lt;p&gt;The algorithms from the original post are doing something different - they aren&amp;#39;t being fed prejudice itself, but raw data. And based on that raw data, they&amp;#39;re developing correlations we humans interpret as prejudice, like certain word associations. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9wq7j", "score_hidden": false, "stickied": false, "created": 1492240110.0, "created_utc": 1492211310.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dg9o1sf", "gilded": 0, "archived": false, "score": -7, "report_reasons": null, "author": "[deleted]", "parent_id": "t3_65cnj6", "subreddit_name_prefixed": "r/linguistics", "controversiality": 0, "body": "[deleted]", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;[deleted]&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "linguistics", "name": "t1_dg9o1sf", "score_hidden": false, "stickied": false, "created": 1492229033.0, "created_utc": 1492200233.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": -7}}], "after": null, "before": null}}]