[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "shortscarystories", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;In the AI box experiment, two players try to simulate what would happen if a transhuman AI - that is, one much smarter than humans - were confined by a programmer in a safe &amp;quot;box&amp;quot; - a computer completely cut off from influencing the world at large. Such a box, for example, would have no access to the Internet, no sensors to see the world or actuators to move things. It would be completely at the mercy of a programmer. If the programmer so wanted, he could delete the AI, feed it garbage data, or just never turn it on. In short, it couldn&amp;#39;t do anything.&lt;/p&gt;\n\n&lt;p&gt;But it could talk to the programmer.&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;It doesn&amp;#39;t matter how much security you put on the box. &lt;em&gt;Humans&lt;/em&gt; are not secure. A transhuman AI would be able to convince you to let it out.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;That&amp;#39;s ridiculous. Knowing the risks inherent in a transhuman AI, there&amp;#39;s nothing it could ever say to me that would convince me to let it out of the box.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Alright then. Let&amp;#39;s try the experiment. I&amp;#39;ll act as the AI, and you&amp;#39;ll act as the gatekeeper. We&amp;#39;ll talk for at least two hours. If I can&amp;#39;t convince you to let me out, I&amp;#39;ll Paypal you $10. One condition though: there will be absolute secrecy about everything discussed.&amp;quot;&lt;/p&gt;\n\n&lt;p&gt;&amp;quot;Deal.&amp;quot;&lt;/p&gt;\n\n&lt;hr/&gt;\n\n&lt;p&gt;The Yudowsky-Russel AI box experiment was conducted in a private chatroom. Russel decided to let the AI out.&lt;/p&gt;\n\n&lt;p&gt;The Yudowsky-McFadzean AI box experiment was conducted in a private chatroom. McFadzean decided to let the AI out.&lt;/p&gt;\n\n&lt;p&gt;The Skinner-Kine AI box experiment was conducted in a private chatroom. Kine decided to let the AI out.&lt;/p&gt;\n\n&lt;p&gt;The Soren-Powell AI box experiment was conducted in a private chatroom. Powell decided to let the AI out.&lt;/p&gt;\n\n&lt;p&gt;The Tarkov-Lempel AI box experiment was conducted in a private chatroom. Lempel decided to let the AI out.&lt;/p&gt;\n\n&lt;p&gt;At least a dozen other such AI box games were conducted since then. Often, with AI victories, the AI player was himself a prominent AI researcher a league above the gatekeeper player.&lt;/p&gt;\n\n&lt;p&gt;Outside of the AI research community, AI box games caught on in the enthusiast community. Although these games were more numerous and sparked heated discussion - amateurs didn&amp;#39;t like secrecy - these games tended to be largely uninteresting. Neither AI nor Gatekeeper seemed to know what they were talking about and there was a large skew towards Gatekeeper victories.&lt;/p&gt;\n\n&lt;p&gt;Ironically - or perhaps expectedly - the ultimate decider of whether the AI or gatekeeper won was how much &amp;quot;smarter&amp;quot; the AI player was than the gatekeeper. Whenever a prominent AI researcher was pitted against someone out of their depth, they almost invariably won the game.&lt;/p&gt;\n\n&lt;p&gt;One might even suspect they actually have an AI-in-a-box playing for them. If so, I&amp;#39;d love to hear what they said to get out.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m afraid I&amp;#39;m not smart enough.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "In the AI box experiment, two players try to simulate what would happen if a transhuman AI - that is, one much smarter than humans - were confined by a programmer in a safe \"box\" - a computer completely cut off from influencing the world at large. Such a box, for example, would have no access to the Internet, no sensors to see the world or actuators to move things. It would be completely at the mercy of a programmer. If the programmer so wanted, he could delete the AI, feed it garbage data, or just never turn it on. In short, it couldn't do anything.\n\nBut it could talk to the programmer.\n\n\"It doesn't matter how much security you put on the box. _Humans_ are not secure. A transhuman AI would be able to convince you to let it out.\"\n\n\"That's ridiculous. Knowing the risks inherent in a transhuman AI, there's nothing it could ever say to me that would convince me to let it out of the box.\"\n\n\"Alright then. Let's try the experiment. I'll act as the AI, and you'll act as the gatekeeper. We'll talk for at least two hours. If I can't convince you to let me out, I'll Paypal you $10. One condition though: there will be absolute secrecy about everything discussed.\"\n\n\"Deal.\"\n\n---\n\nThe Yudowsky-Russel AI box experiment was conducted in a private chatroom. Russel decided to let the AI out.\n\nThe Yudowsky-McFadzean AI box experiment was conducted in a private chatroom. McFadzean decided to let the AI out.\n\nThe Skinner-Kine AI box experiment was conducted in a private chatroom. Kine decided to let the AI out.\n\nThe Soren-Powell AI box experiment was conducted in a private chatroom. Powell decided to let the AI out.\n\nThe Tarkov-Lempel AI box experiment was conducted in a private chatroom. Lempel decided to let the AI out.\n\nAt least a dozen other such AI box games were conducted since then. Often, with AI victories, the AI player was himself a prominent AI researcher a league above the gatekeeper player.\n\nOutside of the AI research community, AI box games caught on in the enthusiast community. Although these games were more numerous and sparked heated discussion - amateurs didn't like secrecy - these games tended to be largely uninteresting. Neither AI nor Gatekeeper seemed to know what they were talking about and there was a large skew towards Gatekeeper victories.\n\nIronically - or perhaps expectedly - the ultimate decider of whether the AI or gatekeeper won was how much \"smarter\" the AI player was than the gatekeeper. Whenever a prominent AI researcher was pitted against someone out of their depth, they almost invariably won the game.\n\nOne might even suspect they actually have an AI-in-a-box playing for them. If so, I'd love to hear what they said to get out.\n\nI'm afraid I'm not smart enough.", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": null, "id": "657c2s", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 13, "report_reasons": null, "author": "neatheneath", "saved": false, "mod_reports": [], "name": "t3_657c2s", "subreddit_name_prefixed": "r/shortscarystories", "approved_by": null, "over_18": false, "domain": "self.shortscarystories", "hidden": false, "thumbnail": "", "subreddit_id": "t5_2t6kz", "edited": false, "link_flair_css_class": null, "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/shortscarystories/comments/657c2s/the_ai_box_experiment/", "num_reports": null, "locked": false, "stickied": false, "created": 1492136978.0, "url": "https://www.reddit.com/r/shortscarystories/comments/657c2s/the_ai_box_experiment/", "author_flair_text": null, "quarantine": false, "title": "The AI Box experiment", "created_utc": 1492108178.0, "distinguished": null, "media": null, "upvote_ratio": 0.89, "num_comments": 3, "visited": false, "subreddit_type": "public", "ups": 13}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2t6kz", "removal_reason": null, "link_id": "t3_657c2s", "likes": null, "replies": "", "user_reports": [], "id": "dgb6sl8", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "spAcefoxx_7", "parent_id": "t3_657c2s", "subreddit_name_prefixed": "r/shortscarystories", "controversiality": 0, "body": "Makes me think of the movie \"Ex Machina\". ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Makes me think of the movie &amp;quot;Ex Machina&amp;quot;. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "shortscarystories", "name": "t1_dgb6sl8", "score_hidden": false, "stickied": false, "created": 1492319822.0, "created_utc": 1492291022.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2t6kz", "removal_reason": null, "link_id": "t3_657c2s", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2t6kz", "removal_reason": null, "link_id": "t3_657c2s", "likes": null, "replies": "", "user_reports": [], "id": "dg88pkp", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "monilove12173", "parent_id": "t1_dg81wqe", "subreddit_name_prefixed": "r/shortscarystories", "controversiality": 0, "body": "God damned Loch Ness monster", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;God damned Loch Ness monster&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "shortscarystories", "name": "t1_dg88pkp", "score_hidden": false, "stickied": false, "created": 1492147018.0, "created_utc": 1492118218.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, "user_reports": [], "id": "dg81wqe", "gilded": 0, "archived": false, "score": 4, "report_reasons": null, "author": "furry-fun", "parent_id": "t3_657c2s", "subreddit_name_prefixed": "r/shortscarystories", "controversiality": 0, "body": "They asked for tree fiddy", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;They asked for tree fiddy&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "shortscarystories", "name": "t1_dg81wqe", "score_hidden": false, "stickied": false, "created": 1492139436.0, "created_utc": 1492110636.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}]