[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Research", "id": "64pr4m", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 4, "report_reasons": null, "author": "NicolasGuacamole", "saved": false, "mod_reports": [], "name": "t3_64pr4m", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "arxiv.org", "hidden": false, "thumbnail": "default", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "three", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/64pr4m/r_170402966_loss_maxpooling_for_semantic_image/", "num_reports": null, "locked": false, "stickied": false, "created": 1491930797.0, "url": "https://arxiv.org/abs/1704.02966", "author_flair_text": null, "quarantine": false, "title": "[R] [1704.02966] Loss Max-Pooling for Semantic Image Segmentation", "created_utc": 1491901997.0, "distinguished": null, "media": null, "upvote_ratio": 0.74, "num_comments": 3, "visited": false, "subreddit_type": "public", "ups": 4}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64pr4m", "likes": null, "replies": "", "user_reports": [], "id": "dg41wln", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "arXiv_abstract_bot", "parent_id": "t3_64pr4m", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Title: Loss Max-Pooling for Semantic Image Segmentation  \n\nAuthors: [Samuel Rota Bul\u00f2](http://arxiv.org/find/cs/1/au:+Bulo_S/0/1/0/all/0/1), [Gerhard Neuhold](http://arxiv.org/find/cs/1/au:+Neuhold_G/0/1/0/all/0/1), [Peter Kontschieder](http://arxiv.org/find/cs/1/au:+Kontschieder_P/0/1/0/all/0/1)  \n\n&gt; Abstract: We introduce a novel loss max-pooling concept for handling imbalanced training data distributions, applicable as alternative loss layer in the context of deep neural networks for semantic image segmentation. Most real-world semantic segmentation datasets exhibit long tail distributions with few object categories comprising the majority of data and consequently biasing the classifiers towards them. Our method adaptively re-weights the contributions of each pixel based on their observed losses, targeting under- performing classification results as often encountered for under-represented object classes. Our approach goes beyond conventional cost-sensitive learning attempts through adaptive considerations that allow us to indirectly address both, inter- and intra-class imbalances. We provide a theoretical justification of our approach, complementary to experimental analyses on benchmark datasets. In our experiments on the Cityscapes and Pascal VOC 2012 segmentation datasets we find consistently improved results, demonstrating the efficacy of our approach.  \n\n[PDF link](https://arxiv.org/pdf/1704.02966)  [Landing page](https://arxiv.org/abs/1704.02966)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Title: Loss Max-Pooling for Semantic Image Segmentation  &lt;/p&gt;\n\n&lt;p&gt;Authors: &lt;a href=\"http://arxiv.org/find/cs/1/au:+Bulo_S/0/1/0/all/0/1\"&gt;Samuel Rota Bul\u00f2&lt;/a&gt;, &lt;a href=\"http://arxiv.org/find/cs/1/au:+Neuhold_G/0/1/0/all/0/1\"&gt;Gerhard Neuhold&lt;/a&gt;, &lt;a href=\"http://arxiv.org/find/cs/1/au:+Kontschieder_P/0/1/0/all/0/1\"&gt;Peter Kontschieder&lt;/a&gt;  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Abstract: We introduce a novel loss max-pooling concept for handling imbalanced training data distributions, applicable as alternative loss layer in the context of deep neural networks for semantic image segmentation. Most real-world semantic segmentation datasets exhibit long tail distributions with few object categories comprising the majority of data and consequently biasing the classifiers towards them. Our method adaptively re-weights the contributions of each pixel based on their observed losses, targeting under- performing classification results as often encountered for under-represented object classes. Our approach goes beyond conventional cost-sensitive learning attempts through adaptive considerations that allow us to indirectly address both, inter- and intra-class imbalances. We provide a theoretical justification of our approach, complementary to experimental analyses on benchmark datasets. In our experiments on the Cityscapes and Pascal VOC 2012 segmentation datasets we find consistently improved results, demonstrating the efficacy of our approach.  &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/1704.02966\"&gt;PDF link&lt;/a&gt;  &lt;a href=\"https://arxiv.org/abs/1704.02966\"&gt;Landing page&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg41wln", "score_hidden": false, "stickied": false, "created": 1491930820.0, "created_utc": 1491902020.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64pr4m", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64pr4m", "likes": null, "replies": "", "user_reports": [], "id": "dg500mz", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "NicolasGuacamole", "parent_id": "t1_dg4oi5p", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I don't think so, I'd be interested in having a look when they do though.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t think so, I&amp;#39;d be interested in having a look when they do though.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg500mz", "score_hidden": false, "stickied": false, "created": 1491976866.0, "created_utc": 1491948066.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg4oi5p", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ProGamerGov", "parent_id": "t3_64pr4m", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Have they released the code and pre-trained model(s) for this research paper yet? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Have they released the code and pre-trained model(s) for this research paper yet? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg4oi5p", "score_hidden": false, "stickied": false, "created": 1491963951.0, "created_utc": 1491935151.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}]