[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Would replacing my HDD with a SDD make much of a difference?&lt;/p&gt;\n\n&lt;p&gt;How about adding more RAM?&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "Would replacing my HDD with a SDD make much of a difference?\n\nHow about adding more RAM?", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Discussion", "id": "65t24t", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 1, "report_reasons": null, "author": "SpiderFan", "saved": false, "mod_reports": [], "name": "t3_65t24t", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "self.MachineLearning", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "one", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/65t24t/d_what_are_the_most_important_computer_specs_for/", "num_reports": null, "locked": false, "stickied": false, "created": 1492425630.0, "url": "https://www.reddit.com/r/MachineLearning/comments/65t24t/d_what_are_the_most_important_computer_specs_for/", "author_flair_text": null, "quarantine": false, "title": "[D] What are the most important computer specs for running ML stuff. RAM? SSD?", "created_utc": 1492396830.0, "distinguished": null, "media": null, "upvote_ratio": 0.53, "num_comments": 10, "visited": false, "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": "", "user_reports": [], "id": "dgd67k6", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "SpiderFan", "parent_id": "t1_dgd0ztv", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "you rock, thanks for all that!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;you rock, thanks for all that!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgd67k6", "score_hidden": false, "stickied": false, "created": 1492436568.0, "created_utc": 1492407768.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd0ztv", "gilded": 0, "archived": false, "score": 19, "report_reasons": null, "author": "NichG", "parent_id": "t3_65t24t", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "For neural networks: I found that GPU memory was the trickiest thing, since it constrains the model sizes and batch sizes which are convenient to work with. Sure, you can divide a single gradient update into multiple passes or use multiple GPUs, but those kind of factors are handled inconsistently between libraries, so that can in turn influence your decisions about what libraries to use, etc. I wouldn't want less than 4gb and I still occasionally run into limits sometimes at 8gb. GPU speed makes a big difference of course.\n\nFor other machine learning techniques: the usual libraries don't have built-in GPU implementations for everything yet, so CPU is more important - especially lots of cores. But I think GPU implementations are out or underway for almost everything if you look (there's a GPU accelerated XGBoost, for example). Not sure it will be such a dominant advantage as it was for neural nets though - I'm seeing numbers like x5 or x7 speedups, compared to the x50 or so I've experienced for neural networks. If you're talking about building a cluster rather than a workstation, CPU probably still wins here.\n\nSSD was a nice quality of life improvement for loading giant datasets (especially datasets too large to fit into RAM at once). But if you can fit your problems into RAM by getting a bit more, I'd heavily prioritize that above the SSD. Generally you can set things up so that (if you can fit it into RAM) you only have to load your data once, and then you can use notebooks to train/modify/train again/etc without reloading. So you might have a 5 minute spool up before you can get to work, but then you can keep working for hours without doing that again.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For neural networks: I found that GPU memory was the trickiest thing, since it constrains the model sizes and batch sizes which are convenient to work with. Sure, you can divide a single gradient update into multiple passes or use multiple GPUs, but those kind of factors are handled inconsistently between libraries, so that can in turn influence your decisions about what libraries to use, etc. I wouldn&amp;#39;t want less than 4gb and I still occasionally run into limits sometimes at 8gb. GPU speed makes a big difference of course.&lt;/p&gt;\n\n&lt;p&gt;For other machine learning techniques: the usual libraries don&amp;#39;t have built-in GPU implementations for everything yet, so CPU is more important - especially lots of cores. But I think GPU implementations are out or underway for almost everything if you look (there&amp;#39;s a GPU accelerated XGBoost, for example). Not sure it will be such a dominant advantage as it was for neural nets though - I&amp;#39;m seeing numbers like x5 or x7 speedups, compared to the x50 or so I&amp;#39;ve experienced for neural networks. If you&amp;#39;re talking about building a cluster rather than a workstation, CPU probably still wins here.&lt;/p&gt;\n\n&lt;p&gt;SSD was a nice quality of life improvement for loading giant datasets (especially datasets too large to fit into RAM at once). But if you can fit your problems into RAM by getting a bit more, I&amp;#39;d heavily prioritize that above the SSD. Generally you can set things up so that (if you can fit it into RAM) you only have to load your data once, and then you can use notebooks to train/modify/train again/etc without reloading. So you might have a 5 minute spool up before you can get to work, but then you can keep working for hours without doing that again.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgd0ztv", "score_hidden": false, "stickied": false, "created": 1492427570.0, "created_utc": 1492398770.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 19}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": "", "user_reports": [], "id": "dge45b2", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "SpiderFan", "parent_id": "t1_dgd4h0w", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "thanks!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;thanks!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dge45b2", "score_hidden": false, "stickied": false, "created": 1492491624.0, "created_utc": 1492462824.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgd4h0w", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "darkconfidantislife", "parent_id": "t3_65t24t", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "GPU...memory....", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;GPU...memory....&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgd4h0w", "score_hidden": false, "stickied": false, "created": 1492433117.0, "created_utc": 1492404317.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": "", "user_reports": [], "id": "dge44p3", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "SpiderFan", "parent_id": "t1_dgdlzya", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "excellent thanks!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;excellent thanks!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dge44p3", "score_hidden": false, "stickied": false, "created": 1492491606.0, "created_utc": 1492462806.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": "", "user_reports": [], "id": "dgepihb", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "PM_YOUR_NIPS_PAPER", "parent_id": "t1_dgdlzya", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "SVM is a supervised learning technique. Very few, if any libraries, support GPU accelerated SVM training.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;SVM is a supervised learning technique. Very few, if any libraries, support GPU accelerated SVM training.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgepihb", "score_hidden": false, "stickied": false, "created": 1492519002.0, "created_utc": 1492490202.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdlzya", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "gambs", "parent_id": "t3_65t24t", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "For supervised learning or neural network-based unsupervised learning:\n\n1. GPU memory (assuming you want to train big models)\n2. GPU speed\n3. RAM if you have lots of data (10s-100s of GB)\n\nFor reinforcement learning/everything else:\n\n1. Number of CPUs\n2. CPU speed", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;For supervised learning or neural network-based unsupervised learning:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;GPU memory (assuming you want to train big models)&lt;/li&gt;\n&lt;li&gt;GPU speed&lt;/li&gt;\n&lt;li&gt;RAM if you have lots of data (10s-100s of GB)&lt;/li&gt;\n&lt;/ol&gt;\n\n&lt;p&gt;For reinforcement learning/everything else:&lt;/p&gt;\n\n&lt;ol&gt;\n&lt;li&gt;Number of CPUs&lt;/li&gt;\n&lt;li&gt;CPU speed&lt;/li&gt;\n&lt;/ol&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdlzya", "score_hidden": false, "stickied": false, "created": 1492471233.0, "created_utc": 1492442433.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65t24t", "likes": null, "replies": "", "user_reports": [], "id": "dge44v3", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "SpiderFan", "parent_id": "t1_dgdg2yz", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "excellent thanks!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;excellent thanks!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dge44v3", "score_hidden": false, "stickied": false, "created": 1492491611.0, "created_utc": 1492462811.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdg2yz", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "SVFomin", "parent_id": "t3_65t24t", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "You could read through that \nhttp://timdettmers.com/2015/03/09/deep-learning-hardware-guide/", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You could read through that \n&lt;a href=\"http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/\"&gt;http://timdettmers.com/2015/03/09/deep-learning-hardware-guide/&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdg2yz", "score_hidden": false, "stickied": false, "created": 1492462844.0, "created_utc": 1492434044.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}]