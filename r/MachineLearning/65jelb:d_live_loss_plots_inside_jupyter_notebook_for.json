[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;Is there some reasonably easy way to have live plots of training parameters (e.g. loss, accuracy, validation loss, validation accuracy), that is, ones being updated each epoch?&lt;/p&gt;\n\n&lt;p&gt;Sure, there are built-in progress bar (and even some more Jupyter Notebook ones &lt;a href=\"https://github.com/bstriner/keras-tqdm\"&gt;keras-tqdm&lt;/a&gt;), but what I miss is some plot on how it changes (rather than plotting from &lt;code&gt;history&lt;/code&gt; &lt;em&gt;after&lt;/em&gt; training a model).&lt;/p&gt;\n\n&lt;p&gt;Vide (not yet answered): &lt;a href=\"http://stackoverflow.com/questions/43121986/how-do-i-get-bokeh-to-update-a-plot-displaying-some-measure-vs-epoch-when-using\"&gt;How do I get Bokeh to update a plot displaying some measure vs epoch when using keras fit_generator? - Stack Overflow&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;EDIT:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\"&gt;Live loss plots in Jupyter Notebook for Keras&lt;/a&gt; (a notebook, not yet a library or PR)&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;EDIT2:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;...and actually might turn in a Keras feature: &lt;a href=\"https://github.com/fchollet/keras/issues/1101\"&gt;Issue #1101&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "Is there some reasonably easy way to have live plots of training parameters (e.g. loss, accuracy, validation loss, validation accuracy), that is, ones being updated each epoch?\n\nSure, there are built-in progress bar (and even some more Jupyter Notebook ones [keras-tqdm](https://github.com/bstriner/keras-tqdm)), but what I miss is some plot on how it changes (rather than plotting from `history` *after* training a model).\n\nVide (not yet answered): [How do I get Bokeh to update a plot displaying some measure vs epoch when using keras fit_generator? - Stack Overflow](http://stackoverflow.com/questions/43121986/how-do-i-get-bokeh-to-update-a-plot-displaying-some-measure-vs-epoch-when-using).\n\nEDIT:\n\n* [Live loss plots in Jupyter Notebook for Keras](https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e) (a notebook, not yet a library or PR)\n\nEDIT2:\n\n* ...and actually might turn in a Keras feature: [Issue #1101](https://github.com/fchollet/keras/issues/1101)", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Discussion", "id": "65jelb", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 40, "report_reasons": null, "author": "pmigdal", "saved": false, "mod_reports": [], "name": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "self.MachineLearning", "hidden": false, "preview": {"images": [{"source": {"url": "https://i.redditmedia.com/TEE2JKMANhzyFls-hPmQda_bZxz0aWNOPvASc6Zn8mk.jpg?s=1e2576422935428b637a2fd4d274ee6d", "width": 372, "height": 372}, "resolutions": [{"url": "https://i.redditmedia.com/TEE2JKMANhzyFls-hPmQda_bZxz0aWNOPvASc6Zn8mk.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=108&amp;s=0ec7882afdb282d902c868ca206c5fd4", "width": 108, "height": 108}, {"url": "https://i.redditmedia.com/TEE2JKMANhzyFls-hPmQda_bZxz0aWNOPvASc6Zn8mk.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=216&amp;s=a13facf8310623ecf602336a79d2b90c", "width": 216, "height": 216}, {"url": "https://i.redditmedia.com/TEE2JKMANhzyFls-hPmQda_bZxz0aWNOPvASc6Zn8mk.jpg?fit=crop&amp;crop=faces%2Centropy&amp;arh=2&amp;w=320&amp;s=893122c3ff3588b6a3845d3feaccdbc0", "width": 320, "height": 320}], "variants": {}, "id": "x2ly4d-tLmiZwxQa2ufAzu-kz4fzjlYcZIDShT5Mj54"}], "enabled": false}, "thumbnail": "self", "subreddit_id": "t5_2r3gv", "edited": 1492338370.0, "link_flair_css_class": "one", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "post_hint": "self", "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/65jelb/d_live_loss_plots_inside_jupyter_notebook_for/", "num_reports": null, "locked": false, "stickied": false, "created": 1492296284.0, "url": "https://www.reddit.com/r/MachineLearning/comments/65jelb/d_live_loss_plots_inside_jupyter_notebook_for/", "author_flair_text": null, "quarantine": false, "title": "[D] Live loss plots inside Jupyter Notebook for Keras?", "created_utc": 1492267484.0, "distinguished": null, "media": null, "upvote_ratio": 0.84, "num_comments": 26, "visited": false, "subreddit_type": "public", "ups": 40}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgavu17", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "drcopus", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I set up a `LambdaCallback` to update a logs file (which is a serialized Python dictionary) and plot the history\n\n    from keras.callbacks import LambdaCallback\n    from IPython.display import clear_output\n    import pickle    \n    import matplotlib.pyplot as plt\n    \n    def plot_metrics( epoch, ep_metrics ):\n        logs = pickle.load(open( LOGS_PATH, 'rb' ))\n        for metric in ep_metrics.keys():\n            logs[ metric ].append( ep_metrics[ metric ] )\n        logs[ 'epochs' ].append( epoch )\n        colours = [ 'r', 'orange', 'b', 'purple' ]\n        \n        fig, ax = plt.subplots()\n        xs = np.arange(epoch)\n        ax.plot( logs['epochs'], logs['acc'], colours.pop(0), label = 'acc' )\n        ax.plot( logs['epochs'], logs['val_acc'], colours.pop(0), label = 'val_acc' )\n        ax.set_xlabel( 'Epoch' )\n        ax.set_ylim([ 0, 1.3 ])\n        ax.set_ylabel( 'Accuracy' )\n        ax.legend( loc = 2 )\n        \n        ax = ax.twinx()\n        ax.plot( logs['epochs'], logs['loss'], colours.pop(0), label = 'loss' )\n        ax.plot( logs['epochs'], logs['val_loss'], colours.pop(0), label = 'val_loss' )\n        ax.set_ylabel( 'Loss' )\n        ax.set_ylim([ 0, 1.3*max(logs['loss'] + logs['val_loss']) ])\n        ax.legend( loc = 1 )\n        t1 = logs[ 'time_at_last_epoch' ]\n        t2 = time()\n        dt = t2 - t1\n        logs['time_at_last_epoch'] = t2\n        logs[ 'runtimes' ].append(dt)\n        title_str = 'Training History\\n'\n        title_str += 'Total Time = %.2fs\\n'\n        title_str += 'Time of Last Epoch = %.0fs\\n'\n        title_str += 'Accuracy of Last Epoch = %.4f\\n'\n        title_str += 'Loss of Last Epoch = %.4f\\n'\n        title_str += 'Validation Accuracy of Last Epoch = %.4f\\n'\n        title_str += 'Validation Loss of Last Epoch = %.4f'\n        title_params = ( sum(logs['runtimes']), dt, \n                         ep_metrics['acc'], ep_metrics['loss'],\n                         ep_metrics['val_acc'], ep_metrics['val_loss'] )\n        ax.set_title( title_str % title_params )\n        plt.show()\n        clear_output( wait = True )\n        pickle.dump( logs, open( LOGS_PATH, 'wb' ) )\n\n    logs = pickle.load( open( LOGS_PATH, 'rb' ) )\n    logs[ 'time_at_last_epoch' ] = time()\n    pickle.dump( logs, open( LOGS_PATH, 'wb' ) )\n    plot_metrics_callback = LambdaCallback( on_epoch_end = plot_metrics )\n    initial_epoch = 0 if logs['epochs'] == [] else logs['epochs'][-1]\n    train_generator.reset()\n    model.fit_generator( \n        train_generator,\n        samples_per_epoch = 200,\n        nb_epoch = initial_epoch + 7,\n        initial_epoch = initial_epoch,\n        verbose = 0, \n        validation_data = test_generator,\n        nb_val_samples = 80,\n        callbacks = [ plot_metrics_callback ] )\n\nThere is some code missing from the excerpt above, but hopefully there is enough there for you to get the gist.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I set up a &lt;code&gt;LambdaCallback&lt;/code&gt; to update a logs file (which is a serialized Python dictionary) and plot the history&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;from keras.callbacks import LambdaCallback\nfrom IPython.display import clear_output\nimport pickle    \nimport matplotlib.pyplot as plt\n\ndef plot_metrics( epoch, ep_metrics ):\n    logs = pickle.load(open( LOGS_PATH, &amp;#39;rb&amp;#39; ))\n    for metric in ep_metrics.keys():\n        logs[ metric ].append( ep_metrics[ metric ] )\n    logs[ &amp;#39;epochs&amp;#39; ].append( epoch )\n    colours = [ &amp;#39;r&amp;#39;, &amp;#39;orange&amp;#39;, &amp;#39;b&amp;#39;, &amp;#39;purple&amp;#39; ]\n\n    fig, ax = plt.subplots()\n    xs = np.arange(epoch)\n    ax.plot( logs[&amp;#39;epochs&amp;#39;], logs[&amp;#39;acc&amp;#39;], colours.pop(0), label = &amp;#39;acc&amp;#39; )\n    ax.plot( logs[&amp;#39;epochs&amp;#39;], logs[&amp;#39;val_acc&amp;#39;], colours.pop(0), label = &amp;#39;val_acc&amp;#39; )\n    ax.set_xlabel( &amp;#39;Epoch&amp;#39; )\n    ax.set_ylim([ 0, 1.3 ])\n    ax.set_ylabel( &amp;#39;Accuracy&amp;#39; )\n    ax.legend( loc = 2 )\n\n    ax = ax.twinx()\n    ax.plot( logs[&amp;#39;epochs&amp;#39;], logs[&amp;#39;loss&amp;#39;], colours.pop(0), label = &amp;#39;loss&amp;#39; )\n    ax.plot( logs[&amp;#39;epochs&amp;#39;], logs[&amp;#39;val_loss&amp;#39;], colours.pop(0), label = &amp;#39;val_loss&amp;#39; )\n    ax.set_ylabel( &amp;#39;Loss&amp;#39; )\n    ax.set_ylim([ 0, 1.3*max(logs[&amp;#39;loss&amp;#39;] + logs[&amp;#39;val_loss&amp;#39;]) ])\n    ax.legend( loc = 1 )\n    t1 = logs[ &amp;#39;time_at_last_epoch&amp;#39; ]\n    t2 = time()\n    dt = t2 - t1\n    logs[&amp;#39;time_at_last_epoch&amp;#39;] = t2\n    logs[ &amp;#39;runtimes&amp;#39; ].append(dt)\n    title_str = &amp;#39;Training History\\n&amp;#39;\n    title_str += &amp;#39;Total Time = %.2fs\\n&amp;#39;\n    title_str += &amp;#39;Time of Last Epoch = %.0fs\\n&amp;#39;\n    title_str += &amp;#39;Accuracy of Last Epoch = %.4f\\n&amp;#39;\n    title_str += &amp;#39;Loss of Last Epoch = %.4f\\n&amp;#39;\n    title_str += &amp;#39;Validation Accuracy of Last Epoch = %.4f\\n&amp;#39;\n    title_str += &amp;#39;Validation Loss of Last Epoch = %.4f&amp;#39;\n    title_params = ( sum(logs[&amp;#39;runtimes&amp;#39;]), dt, \n                     ep_metrics[&amp;#39;acc&amp;#39;], ep_metrics[&amp;#39;loss&amp;#39;],\n                     ep_metrics[&amp;#39;val_acc&amp;#39;], ep_metrics[&amp;#39;val_loss&amp;#39;] )\n    ax.set_title( title_str % title_params )\n    plt.show()\n    clear_output( wait = True )\n    pickle.dump( logs, open( LOGS_PATH, &amp;#39;wb&amp;#39; ) )\n\nlogs = pickle.load( open( LOGS_PATH, &amp;#39;rb&amp;#39; ) )\nlogs[ &amp;#39;time_at_last_epoch&amp;#39; ] = time()\npickle.dump( logs, open( LOGS_PATH, &amp;#39;wb&amp;#39; ) )\nplot_metrics_callback = LambdaCallback( on_epoch_end = plot_metrics )\ninitial_epoch = 0 if logs[&amp;#39;epochs&amp;#39;] == [] else logs[&amp;#39;epochs&amp;#39;][-1]\ntrain_generator.reset()\nmodel.fit_generator( \n    train_generator,\n    samples_per_epoch = 200,\n    nb_epoch = initial_epoch + 7,\n    initial_epoch = initial_epoch,\n    verbose = 0, \n    validation_data = test_generator,\n    nb_val_samples = 80,\n    callbacks = [ plot_metrics_callback ] )\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;There is some code missing from the excerpt above, but hopefully there is enough there for you to get the gist.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgavu17", "score_hidden": false, "stickied": false, "created": 1492304920.0, "created_utc": 1492276120.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgavp6v", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "pmigdal", "parent_id": "t1_dgauna7", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Precisely for the same reason why I use Jupyter Notebook at all - to get results code and results in one place, also for showing it to others.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Precisely for the same reason why I use Jupyter Notebook at all - to get results code and results in one place, also for showing it to others.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgavp6v", "score_hidden": false, "stickied": false, "created": 1492304736.0, "created_utc": 1492275936.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgazam8", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "nonstoptimist", "parent_id": "t1_dgaynxr", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Woo! Got it working. Thanks for the tip!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Woo! Got it working. Thanks for the tip!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgazam8", "score_hidden": false, "stickied": false, "created": 1492309624.0, "created_utc": 1492280824.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaynxr", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "cromulen7", "parent_id": "t1_dgayf8x", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "You use different folders for each model.  \ne.g.  \nlogdir/model1  \nlogdir/model2  \nand run tensotboard --logdir logdir  \n  \nTensorboard then shows those folders with little check boxes and you can select which folders to graph.  \nIf you select two folders, you will get two lines with different colors on the same figure.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You use different folders for each model.&lt;br/&gt;\ne.g.&lt;br/&gt;\nlogdir/model1&lt;br/&gt;\nlogdir/model2&lt;br/&gt;\nand run tensotboard --logdir logdir  &lt;/p&gt;\n\n&lt;p&gt;Tensorboard then shows those folders with little check boxes and you can select which folders to graph.&lt;br/&gt;\nIf you select two folders, you will get two lines with different colors on the same figure.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgaynxr", "score_hidden": false, "stickied": false, "created": 1492308750.0, "created_utc": 1492279950.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 6}}], "after": null, "before": null}}, "user_reports": [], "id": "dgayf8x", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "nonstoptimist", "parent_id": "t1_dgauna7", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Your comment prompted me to go try using tensorboard with keras. It's actually pretty easy!\n\nOne question though, how can I compare runs with different hyperparameters on the same loss graph?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Your comment prompted me to go try using tensorboard with keras. It&amp;#39;s actually pretty easy!&lt;/p&gt;\n\n&lt;p&gt;One question though, how can I compare runs with different hyperparameters on the same loss graph?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgayf8x", "score_hidden": false, "stickied": false, "created": 1492308423.0, "created_utc": 1492279623.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgcc5k3", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "schmook", "parent_id": "t1_dgcb943", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Hum, that's nice! ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Hum, that&amp;#39;s nice! &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgcc5k3", "score_hidden": false, "stickied": false, "created": 1492394276.0, "created_utc": 1492365476.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgcb943", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "blazej0", "parent_id": "t1_dgb2gj5", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "No, you run the experiment on your server/infrastructure and only the meta data (e.g. data to be included in graphs) is sent to the Neptune server.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;No, you run the experiment on your server/infrastructure and only the meta data (e.g. data to be included in graphs) is sent to the Neptune server.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgcb943", "score_hidden": false, "stickied": false, "created": 1492393098.0, "created_utc": 1492364298.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb2gj5", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "schmook", "parent_id": "t1_dgazam3", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "This is pretty interesting, but I'm not getting one thing. Do I have to run training on their servers? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is pretty interesting, but I&amp;#39;m not getting one thing. Do I have to run training on their servers? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb2gj5", "score_hidden": false, "stickied": false, "created": 1492313876.0, "created_utc": 1492285076.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgazam3", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "pmigdal", "parent_id": "t1_dgaw1l5", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "If you want a fully-fledged ML experiment controller, we develop https://neptune.deepsense.io/.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If you want a fully-fledged ML experiment controller, we develop &lt;a href=\"https://neptune.deepsense.io/\"&gt;https://neptune.deepsense.io/&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgazam3", "score_hidden": false, "stickied": false, "created": 1492309624.0, "created_utc": 1492280824.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaw1l5", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "drcopus", "parent_id": "t1_dgauna7", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I felt tensorboard was a little lacking in features ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I felt tensorboard was a little lacking in features &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgaw1l5", "score_hidden": false, "stickied": false, "created": 1492305203.0, "created_utc": 1492276403.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgauna7", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "warmspringwinds", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "It might be offtopic, but why don't you use tensorboard?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It might be offtopic, but why don&amp;#39;t you use tensorboard?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgauna7", "score_hidden": false, "stickied": false, "created": 1492303274.0, "created_utc": 1492274474.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgb3rnm", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "pmigdal", "parent_id": "t1_dgb3jh9", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "It is not slow at all (at least compared to the typical duration of each epoch phase).", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It is not slow at all (at least compared to the typical duration of each epoch phase).&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb3rnm", "score_hidden": false, "stickied": false, "created": 1492315662.0, "created_utc": 1492286862.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb3jh9", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Kiuhnm", "parent_id": "t1_dgb2h46", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "If matplotlib is too slow, you could also try plotly, which is very fast. It even supports webgl for scatter plots.\n\nYou can use it offline (I tested it in chrome) with a [widget](https://github.com/mtomassoli/JSWidget) I hacked together.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If matplotlib is too slow, you could also try plotly, which is very fast. It even supports webgl for scatter plots.&lt;/p&gt;\n\n&lt;p&gt;You can use it offline (I tested it in chrome) with a &lt;a href=\"https://github.com/mtomassoli/JSWidget\"&gt;widget&lt;/a&gt; I hacked together.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb3jh9", "score_hidden": false, "stickied": false, "created": 1492315343.0, "created_utc": 1492286543.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb2h46", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "pmigdal", "parent_id": "t1_dgaya15", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "This thing (`clear_output(wait=True)`) helped me a lot, thanks!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This thing (&lt;code&gt;clear_output(wait=True)&lt;/code&gt;) helped me a lot, thanks!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb2h46", "score_hidden": false, "stickied": false, "created": 1492313896.0, "created_utc": 1492285096.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgaya15", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "Pryther", "parent_id": "t1_dgarvco", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "drcopus has a pretty similar solution. The keras documentation gives all code you need for CSVLogger, how to live update a plot you can see here: http://stackoverflow.com/questions/21360361/how-to-dynamically-update-a-plot-in-a-loop-in-ipython-notebook-within-one-cell", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;drcopus has a pretty similar solution. The keras documentation gives all code you need for CSVLogger, how to live update a plot you can see here: &lt;a href=\"http://stackoverflow.com/questions/21360361/how-to-dynamically-update-a-plot-in-a-loop-in-ipython-notebook-within-one-cell\"&gt;http://stackoverflow.com/questions/21360361/how-to-dynamically-update-a-plot-in-a-loop-in-ipython-notebook-within-one-cell&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgaya15", "score_hidden": false, "stickied": false, "created": 1492308230.0, "created_utc": 1492279430.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dgarvco", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "pmigdal", "parent_id": "t1_dgar3w9", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Do you have some code snippet?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Do you have some code snippet?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgarvco", "score_hidden": false, "stickied": false, "created": 1492299381.0, "created_utc": 1492270581.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgar3w9", "gilded": 0, "archived": false, "score": 7, "report_reasons": null, "author": "Pryther", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Maybe theres a better way, but I use the keras CSVlogger and just refresh every few seconds with IPython.display", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Maybe theres a better way, but I use the keras CSVlogger and just refresh every few seconds with IPython.display&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgar3w9", "score_hidden": false, "stickied": false, "created": 1492298297.0, "created_utc": 1492269497.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 7}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgb4oy0", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "ReginaldIII", "parent_id": "t1_dgb33q4", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Here's a code example for bokeh: https://gist.github.com/L2Program/c7e8cbbb9abd545810e7471dc1b7352a I threw together a few weeks ago. It plots loss and accuracy side by side and live updates the data in them each epoch. The key is to get a handle to the lines you add to your figures:\n    \n    p_loss = figure(title=\"Loss\",     webgl=True, toolbar_location=None, plot_height=300, plot_width=int(980/2))\n    p_acc  = figure(title=\"Accuracy\", webgl=True, toolbar_location=None, plot_height=300, plot_width=int(980/2))\n    t_loss = p_loss.line([0], [0], color=\"#2222aa\", line_width=1)\n    v_loss = p_loss.line([0], [0], color=\"#22aa22\", line_width=1)\n    t_acc  =  p_acc.line([0], [0], color=\"#2222aa\", line_width=1)\n    v_acc  =  p_acc.line([0], [0], color=\"#22aa22\", line_width=1)\n\n    show(row(p_loss, p_acc), notebook_handle=True)\n\nand then update them using the following in your loop each epoch or using a callback function to `fit`:\n\n    t_loss.data_source.data = {'x': epochs, 'y': losses}\n    v_loss.data_source.data = {'x': epochs, 'y': val_losses}\n    t_acc.data_source.data  = {'x': epochs, 'y': accurs}\n    v_acc.data_source.data  = {'x': epochs, 'y': val_accurs}\n    push_notebook()\n\nThis will update the data shown without redrawing the whole figure, or messing with text being outputted to the output of the cell. Hope that helps :) I have code for live updating image plots too using bokeh, but its a bit more involved as you have to convert your images to RGBA 32bit/pixel format. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Here&amp;#39;s a code example for bokeh: &lt;a href=\"https://gist.github.com/L2Program/c7e8cbbb9abd545810e7471dc1b7352a\"&gt;https://gist.github.com/L2Program/c7e8cbbb9abd545810e7471dc1b7352a&lt;/a&gt; I threw together a few weeks ago. It plots loss and accuracy side by side and live updates the data in them each epoch. The key is to get a handle to the lines you add to your figures:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;p_loss = figure(title=&amp;quot;Loss&amp;quot;,     webgl=True, toolbar_location=None, plot_height=300, plot_width=int(980/2))\np_acc  = figure(title=&amp;quot;Accuracy&amp;quot;, webgl=True, toolbar_location=None, plot_height=300, plot_width=int(980/2))\nt_loss = p_loss.line([0], [0], color=&amp;quot;#2222aa&amp;quot;, line_width=1)\nv_loss = p_loss.line([0], [0], color=&amp;quot;#22aa22&amp;quot;, line_width=1)\nt_acc  =  p_acc.line([0], [0], color=&amp;quot;#2222aa&amp;quot;, line_width=1)\nv_acc  =  p_acc.line([0], [0], color=&amp;quot;#22aa22&amp;quot;, line_width=1)\n\nshow(row(p_loss, p_acc), notebook_handle=True)\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;and then update them using the following in your loop each epoch or using a callback function to &lt;code&gt;fit&lt;/code&gt;:&lt;/p&gt;\n\n&lt;pre&gt;&lt;code&gt;t_loss.data_source.data = {&amp;#39;x&amp;#39;: epochs, &amp;#39;y&amp;#39;: losses}\nv_loss.data_source.data = {&amp;#39;x&amp;#39;: epochs, &amp;#39;y&amp;#39;: val_losses}\nt_acc.data_source.data  = {&amp;#39;x&amp;#39;: epochs, &amp;#39;y&amp;#39;: accurs}\nv_acc.data_source.data  = {&amp;#39;x&amp;#39;: epochs, &amp;#39;y&amp;#39;: val_accurs}\npush_notebook()\n&lt;/code&gt;&lt;/pre&gt;\n\n&lt;p&gt;This will update the data shown without redrawing the whole figure, or messing with text being outputted to the output of the cell. Hope that helps :) I have code for live updating image plots too using bokeh, but its a bit more involved as you have to convert your images to RGBA 32bit/pixel format. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb4oy0", "score_hidden": false, "stickied": false, "created": 1492316928.0, "created_utc": 1492288128.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dgb33q4", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "pmigdal", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "It seems there is no plug&amp;play library. Though, thanks to your help, I managed to create some minimalistic example:\n\n* [Live loss plots in Jupyter Notebook for Keras - gist](https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e)\n\nEnjoy!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems there is no plug&amp;amp;play library. Though, thanks to your help, I managed to create some minimalistic example:&lt;/p&gt;\n\n&lt;ul&gt;\n&lt;li&gt;&lt;a href=\"https://gist.github.com/stared/dfb4dfaf6d9a8501cd1cc8b8cb806d2e\"&gt;Live loss plots in Jupyter Notebook for Keras - gist&lt;/a&gt;&lt;/li&gt;\n&lt;/ul&gt;\n\n&lt;p&gt;Enjoy!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb33q4", "score_hidden": false, "stickied": false, "created": 1492314736.0, "created_utc": 1492285936.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgb8f9c", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "inlineint", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I've implemented some time ago a similar thing with Matplotlib notebook backend for PyTorch.\n\n[This is a notebook with an example](https://gist.github.com/a-rodin/799a6548817df8fbd2fb4a58dd9f5b81)\n\nIt turned out that Matplotlib 2.0 has problems with `figure.draw()` on Retina displays, so the notebook contains a workaround for it.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve implemented some time ago a similar thing with Matplotlib notebook backend for PyTorch.&lt;/p&gt;\n\n&lt;p&gt;&lt;a href=\"https://gist.github.com/a-rodin/799a6548817df8fbd2fb4a58dd9f5b81\"&gt;This is a notebook with an example&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;It turned out that Matplotlib 2.0 has problems with &lt;code&gt;figure.draw()&lt;/code&gt; on Retina displays, so the notebook contains a workaround for it.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgb8f9c", "score_hidden": false, "stickied": false, "created": 1492322057.0, "created_utc": 1492293257.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgdgu6o", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "pmigdal", "parent_id": "t1_dgdbo66", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Cool library, but I don't see how to get **live** plots.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Cool library, but I don&amp;#39;t see how to get &lt;strong&gt;live&lt;/strong&gt; plots.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdgu6o", "score_hidden": false, "stickied": false, "created": 1492464122.0, "created_utc": 1492435322.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdbo66", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "wdroz", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Use scikit wrapper and then scikit-plot : https://github.com/reiinakano/scikit-plot", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Use scikit wrapper and then scikit-plot : &lt;a href=\"https://github.com/reiinakano/scikit-plot\"&gt;https://github.com/reiinakano/scikit-plot&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdbo66", "score_hidden": false, "stickied": false, "created": 1492451893.0, "created_utc": 1492423093.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgatti4", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "mauinz", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Alternatively you can plot, erase the plot and re plot. But I've had issues with this feature in notebooks ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Alternatively you can plot, erase the plot and re plot. But I&amp;#39;ve had issues with this feature in notebooks &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgatti4", "score_hidden": false, "stickied": false, "created": 1492302103.0, "created_utc": 1492273303.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgawj05", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Megatron_McLargeHuge", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I hacked together something to do this a few years ago using javascript in an IFrame. Another process ran a zmq-websocket bridge to forward updates from the running code to the JS plotting code.\n\nIt was more hassle that it was worth to keep editing the JS to do the same as my matlotlib plots so these days I just run a new plot every n iterations and deal with it scrolling. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I hacked together something to do this a few years ago using javascript in an IFrame. Another process ran a zmq-websocket bridge to forward updates from the running code to the JS plotting code.&lt;/p&gt;\n\n&lt;p&gt;It was more hassle that it was worth to keep editing the JS to do the same as my matlotlib plots so these days I just run a new plot every n iterations and deal with it scrolling. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgawj05", "score_hidden": false, "stickied": false, "created": 1492305861.0, "created_utc": 1492277061.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgayji9", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Iknite", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Just another point of view of the problem. Seems like you're attached to the tool instead to find the best one. It's ok, jupyter notebook it's great for hacking around the ideas, but it's not for everything. You had a complex environment/setup find the correct one (jupyter kernels are not as isolated as it seems, for example)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Just another point of view of the problem. Seems like you&amp;#39;re attached to the tool instead to find the best one. It&amp;#39;s ok, jupyter notebook it&amp;#39;s great for hacking around the ideas, but it&amp;#39;s not for everything. You had a complex environment/setup find the correct one (jupyter kernels are not as isolated as it seems, for example)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgayji9", "score_hidden": false, "stickied": false, "created": 1492308581.0, "created_utc": 1492279781.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65jelb", "likes": null, "replies": "", "user_reports": [], "id": "dgbavjo", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "The_Man_of_Science", "parent_id": "t3_65jelb", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "You can try out using the Keras Monitor callback:\n\nHere: https://keras.io/callbacks/#remotemonitor\n\nAnd then you can either use a flask or this App for the realtime Viz: https://github.com/fchollet/hualos", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;You can try out using the Keras Monitor callback:&lt;/p&gt;\n\n&lt;p&gt;Here: &lt;a href=\"https://keras.io/callbacks/#remotemonitor\"&gt;https://keras.io/callbacks/#remotemonitor&lt;/a&gt;&lt;/p&gt;\n\n&lt;p&gt;And then you can either use a flask or this App for the realtime Viz: &lt;a href=\"https://github.com/fchollet/hualos\"&gt;https://github.com/fchollet/hualos&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgbavjo", "score_hidden": false, "stickied": false, "created": 1492325588.0, "created_utc": 1492296788.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}]