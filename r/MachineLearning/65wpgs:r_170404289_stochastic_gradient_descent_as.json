[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": null, "selftext": "", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Research", "id": "65wpgs", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 51, "report_reasons": null, "author": "Mandrathax", "saved": false, "mod_reports": [], "name": "t3_65wpgs", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "arxiv.org", "hidden": false, "thumbnail": "default", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "three", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": false, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/65wpgs/r_170404289_stochastic_gradient_descent_as/", "num_reports": null, "locked": false, "stickied": false, "created": 1492476345.0, "url": "https://arxiv.org/abs/1704.04289", "author_flair_text": null, "quarantine": false, "title": "[R] [1704.04289] Stochastic Gradient Descent as Approximate Bayesian Inference", "created_utc": 1492447545.0, "distinguished": null, "media": null, "upvote_ratio": 0.95, "num_comments": 5, "visited": false, "subreddit_type": "public", "ups": 51}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wpgs", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wpgs", "likes": null, "replies": "", "user_reports": [], "id": "dgeixsb", "gilded": 0, "archived": false, "score": -1, "report_reasons": null, "author": "intendedUser", "parent_id": "t1_dgdtsz6", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Can you recommend a good introduction to learn how to apply SGD?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you recommend a good introduction to learn how to apply SGD?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgeixsb", "score_hidden": false, "stickied": false, "created": 1492510159.0, "created_utc": 1492481359.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": -1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdtsz6", "gilded": 0, "archived": false, "score": 9, "report_reasons": null, "author": "bobchennan", "parent_id": "t3_65wpgs", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "SGD is always more powerful than you thought.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;SGD is always more powerful than you thought.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdtsz6", "score_hidden": false, "stickied": false, "created": 1492480011.0, "created_utc": 1492451211.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 9}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wpgs", "likes": null, "replies": "", "user_reports": [], "id": "dgdqj0l", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "arXiv_abstract_bot", "parent_id": "t3_65wpgs", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Title: Stochastic Gradient Descent as Approximate Bayesian Inference  \n\nAuthors: [Stephan Mandt](http://arxiv.org/find/stat/1/au:+Mandt_S/0/1/0/all/0/1), [Matthew D. Hoffman](http://arxiv.org/find/stat/1/au:+Hoffman_M/0/1/0/all/0/1), [David M. Blei](http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1)  \n\n&gt; Abstract: Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also propose SGD with momentum for sampling and show how to adjust the damping coefficient accordingly. (4) We analyze MCMC algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.  \n\n[PDF link](https://arxiv.org/pdf/1704.04289)  [Landing page](https://arxiv.org/abs/1704.04289)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Title: Stochastic Gradient Descent as Approximate Bayesian Inference  &lt;/p&gt;\n\n&lt;p&gt;Authors: &lt;a href=\"http://arxiv.org/find/stat/1/au:+Mandt_S/0/1/0/all/0/1\"&gt;Stephan Mandt&lt;/a&gt;, &lt;a href=\"http://arxiv.org/find/stat/1/au:+Hoffman_M/0/1/0/all/0/1\"&gt;Matthew D. Hoffman&lt;/a&gt;, &lt;a href=\"http://arxiv.org/find/stat/1/au:+Blei_D/0/1/0/all/0/1\"&gt;David M. Blei&lt;/a&gt;  &lt;/p&gt;\n\n&lt;blockquote&gt;\n&lt;p&gt;Abstract: Stochastic Gradient Descent with a constant learning rate (constant SGD) simulates a Markov chain with a stationary distribution. With this perspective, we derive several new results. (1) We show that constant SGD can be used as an approximate Bayesian posterior inference algorithm. Specifically, we show how to adjust the tuning parameters of constant SGD to best match the stationary distribution to a posterior, minimizing the Kullback-Leibler divergence between these two distributions. (2) We demonstrate that constant SGD gives rise to a new variational EM algorithm that optimizes hyperparameters in complex probabilistic models. (3) We also propose SGD with momentum for sampling and show how to adjust the damping coefficient accordingly. (4) We analyze MCMC algorithms. For Langevin Dynamics and Stochastic Gradient Fisher Scoring, we quantify the approximation errors due to finite learning rates. Finally (5), we use the stochastic process perspective to give a short proof of why Polyak averaging is optimal. Based on this idea, we propose a scalable approximate MCMC algorithm, the Averaged Stochastic Gradient Sampler.  &lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;&lt;a href=\"https://arxiv.org/pdf/1704.04289\"&gt;PDF link&lt;/a&gt;  &lt;a href=\"https://arxiv.org/abs/1704.04289\"&gt;Landing page&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdqj0l", "score_hidden": false, "stickied": false, "created": 1492476376.0, "created_utc": 1492447576.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wpgs", "likes": null, "replies": "", "user_reports": [], "id": "dgekg1r", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "JCPenis", "parent_id": "t3_65wpgs", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "So this is not variational inference?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;So this is not variational inference?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgekg1r", "score_hidden": false, "stickied": false, "created": 1492511944.0, "created_utc": 1492483144.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wpgs", "likes": null, "replies": "", "user_reports": [], "id": "dgevo0r", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "dzyl", "parent_id": "t3_65wpgs", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "This looks very promising and interesting, I (far from) fully grasp what is going on however. Is my intuition correct in that this method only works after the network has fully converged, which means it is not suited for using it in the exploration part of reinforcement learning, given that that is a dynamical system?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This looks very promising and interesting, I (far from) fully grasp what is going on however. Is my intuition correct in that this method only works after the network has fully converged, which means it is not suited for using it in the exploration part of reinforcement learning, given that that is a dynamical system?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgevo0r", "score_hidden": false, "stickied": false, "created": 1492533307.0, "created_utc": 1492504507.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}]