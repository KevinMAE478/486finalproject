[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;ve seen the ALI and BiGAN frameworks.  But I was curious to why one doesn&amp;#39;t first finish training their preferred flavor of GAN to convergence before doing the following: generate a few million noise vectors Z, use G to map Z to X, create a new network to learn G&lt;sup&gt;-1&lt;/sup&gt; since we have X and Z.&lt;/p&gt;\n\n&lt;p&gt;This seems like it would be computationally cheaper than trying to learn the inverse mapping simultaneously with the GAN objective.  But I don&amp;#39;t really hear of people doing this, and it seems so simple, so I suspect there might be a flaw in my logic.  &lt;/p&gt;\n\n&lt;p&gt;I further realize that integrating learning of the inverse map with the GAN objective can lead to better learned features in the latent space as described in the papers, but several new GAN frameworks (WGAN, BEGAN, LS-GAN, etc...) have popped up since that time.  I was wondering if anybody had explored whether the advantages in representation brought about by BiGAN/ALI could be achieved simply by moving to a better, newer GAN framework?  I think the better question might be if BiGAN/ALI on top of a newer GAN would have better representations than just a newer GAN by itself.  If the answer is no, I think an argument can be made for training the inverse mapping after GAN convergence.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "I've seen the ALI and BiGAN frameworks.  But I was curious to why one doesn't first finish training their preferred flavor of GAN to convergence before doing the following: generate a few million noise vectors Z, use G to map Z to X, create a new network to learn G^(-1) since we have X and Z.\n\nThis seems like it would be computationally cheaper than trying to learn the inverse mapping simultaneously with the GAN objective.  But I don't really hear of people doing this, and it seems so simple, so I suspect there might be a flaw in my logic.  \n\nI further realize that integrating learning of the inverse map with the GAN objective can lead to better learned features in the latent space as described in the papers, but several new GAN frameworks (WGAN, BEGAN, LS-GAN, etc...) have popped up since that time.  I was wondering if anybody had explored whether the advantages in representation brought about by BiGAN/ALI could be achieved simply by moving to a better, newer GAN framework?  I think the better question might be if BiGAN/ALI on top of a newer GAN would have better representations than just a newer GAN by itself.  If the answer is no, I think an argument can be made for training the inverse mapping after GAN convergence.", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Discussion", "id": "64w269", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 9, "report_reasons": null, "author": "TheFlyingDrildo", "saved": false, "mod_reports": [], "name": "t3_64w269", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "self.MachineLearning", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "one", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/64w269/d_learning_inverse_map_of_generator_after/", "num_reports": null, "locked": false, "stickied": false, "created": 1492000150.0, "url": "https://www.reddit.com/r/MachineLearning/comments/64w269/d_learning_inverse_map_of_generator_after/", "author_flair_text": null, "quarantine": false, "title": "[D] Learning Inverse Map of Generator after training GAN?", "created_utc": 1491971350.0, "distinguished": null, "media": null, "upvote_ratio": 0.91, "num_comments": 13, "visited": false, "subreddit_type": "public", "ups": 9}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": "", "user_reports": [], "id": "dg7hrgo", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "vdumoulin", "parent_id": "t1_dg65zi4", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "The issue with VAEs (at least in their vanilla form, without things like normalizing flows or inverse autoregressive flows) is that the form of the approximate posterior is usually very simple (e.g., gaussian with a diagonal covariance matrix), because the log-likelihood lower-bound requires its density function to be known and efficiently computable.\n\nBecause of that, it is hard for the model to have the approximate posterior \"fill in\" the space covered by the prior. To understand why this is a problem, I like to think of it in terms of a \"generative contract\": the generative model says \"At test time I'm going to sample from this distribution (p(z)) and decode.\", and in order for this to make sense the decoder has to map any z that's likely under the prior to data-like x samples. For this to hold, you need to have a good autoencoder, and you need the autoencoder's latent representation distribution to align with the prior. If there are \"holes\" (i.e., regions which are likely under the prior yet are not reached by encoding some training example), then sampling points in these holes and decoding them will yield odd-looking samples, because the decoder hasn't been trained with this sort of data. This is why you see lots of \"smearing\" in VAE samples but not in VAE reconstructions.\n\nOn the other hand, the adversarial framework allows one to train approximate posteriors with unknown density functions (e.g., an approximate posterior obtained by concatenating the input with some noise source and encoding), which makes it very straightforward to cover the space of the prior without additional tricks like normalizing flows or inverse autoregressive flows.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The issue with VAEs (at least in their vanilla form, without things like normalizing flows or inverse autoregressive flows) is that the form of the approximate posterior is usually very simple (e.g., gaussian with a diagonal covariance matrix), because the log-likelihood lower-bound requires its density function to be known and efficiently computable.&lt;/p&gt;\n\n&lt;p&gt;Because of that, it is hard for the model to have the approximate posterior &amp;quot;fill in&amp;quot; the space covered by the prior. To understand why this is a problem, I like to think of it in terms of a &amp;quot;generative contract&amp;quot;: the generative model says &amp;quot;At test time I&amp;#39;m going to sample from this distribution (p(z)) and decode.&amp;quot;, and in order for this to make sense the decoder has to map any z that&amp;#39;s likely under the prior to data-like x samples. For this to hold, you need to have a good autoencoder, and you need the autoencoder&amp;#39;s latent representation distribution to align with the prior. If there are &amp;quot;holes&amp;quot; (i.e., regions which are likely under the prior yet are not reached by encoding some training example), then sampling points in these holes and decoding them will yield odd-looking samples, because the decoder hasn&amp;#39;t been trained with this sort of data. This is why you see lots of &amp;quot;smearing&amp;quot; in VAE samples but not in VAE reconstructions.&lt;/p&gt;\n\n&lt;p&gt;On the other hand, the adversarial framework allows one to train approximate posteriors with unknown density functions (e.g., an approximate posterior obtained by concatenating the input with some noise source and encoding), which makes it very straightforward to cover the space of the prior without additional tricks like normalizing flows or inverse autoregressive flows.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7hrgo", "score_hidden": false, "stickied": false, "created": 1492116591.0, "created_utc": 1492087791.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg65zi4", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "tmiano", "parent_id": "t1_dg5vico", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "It seems from the toy example that VAEs seem to perform the best at learning a representation of the data - at least from what I can tell visually, the VAE keeps the local and global relationships between the modes intact where the other methods don't seem to do that as well. This plus the fact that the VAE is sure to generate all modes mean that all modes will get an inverse mapping that makes sense. Do you think this is a fair assessment? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It seems from the toy example that VAEs seem to perform the best at learning a representation of the data - at least from what I can tell visually, the VAE keeps the local and global relationships between the modes intact where the other methods don&amp;#39;t seem to do that as well. This plus the fact that the VAE is sure to generate all modes mean that all modes will get an inverse mapping that makes sense. Do you think this is a fair assessment? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg65zi4", "score_hidden": false, "stickied": false, "created": 1492045290.0, "created_utc": 1492016490.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": "", "user_reports": [], "id": "dg7teab", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "anonDogeLover", "parent_id": "t1_dg7gug7", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Ah ok thanks for responding", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah ok thanks for responding&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7teab", "score_hidden": false, "stickied": false, "created": 1492130354.0, "created_utc": 1492101554.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg7gug7", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "vdumoulin", "parent_id": "t1_dg6dbgs", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I don't have them anymore, you'd have to re-train the model. :/ Sorry about that, I tend to be too aggressive in cleaning up disk space.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t have them anymore, you&amp;#39;d have to re-train the model. :/ Sorry about that, I tend to be too aggressive in cleaning up disk space.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7gug7", "score_hidden": false, "stickied": false, "created": 1492115084.0, "created_utc": 1492086284.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 3}}], "after": null, "before": null}}, "user_reports": [], "id": "dg6dbgs", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "anonDogeLover", "parent_id": "t1_dg5vico", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Can you please release the weights for tiny imagenet and full imagenet if you have it?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Can you please release the weights for tiny imagenet and full imagenet if you have it?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg6dbgs", "score_hidden": false, "stickied": false, "created": 1492052759.0, "created_utc": 1492023959.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg5vico", "gilded": 0, "archived": false, "score": 6, "report_reasons": null, "author": "vdumoulin", "parent_id": "t3_64w269", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "ALI paper author. In the latest version of the paper, we examine this question on a toy dataset. The experiment details and figure can be found [here](https://ishmaelbelghazi.github.io/ALI/#toy_dataset).\n\nTL;DR: It doesn't work very well if what you're interested in is learning a good representation for your data. You can only invert what your generator has learned to represent, which means the inverse mapping won't know what to do with missing modes.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;ALI paper author. In the latest version of the paper, we examine this question on a toy dataset. The experiment details and figure can be found &lt;a href=\"https://ishmaelbelghazi.github.io/ALI/#toy_dataset\"&gt;here&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;TL;DR: It doesn&amp;#39;t work very well if what you&amp;#39;re interested in is learning a good representation for your data. You can only invert what your generator has learned to represent, which means the inverse mapping won&amp;#39;t know what to do with missing modes.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg5vico", "score_hidden": false, "stickied": false, "created": 1492033538.0, "created_utc": 1492004738.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 6}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": "", "user_reports": [], "id": "dg7j0i2", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "junyanz", "parent_id": "t1_dg5lo2t", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Code for learning inverse mapping of a pretrained GAN can be found here: https://github.com/junyanz/iGAN/tree/master/train_dcgan", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Code for learning inverse mapping of a pretrained GAN can be found here: &lt;a href=\"https://github.com/junyanz/iGAN/tree/master/train_dcgan\"&gt;https://github.com/junyanz/iGAN/tree/master/train_dcgan&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7j0i2", "score_hidden": false, "stickied": false, "created": 1492118451.0, "created_utc": 1492089651.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg5lo2t", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "DanielWaterworth", "parent_id": "t3_64w269", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "This subject is tacked in \"4.1 Projecting an Image onto the Manifold\" of [this paper](https://arxiv.org/abs/1609.03552). Training a decoder network is under \"Projection via a feedforward network\".", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This subject is tacked in &amp;quot;4.1 Projecting an Image onto the Manifold&amp;quot; of &lt;a href=\"https://arxiv.org/abs/1609.03552\"&gt;this paper&lt;/a&gt;. Training a decoder network is under &amp;quot;Projection via a feedforward network&amp;quot;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg5lo2t", "score_hidden": false, "stickied": false, "created": 1492010503.0, "created_utc": 1491981703.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": "", "user_reports": [], "id": "dg5moj2", "gilded": 0, "archived": false, "score": 3, "report_reasons": null, "author": "kjearns", "parent_id": "t3_64w269", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "This is the principle behind Generative Compression https://arxiv.org/abs/1703.01467", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;This is the principle behind Generative Compression &lt;a href=\"https://arxiv.org/abs/1703.01467\"&gt;https://arxiv.org/abs/1703.01467&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg5moj2", "score_hidden": false, "stickied": false, "created": 1492013433.0, "created_utc": 1491984633.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 3}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": "", "user_reports": [], "id": "dg7tk5o", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "anonDogeLover", "parent_id": "t1_dg7j41s", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Great, thanks", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Great, thanks&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7tk5o", "score_hidden": false, "stickied": false, "created": 1492130530.0, "created_utc": 1492101730.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg7j41s", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "junyanz", "parent_id": "t1_dg6d5le", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "CycleGAN repo includes a BIGAN/ALI implemention with lsgan: https://github.com/junyanz/CycleGAN ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;CycleGAN repo includes a BIGAN/ALI implemention with lsgan: &lt;a href=\"https://github.com/junyanz/CycleGAN\"&gt;https://github.com/junyanz/CycleGAN&lt;/a&gt; &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7j41s", "score_hidden": false, "stickied": false, "created": 1492118589.0, "created_utc": 1492089789.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dg6d5le", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "anonDogeLover", "parent_id": "t3_64w269", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "+1 for replicating ALI and BiGAN with an LS-GAN (least squares GAN). Anyone tried this? Code anywhere?", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;+1 for replicating ALI and BiGAN with an LS-GAN (least squares GAN). Anyone tried this? Code anywhere?&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg6d5le", "score_hidden": false, "stickied": false, "created": 1492052584.0, "created_utc": 1492023784.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64w269", "likes": null, "replies": "", "user_reports": [], "id": "dg5l4oy", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "AlexDimakis", "parent_id": "t3_64w269", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "If I understand what you want: after you have trained a GAN G(z), to `invert' it, i.e. given an image X1 to find a Z1 that produces G(Z1) close to X1. \nYou can do this by backpropagation on Z to make G(Z) match X1. This is updating Z using its gradient but is not changing the weights of the network. So you solve min_z || G(z) - X1||_2 using gradient descent on Z. \nSee this repo for a generalization of this idea and the paper on arxiv:\nhttps://github.com/AshishBora/csgm", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;If I understand what you want: after you have trained a GAN G(z), to `invert&amp;#39; it, i.e. given an image X1 to find a Z1 that produces G(Z1) close to X1. \nYou can do this by backpropagation on Z to make G(Z) match X1. This is updating Z using its gradient but is not changing the weights of the network. So you solve min_z || G(z) - X1||_2 using gradient descent on Z. \nSee this repo for a generalization of this idea and the paper on arxiv:\n&lt;a href=\"https://github.com/AshishBora/csgm\"&gt;https://github.com/AshishBora/csgm&lt;/a&gt;&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg5l4oy", "score_hidden": false, "stickied": false, "created": 1492009056.0, "created_utc": 1491980256.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}]