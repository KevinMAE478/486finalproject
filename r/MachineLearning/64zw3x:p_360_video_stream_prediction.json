[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I&amp;#39;m currently tasked with creating neural network that should predict what direction will user look at in the certain point of time.&lt;/p&gt;\n\n&lt;p&gt;I want to split the 360 video in the 15 degree chunks (total user view angle is 60 degrees) and create network that would predict and preload certain chunks of video. Entire 360 video will be streamed with lowest quality apart from that 60 degree user is looking at.&lt;/p&gt;\n\n&lt;p&gt;I have dataset which contains data for 60 seconds long video and recorded user behavior:&lt;/p&gt;\n\n&lt;p&gt;Example:&lt;/p&gt;\n\n&lt;table&gt;&lt;thead&gt;\n&lt;tr&gt;\n&lt;th align=\"center\"&gt;session_id&lt;/th&gt;\n&lt;th align=\"center\"&gt;time&lt;/th&gt;\n&lt;th align=\"center\"&gt;view focal point&lt;/th&gt;\n&lt;/tr&gt;\n&lt;/thead&gt;&lt;tbody&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;1.902058&lt;/td&gt;\n&lt;td align=\"center\"&gt;8&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.000838&lt;/td&gt;\n&lt;td align=\"center\"&gt;12&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.101868&lt;/td&gt;\n&lt;td align=\"center\"&gt;16&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.200833&lt;/td&gt;\n&lt;td align=\"center\"&gt;16&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.300319&lt;/td&gt;\n&lt;td align=\"center\"&gt;18&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.402479&lt;/td&gt;\n&lt;td align=\"center\"&gt;18&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.500449&lt;/td&gt;\n&lt;td align=\"center\"&gt;18&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.650183&lt;/td&gt;\n&lt;td align=\"center\"&gt;18&lt;/td&gt;\n&lt;/tr&gt;\n&lt;tr&gt;\n&lt;td align=\"center\"&gt;s1489657649x33f872685a2b0ex37846277&lt;/td&gt;\n&lt;td align=\"center\"&gt;2.752058&lt;/td&gt;\n&lt;td align=\"center\"&gt;18&lt;/td&gt;\n&lt;/tr&gt;\n&lt;/tbody&gt;&lt;/table&gt;\n\n&lt;p&gt;My problem is that there is no fixed point in time for this recording intervals of behavior and I have no idea what methods to use or how to model the network.&lt;/p&gt;\n\n&lt;p&gt;I&amp;#39;m asking for any kind of pointers in regard what type of network this should be and how would one model it.&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "I'm currently tasked with creating neural network that should predict what direction will user look at in the certain point of time.\n\nI want to split the 360 video in the 15 degree chunks (total user view angle is 60 degrees) and create network that would predict and preload certain chunks of video. Entire 360 video will be streamed with lowest quality apart from that 60 degree user is looking at.\n\nI have dataset which contains data for 60 seconds long video and recorded user behavior:\n\nExample:\n\n    session_id|time|view focal point\n    :--:|:--:|:--:\n    s1489657649x33f872685a2b0ex37846277|1.902058|8\n    s1489657649x33f872685a2b0ex37846277|2.000838|12\n    s1489657649x33f872685a2b0ex37846277|2.101868|16\n    s1489657649x33f872685a2b0ex37846277|2.200833|16\n    s1489657649x33f872685a2b0ex37846277|2.300319|18\n    s1489657649x33f872685a2b0ex37846277|2.402479|18\n    s1489657649x33f872685a2b0ex37846277|2.500449|18\n    s1489657649x33f872685a2b0ex37846277|2.650183|18\n    s1489657649x33f872685a2b0ex37846277|2.752058|18\n\n\nMy problem is that there is no fixed point in time for this recording intervals of behavior and I have no idea what methods to use or how to model the network.\n\nI'm asking for any kind of pointers in regard what type of network this should be and how would one model it.\n", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Project", "id": "64zw3x", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 7, "report_reasons": null, "author": "janez01", "saved": false, "mod_reports": [], "name": "t3_64zw3x", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "self.MachineLearning", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "four", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/64zw3x/p_360_video_stream_prediction/", "num_reports": null, "locked": false, "stickied": false, "created": 1492049403.0, "url": "https://www.reddit.com/r/MachineLearning/comments/64zw3x/p_360_video_stream_prediction/", "author_flair_text": null, "quarantine": false, "title": "[P] 360 video stream prediction", "created_utc": 1492020603.0, "distinguished": null, "media": null, "upvote_ratio": 0.81, "num_comments": 3, "visited": false, "subreddit_type": "public", "ups": 7}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64zw3x", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64zw3x", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_64zw3x", "likes": null, "replies": "", "user_reports": [], "id": "dg85dnf", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "pete0273", "parent_id": "t1_dg852b6", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Oh that's super cool and novel. That's actually really cool. I'll think about it, but I'm still pretty new to the field :)", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Oh that&amp;#39;s super cool and novel. That&amp;#39;s actually really cool. I&amp;#39;ll think about it, but I&amp;#39;m still pretty new to the field :)&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg85dnf", "score_hidden": false, "stickied": false, "created": 1492143219.0, "created_utc": 1492114419.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg852b6", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "janez01", "parent_id": "t1_dg7f2d5", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "First of all thank you for such detailed answer. However, my project task doesn't involve any video processing (as of yet) and NN should be purely formed by users behavior. So lets say my dataset cosist of data for single video of 60 seconds length that was watched by 1000 users. So I have data on \"what\" users found interesting to focus on and my network should learn from them and possibly learn in future from new users. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;First of all thank you for such detailed answer. However, my project task doesn&amp;#39;t involve any video processing (as of yet) and NN should be purely formed by users behavior. So lets say my dataset cosist of data for single video of 60 seconds length that was watched by 1000 users. So I have data on &amp;quot;what&amp;quot; users found interesting to focus on and my network should learn from them and possibly learn in future from new users. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg852b6", "score_hidden": false, "stickied": false, "created": 1492142867.0, "created_utc": 1492114067.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dg7f2d5", "gilded": 0, "archived": false, "score": 5, "report_reasons": null, "author": "pete0273", "parent_id": "t3_64zw3x", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "That sounds like a foveal-filter attention LSTM. Foveal-filter means clearer in the center of focus (your 15 degree window), blurry in the adjacent windows (the 30 degrees on either side) and black in the rest of the video frame. Attention means a reinforcement learning agent learns where in the sphere to focus. It learns by following a reward signal (which can be very sparse). In your case the reward signal would be the degree to which it extracts the info you want from the 360 video. Creating rewards and costs is the hardest part of neural net design. Lastly LSTM is the model that will be learning to attend. Your LSTM will be processing the slice of the 360 input frame consisting of the 15 degree window plus the 30 degrees on each side that are blurry (a total of 75 degrees of input). From this input it will output two things. A prediction of what it's seeing, and a softmax distribution over 15 degree slices giving its guess about the reward of each slice it could focus on next frame.\n\nYou want to learn that reward distribution. To learn to follow a dog that runs past the camera you learn to recognize a dog, assign reward for looking at it, and then learn weights of the LSTM which make it output an accurate softmax distribution over 15 degree slices. The ideal distribution over 15 degree slices will shift as the dog approaches one edge of the current focus slice. Once the softmax value of the adjacent 15 degree focus window has the highest value in the softmax distribution, focus switches to that window (where the dog should now be since he's crossed the edge of the previous focus window).\n\nLearning to attend is simply learning the weights of the LSTM so that the 15 + 30 + 30 input image creates an accurate softmax distribution over 15 degree windows to look at next.\n\nIf you see a car driving at you, and your reward is to get its license plate, then the car becoming very close should spike the output softmax distribution entry of the 15 degree frame that is 180 degrees opposite, since the car is about to pass the camera.\n\nThey used this model on images of houses to learn to read house addresses, and it learned to only look at the numbers and to read from left to right.", "edited": 1492083566.0, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;That sounds like a foveal-filter attention LSTM. Foveal-filter means clearer in the center of focus (your 15 degree window), blurry in the adjacent windows (the 30 degrees on either side) and black in the rest of the video frame. Attention means a reinforcement learning agent learns where in the sphere to focus. It learns by following a reward signal (which can be very sparse). In your case the reward signal would be the degree to which it extracts the info you want from the 360 video. Creating rewards and costs is the hardest part of neural net design. Lastly LSTM is the model that will be learning to attend. Your LSTM will be processing the slice of the 360 input frame consisting of the 15 degree window plus the 30 degrees on each side that are blurry (a total of 75 degrees of input). From this input it will output two things. A prediction of what it&amp;#39;s seeing, and a softmax distribution over 15 degree slices giving its guess about the reward of each slice it could focus on next frame.&lt;/p&gt;\n\n&lt;p&gt;You want to learn that reward distribution. To learn to follow a dog that runs past the camera you learn to recognize a dog, assign reward for looking at it, and then learn weights of the LSTM which make it output an accurate softmax distribution over 15 degree slices. The ideal distribution over 15 degree slices will shift as the dog approaches one edge of the current focus slice. Once the softmax value of the adjacent 15 degree focus window has the highest value in the softmax distribution, focus switches to that window (where the dog should now be since he&amp;#39;s crossed the edge of the previous focus window).&lt;/p&gt;\n\n&lt;p&gt;Learning to attend is simply learning the weights of the LSTM so that the 15 + 30 + 30 input image creates an accurate softmax distribution over 15 degree windows to look at next.&lt;/p&gt;\n\n&lt;p&gt;If you see a car driving at you, and your reward is to get its license plate, then the car becoming very close should spike the output softmax distribution entry of the 15 degree frame that is 180 degrees opposite, since the car is about to pass the camera.&lt;/p&gt;\n\n&lt;p&gt;They used this model on images of houses to learn to read house addresses, and it learned to only look at the numbers and to read from left to right.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dg7f2d5", "score_hidden": false, "stickied": false, "created": 1492111491.0, "created_utc": 1492082691.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 5}}], "after": null, "before": null}}]