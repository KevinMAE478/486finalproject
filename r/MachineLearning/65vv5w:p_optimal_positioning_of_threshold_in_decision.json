[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;When deciding on the value of a threshold for continuous valued attributes in a decision tree there will be infinitely many thresholds giving the same information gain.&lt;/p&gt;\n\n&lt;p&gt;E.g. if class one has attribute values 4 4.5 5 and class two has values 6 9 12 14, any threshold between 5 and 6 will give the same information gain.&lt;/p&gt;\n\n&lt;p&gt;My question is what is the optimum value of the threshold - is it simply 5.5 since this puts it equidistant from the nearest two neighbours? Or is it closer towards 6 since class one has more values of attributes closer to the boundary?&lt;/p&gt;\n\n&lt;p&gt;Does the fact that I have different sized training sets for each class affect it?&lt;/p&gt;\n\n&lt;p&gt;Cheers&lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "When deciding on the value of a threshold for continuous valued attributes in a decision tree there will be infinitely many thresholds giving the same information gain.\n\nE.g. if class one has attribute values 4 4.5 5 and class two has values 6 9 12 14, any threshold between 5 and 6 will give the same information gain.\n\nMy question is what is the optimum value of the threshold - is it simply 5.5 since this puts it equidistant from the nearest two neighbours? Or is it closer towards 6 since class one has more values of attributes closer to the boundary?\n\nDoes the fact that I have different sized training sets for each class affect it?\n\nCheers", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Project", "id": "65vv5w", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 1, "report_reasons": null, "author": "Stripes96", "saved": false, "mod_reports": [], "name": "t3_65vv5w", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "self.MachineLearning", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "four", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/65vv5w/p_optimal_positioning_of_threshold_in_decision/", "num_reports": null, "locked": false, "stickied": false, "created": 1492468144.0, "url": "https://www.reddit.com/r/MachineLearning/comments/65vv5w/p_optimal_positioning_of_threshold_in_decision/", "author_flair_text": null, "quarantine": false, "title": "[P] Optimal positioning of threshold in decision tree", "created_utc": 1492439344.0, "distinguished": null, "media": null, "upvote_ratio": 0.67, "num_comments": 8, "visited": false, "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": "", "user_reports": [], "id": "dgdkxb6", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Stripes96", "parent_id": "t1_dgdksop", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Good idea - I'll do a trial run of that and see how it turns out!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Good idea - I&amp;#39;ll do a trial run of that and see how it turns out!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdkxb6", "score_hidden": false, "stickied": false, "created": 1492469915.0, "created_utc": 1492441115.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdksop", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "dzyl", "parent_id": "t1_dgdkfhy", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I don't actually know how this is usually done, but an extra step you could take is to fit a slightly more difficult function like a polynomial on the values around the optimal boundary where y is how good you are doing and take the highest point on that approximation, I could imagine this increases generalization.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I don&amp;#39;t actually know how this is usually done, but an extra step you could take is to fit a slightly more difficult function like a polynomial on the values around the optimal boundary where y is how good you are doing and take the highest point on that approximation, I could imagine this increases generalization.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdksop", "score_hidden": false, "stickied": false, "created": 1492469756.0, "created_utc": 1492440956.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 2}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65vv5w", "likes": null, "replies": "", "user_reports": [], "id": "dgev9ju", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Stripes96", "parent_id": "t1_dgea0so", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Multiple splits in the same tree? so one node can be \"is A greater than 7\" and the next can be is \"A greater than 17\"? \n\nOr do you mean only in seperate trees? so I can split once based on A in tree 1, once in tree 2 etc", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Multiple splits in the same tree? so one node can be &amp;quot;is A greater than 7&amp;quot; and the next can be is &amp;quot;A greater than 17&amp;quot;? &lt;/p&gt;\n\n&lt;p&gt;Or do you mean only in seperate trees? so I can split once based on A in tree 1, once in tree 2 etc&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgev9ju", "score_hidden": false, "stickied": false, "created": 1492532026.0, "created_utc": 1492503226.0, "depth": 5, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgea0so", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "micro_cam", "parent_id": "t1_dgds9lk", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "In a random forest you definetly want to allow multiple splits on each attribute. This will let it approximate smooth functions better.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;In a random forest you definetly want to allow multiple splits on each attribute. This will let it approximate smooth functions better.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgea0so", "score_hidden": false, "stickied": false, "created": 1492498982.0, "created_utc": 1492470182.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgds9lk", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Stripes96", "parent_id": "t1_dgdnhi8", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Fair point - I'm planning on doing this so duly noted. Final question, if I make a decision based on an feature - e.g. \"is value A over 27\", is there any reason to keep/discard value A for use later. I would be OK to make another decision later such as \"is value A over 19\" ? I only ask because a lot of implementations discard attributes when they've been used, but since I'm using thresholds which can vary, I wouldn't be asking the same question again\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Fair point - I&amp;#39;m planning on doing this so duly noted. Final question, if I make a decision based on an feature - e.g. &amp;quot;is value A over 27&amp;quot;, is there any reason to keep/discard value A for use later. I would be OK to make another decision later such as &amp;quot;is value A over 19&amp;quot; ? I only ask because a lot of implementations discard attributes when they&amp;#39;ve been used, but since I&amp;#39;m using thresholds which can vary, I wouldn&amp;#39;t be asking the same question again&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgds9lk", "score_hidden": false, "stickied": false, "created": 1492478310.0, "created_utc": 1492449510.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdnhi8", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "beamsearch", "parent_id": "t1_dgdkfhy", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "It's important to keep in mind that if you're doing this inside of a random forest, it's probably not an issue. Since you drop observations as part of the bagging procedure, then in *expectation* you're probably producing a quasi-optimal threshold. Hand-waving away the fact that all of the trees in the forest are going to look slightly different, averaging over all of the different thresholds will make picking the exact right threshold in any given tree unimportant, and may even make out of sample performance worse.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;It&amp;#39;s important to keep in mind that if you&amp;#39;re doing this inside of a random forest, it&amp;#39;s probably not an issue. Since you drop observations as part of the bagging procedure, then in &lt;em&gt;expectation&lt;/em&gt; you&amp;#39;re probably producing a quasi-optimal threshold. Hand-waving away the fact that all of the trees in the forest are going to look slightly different, averaging over all of the different thresholds will make picking the exact right threshold in any given tree unimportant, and may even make out of sample performance worse.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdnhi8", "score_hidden": false, "stickied": false, "created": 1492472955.0, "created_utc": 1492444155.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdkfhy", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Stripes96", "parent_id": "t1_dgdk8fa", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Ah I see - well if that's the general approach then simply putting the threshold halfway between my two nearest values would be an improvement, even if not optimal!\n\nThanks for the quick response!", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Ah I see - well if that&amp;#39;s the general approach then simply putting the threshold halfway between my two nearest values would be an improvement, even if not optimal!&lt;/p&gt;\n\n&lt;p&gt;Thanks for the quick response!&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdkfhy", "score_hidden": false, "stickied": false, "created": 1492469291.0, "created_utc": 1492440491.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdk8fa", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "beamsearch", "parent_id": "t3_65vv5w", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "I think typically you choose one of the *actual* values as your threshold (e.g. &gt; 5 in your case), but this is just an implementation choice to limit the number of values you must consider.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;I think typically you choose one of the &lt;em&gt;actual&lt;/em&gt; values as your threshold (e.g. &amp;gt; 5 in your case), but this is just an implementation choice to limit the number of values you must consider.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdk8fa", "score_hidden": false, "stickied": false, "created": 1492469038.0, "created_utc": 1492440238.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}]