[{"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t3", "data": {"contest_mode": false, "banned_by": null, "media_embed": {}, "subreddit": "MachineLearning", "selftext_html": "&lt;!-- SC_OFF --&gt;&lt;div class=\"md\"&gt;&lt;p&gt;I am working on a denoising autoencoder and my very first problem is that every paper I&amp;#39;ve looked at so far does not provide any kind of measure to compare against. For example, if you have a classifier, you can compare classification accuracy, but with denoising autoencoders I found exactly nothing. &lt;/p&gt;\n\n&lt;p&gt;Does anyone know what measures are used for benchmarking a denoising autoencoder? Also do you have a recent paper that provides such a measure to test against? &lt;/p&gt;\n&lt;/div&gt;&lt;!-- SC_ON --&gt;", "selftext": "I am working on a denoising autoencoder and my very first problem is that every paper I've looked at so far does not provide any kind of measure to compare against. For example, if you have a classifier, you can compare classification accuracy, but with denoising autoencoders I found exactly nothing. \n\nDoes anyone know what measures are used for benchmarking a denoising autoencoder? Also do you have a recent paper that provides such a measure to test against? ", "likes": null, "suggested_sort": null, "user_reports": [], "secure_media": null, "link_flair_text": "Project", "id": "65wnp1", "gilded": 0, "secure_media_embed": {}, "clicked": false, "score": 1, "report_reasons": null, "author": "hyperqube12", "saved": false, "mod_reports": [], "name": "t3_65wnp1", "subreddit_name_prefixed": "r/MachineLearning", "approved_by": null, "over_18": false, "domain": "self.MachineLearning", "hidden": false, "thumbnail": "self", "subreddit_id": "t5_2r3gv", "edited": false, "link_flair_css_class": "four", "author_flair_css_class": null, "downs": 0, "brand_safe": true, "archived": false, "removal_reason": null, "is_self": true, "hide_score": false, "spoiler": false, "permalink": "/r/MachineLearning/comments/65wnp1/p_benchmarking_a_denoising_autoencoder/", "num_reports": null, "locked": false, "stickied": false, "created": 1492475868.0, "url": "https://www.reddit.com/r/MachineLearning/comments/65wnp1/p_benchmarking_a_denoising_autoencoder/", "author_flair_text": null, "quarantine": false, "title": "[P] Benchmarking a denoising autoencoder.", "created_utc": 1492447068.0, "distinguished": null, "media": null, "upvote_ratio": 1.0, "num_comments": 8, "visited": false, "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": "", "user_reports": [], "id": "dgdszpk", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "hyperqube12", "parent_id": "t1_dgdsh00", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "The problem is I still have no source to benchmark against, even by reading through that discussion. Hence, my question here. Can you provide one single paper I could benchmark a DAE against? ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;The problem is I still have no source to benchmark against, even by reading through that discussion. Hence, my question here. Can you provide one single paper I could benchmark a DAE against? &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdszpk", "score_hidden": false, "stickied": false, "created": 1492479119.0, "created_utc": 1492450319.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgdsh00", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "ajmooch", "parent_id": "t3_65wnp1", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "See this [previous discussion](https://www.reddit.com/r/MLQuestions/comments/63knpk/benchmarking_a_denoising_autoencoder_on_cifar10/).", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;See this &lt;a href=\"https://www.reddit.com/r/MLQuestions/comments/63knpk/benchmarking_a_denoising_autoencoder_on_cifar10/\"&gt;previous discussion&lt;/a&gt;.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgdsh00", "score_hidden": false, "stickied": false, "created": 1492478539.0, "created_utc": 1492449739.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": {"kind": "Listing", "data": {"modhash": "", "children": [{"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": "", "user_reports": [], "id": "dgesn49", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "rui_", "parent_id": "t1_dges0kg", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Gotcha. I agree. In general, simply checking the reconstruction loss is not a meaningful metric.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Gotcha. I agree. In general, simply checking the reconstruction loss is not a meaningful metric.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgesn49", "score_hidden": false, "stickied": false, "created": 1492524811.0, "created_utc": 1492496011.0, "depth": 4, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dges0kg", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "aviniumau", "parent_id": "t1_dgeqpa6", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "&gt; But aren't you adding noise? Denoising a noisy image is not as trivial as learning an identity function. If you look at the ladder network, a denoising-based approach can learn useful representations.\n\nOh, I'm definitely not saying that a DAE doesn't learn good latent representations, just that reconstruction error doesn't seem to be a useful benchmark for how \"good\" they are. The \"zero-error\" autoencoder was just a hypothetical that would obliterate the benchmark, but perform poorly on the underlying task.\n", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;But aren&amp;#39;t you adding noise? Denoising a noisy image is not as trivial as learning an identity function. If you look at the ladder network, a denoising-based approach can learn useful representations.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;Oh, I&amp;#39;m definitely not saying that a DAE doesn&amp;#39;t learn good latent representations, just that reconstruction error doesn&amp;#39;t seem to be a useful benchmark for how &amp;quot;good&amp;quot; they are. The &amp;quot;zero-error&amp;quot; autoencoder was just a hypothetical that would obliterate the benchmark, but perform poorly on the underlying task.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dges0kg", "score_hidden": false, "stickied": false, "created": 1492523430.0, "created_utc": 1492494630.0, "depth": 3, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgeqpa6", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "rui_", "parent_id": "t1_dgeoq5c", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "&gt; I don't think the \"denoising\", in and of itself (i.e. reconstruction error) is really relevant, because the error could be reduced to zero by simply widening the autoencoder and copying input to output.\n\nBut aren't you adding noise? Denoising a noisy image is not as trivial as learning an identity function. If you look at the [ladder network](https://arxiv.org/abs/1507.02672), a denoising-based approach can learn useful representations.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;blockquote&gt;\n&lt;p&gt;I don&amp;#39;t think the &amp;quot;denoising&amp;quot;, in and of itself (i.e. reconstruction error) is really relevant, because the error could be reduced to zero by simply widening the autoencoder and copying input to output.&lt;/p&gt;\n&lt;/blockquote&gt;\n\n&lt;p&gt;But aren&amp;#39;t you adding noise? Denoising a noisy image is not as trivial as learning an identity function. If you look at the &lt;a href=\"https://arxiv.org/abs/1507.02672\"&gt;ladder network&lt;/a&gt;, a denoising-based approach can learn useful representations.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgeqpa6", "score_hidden": false, "stickied": false, "created": 1492520984.0, "created_utc": 1492492184.0, "depth": 2, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}, "user_reports": [], "id": "dgeoq5c", "gilded": 0, "archived": false, "score": 2, "report_reasons": null, "author": "aviniumau", "parent_id": "t1_dge2ny1", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Doesn't it really only make sense to look at the relative improvement in the accuracy of the underlying task that you're feeding into - e.g. test error on CIFAR without DAE vs with DAE?\n\nI don't think the \"denoising\", in and of itself (i.e. reconstruction error) is really relevant, because the error could be reduced to zero by simply widening the autoencoder and copying input to output. You've suddenly got perfect zero-error encoding, but that doesn't achieve anything for the underlying task at hand.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Doesn&amp;#39;t it really only make sense to look at the relative improvement in the accuracy of the underlying task that you&amp;#39;re feeding into - e.g. test error on CIFAR without DAE vs with DAE?&lt;/p&gt;\n\n&lt;p&gt;I don&amp;#39;t think the &amp;quot;denoising&amp;quot;, in and of itself (i.e. reconstruction error) is really relevant, because the error could be reduced to zero by simply widening the autoencoder and copying input to output. You&amp;#39;ve suddenly got perfect zero-error encoding, but that doesn&amp;#39;t achieve anything for the underlying task at hand.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgeoq5c", "score_hidden": false, "stickied": false, "created": 1492517795.0, "created_utc": 1492488995.0, "depth": 1, "mod_reports": [], "subreddit_type": "public", "ups": 2}}], "after": null, "before": null}}, "user_reports": [], "id": "dge2ny1", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "Sigiward", "parent_id": "t3_65wnp1", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "A DAE is in most cases not used to denoise, but rather used to learn a latent representation of some distribution, to then be used for some other task. Since we are only able to evaluate the quality of a learned latent representation with respect to some task you will only find task-specific benchmarks, such as classification as you pointed out.", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;A DAE is in most cases not used to denoise, but rather used to learn a latent representation of some distribution, to then be used for some other task. Since we are only able to evaluate the quality of a learned latent representation with respect to some task you will only find task-specific benchmarks, such as classification as you pointed out.&lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dge2ny1", "score_hidden": false, "stickied": false, "created": 1492489961.0, "created_utc": 1492461161.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}, {"kind": "t1", "data": {"subreddit_id": "t5_2r3gv", "removal_reason": null, "link_id": "t3_65wnp1", "likes": null, "replies": "", "user_reports": [], "id": "dgeu9g3", "gilded": 0, "archived": false, "score": 1, "report_reasons": null, "author": "lysecret", "parent_id": "t3_65wnp1", "subreddit_name_prefixed": "r/MachineLearning", "controversiality": 0, "body": "Reconstruction error. ", "edited": false, "downs": 0, "body_html": "&lt;div class=\"md\"&gt;&lt;p&gt;Reconstruction error. &lt;/p&gt;\n&lt;/div&gt;", "subreddit": "MachineLearning", "name": "t1_dgeu9g3", "score_hidden": false, "stickied": false, "created": 1492528977.0, "created_utc": 1492500177.0, "depth": 0, "mod_reports": [], "subreddit_type": "public", "ups": 1}}], "after": null, "before": null}}]